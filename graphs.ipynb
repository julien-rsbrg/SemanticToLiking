{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.nn\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from examples.introduction.my_GAT_implem import GNN_naive_framework\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/paired_data_newSim.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_pair</th>\n",
       "      <th>rated_similarity</th>\n",
       "      <th>abs_liking_diference</th>\n",
       "      <th>word1_liking</th>\n",
       "      <th>word2_liking</th>\n",
       "      <th>word1_experience</th>\n",
       "      <th>word2_experience</th>\n",
       "      <th>depression</th>\n",
       "      <th>depressionCont</th>\n",
       "      <th>female</th>\n",
       "      <th>age</th>\n",
       "      <th>participant</th>\n",
       "      <th>senenceBERT_mpnet_similarity</th>\n",
       "      <th>senenceBERT_miniLM_similarity</th>\n",
       "      <th>sense2vec_similarity</th>\n",
       "      <th>gptLarge_similarity</th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Art gallery. Autobiography book.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375817</td>\n",
       "      <td>0.275882</td>\n",
       "      <td>0.337977</td>\n",
       "      <td>0.671500</td>\n",
       "      <td>Art gallery</td>\n",
       "      <td>Autobiography book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Art gallery. Baking cookies.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59</td>\n",
       "      <td>21</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246449</td>\n",
       "      <td>0.146930</td>\n",
       "      <td>0.209372</td>\n",
       "      <td>0.593072</td>\n",
       "      <td>Art gallery</td>\n",
       "      <td>Baking cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Art gallery. Board games.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347372</td>\n",
       "      <td>0.224889</td>\n",
       "      <td>0.227290</td>\n",
       "      <td>0.726036</td>\n",
       "      <td>Art gallery</td>\n",
       "      <td>Board games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Art gallery. Book club.</td>\n",
       "      <td>52.0</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.390099</td>\n",
       "      <td>0.335998</td>\n",
       "      <td>0.307647</td>\n",
       "      <td>0.792389</td>\n",
       "      <td>Art gallery</td>\n",
       "      <td>Book club</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Art gallery. Bread making.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270840</td>\n",
       "      <td>0.197813</td>\n",
       "      <td>0.225336</td>\n",
       "      <td>0.623973</td>\n",
       "      <td>Art gallery</td>\n",
       "      <td>Bread making</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          word_pair  rated_similarity  abs_liking_diference  \\\n",
       "0  Art gallery. Autobiography book.               NaN                     0   \n",
       "1      Art gallery. Baking cookies.               NaN                    59   \n",
       "2         Art gallery. Board games.               NaN                    57   \n",
       "3           Art gallery. Book club.              52.0                    38   \n",
       "4        Art gallery. Bread making.               NaN                    54   \n",
       "\n",
       "   word1_liking  word2_liking  word1_experience  word2_experience  depression  \\\n",
       "0            21            21                 6                 8           0   \n",
       "1            21            80                 6                14           0   \n",
       "2            21            78                 6                94           0   \n",
       "3            21            59                 6                 0           0   \n",
       "4            21            75                 6                16           0   \n",
       "\n",
       "   depressionCont  female  age  participant  senenceBERT_mpnet_similarity  \\\n",
       "0              12       1   29            1                      0.375817   \n",
       "1              12       1   29            1                      0.246449   \n",
       "2              12       1   29            1                      0.347372   \n",
       "3              12       1   29            1                      0.390099   \n",
       "4              12       1   29            1                      0.270840   \n",
       "\n",
       "   senenceBERT_miniLM_similarity  sense2vec_similarity  gptLarge_similarity  \\\n",
       "0                       0.275882              0.337977             0.671500   \n",
       "1                       0.146930              0.209372             0.593072   \n",
       "2                       0.224889              0.227290             0.726036   \n",
       "3                       0.335998              0.307647             0.792389   \n",
       "4                       0.197813              0.225336             0.623973   \n",
       "\n",
       "         word1               word2  \n",
       "0  Art gallery  Autobiography book  \n",
       "1  Art gallery      Baking cookies  \n",
       "2  Art gallery         Board games  \n",
       "3  Art gallery           Book club  \n",
       "4  Art gallery        Bread making  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_temp = data[\"word_pair\"].str.split(\".\")\n",
    "data[\"word1\"] = _temp.apply(func=lambda x: x[0])\n",
    "data[\"word2\"] = _temp.apply(func=lambda x: x[1][1:])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edges of the word pairs are labelled in `word_pair`. We have the `rated_similarity` variable given by the participant with id stored in `participant`. Some similarity measures are given from different LLMs and stored under:\n",
    "- `senenceBERT_mpnet_similarity`,\n",
    "- `senenceBERT_miniLM_similarity`,\n",
    "- `sense2vec_similarity`,\n",
    "- `gptLarge_similarity`.\n",
    "\n",
    "For the edges, added to these similarity measures, we have the `abs_liking_difference` computed from `word1_liking` and `word2_liking`. The experience for the two words are stored in `word1_experience` and `word2_experience`. \n",
    "\n",
    "Depending directly on the participant, we have his/her `age`, gender under `female` (1 for female), and `depression` and `depressionCont` scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_node_table(complete_data_table:pd.DataFrame,\n",
    "                     feature_names:list[str]) -> pd.DataFrame:\n",
    "    \n",
    "    word1_feature_names = [\"word1_%s\"%fname for fname in feature_names]\n",
    "    extracted_features_word1 = complete_data_table[[\"word1\"]+word1_feature_names]\n",
    "    col_renaming = {\"word1\":\"word\"}\n",
    "    col_renaming.update({word1_feature_names[i]:feature_names[i] for i in range(len(feature_names))})\n",
    "    extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
    "\n",
    "    # in case the complete_data_table doesn't contain an undirected graph\n",
    "    word2_feature_names = [\"word2_%s\"%fname for fname in feature_names]\n",
    "    extracted_features_word2 = complete_data_table[[\"word2\"]+word2_feature_names]\n",
    "    col_renaming = {\"word2\":\"word\"}\n",
    "    col_renaming.update({word2_feature_names[i]:feature_names[i] for i in range(len(feature_names))})\n",
    "    extracted_features_word2.rename(columns=col_renaming,inplace=True)\n",
    "\n",
    "    node_data_table = pd.concat([extracted_features_word1,extracted_features_word2],axis=0)\n",
    "\n",
    "    node_data_table.drop_duplicates(subset=[\"word\"],keep=\"first\",inplace=True)\n",
    "    node_data_table.reset_index(inplace=True,drop=True)\n",
    "    return node_data_table\n",
    "\n",
    "\n",
    "\n",
    "def get_translater_index_to_var(node_table:pd.DataFrame,var_name:str) -> dict:\n",
    "    translater_index_to_var = {}\n",
    "    for v, i in enumerate(node_table[var_name]):\n",
    "        translater_index_to_var[i] = v\n",
    "    return translater_index_to_var\n",
    "\n",
    "\n",
    "\n",
    "def build_edge_table(complete_data_table:pd.DataFrame,\n",
    "                     translater_word_to_index:dict,\n",
    "                     edge_attr_names:list[str]) -> Tuple[pd.DataFrame,dict]:\n",
    "    \n",
    "    complete_data_table[\"word1_index\"] = complete_data_table[\"word1\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
    "    complete_data_table[\"word2_index\"] = complete_data_table[\"word2\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
    "\n",
    "    edge_table = complete_data_table[[\"word1_index\",\"word2_index\"] + edge_attr_names]\n",
    "\n",
    "    return edge_table\n",
    "\n",
    "\n",
    "\n",
    "def convert_table_to_graph(\n",
    "        complete_data_table:pd.DataFrame,\n",
    "        node_attr_names:list[str],\n",
    "        edge_attr_names:list[str],\n",
    "        node_label_names:list[str] = None) -> Data:\n",
    "    \n",
    "    node_table = build_node_table(complete_data_table=complete_data_table,\n",
    "                                  feature_names=node_attr_names)\n",
    "    node_attr = node_table[node_attr_names].values\n",
    "    node_attr = torch.Tensor(node_attr)\n",
    "\n",
    "    translater_word_to_index = get_translater_index_to_var(node_table=node_table,var_name=\"word\")\n",
    "    edge_table = build_edge_table(complete_data_table = complete_data_table,\n",
    "                                  translater_word_to_index = translater_word_to_index,\n",
    "                                  edge_attr_names=edge_attr_names)\n",
    "    \n",
    "    edge_index = edge_table[[\"word1_index\",\"word2_index\"]]\n",
    "    edge_index = torch.Tensor(edge_index.to_numpy()).to(torch.int64)\n",
    "    edge_index = edge_index.T\n",
    "    reversed_edge_index = edge_index[[1,0],:]\n",
    "    edge_index = torch.concat([edge_index,reversed_edge_index],dim=1)\n",
    "\n",
    "    edge_attr = edge_table[edge_attr_names].values # n edges, n edge attr \n",
    "    edge_attr = torch.Tensor(edge_attr)\n",
    "    edge_attr = torch.concat([edge_attr,edge_attr],dim=0)\n",
    "\n",
    "    node_train_mask = torch.ones(len(node_attr),dtype=torch.bool)\n",
    "\n",
    "    node_labels = None\n",
    "    if not(node_label_names is None):\n",
    "        node_labels = node_table[node_label_names].values\n",
    "        node_labels = torch.Tensor(node_labels)\n",
    "\n",
    "    data_graph = Data(\n",
    "        x = node_attr, \n",
    "        edge_index = edge_index,\n",
    "        edge_attr = edge_attr,\n",
    "        y = node_labels, \n",
    "        train_mask = torch.Tensor(node_train_mask), \n",
    "        val_mask = torch.Tensor(~node_train_mask)\n",
    "        )\n",
    "\n",
    "    def test_function(data_graph:Data):\n",
    "        print(\"Test function convert_table_to_graph\")\n",
    "        print(data_graph)\n",
    "        print(\"validate:\",data_graph.validate())\n",
    "        print(\"is undirected:\", data_graph.is_undirected())\n",
    "\n",
    "        has_self_loop = min(abs(data_graph.edge_index[0]-data_graph.edge_index[1])) < 1\n",
    "        print(\"has_self_loop:\",has_self_loop)\n",
    "        print(\"end Test function convert_table_to_graph\")\n",
    "    \n",
    "    test_function(data_graph)\n",
    "    return data_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word_pair', 'rated_similarity', 'abs_liking_diference', 'word1_liking',\n",
       "       'word2_liking', 'word1_experience', 'word2_experience', 'depression',\n",
       "       'depressionCont', 'female', 'age', 'participant',\n",
       "       'senenceBERT_mpnet_similarity', 'senenceBERT_miniLM_similarity',\n",
       "       'sense2vec_similarity', 'gptLarge_similarity', 'word1', 'word2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1_sc_liking</th>\n",
       "      <th>word2_sc_liking</th>\n",
       "      <th>sc_senenceBERT_mpnet_similarity</th>\n",
       "      <th>sc_depressionCont</th>\n",
       "      <th>sc_NoExp_Exp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.172222</td>\n",
       "      <td>-1.152427</td>\n",
       "      <td>1.118413</td>\n",
       "      <td>-0.229448</td>\n",
       "      <td>-0.891164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.172222</td>\n",
       "      <td>0.605846</td>\n",
       "      <td>-0.021906</td>\n",
       "      <td>-0.229448</td>\n",
       "      <td>-0.891164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.172222</td>\n",
       "      <td>0.546244</td>\n",
       "      <td>0.867681</td>\n",
       "      <td>-0.229448</td>\n",
       "      <td>1.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.172222</td>\n",
       "      <td>-0.019980</td>\n",
       "      <td>1.244298</td>\n",
       "      <td>-0.229448</td>\n",
       "      <td>-0.891164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.172222</td>\n",
       "      <td>0.456840</td>\n",
       "      <td>0.193088</td>\n",
       "      <td>-0.229448</td>\n",
       "      <td>-0.891164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198235</th>\n",
       "      <td>0.456083</td>\n",
       "      <td>0.546244</td>\n",
       "      <td>0.040509</td>\n",
       "      <td>-0.708297</td>\n",
       "      <td>1.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198236</th>\n",
       "      <td>0.456083</td>\n",
       "      <td>1.201871</td>\n",
       "      <td>-0.668605</td>\n",
       "      <td>-0.708297</td>\n",
       "      <td>1.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198237</th>\n",
       "      <td>0.394638</td>\n",
       "      <td>0.546244</td>\n",
       "      <td>-1.800021</td>\n",
       "      <td>-0.708297</td>\n",
       "      <td>1.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198238</th>\n",
       "      <td>0.394638</td>\n",
       "      <td>1.201871</td>\n",
       "      <td>-0.165669</td>\n",
       "      <td>-0.708297</td>\n",
       "      <td>1.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198239</th>\n",
       "      <td>0.578974</td>\n",
       "      <td>1.201871</td>\n",
       "      <td>0.032073</td>\n",
       "      <td>-0.708297</td>\n",
       "      <td>-0.891164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198240 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word1_sc_liking  word2_sc_liking  sc_senenceBERT_mpnet_similarity  \\\n",
       "0             -1.172222        -1.152427                         1.118413   \n",
       "1             -1.172222         0.605846                        -0.021906   \n",
       "2             -1.172222         0.546244                         0.867681   \n",
       "3             -1.172222        -0.019980                         1.244298   \n",
       "4             -1.172222         0.456840                         0.193088   \n",
       "...                 ...              ...                              ...   \n",
       "198235         0.456083         0.546244                         0.040509   \n",
       "198236         0.456083         1.201871                        -0.668605   \n",
       "198237         0.394638         0.546244                        -1.800021   \n",
       "198238         0.394638         1.201871                        -0.165669   \n",
       "198239         0.578974         1.201871                         0.032073   \n",
       "\n",
       "        sc_depressionCont  sc_NoExp_Exp  \n",
       "0               -0.229448     -0.891164  \n",
       "1               -0.229448     -0.891164  \n",
       "2               -0.229448      1.122128  \n",
       "3               -0.229448     -0.891164  \n",
       "4               -0.229448     -0.891164  \n",
       "...                   ...           ...  \n",
       "198235          -0.708297      1.122128  \n",
       "198236          -0.708297      1.122128  \n",
       "198237          -0.708297      1.122128  \n",
       "198238          -0.708297      1.122128  \n",
       "198239          -0.708297     -0.891164  \n",
       "\n",
       "[198240 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def nor_function(a,b):\n",
    "    return (a or b) and not(a and b)\n",
    "\n",
    "data[\"NoExp_Exp\"] = data.apply(lambda row: nor_function(row[\"word1_experience\"]>50,row[\"word2_experience\"]>50),axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.loc[:,[\"word1_sc_liking\",\"word2_sc_liking\",\"sc_senenceBERT_mpnet_similarity\",\"sc_depressionCont\",\"sc_NoExp_Exp\"]] = scaler.fit_transform(data.loc[:,[\"word1_liking\",\"word2_liking\",\"senenceBERT_mpnet_similarity\",\"depressionCont\",\"NoExp_Exp\"]])\n",
    "data.loc[:,[\"word1_sc_liking\",\"word2_sc_liking\",\"sc_senenceBERT_mpnet_similarity\",\"sc_depressionCont\",\"sc_NoExp_Exp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test function convert_table_to_graph\n",
      "Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "validate: True\n",
      "is undirected: True\n",
      "has_self_loop: tensor(False)\n",
      "end Test function convert_table_to_graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6355/3484179637.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/tmp/ipykernel_6355/3484179637.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n",
      "/tmp/ipykernel_6355/3484179637.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word1_index\"] = complete_data_table[\"word1\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/tmp/ipykernel_6355/3484179637.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word2_index\"] = complete_data_table[\"word2\"].apply(lambda single_word: translater_word_to_index[single_word])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1722],\n",
       "        [-1.1722],\n",
       "        [ 0.6404],\n",
       "        [ 0.5790],\n",
       "        [-0.0048],\n",
       "        [ 0.4868],\n",
       "        [ 0.8862],\n",
       "        [ 0.9476],\n",
       "        [ 0.8862],\n",
       "        [ 0.7940],\n",
       "        [-1.6023],\n",
       "        [-0.9264],\n",
       "        [ 0.5483],\n",
       "        [-0.1891],\n",
       "        [ 0.9169],\n",
       "        [-0.1891],\n",
       "        [ 0.5483],\n",
       "        [-0.6499],\n",
       "        [-0.2813],\n",
       "        [ 0.8555],\n",
       "        [ 0.7326],\n",
       "        [ 0.7633],\n",
       "        [ 1.2549],\n",
       "        [ 1.2549],\n",
       "        [ 1.0705],\n",
       "        [-0.2813],\n",
       "        [-1.2029],\n",
       "        [ 1.0705],\n",
       "        [-1.4180],\n",
       "        [ 0.9476],\n",
       "        [-1.2951],\n",
       "        [ 0.5483],\n",
       "        [-0.1891],\n",
       "        [ 0.7326],\n",
       "        [ 0.5175],\n",
       "        [ 1.2549],\n",
       "        [ 0.7326],\n",
       "        [-0.7421],\n",
       "        [-0.0969],\n",
       "        [-1.0801],\n",
       "        [-1.1415],\n",
       "        [ 0.9476],\n",
       "        [-0.9264],\n",
       "        [ 0.6097],\n",
       "        [ 1.2549],\n",
       "        [-1.6331],\n",
       "        [ 0.0874],\n",
       "        [-0.4042],\n",
       "        [-1.2951],\n",
       "        [ 1.0091],\n",
       "        [-0.4042],\n",
       "        [-0.5885],\n",
       "        [-1.5409],\n",
       "        [ 0.6097],\n",
       "        [-1.4180],\n",
       "        [ 0.4254],\n",
       "        [-0.4349],\n",
       "        [ 0.4254],\n",
       "        [ 1.2549],\n",
       "        [ 1.2019]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdata = data[data[\"participant\"] == 1]\n",
    "\n",
    "\n",
    "participant_graph = convert_table_to_graph(\n",
    "    complete_data_table=subdata,\n",
    "    node_attr_names=[\"sc_liking\"],\n",
    "    node_label_names=[\"sc_liking\"],\n",
    "    edge_attr_names=[\"senenceBERT_mpnet_similarity\"])\n",
    "\n",
    "participant_graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module = torch_geometric.nn.GATConv(\n",
    "    in_channels=(1,1),\n",
    "    out_channels=1,\n",
    "    heads=1,\n",
    "    negative_slope=1.0,\n",
    "    add_self_loops=False,\n",
    "    edge_dim=1)\n",
    "# my_module(x=participant_graph.x,edge_index=participant_graph.edge_index,edge_attr=participant_graph.edge_attr)\n",
    "\n",
    "complete_model = GNN_naive_framework(my_module,device)\n",
    "opt = complete_model.configure_optimizer(lr=1)\n",
    "scheduler = complete_model.configure_scheduler(opt,1,1,10)\n",
    "\n",
    "participant_graph_batch_0 = Data(x=participant_graph.x[:30],\n",
    "                                 y=participant_graph.x[:30], \n",
    "                                 train_mask = torch.ones(30), \n",
    "                                 edge_index=torch.Tensor([[]]),\n",
    "                                 edge_attr=torch.Tensor([[]]))\n",
    "\n",
    "participant_graph_batch_1 = Data(x=participant_graph.x[30:],\n",
    "                                 y=participant_graph.x[30:], \n",
    "                                 train_mask = torch.ones(30), \n",
    "                                 edge_index=torch.Tensor([[]]),\n",
    "                                 edge_attr=torch.Tensor([[]]))\n",
    "\n",
    "complete_model.train([participant_graph_batch_0,participant_graph_batch_1],10000,1,opt,scheduler,\"train_loss\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2811],\n",
      "        [ 0.1155],\n",
      "        [-0.0220],\n",
      "        [ 0.8436],\n",
      "        [-0.8993]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.8685,  0.5401, -0.8751, -0.3842, -0.5133], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.4244, -0.1107,  0.1504,  0.2150,  0.3811]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0135], requires_grad=True)]\n",
      "== start training ==\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[0.5445],\n",
      "        [0.5445],\n",
      "        [0.5116],\n",
      "        [0.5116],\n",
      "        [0.5166],\n",
      "        [0.5119],\n",
      "        [0.5122],\n",
      "        [0.5125],\n",
      "        [0.5122],\n",
      "        [0.5118],\n",
      "        [0.5550],\n",
      "        [0.5379],\n",
      "        [0.5117],\n",
      "        [0.5199],\n",
      "        [0.5124],\n",
      "        [0.5199],\n",
      "        [0.5117],\n",
      "        [0.5305],\n",
      "        [0.5217],\n",
      "        [0.5120],\n",
      "        [0.5116],\n",
      "        [0.5117],\n",
      "        [0.5153],\n",
      "        [0.5153],\n",
      "        [0.5135],\n",
      "        [0.5217],\n",
      "        [0.5453],\n",
      "        [0.5135],\n",
      "        [0.5508],\n",
      "        [0.5125],\n",
      "        [0.5477],\n",
      "        [0.5117],\n",
      "        [0.5199],\n",
      "        [0.5116],\n",
      "        [0.5118],\n",
      "        [0.5153],\n",
      "        [0.5116],\n",
      "        [0.5329],\n",
      "        [0.5182],\n",
      "        [0.5420],\n",
      "        [0.5437],\n",
      "        [0.5125],\n",
      "        [0.5379],\n",
      "        [0.5116],\n",
      "        [0.5153],\n",
      "        [0.5557],\n",
      "        [0.5153],\n",
      "        [0.5244],\n",
      "        [0.5477],\n",
      "        [0.5130],\n",
      "        [0.5244],\n",
      "        [0.5289],\n",
      "        [0.5536],\n",
      "        [0.5116],\n",
      "        [0.5508],\n",
      "        [0.5121],\n",
      "        [0.5251],\n",
      "        [0.5121],\n",
      "        [0.5153],\n",
      "        [0.5147]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 1/10000,\n",
      " train_loss: 1.0531,\n",
      " train_mae: 2.7359,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-2.2755],\n",
      "        [-2.2755],\n",
      "        [-2.8357],\n",
      "        [-2.8062],\n",
      "        [-2.5501],\n",
      "        [-2.7623],\n",
      "        [-2.9520],\n",
      "        [-2.9799],\n",
      "        [-2.9520],\n",
      "        [-2.9090],\n",
      "        [-2.2347],\n",
      "        [-2.3099],\n",
      "        [-2.7915],\n",
      "        [-2.4852],\n",
      "        [-2.9661],\n",
      "        [-2.4852],\n",
      "        [-2.7915],\n",
      "        [-2.3613],\n",
      "        [-2.4562],\n",
      "        [-2.9378],\n",
      "        [-2.8798],\n",
      "        [-2.8945],\n",
      "        [-3.1063],\n",
      "        [-3.1063],\n",
      "        [-3.0335],\n",
      "        [-2.4562],\n",
      "        [-2.2719],\n",
      "        [-3.0335],\n",
      "        [-2.2497],\n",
      "        [-2.9799],\n",
      "        [-2.2617],\n",
      "        [-2.7915],\n",
      "        [-2.4852],\n",
      "        [-2.8798],\n",
      "        [-2.7768],\n",
      "        [-3.1063],\n",
      "        [-2.8798],\n",
      "        [-2.3425],\n",
      "        [-2.5166],\n",
      "        [-2.2873],\n",
      "        [-2.2793],\n",
      "        [-2.9799],\n",
      "        [-2.3099],\n",
      "        [-2.8209],\n",
      "        [-3.1063],\n",
      "        [-2.2325],\n",
      "        [-2.5859],\n",
      "        [-2.4208],\n",
      "        [-2.2617],\n",
      "        [-3.0071],\n",
      "        [-2.4208],\n",
      "        [-2.3749],\n",
      "        [-2.2393],\n",
      "        [-2.8209],\n",
      "        [-2.2497],\n",
      "        [-2.7334],\n",
      "        [-2.4126],\n",
      "        [-2.7334],\n",
      "        [-3.1063],\n",
      "        [-3.0864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 2/10000,\n",
      " train_loss: 8.9467,\n",
      " train_mae: 0.9524,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.8423],\n",
      "        [-0.8423],\n",
      "        [-0.5991],\n",
      "        [-0.6108],\n",
      "        [-0.7197],\n",
      "        [-0.6286],\n",
      "        [-0.5547],\n",
      "        [-0.5445],\n",
      "        [-0.5547],\n",
      "        [-0.5708],\n",
      "        [-0.8601],\n",
      "        [-0.8274],\n",
      "        [-0.6167],\n",
      "        [-0.7489],\n",
      "        [-0.5495],\n",
      "        [-0.7489],\n",
      "        [-0.6167],\n",
      "        [-0.8048],\n",
      "        [-0.7621],\n",
      "        [-0.5600],\n",
      "        [-0.5820],\n",
      "        [-0.5763],\n",
      "        [-0.4999],\n",
      "        [-0.4999],\n",
      "        [-0.5252],\n",
      "        [-0.7621],\n",
      "        [-0.8439],\n",
      "        [-0.5252],\n",
      "        [-0.8535],\n",
      "        [-0.5445],\n",
      "        [-0.8483],\n",
      "        [-0.6167],\n",
      "        [-0.7489],\n",
      "        [-0.5820],\n",
      "        [-0.6227],\n",
      "        [-0.4999],\n",
      "        [-0.5820],\n",
      "        [-0.8131],\n",
      "        [-0.7348],\n",
      "        [-0.8372],\n",
      "        [-0.8407],\n",
      "        [-0.5445],\n",
      "        [-0.8274],\n",
      "        [-0.6050],\n",
      "        [-0.4999],\n",
      "        [-0.8611],\n",
      "        [-0.7038],\n",
      "        [-0.7780],\n",
      "        [-0.8483],\n",
      "        [-0.5346],\n",
      "        [-0.7780],\n",
      "        [-0.7987],\n",
      "        [-0.8580],\n",
      "        [-0.6050],\n",
      "        [-0.8535],\n",
      "        [-0.6405],\n",
      "        [-0.7818],\n",
      "        [-0.6405],\n",
      "        [-0.4999],\n",
      "        [-0.5068]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 3/10000,\n",
      " train_loss: 1.1833,\n",
      " train_mae: 0.7569,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[0.4610],\n",
      "        [0.4610],\n",
      "        [0.5130],\n",
      "        [0.5091],\n",
      "        [0.4893],\n",
      "        [0.5040],\n",
      "        [0.5327],\n",
      "        [0.5385],\n",
      "        [0.5327],\n",
      "        [0.5246],\n",
      "        [0.4458],\n",
      "        [0.4694],\n",
      "        [0.5073],\n",
      "        [0.4866],\n",
      "        [0.5355],\n",
      "        [0.4866],\n",
      "        [0.5073],\n",
      "        [0.4776],\n",
      "        [0.4852],\n",
      "        [0.5299],\n",
      "        [0.5197],\n",
      "        [0.5221],\n",
      "        [0.5729],\n",
      "        [0.5729],\n",
      "        [0.5513],\n",
      "        [0.4852],\n",
      "        [0.4599],\n",
      "        [0.5513],\n",
      "        [0.4523],\n",
      "        [0.5385],\n",
      "        [0.4566],\n",
      "        [0.5073],\n",
      "        [0.4866],\n",
      "        [0.5197],\n",
      "        [0.5056],\n",
      "        [0.5729],\n",
      "        [0.5197],\n",
      "        [0.4750],\n",
      "        [0.4879],\n",
      "        [0.4642],\n",
      "        [0.4621],\n",
      "        [0.5385],\n",
      "        [0.4694],\n",
      "        [0.5110],\n",
      "        [0.5729],\n",
      "        [0.4448],\n",
      "        [0.4909],\n",
      "        [0.4831],\n",
      "        [0.4566],\n",
      "        [0.5447],\n",
      "        [0.4831],\n",
      "        [0.4791],\n",
      "        [0.4480],\n",
      "        [0.5110],\n",
      "        [0.4523],\n",
      "        [0.5011],\n",
      "        [0.4825],\n",
      "        [0.5011],\n",
      "        [0.5729],\n",
      "        [0.5664]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 4/10000,\n",
      " train_loss: 0.9495,\n",
      " train_mae: 1.0610,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[1.2474],\n",
      "        [1.2474],\n",
      "        [0.9822],\n",
      "        [0.9831],\n",
      "        [1.0628],\n",
      "        [0.9869],\n",
      "        [0.9895],\n",
      "        [0.9935],\n",
      "        [0.9895],\n",
      "        [0.9849],\n",
      "        [1.2559],\n",
      "        [1.2349],\n",
      "        [0.9840],\n",
      "        [1.1088],\n",
      "        [0.9914],\n",
      "        [1.1088],\n",
      "        [0.9840],\n",
      "        [1.2056],\n",
      "        [1.1319],\n",
      "        [0.9877],\n",
      "        [0.9830],\n",
      "        [0.9838],\n",
      "        [1.0233],\n",
      "        [1.0233],\n",
      "        [1.0037],\n",
      "        [1.1319],\n",
      "        [1.2484],\n",
      "        [1.0037],\n",
      "        [1.2533],\n",
      "        [0.9935],\n",
      "        [1.2508],\n",
      "        [0.9840],\n",
      "        [1.1088],\n",
      "        [0.9830],\n",
      "        [0.9853],\n",
      "        [1.0233],\n",
      "        [0.9830],\n",
      "        [1.2177],\n",
      "        [1.0854],\n",
      "        [1.2437],\n",
      "        [1.2463],\n",
      "        [0.9935],\n",
      "        [1.2349],\n",
      "        [0.9825],\n",
      "        [1.0233],\n",
      "        [1.2563],\n",
      "        [1.0419],\n",
      "        [1.1606],\n",
      "        [1.2508],\n",
      "        [0.9983],\n",
      "        [1.1606],\n",
      "        [1.1961],\n",
      "        [1.2551],\n",
      "        [0.9825],\n",
      "        [1.2533],\n",
      "        [0.9912],\n",
      "        [1.1672],\n",
      "        [0.9912],\n",
      "        [1.0233],\n",
      "        [1.0172]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 5/10000,\n",
      " train_loss: 2.0506,\n",
      " train_mae: 1.1764,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[1.4697],\n",
      "        [1.4697],\n",
      "        [1.0899],\n",
      "        [1.0886],\n",
      "        [1.1641],\n",
      "        [1.0892],\n",
      "        [1.1053],\n",
      "        [1.1112],\n",
      "        [1.1053],\n",
      "        [1.0978],\n",
      "        [1.5021],\n",
      "        [1.4413],\n",
      "        [1.0885],\n",
      "        [1.2263],\n",
      "        [1.1082],\n",
      "        [1.2263],\n",
      "        [1.0885],\n",
      "        [1.3855],\n",
      "        [1.2610],\n",
      "        [1.1026],\n",
      "        [1.0939],\n",
      "        [1.0957],\n",
      "        [1.1500],\n",
      "        [1.1500],\n",
      "        [1.1250],\n",
      "        [1.2610],\n",
      "        [1.4724],\n",
      "        [1.1250],\n",
      "        [1.4890],\n",
      "        [1.1112],\n",
      "        [1.4800],\n",
      "        [1.0885],\n",
      "        [1.2263],\n",
      "        [1.0939],\n",
      "        [1.0887],\n",
      "        [1.1500],\n",
      "        [1.0939],\n",
      "        [1.4078],\n",
      "        [1.1934],\n",
      "        [1.4606],\n",
      "        [1.4668],\n",
      "        [1.1112],\n",
      "        [1.4413],\n",
      "        [1.0891],\n",
      "        [1.1500],\n",
      "        [1.5044],\n",
      "        [1.1393],\n",
      "        [1.3071],\n",
      "        [1.4800],\n",
      "        [1.1178],\n",
      "        [1.3071],\n",
      "        [1.3684],\n",
      "        [1.4978],\n",
      "        [1.0891],\n",
      "        [1.4890],\n",
      "        [1.0915],\n",
      "        [1.3182],\n",
      "        [1.0915],\n",
      "        [1.1500],\n",
      "        [1.1423]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 6/10000,\n",
      " train_loss: 2.4559,\n",
      " train_mae: 1.0496,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[1.2671],\n",
      "        [1.2671],\n",
      "        [0.9757],\n",
      "        [0.9717],\n",
      "        [0.9972],\n",
      "        [0.9675],\n",
      "        [0.9991],\n",
      "        [1.0067],\n",
      "        [0.9991],\n",
      "        [0.9890],\n",
      "        [1.3095],\n",
      "        [1.2360],\n",
      "        [0.9701],\n",
      "        [1.0397],\n",
      "        [1.0028],\n",
      "        [1.0397],\n",
      "        [0.9701],\n",
      "        [1.1793],\n",
      "        [1.0668],\n",
      "        [0.9956],\n",
      "        [0.9831],\n",
      "        [0.9860],\n",
      "        [1.0534],\n",
      "        [1.0534],\n",
      "        [1.0236],\n",
      "        [1.0668],\n",
      "        [1.2703],\n",
      "        [1.0236],\n",
      "        [1.2912],\n",
      "        [1.0067],\n",
      "        [1.2794],\n",
      "        [0.9701],\n",
      "        [1.0397],\n",
      "        [0.9831],\n",
      "        [0.9687],\n",
      "        [1.0534],\n",
      "        [0.9831],\n",
      "        [1.2015],\n",
      "        [1.0163],\n",
      "        [1.2568],\n",
      "        [1.2638],\n",
      "        [1.0067],\n",
      "        [1.2360],\n",
      "        [0.9736],\n",
      "        [1.0534],\n",
      "        [1.3127],\n",
      "        [0.9830],\n",
      "        [1.1059],\n",
      "        [1.2794],\n",
      "        [1.0148],\n",
      "        [1.1059],\n",
      "        [1.1626],\n",
      "        [1.3032],\n",
      "        [0.9736],\n",
      "        [1.2912],\n",
      "        [0.9660],\n",
      "        [1.1158],\n",
      "        [0.9660],\n",
      "        [1.0534],\n",
      "        [1.0443]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 7/10000,\n",
      " train_loss: 2.0469,\n",
      " train_mae: 0.8366,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[0.7982],\n",
      "        [0.7982],\n",
      "        [0.7368],\n",
      "        [0.7314],\n",
      "        [0.7094],\n",
      "        [0.7243],\n",
      "        [0.7641],\n",
      "        [0.7723],\n",
      "        [0.7641],\n",
      "        [0.7527],\n",
      "        [0.8325],\n",
      "        [0.7810],\n",
      "        [0.7289],\n",
      "        [0.7162],\n",
      "        [0.7681],\n",
      "        [0.7162],\n",
      "        [0.7289],\n",
      "        [0.7575],\n",
      "        [0.7225],\n",
      "        [0.7601],\n",
      "        [0.7459],\n",
      "        [0.7493],\n",
      "        [0.8239],\n",
      "        [0.8239],\n",
      "        [0.7909],\n",
      "        [0.7225],\n",
      "        [0.8003],\n",
      "        [0.7909],\n",
      "        [0.8163],\n",
      "        [0.7723],\n",
      "        [0.8069],\n",
      "        [0.7289],\n",
      "        [0.7162],\n",
      "        [0.7459],\n",
      "        [0.7265],\n",
      "        [0.8239],\n",
      "        [0.7459],\n",
      "        [0.7660],\n",
      "        [0.7118],\n",
      "        [0.7919],\n",
      "        [0.7961],\n",
      "        [0.7723],\n",
      "        [0.7810],\n",
      "        [0.7340],\n",
      "        [0.8239],\n",
      "        [0.8356],\n",
      "        [0.7088],\n",
      "        [0.7331],\n",
      "        [0.8069],\n",
      "        [0.7813],\n",
      "        [0.7331],\n",
      "        [0.7514],\n",
      "        [0.8268],\n",
      "        [0.7340],\n",
      "        [0.8163],\n",
      "        [0.7202],\n",
      "        [0.7361],\n",
      "        [0.7202],\n",
      "        [0.8239],\n",
      "        [0.8137]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 8/10000,\n",
      " train_loss: 1.3205,\n",
      " train_mae: 0.6858,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[0.1936],\n",
      "        [0.1936],\n",
      "        [0.4434],\n",
      "        [0.4372],\n",
      "        [0.3832],\n",
      "        [0.4287],\n",
      "        [0.4729],\n",
      "        [0.4819],\n",
      "        [0.4729],\n",
      "        [0.4608],\n",
      "        [0.2071],\n",
      "        [0.2065],\n",
      "        [0.4343],\n",
      "        [0.3560],\n",
      "        [0.4773],\n",
      "        [0.3560],\n",
      "        [0.4343],\n",
      "        [0.2511],\n",
      "        [0.3382],\n",
      "        [0.4687],\n",
      "        [0.4534],\n",
      "        [0.4570],\n",
      "        [0.5390],\n",
      "        [0.5390],\n",
      "        [0.5020],\n",
      "        [0.3382],\n",
      "        [0.1934],\n",
      "        [0.5020],\n",
      "        [0.1974],\n",
      "        [0.4819],\n",
      "        [0.1940],\n",
      "        [0.4343],\n",
      "        [0.3560],\n",
      "        [0.4534],\n",
      "        [0.4315],\n",
      "        [0.5390],\n",
      "        [0.4534],\n",
      "        [0.2325],\n",
      "        [0.3709],\n",
      "        [0.1960],\n",
      "        [0.1942],\n",
      "        [0.4819],\n",
      "        [0.2065],\n",
      "        [0.4403],\n",
      "        [0.5390],\n",
      "        [0.2092],\n",
      "        [0.3935],\n",
      "        [0.3104],\n",
      "        [0.1940],\n",
      "        [0.4915],\n",
      "        [0.3104],\n",
      "        [0.2652],\n",
      "        [0.2033],\n",
      "        [0.4403],\n",
      "        [0.1974],\n",
      "        [0.4233],\n",
      "        [0.3029],\n",
      "        [0.4233],\n",
      "        [0.5390],\n",
      "        [0.5275]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 9/10000,\n",
      " train_loss: 0.7179,\n",
      " train_mae: 0.5996,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.4432],\n",
      "        [-0.4432],\n",
      "        [ 0.1525],\n",
      "        [ 0.1456],\n",
      "        [ 0.0719],\n",
      "        [ 0.1361],\n",
      "        [ 0.1857],\n",
      "        [ 0.1960],\n",
      "        [ 0.1857],\n",
      "        [ 0.1719],\n",
      "        [-0.4565],\n",
      "        [-0.3878],\n",
      "        [ 0.1424],\n",
      "        [ 0.0188],\n",
      "        [ 0.1907],\n",
      "        [ 0.0188],\n",
      "        [ 0.1424],\n",
      "        [-0.2473],\n",
      "        [-0.0202],\n",
      "        [ 0.1809],\n",
      "        [ 0.1636],\n",
      "        [ 0.1677],\n",
      "        [ 0.2648],\n",
      "        [ 0.2648],\n",
      "        [ 0.2197],\n",
      "        [-0.0202],\n",
      "        [-0.4467],\n",
      "        [ 0.2197],\n",
      "        [-0.4582],\n",
      "        [ 0.1960],\n",
      "        [-0.4541],\n",
      "        [ 0.1424],\n",
      "        [ 0.0188],\n",
      "        [ 0.1636],\n",
      "        [ 0.1392],\n",
      "        [ 0.2648],\n",
      "        [ 0.1636],\n",
      "        [-0.3032],\n",
      "        [ 0.0490],\n",
      "        [-0.4288],\n",
      "        [-0.4391],\n",
      "        [ 0.1960],\n",
      "        [-0.3878],\n",
      "        [ 0.1490],\n",
      "        [ 0.2648],\n",
      "        [-0.4555],\n",
      "        [ 0.0893],\n",
      "        [-0.0866],\n",
      "        [-0.4541],\n",
      "        [ 0.2073],\n",
      "        [-0.0866],\n",
      "        [-0.2068],\n",
      "        [-0.4579],\n",
      "        [ 0.1490],\n",
      "        [-0.4582],\n",
      "        [ 0.1299],\n",
      "        [-0.1054],\n",
      "        [ 0.1299],\n",
      "        [ 0.2648],\n",
      "        [ 0.2505]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 10/10000,\n",
      " train_loss: 0.4403,\n",
      " train_mae: 0.5381,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0289],\n",
      "        [-1.0289],\n",
      "        [-0.0850],\n",
      "        [-0.0930],\n",
      "        [-0.1801],\n",
      "        [-0.1042],\n",
      "        [-0.0437],\n",
      "        [-0.0302],\n",
      "        [-0.0437],\n",
      "        [-0.0612],\n",
      "        [-1.0696],\n",
      "        [-0.9238],\n",
      "        [-0.0968],\n",
      "        [-0.2507],\n",
      "        [-0.0371],\n",
      "        [-0.2507],\n",
      "        [-0.0968],\n",
      "        [-0.6710],\n",
      "        [-0.3061],\n",
      "        [-0.0498],\n",
      "        [-0.0714],\n",
      "        [-0.0665],\n",
      "        [ 0.0648],\n",
      "        [ 0.0648],\n",
      "        [ 0.0016],\n",
      "        [-0.3061],\n",
      "        [-1.0360],\n",
      "        [ 0.0016],\n",
      "        [-1.0638],\n",
      "        [-0.0302],\n",
      "        [-1.0519],\n",
      "        [-0.0968],\n",
      "        [-0.2507],\n",
      "        [-0.0714],\n",
      "        [-0.1005],\n",
      "        [ 0.0648],\n",
      "        [-0.0714],\n",
      "        [-0.7697],\n",
      "        [-0.2097],\n",
      "        [-1.0007],\n",
      "        [-1.0207],\n",
      "        [-0.0302],\n",
      "        [-0.9238],\n",
      "        [-0.0891],\n",
      "        [ 0.0648],\n",
      "        [-1.0697],\n",
      "        [-0.1585],\n",
      "        [-0.4059],\n",
      "        [-1.0519],\n",
      "        [-0.0152],\n",
      "        [-0.4059],\n",
      "        [-0.6015],\n",
      "        [-1.0688],\n",
      "        [-0.0891],\n",
      "        [-1.0638],\n",
      "        [-0.1112],\n",
      "        [-0.4354],\n",
      "        [-0.1112],\n",
      "        [ 0.0648],\n",
      "        [ 0.0445]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 11/10000,\n",
      " train_loss: 0.4559,\n",
      " train_mae: 0.6483,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.4994],\n",
      "        [-1.4994],\n",
      "        [-0.2271],\n",
      "        [-0.2379],\n",
      "        [-0.3375],\n",
      "        [-0.2521],\n",
      "        [-0.1673],\n",
      "        [-0.1467],\n",
      "        [-0.1673],\n",
      "        [-0.1935],\n",
      "        [-1.5661],\n",
      "        [-1.3412],\n",
      "        [-0.2428],\n",
      "        [-0.4181],\n",
      "        [-0.1574],\n",
      "        [-0.4181],\n",
      "        [-0.2428],\n",
      "        [-0.9702],\n",
      "        [-0.4845],\n",
      "        [-0.1766],\n",
      "        [-0.2082],\n",
      "        [-0.2011],\n",
      "        [ 0.0092],\n",
      "        [ 0.0092],\n",
      "        [-0.0961],\n",
      "        [-0.4845],\n",
      "        [-1.5102],\n",
      "        [-0.0961],\n",
      "        [-1.5538],\n",
      "        [-0.1467],\n",
      "        [-1.5346],\n",
      "        [-0.2428],\n",
      "        [-0.4181],\n",
      "        [-0.2082],\n",
      "        [-0.2476],\n",
      "        [ 0.0092],\n",
      "        [-0.2082],\n",
      "        [-1.1128],\n",
      "        [-0.3708],\n",
      "        [-1.4569],\n",
      "        [-1.4870],\n",
      "        [-0.1467],\n",
      "        [-1.3412],\n",
      "        [-0.2326],\n",
      "        [ 0.0092],\n",
      "        [-1.5670],\n",
      "        [-0.3137],\n",
      "        [-0.6096],\n",
      "        [-1.5346],\n",
      "        [-0.1231],\n",
      "        [-0.6096],\n",
      "        [-0.8723],\n",
      "        [-1.5635],\n",
      "        [-0.2326],\n",
      "        [-1.5538],\n",
      "        [-0.2608],\n",
      "        [-0.6478],\n",
      "        [-0.2608],\n",
      "        [ 0.0092],\n",
      "        [-0.0252]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 12/10000,\n",
      " train_loss: 0.5793,\n",
      " train_mae: 0.7150,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.8164],\n",
      "        [-1.8164],\n",
      "        [-0.2460],\n",
      "        [-0.2633],\n",
      "        [-0.3831],\n",
      "        [-0.2848],\n",
      "        [-0.1413],\n",
      "        [-0.1027],\n",
      "        [-0.1413],\n",
      "        [-0.1887],\n",
      "        [-1.9092],\n",
      "        [-1.6017],\n",
      "        [-0.2710],\n",
      "        [-0.4671],\n",
      "        [-0.1228],\n",
      "        [-0.4671],\n",
      "        [-0.2710],\n",
      "        [-1.1138],\n",
      "        [-0.5383],\n",
      "        [-0.1584],\n",
      "        [-0.2144],\n",
      "        [-0.2021],\n",
      "        [ 0.2041],\n",
      "        [ 0.2041],\n",
      "        [-0.0053],\n",
      "        [-0.5383],\n",
      "        [-1.8311],\n",
      "        [-0.0053],\n",
      "        [-1.8909],\n",
      "        [-0.1027],\n",
      "        [-1.8643],\n",
      "        [-0.2710],\n",
      "        [-0.4671],\n",
      "        [-0.2144],\n",
      "        [-0.2781],\n",
      "        [ 0.2041],\n",
      "        [-0.2144],\n",
      "        [-1.2975],\n",
      "        [-0.4175],\n",
      "        [-1.7586],\n",
      "        [-1.7996],\n",
      "        [-0.1027],\n",
      "        [-1.6017],\n",
      "        [-0.2550],\n",
      "        [ 0.2041],\n",
      "        [-1.9108],\n",
      "        [-0.3586],\n",
      "        [-0.6781],\n",
      "        [-1.8643],\n",
      "        [-0.0577],\n",
      "        [-0.6781],\n",
      "        [-0.9911],\n",
      "        [-1.9050],\n",
      "        [-0.2550],\n",
      "        [-1.8909],\n",
      "        [-0.2971],\n",
      "        [-0.7221],\n",
      "        [-0.2971],\n",
      "        [ 0.2041],\n",
      "        [ 0.1351]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 13/10000,\n",
      " train_loss: 0.5944,\n",
      " train_mae: 0.5941,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.9724e+00],\n",
      "        [-1.9724e+00],\n",
      "        [-1.2149e-01],\n",
      "        [-1.5538e-01],\n",
      "        [-3.2299e-01],\n",
      "        [-1.9537e-01],\n",
      "        [ 1.0191e-01],\n",
      "        [ 1.8749e-01],\n",
      "        [ 1.0191e-01],\n",
      "        [-1.6848e-03],\n",
      "        [-2.0951e+00],\n",
      "        [-1.6940e+00],\n",
      "        [-1.7000e-01],\n",
      "        [-4.0489e-01],\n",
      "        [ 1.4293e-01],\n",
      "        [-4.0489e-01],\n",
      "        [-1.7000e-01],\n",
      "        [-1.0971e+00],\n",
      "        [-4.7512e-01],\n",
      "        [ 6.4270e-02],\n",
      "        [-5.6544e-02],\n",
      "        [-3.0400e-02],\n",
      "        [ 8.4875e-01],\n",
      "        [ 8.4875e-01],\n",
      "        [ 4.0427e-01],\n",
      "        [-4.7512e-01],\n",
      "        [-1.9916e+00],\n",
      "        [ 4.0427e-01],\n",
      "        [-2.0702e+00],\n",
      "        [ 1.8749e-01],\n",
      "        [-2.0352e+00],\n",
      "        [-1.7000e-01],\n",
      "        [-4.0489e-01],\n",
      "        [-5.6544e-02],\n",
      "        [-1.8329e-01],\n",
      "        [ 8.4875e-01],\n",
      "        [-5.6544e-02],\n",
      "        [-1.3149e+00],\n",
      "        [-3.5667e-01],\n",
      "        [-1.8968e+00],\n",
      "        [-1.9504e+00],\n",
      "        [ 1.8749e-01],\n",
      "        [-1.6940e+00],\n",
      "        [-1.3926e-01],\n",
      "        [ 8.4875e-01],\n",
      "        [-2.0974e+00],\n",
      "        [-2.9797e-01],\n",
      "        [-6.1727e-01],\n",
      "        [-2.0352e+00],\n",
      "        [ 2.8794e-01],\n",
      "        [-6.1727e-01],\n",
      "        [-9.5656e-01],\n",
      "        [-2.0892e+00],\n",
      "        [-1.3926e-01],\n",
      "        [-2.0702e+00],\n",
      "        [-2.1647e-01],\n",
      "        [-6.6320e-01],\n",
      "        [-2.1647e-01],\n",
      "        [ 8.4875e-01],\n",
      "        [ 7.0714e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 14/10000,\n",
      " train_loss: 0.3969,\n",
      " train_mae: 0.4208,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.9899],\n",
      "        [-1.9899],\n",
      "        [ 0.1746],\n",
      "        [ 0.0989],\n",
      "        [-0.1861],\n",
      "        [ 0.0130],\n",
      "        [ 0.6836],\n",
      "        [ 0.8703],\n",
      "        [ 0.6836],\n",
      "        [ 0.4491],\n",
      "        [-2.1517],\n",
      "        [-1.6366],\n",
      "        [ 0.0670],\n",
      "        [-0.2633],\n",
      "        [ 0.7740],\n",
      "        [-0.2633],\n",
      "        [ 0.0670],\n",
      "        [-0.9479],\n",
      "        [-0.3279],\n",
      "        [ 0.5992],\n",
      "        [ 0.3230],\n",
      "        [ 0.3831],\n",
      "        [ 2.0091],\n",
      "        [ 2.0091],\n",
      "        [ 1.3044],\n",
      "        [-0.3279],\n",
      "        [-2.0150],\n",
      "        [ 1.3044],\n",
      "        [-2.1184],\n",
      "        [ 0.8703],\n",
      "        [-2.0722],\n",
      "        [ 0.0670],\n",
      "        [-0.2633],\n",
      "        [ 0.3230],\n",
      "        [ 0.0385],\n",
      "        [ 2.0091],\n",
      "        [ 0.3230],\n",
      "        [-1.1883],\n",
      "        [-0.2186],\n",
      "        [-1.8922],\n",
      "        [-1.9614],\n",
      "        [ 0.8703],\n",
      "        [-1.6366],\n",
      "        [ 0.1347],\n",
      "        [ 2.0091],\n",
      "        [-2.1549],\n",
      "        [-0.1594],\n",
      "        [-0.4613],\n",
      "        [-2.0722],\n",
      "        [ 1.0788],\n",
      "        [-0.4613],\n",
      "        [-0.7994],\n",
      "        [-2.1437],\n",
      "        [ 0.1347],\n",
      "        [-2.1184],\n",
      "        [-0.0298],\n",
      "        [-0.5054],\n",
      "        [-0.0298],\n",
      "        [ 2.0091],\n",
      "        [ 1.8103]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 15/10000,\n",
      " train_loss: 0.2447,\n",
      " train_mae: 0.5021,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.9196e+00],\n",
      "        [-1.9196e+00],\n",
      "        [ 5.4372e-01],\n",
      "        [ 4.1227e-01],\n",
      "        [-2.7421e-02],\n",
      "        [ 2.6432e-01],\n",
      "        [ 1.3787e+00],\n",
      "        [ 1.6502e+00],\n",
      "        [ 1.3787e+00],\n",
      "        [ 1.0092e+00],\n",
      "        [-2.1352e+00],\n",
      "        [-1.4796e+00],\n",
      "        [ 3.5691e-01],\n",
      "        [-9.7861e-02],\n",
      "        [ 1.5128e+00],\n",
      "        [-9.7861e-02],\n",
      "        [ 3.5691e-01],\n",
      "        [-7.2901e-01],\n",
      "        [-1.5400e-01],\n",
      "        [ 1.2493e+00],\n",
      "        [ 7.9877e-01],\n",
      "        [ 9.0000e-01],\n",
      "        [ 2.8880e+00],\n",
      "        [ 2.8880e+00],\n",
      "        [ 2.2025e+00],\n",
      "        [-1.5400e-01],\n",
      "        [-1.9523e+00],\n",
      "        [ 2.2025e+00],\n",
      "        [-2.0900e+00],\n",
      "        [ 1.6502e+00],\n",
      "        [-2.0281e+00],\n",
      "        [ 3.5691e-01],\n",
      "        [-9.7861e-02],\n",
      "        [ 7.9877e-01],\n",
      "        [ 3.0778e-01],\n",
      "        [ 2.8880e+00],\n",
      "        [ 7.9877e-01],\n",
      "        [-9.7629e-01],\n",
      "        [-5.8246e-02],\n",
      "        [-1.7938e+00],\n",
      "        [-1.8825e+00],\n",
      "        [ 1.6502e+00],\n",
      "        [-1.4796e+00],\n",
      "        [ 4.7438e-01],\n",
      "        [ 2.8880e+00],\n",
      "        [-2.1395e+00],\n",
      "        [ 1.0833e-03],\n",
      "        [-2.7102e-01],\n",
      "        [-2.0281e+00],\n",
      "        [ 1.9291e+00],\n",
      "        [-2.7102e-01],\n",
      "        [-5.8349e-01],\n",
      "        [-2.1243e+00],\n",
      "        [ 4.7438e-01],\n",
      "        [-2.0900e+00],\n",
      "        [ 1.9227e-01],\n",
      "        [-3.1040e-01],\n",
      "        [ 1.9227e-01],\n",
      "        [ 2.8880e+00],\n",
      "        [ 2.7182e+00]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 16/10000,\n",
      " train_loss: 0.4728,\n",
      " train_mae: 0.5316,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.8142],\n",
      "        [-1.8142],\n",
      "        [ 0.6494],\n",
      "        [ 0.5185],\n",
      "        [ 0.0950],\n",
      "        [ 0.3724],\n",
      "        [ 1.4967],\n",
      "        [ 1.7762],\n",
      "        [ 1.4967],\n",
      "        [ 1.1190],\n",
      "        [-2.1036],\n",
      "        [-1.2814],\n",
      "        [ 0.4637],\n",
      "        [ 0.0362],\n",
      "        [ 1.6345],\n",
      "        [ 0.0362],\n",
      "        [ 0.4637],\n",
      "        [-0.5110],\n",
      "        [-0.0099],\n",
      "        [ 1.3641],\n",
      "        [ 0.9057],\n",
      "        [ 1.0082],\n",
      "        [ 3.0606],\n",
      "        [ 3.0606],\n",
      "        [ 2.3481],\n",
      "        [-0.0099],\n",
      "        [-1.8568],\n",
      "        [ 2.3481],\n",
      "        [-2.0412],\n",
      "        [ 1.7762],\n",
      "        [-1.9572],\n",
      "        [ 0.4637],\n",
      "        [ 0.0362],\n",
      "        [ 0.9057],\n",
      "        [ 0.4152],\n",
      "        [ 3.0606],\n",
      "        [ 0.9057],\n",
      "        [-0.7483],\n",
      "        [ 0.0689],\n",
      "        [-1.6545],\n",
      "        [-1.7664],\n",
      "        [ 1.7762],\n",
      "        [-1.2814],\n",
      "        [ 0.5802],\n",
      "        [ 3.0606],\n",
      "        [-2.1096],\n",
      "        [ 0.1201],\n",
      "        [-0.1070],\n",
      "        [-1.9572],\n",
      "        [ 2.0645],\n",
      "        [-0.1070],\n",
      "        [-0.3779],\n",
      "        [-2.0885],\n",
      "        [ 0.5802],\n",
      "        [-2.0412],\n",
      "        [ 0.3020],\n",
      "        [-0.1401],\n",
      "        [ 0.3020],\n",
      "        [ 3.0606],\n",
      "        [ 2.8842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 17/10000,\n",
      " train_loss: 0.5458,\n",
      " train_mae: 0.4213,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.6904],\n",
      "        [-1.6904],\n",
      "        [ 0.5341],\n",
      "        [ 0.4483],\n",
      "        [ 0.1687],\n",
      "        [ 0.3536],\n",
      "        [ 1.1381],\n",
      "        [ 1.3632],\n",
      "        [ 1.1381],\n",
      "        [ 0.8564],\n",
      "        [-2.0776],\n",
      "        [-1.0712],\n",
      "        [ 0.4126],\n",
      "        [ 0.1236],\n",
      "        [ 1.2471],\n",
      "        [ 0.1236],\n",
      "        [ 0.4126],\n",
      "        [-0.3276],\n",
      "        [ 0.0874],\n",
      "        [ 1.0364],\n",
      "        [ 0.7068],\n",
      "        [ 0.7779],\n",
      "        [ 2.6796],\n",
      "        [ 2.6796],\n",
      "        [ 1.8812],\n",
      "        [ 0.0874],\n",
      "        [-1.7447],\n",
      "        [ 1.8812],\n",
      "        [-1.9903],\n",
      "        [ 1.3632],\n",
      "        [-1.8762],\n",
      "        [ 0.4126],\n",
      "        [ 0.1236],\n",
      "        [ 0.7068],\n",
      "        [ 0.3812],\n",
      "        [ 2.6796],\n",
      "        [ 0.7068],\n",
      "        [-0.5411],\n",
      "        [ 0.1490],\n",
      "        [-1.4936],\n",
      "        [-1.6304],\n",
      "        [ 1.3632],\n",
      "        [-1.0712],\n",
      "        [ 0.4886],\n",
      "        [ 2.6796],\n",
      "        [-2.0862],\n",
      "        [ 0.1870],\n",
      "        [ 0.0102],\n",
      "        [-1.8762],\n",
      "        [ 1.6136],\n",
      "        [ 0.0102],\n",
      "        [-0.2131],\n",
      "        [-2.0563],\n",
      "        [ 0.4886],\n",
      "        [-1.9903],\n",
      "        [ 0.3080],\n",
      "        [-0.0164],\n",
      "        [ 0.3080],\n",
      "        [ 2.6796],\n",
      "        [ 2.4615]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 18/10000,\n",
      " train_loss: 0.3194,\n",
      " train_mae: 0.3086,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.5371],\n",
      "        [-1.5371],\n",
      "        [ 0.4056],\n",
      "        [ 0.3630],\n",
      "        [ 0.2140],\n",
      "        [ 0.3159],\n",
      "        [ 0.7179],\n",
      "        [ 0.8457],\n",
      "        [ 0.7179],\n",
      "        [ 0.5679],\n",
      "        [-2.0464],\n",
      "        [-0.8547],\n",
      "        [ 0.3453],\n",
      "        [ 0.1807],\n",
      "        [ 0.7788],\n",
      "        [ 0.1807],\n",
      "        [ 0.3453],\n",
      "        [-0.1784],\n",
      "        [ 0.1530],\n",
      "        [ 0.6627],\n",
      "        [ 0.4917],\n",
      "        [ 0.5277],\n",
      "        [ 1.8431],\n",
      "        [ 1.8431],\n",
      "        [ 1.1763],\n",
      "        [ 0.1530],\n",
      "        [-1.6039],\n",
      "        [ 1.1763],\n",
      "        [-1.9242],\n",
      "        [ 0.8457],\n",
      "        [-1.7715],\n",
      "        [ 0.3453],\n",
      "        [ 0.1807],\n",
      "        [ 0.4917],\n",
      "        [ 0.3297],\n",
      "        [ 1.8431],\n",
      "        [ 0.4917],\n",
      "        [-0.3600],\n",
      "        [ 0.1997],\n",
      "        [-1.3053],\n",
      "        [-1.4647],\n",
      "        [ 0.8457],\n",
      "        [-0.8547],\n",
      "        [ 0.3830],\n",
      "        [ 1.8431],\n",
      "        [-2.0587],\n",
      "        [ 0.2262],\n",
      "        [ 0.0931],\n",
      "        [-1.7715],\n",
      "        [ 0.9982],\n",
      "        [ 0.0931],\n",
      "        [-0.0844],\n",
      "        [-2.0162],\n",
      "        [ 0.3830],\n",
      "        [-1.9242],\n",
      "        [ 0.2928],\n",
      "        [ 0.0723],\n",
      "        [ 0.2928],\n",
      "        [ 1.8431],\n",
      "        [ 1.6354]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 19/10000,\n",
      " train_loss: 0.1212,\n",
      " train_mae: 0.3212,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3418],\n",
      "        [-1.3418],\n",
      "        [ 0.3555],\n",
      "        [ 0.3356],\n",
      "        [ 0.2564],\n",
      "        [ 0.3130],\n",
      "        [ 0.4991],\n",
      "        [ 0.5588],\n",
      "        [ 0.4991],\n",
      "        [ 0.4301],\n",
      "        [-1.9898],\n",
      "        [-0.6338],\n",
      "        [ 0.3272],\n",
      "        [ 0.2317],\n",
      "        [ 0.5274],\n",
      "        [ 0.2317],\n",
      "        [ 0.3272],\n",
      "        [-0.0487],\n",
      "        [ 0.2105],\n",
      "        [ 0.4736],\n",
      "        [ 0.3952],\n",
      "        [ 0.4117],\n",
      "        [ 1.0988],\n",
      "        [ 1.0988],\n",
      "        [ 0.7206],\n",
      "        [ 0.2105],\n",
      "        [-1.4198],\n",
      "        [ 0.7206],\n",
      "        [-1.8216],\n",
      "        [ 0.5588],\n",
      "        [-1.6237],\n",
      "        [ 0.3272],\n",
      "        [ 0.2317],\n",
      "        [ 0.3952],\n",
      "        [ 0.3197],\n",
      "        [ 1.0988],\n",
      "        [ 0.3952],\n",
      "        [-0.1971],\n",
      "        [ 0.2461],\n",
      "        [-1.0847],\n",
      "        [-1.2595],\n",
      "        [ 0.5588],\n",
      "        [-0.6338],\n",
      "        [ 0.3450],\n",
      "        [ 1.0988],\n",
      "        [-2.0072],\n",
      "        [ 0.2648],\n",
      "        [ 0.1644],\n",
      "        [-1.6237],\n",
      "        [ 0.6319],\n",
      "        [ 0.1644],\n",
      "        [ 0.0261],\n",
      "        [-1.9472],\n",
      "        [ 0.3450],\n",
      "        [-1.8216],\n",
      "        [ 0.3016],\n",
      "        [ 0.1483],\n",
      "        [ 0.3016],\n",
      "        [ 1.0988],\n",
      "        [ 0.9715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 20/10000,\n",
      " train_loss: 0.1213,\n",
      " train_mae: 0.3750,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1185],\n",
      "        [-1.1185],\n",
      "        [ 0.3650],\n",
      "        [ 0.3547],\n",
      "        [ 0.3075],\n",
      "        [ 0.3426],\n",
      "        [ 0.4368],\n",
      "        [ 0.4661],\n",
      "        [ 0.4368],\n",
      "        [ 0.4028],\n",
      "        [-1.9018],\n",
      "        [-0.4237],\n",
      "        [ 0.3502],\n",
      "        [ 0.2885],\n",
      "        [ 0.4507],\n",
      "        [ 0.2885],\n",
      "        [ 0.3502],\n",
      "        [ 0.0686],\n",
      "        [ 0.2719],\n",
      "        [ 0.4243],\n",
      "        [ 0.3853],\n",
      "        [ 0.3936],\n",
      "        [ 0.7384],\n",
      "        [ 0.7384],\n",
      "        [ 0.5456],\n",
      "        [ 0.2719],\n",
      "        [-1.2038],\n",
      "        [ 0.5456],\n",
      "        [-1.6801],\n",
      "        [ 0.4661],\n",
      "        [-1.4372],\n",
      "        [ 0.3502],\n",
      "        [ 0.2885],\n",
      "        [ 0.3853],\n",
      "        [ 0.3462],\n",
      "        [ 0.7384],\n",
      "        [ 0.3853],\n",
      "        [-0.0510],\n",
      "        [ 0.2996],\n",
      "        [-0.8506],\n",
      "        [-1.0305],\n",
      "        [ 0.4661],\n",
      "        [-0.4237],\n",
      "        [ 0.3596],\n",
      "        [ 0.7384],\n",
      "        [-1.9257],\n",
      "        [ 0.3136],\n",
      "        [ 0.2361],\n",
      "        [-1.4372],\n",
      "        [ 0.5020],\n",
      "        [ 0.2361],\n",
      "        [ 0.1278],\n",
      "        [-1.8442],\n",
      "        [ 0.3596],\n",
      "        [-1.6801],\n",
      "        [ 0.3363],\n",
      "        [ 0.2235],\n",
      "        [ 0.3363],\n",
      "        [ 0.7384],\n",
      "        [ 0.6719]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 21/10000,\n",
      " train_loss: 0.1733,\n",
      " train_mae: 0.4063,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.9079],\n",
      "        [-0.9079],\n",
      "        [ 0.4020],\n",
      "        [ 0.3959],\n",
      "        [ 0.3646],\n",
      "        [ 0.3887],\n",
      "        [ 0.4423],\n",
      "        [ 0.4583],\n",
      "        [ 0.4423],\n",
      "        [ 0.4234],\n",
      "        [-1.7988],\n",
      "        [-0.2476],\n",
      "        [ 0.3933],\n",
      "        [ 0.3492],\n",
      "        [ 0.4499],\n",
      "        [ 0.3492],\n",
      "        [ 0.3933],\n",
      "        [ 0.1704],\n",
      "        [ 0.3358],\n",
      "        [ 0.4354],\n",
      "        [ 0.4136],\n",
      "        [ 0.4183],\n",
      "        [ 0.6044],\n",
      "        [ 0.6044],\n",
      "        [ 0.5011],\n",
      "        [ 0.3358],\n",
      "        [-0.9963],\n",
      "        [ 0.5011],\n",
      "        [-1.5262],\n",
      "        [ 0.4583],\n",
      "        [-1.2476],\n",
      "        [ 0.3933],\n",
      "        [ 0.3492],\n",
      "        [ 0.4136],\n",
      "        [ 0.3909],\n",
      "        [ 0.6044],\n",
      "        [ 0.4136],\n",
      "        [ 0.0718],\n",
      "        [ 0.3582],\n",
      "        [-0.6417],\n",
      "        [-0.8187],\n",
      "        [ 0.4583],\n",
      "        [-0.2476],\n",
      "        [ 0.3988],\n",
      "        [ 0.6044],\n",
      "        [-1.8293],\n",
      "        [ 0.3693],\n",
      "        [ 0.3067],\n",
      "        [-1.2476],\n",
      "        [ 0.4776],\n",
      "        [ 0.3067],\n",
      "        [ 0.2188],\n",
      "        [-1.7261],\n",
      "        [ 0.3988],\n",
      "        [-1.5262],\n",
      "        [ 0.3848],\n",
      "        [ 0.2965],\n",
      "        [ 0.3848],\n",
      "        [ 0.6044],\n",
      "        [ 0.5687]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 22/10000,\n",
      " train_loss: 0.2154,\n",
      " train_mae: 0.4240,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.7558],\n",
      "        [-0.7558],\n",
      "        [ 0.4463],\n",
      "        [ 0.4424],\n",
      "        [ 0.4196],\n",
      "        [ 0.4377],\n",
      "        [ 0.4710],\n",
      "        [ 0.4806],\n",
      "        [ 0.4710],\n",
      "        [ 0.4596],\n",
      "        [-1.7130],\n",
      "        [-0.1237],\n",
      "        [ 0.4407],\n",
      "        [ 0.4064],\n",
      "        [ 0.4756],\n",
      "        [ 0.4064],\n",
      "        [ 0.4407],\n",
      "        [ 0.2506],\n",
      "        [ 0.3947],\n",
      "        [ 0.4669],\n",
      "        [ 0.4535],\n",
      "        [ 0.4564],\n",
      "        [ 0.5657],\n",
      "        [ 0.5657],\n",
      "        [ 0.5059],\n",
      "        [ 0.3947],\n",
      "        [-0.8448],\n",
      "        [ 0.5059],\n",
      "        [-1.4050],\n",
      "        [ 0.4806],\n",
      "        [-1.1047],\n",
      "        [ 0.4407],\n",
      "        [ 0.4064],\n",
      "        [ 0.4535],\n",
      "        [ 0.4391],\n",
      "        [ 0.5657],\n",
      "        [ 0.4535],\n",
      "        [ 0.1637],\n",
      "        [ 0.4142],\n",
      "        [-0.4942],\n",
      "        [-0.6670],\n",
      "        [ 0.4806],\n",
      "        [-0.1237],\n",
      "        [ 0.4442],\n",
      "        [ 0.5657],\n",
      "        [-1.7484],\n",
      "        [ 0.4236],\n",
      "        [ 0.3694],\n",
      "        [-1.1047],\n",
      "        [ 0.4921],\n",
      "        [ 0.3694],\n",
      "        [ 0.2929],\n",
      "        [-1.6293],\n",
      "        [ 0.4442],\n",
      "        [-1.4050],\n",
      "        [ 0.4351],\n",
      "        [ 0.3606],\n",
      "        [ 0.4351],\n",
      "        [ 0.5657],\n",
      "        [ 0.5451]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 23/10000,\n",
      " train_loss: 0.2476,\n",
      " train_mae: 0.4324,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.6928],\n",
      "        [-0.6928],\n",
      "        [ 0.4852],\n",
      "        [ 0.4826],\n",
      "        [ 0.4647],\n",
      "        [ 0.4793],\n",
      "        [ 0.5016],\n",
      "        [ 0.5078],\n",
      "        [ 0.5016],\n",
      "        [ 0.4941],\n",
      "        [-1.6762],\n",
      "        [-0.0616],\n",
      "        [ 0.4814],\n",
      "        [ 0.4524],\n",
      "        [ 0.5045],\n",
      "        [ 0.4524],\n",
      "        [ 0.4814],\n",
      "        [ 0.3035],\n",
      "        [ 0.4415],\n",
      "        [ 0.4989],\n",
      "        [ 0.4901],\n",
      "        [ 0.4920],\n",
      "        [ 0.5610],\n",
      "        [ 0.5610],\n",
      "        [ 0.5238],\n",
      "        [ 0.4415],\n",
      "        [-0.7831],\n",
      "        [ 0.5238],\n",
      "        [-1.3569],\n",
      "        [ 0.5078],\n",
      "        [-1.0480],\n",
      "        [ 0.4814],\n",
      "        [ 0.4524],\n",
      "        [ 0.4901],\n",
      "        [ 0.4803],\n",
      "        [ 0.5610],\n",
      "        [ 0.4901],\n",
      "        [ 0.2195],\n",
      "        [ 0.4597],\n",
      "        [-0.4296],\n",
      "        [-0.6032],\n",
      "        [ 0.5078],\n",
      "        [-0.0616],\n",
      "        [ 0.4839],\n",
      "        [ 0.5610],\n",
      "        [-1.7130],\n",
      "        [ 0.4682],\n",
      "        [ 0.4174],\n",
      "        [-1.0480],\n",
      "        [ 0.5151],\n",
      "        [ 0.4174],\n",
      "        [ 0.3442],\n",
      "        [-1.5893],\n",
      "        [ 0.4839],\n",
      "        [-1.3569],\n",
      "        [ 0.4774],\n",
      "        [ 0.4090],\n",
      "        [ 0.4774],\n",
      "        [ 0.5610],\n",
      "        [ 0.5483]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 24/10000,\n",
      " train_loss: 0.2664,\n",
      " train_mae: 0.4263,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.7297],\n",
      "        [-0.7297],\n",
      "        [ 0.5122],\n",
      "        [ 0.5103],\n",
      "        [ 0.4952],\n",
      "        [ 0.5079],\n",
      "        [ 0.5236],\n",
      "        [ 0.5278],\n",
      "        [ 0.5236],\n",
      "        [ 0.5185],\n",
      "        [-1.6998],\n",
      "        [-0.0654],\n",
      "        [ 0.5094],\n",
      "        [ 0.4829],\n",
      "        [ 0.5257],\n",
      "        [ 0.4829],\n",
      "        [ 0.5094],\n",
      "        [ 0.3257],\n",
      "        [ 0.4716],\n",
      "        [ 0.5218],\n",
      "        [ 0.5157],\n",
      "        [ 0.5170],\n",
      "        [ 0.5631],\n",
      "        [ 0.5631],\n",
      "        [ 0.5386],\n",
      "        [ 0.4716],\n",
      "        [-0.8225],\n",
      "        [ 0.5386],\n",
      "        [-1.3958],\n",
      "        [ 0.5278],\n",
      "        [-1.0909],\n",
      "        [ 0.5094],\n",
      "        [ 0.4829],\n",
      "        [ 0.5157],\n",
      "        [ 0.5086],\n",
      "        [ 0.5631],\n",
      "        [ 0.5157],\n",
      "        [ 0.2358],\n",
      "        [ 0.4903],\n",
      "        [-0.4556],\n",
      "        [-0.6369],\n",
      "        [ 0.5278],\n",
      "        [-0.0654],\n",
      "        [ 0.5112],\n",
      "        [ 0.5631],\n",
      "        [-1.7340],\n",
      "        [ 0.4986],\n",
      "        [ 0.4465],\n",
      "        [-1.0909],\n",
      "        [ 0.5328],\n",
      "        [ 0.4465],\n",
      "        [ 0.3691],\n",
      "        [-1.6183],\n",
      "        [ 0.5112],\n",
      "        [-1.3958],\n",
      "        [ 0.5065],\n",
      "        [ 0.4377],\n",
      "        [ 0.5065],\n",
      "        [ 0.5631],\n",
      "        [ 0.5548]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 25/10000,\n",
      " train_loss: 0.2676,\n",
      " train_mae: 0.4135,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-0.8574],\n",
      "        [-0.8574],\n",
      "        [ 0.5259],\n",
      "        [ 0.5244],\n",
      "        [ 0.5107],\n",
      "        [ 0.5225],\n",
      "        [ 0.5342],\n",
      "        [ 0.5372],\n",
      "        [ 0.5342],\n",
      "        [ 0.5305],\n",
      "        [-1.7685],\n",
      "        [-0.1351],\n",
      "        [ 0.5238],\n",
      "        [ 0.4974],\n",
      "        [ 0.5357],\n",
      "        [ 0.4974],\n",
      "        [ 0.5238],\n",
      "        [ 0.3170],\n",
      "        [ 0.4849],\n",
      "        [ 0.5329],\n",
      "        [ 0.5284],\n",
      "        [ 0.5294],\n",
      "        [ 0.5618],\n",
      "        [ 0.5618],\n",
      "        [ 0.5448],\n",
      "        [ 0.4849],\n",
      "        [-0.9523],\n",
      "        [ 0.5448],\n",
      "        [-1.5033],\n",
      "        [ 0.5372],\n",
      "        [-1.2181],\n",
      "        [ 0.5238],\n",
      "        [ 0.4974],\n",
      "        [ 0.5284],\n",
      "        [ 0.5231],\n",
      "        [ 0.5618],\n",
      "        [ 0.5284],\n",
      "        [ 0.2122],\n",
      "        [ 0.5055],\n",
      "        [-0.5681],\n",
      "        [-0.7609],\n",
      "        [ 0.5372],\n",
      "        [-0.1351],\n",
      "        [ 0.5251],\n",
      "        [ 0.5618],\n",
      "        [-1.7971],\n",
      "        [ 0.5142],\n",
      "        [ 0.4566],\n",
      "        [-1.2181],\n",
      "        [ 0.5407],\n",
      "        [ 0.4566],\n",
      "        [ 0.3674],\n",
      "        [-1.6995],\n",
      "        [ 0.5251],\n",
      "        [-1.5033],\n",
      "        [ 0.5214],\n",
      "        [ 0.4466],\n",
      "        [ 0.5214],\n",
      "        [ 0.5618],\n",
      "        [ 0.5561]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 26/10000,\n",
      " train_loss: 0.2556,\n",
      " train_mae: 0.4014,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0457],\n",
      "        [-1.0457],\n",
      "        [ 0.5294],\n",
      "        [ 0.5282],\n",
      "        [ 0.5150],\n",
      "        [ 0.5267],\n",
      "        [ 0.5357],\n",
      "        [ 0.5379],\n",
      "        [ 0.5357],\n",
      "        [ 0.5329],\n",
      "        [-1.8535],\n",
      "        [-0.2632],\n",
      "        [ 0.5277],\n",
      "        [ 0.4999],\n",
      "        [ 0.5368],\n",
      "        [ 0.4999],\n",
      "        [ 0.5277],\n",
      "        [ 0.2808],\n",
      "        [ 0.4853],\n",
      "        [ 0.5347],\n",
      "        [ 0.5313],\n",
      "        [ 0.5321],\n",
      "        [ 0.5558],\n",
      "        [ 0.5558],\n",
      "        [ 0.5435],\n",
      "        [ 0.4853],\n",
      "        [-1.1394],\n",
      "        [ 0.5435],\n",
      "        [-1.6400],\n",
      "        [ 0.5379],\n",
      "        [-1.3902],\n",
      "        [ 0.5277],\n",
      "        [ 0.4999],\n",
      "        [ 0.5313],\n",
      "        [ 0.5272],\n",
      "        [ 0.5558],\n",
      "        [ 0.5313],\n",
      "        [ 0.1523],\n",
      "        [ 0.5092],\n",
      "        [-0.7468],\n",
      "        [-0.9482],\n",
      "        [ 0.5379],\n",
      "        [-0.2632],\n",
      "        [ 0.5288],\n",
      "        [ 0.5558],\n",
      "        [-1.8753],\n",
      "        [ 0.5188],\n",
      "        [ 0.4515],\n",
      "        [-1.3902],\n",
      "        [ 0.5405],\n",
      "        [ 0.4515],\n",
      "        [ 0.3428],\n",
      "        [-1.7997],\n",
      "        [ 0.5288],\n",
      "        [-1.6400],\n",
      "        [ 0.5258],\n",
      "        [ 0.4394],\n",
      "        [ 0.5258],\n",
      "        [ 0.5558],\n",
      "        [ 0.5517]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 27/10000,\n",
      " train_loss: 0.2415,\n",
      " train_mae: 0.3999,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2496],\n",
      "        [-1.2496],\n",
      "        [ 0.5286],\n",
      "        [ 0.5276],\n",
      "        [ 0.5143],\n",
      "        [ 0.5264],\n",
      "        [ 0.5335],\n",
      "        [ 0.5352],\n",
      "        [ 0.5335],\n",
      "        [ 0.5314],\n",
      "        [-1.9293],\n",
      "        [-0.4306],\n",
      "        [ 0.5272],\n",
      "        [ 0.4967],\n",
      "        [ 0.5344],\n",
      "        [ 0.4967],\n",
      "        [ 0.5272],\n",
      "        [ 0.2246],\n",
      "        [ 0.4791],\n",
      "        [ 0.5328],\n",
      "        [ 0.5301],\n",
      "        [ 0.5307],\n",
      "        [ 0.5487],\n",
      "        [ 0.5487],\n",
      "        [ 0.5395],\n",
      "        [ 0.4791],\n",
      "        [-1.3372],\n",
      "        [ 0.5395],\n",
      "        [-1.7667],\n",
      "        [ 0.5352],\n",
      "        [-1.5605],\n",
      "        [ 0.5272],\n",
      "        [ 0.4967],\n",
      "        [ 0.5301],\n",
      "        [ 0.5268],\n",
      "        [ 0.5487],\n",
      "        [ 0.5301],\n",
      "        [ 0.0649],\n",
      "        [ 0.5076],\n",
      "        [-0.9552],\n",
      "        [-1.1561],\n",
      "        [ 0.5352],\n",
      "        [-0.4306],\n",
      "        [ 0.5281],\n",
      "        [ 0.5487],\n",
      "        [-1.9452],\n",
      "        [ 0.5186],\n",
      "        [ 0.4378],\n",
      "        [-1.5605],\n",
      "        [ 0.5372],\n",
      "        [ 0.4378],\n",
      "        [ 0.3022],\n",
      "        [-1.8897],\n",
      "        [ 0.5281],\n",
      "        [-1.7667],\n",
      "        [ 0.5256],\n",
      "        [ 0.4228],\n",
      "        [ 0.5256],\n",
      "        [ 0.5487],\n",
      "        [ 0.5456]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 28/10000,\n",
      " train_loss: 0.2336,\n",
      " train_mae: 0.4107,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.4274],\n",
      "        [-1.4274],\n",
      "        [ 0.5300],\n",
      "        [ 0.5292],\n",
      "        [ 0.5154],\n",
      "        [ 0.5281],\n",
      "        [ 0.5340],\n",
      "        [ 0.5354],\n",
      "        [ 0.5340],\n",
      "        [ 0.5323],\n",
      "        [-1.9813],\n",
      "        [-0.6087],\n",
      "        [ 0.5288],\n",
      "        [ 0.4947],\n",
      "        [ 0.5347],\n",
      "        [ 0.4947],\n",
      "        [ 0.5288],\n",
      "        [ 0.1590],\n",
      "        [ 0.4736],\n",
      "        [ 0.5334],\n",
      "        [ 0.5313],\n",
      "        [ 0.5318],\n",
      "        [ 0.5458],\n",
      "        [ 0.5458],\n",
      "        [ 0.5387],\n",
      "        [ 0.4736],\n",
      "        [-1.5054],\n",
      "        [ 0.5387],\n",
      "        [-1.8600],\n",
      "        [ 0.5354],\n",
      "        [-1.6956],\n",
      "        [ 0.5288],\n",
      "        [ 0.4947],\n",
      "        [ 0.5313],\n",
      "        [ 0.5285],\n",
      "        [ 0.5458],\n",
      "        [ 0.5313],\n",
      "        [-0.0361],\n",
      "        [ 0.5076],\n",
      "        [-1.1519],\n",
      "        [-1.3422],\n",
      "        [ 0.5354],\n",
      "        [-0.6087],\n",
      "        [ 0.5296],\n",
      "        [ 0.5458],\n",
      "        [-1.9926],\n",
      "        [ 0.5201],\n",
      "        [ 0.4231],\n",
      "        [-1.6956],\n",
      "        [ 0.5369],\n",
      "        [ 0.4231],\n",
      "        [ 0.2550],\n",
      "        [-1.9524],\n",
      "        [ 0.5296],\n",
      "        [-1.8600],\n",
      "        [ 0.5274],\n",
      "        [ 0.4045],\n",
      "        [ 0.5274],\n",
      "        [ 0.5458],\n",
      "        [ 0.5435]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 29/10000,\n",
      " train_loss: 0.2327,\n",
      " train_mae: 0.4159,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.5557],\n",
      "        [-1.5557],\n",
      "        [ 0.5388],\n",
      "        [ 0.5381],\n",
      "        [ 0.5235],\n",
      "        [ 0.5372],\n",
      "        [ 0.5421],\n",
      "        [ 0.5432],\n",
      "        [ 0.5421],\n",
      "        [ 0.5407],\n",
      "        [-2.0028],\n",
      "        [-0.7693],\n",
      "        [ 0.5378],\n",
      "        [ 0.4995],\n",
      "        [ 0.5427],\n",
      "        [ 0.4995],\n",
      "        [ 0.5378],\n",
      "        [ 0.0950],\n",
      "        [ 0.4745],\n",
      "        [ 0.5416],\n",
      "        [ 0.5399],\n",
      "        [ 0.5403],\n",
      "        [ 0.5516],\n",
      "        [ 0.5516],\n",
      "        [ 0.5459],\n",
      "        [ 0.4745],\n",
      "        [-1.6230],\n",
      "        [ 0.5459],\n",
      "        [-1.9116],\n",
      "        [ 0.5432],\n",
      "        [-1.7815],\n",
      "        [ 0.5378],\n",
      "        [ 0.4995],\n",
      "        [ 0.5399],\n",
      "        [ 0.5375],\n",
      "        [ 0.5516],\n",
      "        [ 0.5399],\n",
      "        [-0.1352],\n",
      "        [ 0.5145],\n",
      "        [-1.3071],\n",
      "        [-1.4806],\n",
      "        [ 0.5432],\n",
      "        [-0.7693],\n",
      "        [ 0.5385],\n",
      "        [ 0.5516],\n",
      "        [-2.0111],\n",
      "        [ 0.5289],\n",
      "        [ 0.4138],\n",
      "        [-1.7815],\n",
      "        [ 0.5445],\n",
      "        [ 0.4138],\n",
      "        [ 0.2104],\n",
      "        [-1.9815],\n",
      "        [ 0.5385],\n",
      "        [-1.9116],\n",
      "        [ 0.5365],\n",
      "        [ 0.3914],\n",
      "        [ 0.5365],\n",
      "        [ 0.5516],\n",
      "        [ 0.5497]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 30/10000,\n",
      " train_loss: 0.2341,\n",
      " train_mae: 0.4121,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.6292],\n",
      "        [-1.6292],\n",
      "        [ 0.5577],\n",
      "        [ 0.5571],\n",
      "        [ 0.5415],\n",
      "        [ 0.5562],\n",
      "        [ 0.5605],\n",
      "        [ 0.5614],\n",
      "        [ 0.5605],\n",
      "        [ 0.5593],\n",
      "        [-1.9924],\n",
      "        [-0.8944],\n",
      "        [ 0.5568],\n",
      "        [ 0.5142],\n",
      "        [ 0.5609],\n",
      "        [ 0.5142],\n",
      "        [ 0.5568],\n",
      "        [ 0.0414],\n",
      "        [ 0.4851],\n",
      "        [ 0.5601],\n",
      "        [ 0.5586],\n",
      "        [ 0.5589],\n",
      "        [ 0.5682],\n",
      "        [ 0.5682],\n",
      "        [ 0.5636],\n",
      "        [ 0.4851],\n",
      "        [-1.6867],\n",
      "        [ 0.5636],\n",
      "        [-1.9222],\n",
      "        [ 0.5614],\n",
      "        [-1.8183],\n",
      "        [ 0.5568],\n",
      "        [ 0.5142],\n",
      "        [ 0.5586],\n",
      "        [ 0.5565],\n",
      "        [ 0.5682],\n",
      "        [ 0.5586],\n",
      "        [-0.2201],\n",
      "        [ 0.5314],\n",
      "        [-1.4093],\n",
      "        [-1.5640],\n",
      "        [ 0.5614],\n",
      "        [-0.8944],\n",
      "        [ 0.5574],\n",
      "        [ 0.5682],\n",
      "        [-1.9987],\n",
      "        [ 0.5475],\n",
      "        [ 0.4140],\n",
      "        [-1.8183],\n",
      "        [ 0.5624],\n",
      "        [ 0.4140],\n",
      "        [ 0.1752],\n",
      "        [-1.9763],\n",
      "        [ 0.5574],\n",
      "        [-1.9222],\n",
      "        [ 0.5556],\n",
      "        [ 0.3876],\n",
      "        [ 0.5556],\n",
      "        [ 0.5682],\n",
      "        [ 0.5667]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 31/10000,\n",
      " train_loss: 0.2329,\n",
      " train_mae: 0.4058,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.6538e+00],\n",
      "        [-1.6538e+00],\n",
      "        [ 5.8628e-01],\n",
      "        [ 5.8576e-01],\n",
      "        [ 5.6920e-01],\n",
      "        [ 5.8493e-01],\n",
      "        [ 5.8872e-01],\n",
      "        [ 5.8949e-01],\n",
      "        [ 5.8872e-01],\n",
      "        [ 5.8770e-01],\n",
      "        [-1.9526e+00],\n",
      "        [-9.7882e-01],\n",
      "        [ 5.8549e-01],\n",
      "        [ 5.3852e-01],\n",
      "        [ 5.8909e-01],\n",
      "        [ 5.3852e-01],\n",
      "        [ 5.8549e-01],\n",
      "        [ 1.6875e-03],\n",
      "        [ 5.0546e-01],\n",
      "        [ 5.8836e-01],\n",
      "        [ 5.8710e-01],\n",
      "        [ 5.8739e-01],\n",
      "        [ 5.9521e-01],\n",
      "        [ 5.9521e-01],\n",
      "        [ 5.9136e-01],\n",
      "        [ 5.0546e-01],\n",
      "        [-1.7028e+00],\n",
      "        [ 5.9136e-01],\n",
      "        [-1.8971e+00],\n",
      "        [ 5.8949e-01],\n",
      "        [-1.8128e+00],\n",
      "        [ 5.8549e-01],\n",
      "        [ 5.3852e-01],\n",
      "        [ 5.8710e-01],\n",
      "        [ 5.8522e-01],\n",
      "        [ 5.9521e-01],\n",
      "        [ 5.8710e-01],\n",
      "        [-2.8518e-01],\n",
      "        [ 5.5790e-01],\n",
      "        [-1.4610e+00],\n",
      "        [-1.5975e+00],\n",
      "        [ 5.8949e-01],\n",
      "        [-9.7882e-01],\n",
      "        [ 5.8602e-01],\n",
      "        [ 5.9521e-01],\n",
      "        [-1.9575e+00],\n",
      "        [ 5.7579e-01],\n",
      "        [ 4.2413e-01],\n",
      "        [-1.8128e+00],\n",
      "        [ 5.9037e-01],\n",
      "        [ 4.2413e-01],\n",
      "        [ 1.5188e-01],\n",
      "        [-1.9399e+00],\n",
      "        [ 5.8602e-01],\n",
      "        [-1.8971e+00],\n",
      "        [ 5.8431e-01],\n",
      "        [ 3.9391e-01],\n",
      "        [ 5.8431e-01],\n",
      "        [ 5.9521e-01],\n",
      "        [ 5.9395e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 32/10000,\n",
      " train_loss: 0.2275,\n",
      " train_mae: 0.3957,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.6407],\n",
      "        [-1.6407],\n",
      "        [ 0.6216],\n",
      "        [ 0.6212],\n",
      "        [ 0.6036],\n",
      "        [ 0.6204],\n",
      "        [ 0.6238],\n",
      "        [ 0.6245],\n",
      "        [ 0.6238],\n",
      "        [ 0.6229],\n",
      "        [-1.8890],\n",
      "        [-1.0280],\n",
      "        [ 0.6209],\n",
      "        [ 0.5696],\n",
      "        [ 0.6241],\n",
      "        [ 0.5696],\n",
      "        [ 0.6209],\n",
      "        [-0.0262],\n",
      "        [ 0.5326],\n",
      "        [ 0.6235],\n",
      "        [ 0.6224],\n",
      "        [ 0.6226],\n",
      "        [ 0.6293],\n",
      "        [ 0.6293],\n",
      "        [ 0.6261],\n",
      "        [ 0.5326],\n",
      "        [-1.6825],\n",
      "        [ 0.6261],\n",
      "        [-1.8442],\n",
      "        [ 0.6245],\n",
      "        [-1.7750],\n",
      "        [ 0.6209],\n",
      "        [ 0.5696],\n",
      "        [ 0.6224],\n",
      "        [ 0.6206],\n",
      "        [ 0.6293],\n",
      "        [ 0.6224],\n",
      "        [-0.3324],\n",
      "        [ 0.5911],\n",
      "        [-1.4725],\n",
      "        [-1.5922],\n",
      "        [ 0.6245],\n",
      "        [-1.0280],\n",
      "        [ 0.6214],\n",
      "        [ 0.6293],\n",
      "        [-1.8929],\n",
      "        [ 0.6108],\n",
      "        [ 0.4413],\n",
      "        [-1.7750],\n",
      "        [ 0.6252],\n",
      "        [ 0.4413],\n",
      "        [ 0.1380],\n",
      "        [-1.8788],\n",
      "        [ 0.6214],\n",
      "        [-1.8442],\n",
      "        [ 0.6198],\n",
      "        [ 0.4074],\n",
      "        [ 0.6198],\n",
      "        [ 0.6293],\n",
      "        [ 0.6283]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 33/10000,\n",
      " train_loss: 0.2192,\n",
      " train_mae: 0.3829,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.6030],\n",
      "        [-1.6030],\n",
      "        [ 0.6589],\n",
      "        [ 0.6584],\n",
      "        [ 0.6397],\n",
      "        [ 0.6577],\n",
      "        [ 0.6608],\n",
      "        [ 0.6614],\n",
      "        [ 0.6608],\n",
      "        [ 0.6600],\n",
      "        [-1.8100],\n",
      "        [-1.0530],\n",
      "        [ 0.6582],\n",
      "        [ 0.6023],\n",
      "        [ 0.6611],\n",
      "        [ 0.6023],\n",
      "        [ 0.6582],\n",
      "        [-0.0491],\n",
      "        [ 0.5613],\n",
      "        [ 0.6605],\n",
      "        [ 0.6595],\n",
      "        [ 0.6598],\n",
      "        [ 0.6656],\n",
      "        [ 0.6656],\n",
      "        [ 0.6628],\n",
      "        [ 0.5613],\n",
      "        [-1.6387],\n",
      "        [ 0.6628],\n",
      "        [-1.7735],\n",
      "        [ 0.6614],\n",
      "        [-1.7163],\n",
      "        [ 0.6582],\n",
      "        [ 0.6023],\n",
      "        [ 0.6595],\n",
      "        [ 0.6580],\n",
      "        [ 0.6656],\n",
      "        [ 0.6595],\n",
      "        [-0.3692],\n",
      "        [ 0.6260],\n",
      "        [-1.4572],\n",
      "        [-1.5614],\n",
      "        [ 0.6614],\n",
      "        [-1.0530],\n",
      "        [ 0.6587],\n",
      "        [ 0.6656],\n",
      "        [-1.8132],\n",
      "        [ 0.6475],\n",
      "        [ 0.4599],\n",
      "        [-1.7163],\n",
      "        [ 0.6621],\n",
      "        [ 0.4599],\n",
      "        [ 0.1272],\n",
      "        [-1.8017],\n",
      "        [ 0.6587],\n",
      "        [-1.7735],\n",
      "        [ 0.6571],\n",
      "        [ 0.4224],\n",
      "        [ 0.6571],\n",
      "        [ 0.6656],\n",
      "        [ 0.6647]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 34/10000,\n",
      " train_loss: 0.2105,\n",
      " train_mae: 0.3681,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.5534],\n",
      "        [-1.5534],\n",
      "        [ 0.6924],\n",
      "        [ 0.6920],\n",
      "        [ 0.6719],\n",
      "        [ 0.6913],\n",
      "        [ 0.6942],\n",
      "        [ 0.6947],\n",
      "        [ 0.6942],\n",
      "        [ 0.6935],\n",
      "        [-1.7250],\n",
      "        [-1.0664],\n",
      "        [ 0.6918],\n",
      "        [ 0.6307],\n",
      "        [ 0.6944],\n",
      "        [ 0.6307],\n",
      "        [ 0.6918],\n",
      "        [-0.0759],\n",
      "        [ 0.5853],\n",
      "        [ 0.6939],\n",
      "        [ 0.6930],\n",
      "        [ 0.6933],\n",
      "        [ 0.6984],\n",
      "        [ 0.6984],\n",
      "        [ 0.6959],\n",
      "        [ 0.5853],\n",
      "        [-1.5835],\n",
      "        [ 0.6959],\n",
      "        [-1.6953],\n",
      "        [ 0.6947],\n",
      "        [-1.6483],\n",
      "        [ 0.6918],\n",
      "        [ 0.6307],\n",
      "        [ 0.6930],\n",
      "        [ 0.6915],\n",
      "        [ 0.6984],\n",
      "        [ 0.6930],\n",
      "        [-0.4057],\n",
      "        [ 0.6569],\n",
      "        [-1.4283],\n",
      "        [-1.5180],\n",
      "        [ 0.6947],\n",
      "        [-1.0664],\n",
      "        [ 0.6922],\n",
      "        [ 0.6984],\n",
      "        [-1.7276],\n",
      "        [ 0.6805],\n",
      "        [ 0.4732],\n",
      "        [-1.6483],\n",
      "        [ 0.6953],\n",
      "        [ 0.4732],\n",
      "        [ 0.1111],\n",
      "        [-1.7183],\n",
      "        [ 0.6922],\n",
      "        [-1.6953],\n",
      "        [ 0.6907],\n",
      "        [ 0.4318],\n",
      "        [ 0.6907],\n",
      "        [ 0.6984],\n",
      "        [ 0.6976]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 35/10000,\n",
      " train_loss: 0.2027,\n",
      " train_mae: 0.3523,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.5026],\n",
      "        [-1.5026],\n",
      "        [ 0.7172],\n",
      "        [ 0.7168],\n",
      "        [ 0.6950],\n",
      "        [ 0.7160],\n",
      "        [ 0.7188],\n",
      "        [ 0.7192],\n",
      "        [ 0.7188],\n",
      "        [ 0.7181],\n",
      "        [-1.6430],\n",
      "        [-1.0787],\n",
      "        [ 0.7165],\n",
      "        [ 0.6493],\n",
      "        [ 0.7190],\n",
      "        [ 0.6493],\n",
      "        [ 0.7165],\n",
      "        [-0.1156],\n",
      "        [ 0.5988],\n",
      "        [ 0.7186],\n",
      "        [ 0.7177],\n",
      "        [ 0.7179],\n",
      "        [ 0.7226],\n",
      "        [ 0.7226],\n",
      "        [ 0.7204],\n",
      "        [ 0.5988],\n",
      "        [-1.5276],\n",
      "        [ 0.7204],\n",
      "        [-1.6191],\n",
      "        [ 0.7192],\n",
      "        [-1.5809],\n",
      "        [ 0.7165],\n",
      "        [ 0.6493],\n",
      "        [ 0.7177],\n",
      "        [ 0.7163],\n",
      "        [ 0.7226],\n",
      "        [ 0.7177],\n",
      "        [-0.4511],\n",
      "        [ 0.6784],\n",
      "        [-1.3970],\n",
      "        [-1.4729],\n",
      "        [ 0.7192],\n",
      "        [-1.0787],\n",
      "        [ 0.7170],\n",
      "        [ 0.7226],\n",
      "        [-1.6451],\n",
      "        [ 0.7044],\n",
      "        [ 0.4744],\n",
      "        [-1.5809],\n",
      "        [ 0.7198],\n",
      "        [ 0.4744],\n",
      "        [ 0.0810],\n",
      "        [-1.6376],\n",
      "        [ 0.7170],\n",
      "        [-1.6191],\n",
      "        [ 0.7154],\n",
      "        [ 0.4286],\n",
      "        [ 0.7154],\n",
      "        [ 0.7226],\n",
      "        [ 0.7219]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 36/10000,\n",
      " train_loss: 0.1954,\n",
      " train_mae: 0.3397,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.4582],\n",
      "        [-1.4582],\n",
      "        [ 0.7295],\n",
      "        [ 0.7291],\n",
      "        [ 0.7053],\n",
      "        [ 0.7284],\n",
      "        [ 0.7310],\n",
      "        [ 0.7314],\n",
      "        [ 0.7310],\n",
      "        [ 0.7304],\n",
      "        [-1.5710],\n",
      "        [-1.0969],\n",
      "        [ 0.7289],\n",
      "        [ 0.6540],\n",
      "        [ 0.7312],\n",
      "        [ 0.6540],\n",
      "        [ 0.7289],\n",
      "        [-0.1748],\n",
      "        [ 0.5973],\n",
      "        [ 0.7308],\n",
      "        [ 0.7300],\n",
      "        [ 0.7302],\n",
      "        [ 0.7344],\n",
      "        [ 0.7344],\n",
      "        [ 0.7324],\n",
      "        [ 0.5973],\n",
      "        [-1.4785],\n",
      "        [ 0.7324],\n",
      "        [-1.5520],\n",
      "        [ 0.7314],\n",
      "        [-1.5216],\n",
      "        [ 0.7289],\n",
      "        [ 0.6540],\n",
      "        [ 0.7300],\n",
      "        [ 0.7286],\n",
      "        [ 0.7344],\n",
      "        [ 0.7300],\n",
      "        [-0.5118],\n",
      "        [ 0.6867],\n",
      "        [-1.3709],\n",
      "        [-1.4339],\n",
      "        [ 0.7314],\n",
      "        [-1.0969],\n",
      "        [ 0.7293],\n",
      "        [ 0.7344],\n",
      "        [-1.5727],\n",
      "        [ 0.7157],\n",
      "        [ 0.4580],\n",
      "        [-1.5216],\n",
      "        [ 0.7319],\n",
      "        [ 0.4580],\n",
      "        [ 0.0305],\n",
      "        [-1.5667],\n",
      "        [ 0.7293],\n",
      "        [-1.5520],\n",
      "        [ 0.7277],\n",
      "        [ 0.4073],\n",
      "        [ 0.7277],\n",
      "        [ 0.7344],\n",
      "        [ 0.7338]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 37/10000,\n",
      " train_loss: 0.1871,\n",
      " train_mae: 0.3298,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.4242],\n",
      "        [-1.4242],\n",
      "        [ 0.7281],\n",
      "        [ 0.7277],\n",
      "        [ 0.7012],\n",
      "        [ 0.7269],\n",
      "        [ 0.7295],\n",
      "        [ 0.7299],\n",
      "        [ 0.7295],\n",
      "        [ 0.7290],\n",
      "        [-1.5130],\n",
      "        [-1.1232],\n",
      "        [ 0.7275],\n",
      "        [ 0.6429],\n",
      "        [ 0.7297],\n",
      "        [ 0.6429],\n",
      "        [ 0.7275],\n",
      "        [-0.2561],\n",
      "        [ 0.5783],\n",
      "        [ 0.7293],\n",
      "        [ 0.7286],\n",
      "        [ 0.7288],\n",
      "        [ 0.7326],\n",
      "        [ 0.7326],\n",
      "        [ 0.7308],\n",
      "        [ 0.5783],\n",
      "        [-1.4404],\n",
      "        [ 0.7308],\n",
      "        [-1.4982],\n",
      "        [ 0.7299],\n",
      "        [-1.4745],\n",
      "        [ 0.7275],\n",
      "        [ 0.6429],\n",
      "        [ 0.7286],\n",
      "        [ 0.7272],\n",
      "        [ 0.7326],\n",
      "        [ 0.7286],\n",
      "        [-0.5893],\n",
      "        [ 0.6801],\n",
      "        [-1.3536],\n",
      "        [-1.4047],\n",
      "        [ 0.7299],\n",
      "        [-1.1232],\n",
      "        [ 0.7279],\n",
      "        [ 0.7326],\n",
      "        [-1.5144],\n",
      "        [ 0.7129],\n",
      "        [ 0.4212],\n",
      "        [-1.4745],\n",
      "        [ 0.7303],\n",
      "        [ 0.4212],\n",
      "        [-0.0436],\n",
      "        [-1.5096],\n",
      "        [ 0.7279],\n",
      "        [-1.4982],\n",
      "        [ 0.7263],\n",
      "        [ 0.3645],\n",
      "        [ 0.7263],\n",
      "        [ 0.7326],\n",
      "        [ 0.7321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 38/10000,\n",
      " train_loss: 0.1768,\n",
      " train_mae: 0.3201,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.4011],\n",
      "        [-1.4011],\n",
      "        [ 0.7140],\n",
      "        [ 0.7136],\n",
      "        [ 0.6837],\n",
      "        [ 0.7128],\n",
      "        [ 0.7154],\n",
      "        [ 0.7158],\n",
      "        [ 0.7154],\n",
      "        [ 0.7149],\n",
      "        [-1.4697],\n",
      "        [-1.1560],\n",
      "        [ 0.7134],\n",
      "        [ 0.6166],\n",
      "        [ 0.7156],\n",
      "        [ 0.6166],\n",
      "        [ 0.7134],\n",
      "        [-0.3571],\n",
      "        [ 0.5422],\n",
      "        [ 0.7152],\n",
      "        [ 0.7145],\n",
      "        [ 0.7147],\n",
      "        [ 0.7183],\n",
      "        [ 0.7183],\n",
      "        [ 0.7166],\n",
      "        [ 0.5422],\n",
      "        [-1.4137],\n",
      "        [ 0.7166],\n",
      "        [-1.4583],\n",
      "        [ 0.7158],\n",
      "        [-1.4401],\n",
      "        [ 0.7134],\n",
      "        [ 0.6166],\n",
      "        [ 0.7145],\n",
      "        [ 0.7131],\n",
      "        [ 0.7183],\n",
      "        [ 0.7145],\n",
      "        [-0.6804],\n",
      "        [ 0.6595],\n",
      "        [-1.3453],\n",
      "        [-1.3858],\n",
      "        [ 0.7158],\n",
      "        [-1.1560],\n",
      "        [ 0.7138],\n",
      "        [ 0.7183],\n",
      "        [-1.4708],\n",
      "        [ 0.6971],\n",
      "        [ 0.3634],\n",
      "        [-1.4401],\n",
      "        [ 0.7162],\n",
      "        [ 0.3634],\n",
      "        [-0.1402],\n",
      "        [-1.4671],\n",
      "        [ 0.7138],\n",
      "        [-1.4583],\n",
      "        [ 0.7121],\n",
      "        [ 0.2999],\n",
      "        [ 0.7121],\n",
      "        [ 0.7183],\n",
      "        [ 0.7177]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 39/10000,\n",
      " train_loss: 0.1648,\n",
      " train_mae: 0.3107,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3864],\n",
      "        [-1.3864],\n",
      "        [ 0.6906],\n",
      "        [ 0.6902],\n",
      "        [ 0.6559],\n",
      "        [ 0.6894],\n",
      "        [ 0.6919],\n",
      "        [ 0.6923],\n",
      "        [ 0.6919],\n",
      "        [ 0.6914],\n",
      "        [-1.4386],\n",
      "        [-1.1911],\n",
      "        [ 0.6899],\n",
      "        [ 0.5777],\n",
      "        [ 0.6921],\n",
      "        [ 0.5777],\n",
      "        [ 0.6899],\n",
      "        [-0.4715],\n",
      "        [ 0.4914],\n",
      "        [ 0.6918],\n",
      "        [ 0.6911],\n",
      "        [ 0.6913],\n",
      "        [ 0.6946],\n",
      "        [ 0.6946],\n",
      "        [ 0.6931],\n",
      "        [ 0.4914],\n",
      "        [-1.3961],\n",
      "        [ 0.6931],\n",
      "        [-1.4299],\n",
      "        [ 0.6923],\n",
      "        [-1.4161],\n",
      "        [ 0.6899],\n",
      "        [ 0.5777],\n",
      "        [ 0.6911],\n",
      "        [ 0.6897],\n",
      "        [ 0.6946],\n",
      "        [ 0.6911],\n",
      "        [-0.7776],\n",
      "        [ 0.6278],\n",
      "        [-1.3431],\n",
      "        [-1.3746],\n",
      "        [ 0.6923],\n",
      "        [-1.1911],\n",
      "        [ 0.6904],\n",
      "        [ 0.6946],\n",
      "        [-1.4395],\n",
      "        [ 0.6715],\n",
      "        [ 0.2872],\n",
      "        [-1.4161],\n",
      "        [ 0.6927],\n",
      "        [ 0.2872],\n",
      "        [-0.2543],\n",
      "        [-1.4365],\n",
      "        [ 0.6904],\n",
      "        [-1.4299],\n",
      "        [ 0.6886],\n",
      "        [ 0.2161],\n",
      "        [ 0.6886],\n",
      "        [ 0.6946],\n",
      "        [ 0.6941]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 40/10000,\n",
      " train_loss: 0.1527,\n",
      " train_mae: 0.3030,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3756],\n",
      "        [-1.3756],\n",
      "        [ 0.6627],\n",
      "        [ 0.6622],\n",
      "        [ 0.6226],\n",
      "        [ 0.6613],\n",
      "        [ 0.6640],\n",
      "        [ 0.6643],\n",
      "        [ 0.6640],\n",
      "        [ 0.6635],\n",
      "        [-1.4150],\n",
      "        [-1.2226],\n",
      "        [ 0.6620],\n",
      "        [ 0.5308],\n",
      "        [ 0.6642],\n",
      "        [ 0.5308],\n",
      "        [ 0.6620],\n",
      "        [-0.5892],\n",
      "        [ 0.4301],\n",
      "        [ 0.6638],\n",
      "        [ 0.6632],\n",
      "        [ 0.6634],\n",
      "        [ 0.6665],\n",
      "        [ 0.6665],\n",
      "        [ 0.6651],\n",
      "        [ 0.4301],\n",
      "        [-1.3830],\n",
      "        [ 0.6651],\n",
      "        [-1.4083],\n",
      "        [ 0.6643],\n",
      "        [-1.3980],\n",
      "        [ 0.6620],\n",
      "        [ 0.5308],\n",
      "        [ 0.6632],\n",
      "        [ 0.6617],\n",
      "        [ 0.6665],\n",
      "        [ 0.6632],\n",
      "        [-0.8717],\n",
      "        [ 0.5895],\n",
      "        [-1.3425],\n",
      "        [-1.3666],\n",
      "        [ 0.6643],\n",
      "        [-1.2226],\n",
      "        [ 0.6625],\n",
      "        [ 0.6665],\n",
      "        [-1.4157],\n",
      "        [ 0.6408],\n",
      "        [ 0.1972],\n",
      "        [-1.3980],\n",
      "        [ 0.6647],\n",
      "        [ 0.1972],\n",
      "        [-0.3769],\n",
      "        [-1.4134],\n",
      "        [ 0.6625],\n",
      "        [-1.4083],\n",
      "        [ 0.6605],\n",
      "        [ 0.1181],\n",
      "        [ 0.6605],\n",
      "        [ 0.6665],\n",
      "        [ 0.6661]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 41/10000,\n",
      " train_loss: 0.1420,\n",
      " train_mae: 0.2965,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3635],\n",
      "        [-1.3635],\n",
      "        [ 0.6356],\n",
      "        [ 0.6352],\n",
      "        [ 0.5889],\n",
      "        [ 0.6342],\n",
      "        [ 0.6369],\n",
      "        [ 0.6373],\n",
      "        [ 0.6369],\n",
      "        [ 0.6365],\n",
      "        [-1.3931],\n",
      "        [-1.2451],\n",
      "        [ 0.6349],\n",
      "        [ 0.4807],\n",
      "        [ 0.6371],\n",
      "        [ 0.4807],\n",
      "        [ 0.6349],\n",
      "        [-0.6998],\n",
      "        [ 0.3632],\n",
      "        [ 0.6368],\n",
      "        [ 0.6362],\n",
      "        [ 0.6363],\n",
      "        [ 0.6393],\n",
      "        [ 0.6393],\n",
      "        [ 0.6380],\n",
      "        [ 0.3632],\n",
      "        [-1.3690],\n",
      "        [ 0.6380],\n",
      "        [-1.3880],\n",
      "        [ 0.6373],\n",
      "        [-1.3803],\n",
      "        [ 0.6349],\n",
      "        [ 0.4807],\n",
      "        [ 0.6362],\n",
      "        [ 0.6346],\n",
      "        [ 0.6393],\n",
      "        [ 0.6362],\n",
      "        [-0.9535],\n",
      "        [ 0.5499],\n",
      "        [-1.3385],\n",
      "        [-1.3568],\n",
      "        [ 0.6373],\n",
      "        [-1.2451],\n",
      "        [ 0.6354],\n",
      "        [ 0.6393],\n",
      "        [-1.3937],\n",
      "        [ 0.6104],\n",
      "        [ 0.0996],\n",
      "        [-1.3803],\n",
      "        [ 0.6376],\n",
      "        [ 0.0996],\n",
      "        [-0.4977],\n",
      "        [-1.3918],\n",
      "        [ 0.6354],\n",
      "        [-1.3880],\n",
      "        [ 0.6332],\n",
      "        [ 0.0128],\n",
      "        [ 0.6332],\n",
      "        [ 0.6393],\n",
      "        [ 0.6389]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 42/10000,\n",
      " train_loss: 0.1337,\n",
      " train_mae: 0.2911,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3454e+00],\n",
      "        [-1.3454e+00],\n",
      "        [ 6.1441e-01],\n",
      "        [ 6.1393e-01],\n",
      "        [ 5.5982e-01],\n",
      "        [ 6.1286e-01],\n",
      "        [ 6.1575e-01],\n",
      "        [ 6.1606e-01],\n",
      "        [ 6.1575e-01],\n",
      "        [ 6.1530e-01],\n",
      "        [-1.3677e+00],\n",
      "        [-1.2544e+00],\n",
      "        [ 6.1363e-01],\n",
      "        [ 4.3222e-01],\n",
      "        [ 6.1591e-01],\n",
      "        [ 4.3222e-01],\n",
      "        [ 6.1363e-01],\n",
      "        [-7.9366e-01],\n",
      "        [ 2.9588e-01],\n",
      "        [ 6.1560e-01],\n",
      "        [ 6.1498e-01],\n",
      "        [ 6.1514e-01],\n",
      "        [ 6.1804e-01],\n",
      "        [ 6.1804e-01],\n",
      "        [ 6.1675e-01],\n",
      "        [ 2.9588e-01],\n",
      "        [-1.3495e+00],\n",
      "        [ 6.1675e-01],\n",
      "        [-1.3637e+00],\n",
      "        [ 6.1606e-01],\n",
      "        [-1.3579e+00],\n",
      "        [ 6.1363e-01],\n",
      "        [ 4.3222e-01],\n",
      "        [ 6.1498e-01],\n",
      "        [ 6.1327e-01],\n",
      "        [ 6.1804e-01],\n",
      "        [ 6.1498e-01],\n",
      "        [-1.0160e+00],\n",
      "        [ 5.1370e-01],\n",
      "        [-1.3265e+00],\n",
      "        [-1.3403e+00],\n",
      "        [ 6.1606e-01],\n",
      "        [-1.2544e+00],\n",
      "        [ 6.1419e-01],\n",
      "        [ 6.1804e-01],\n",
      "        [-1.3682e+00],\n",
      "        [ 5.8514e-01],\n",
      "        [ 1.0847e-03],\n",
      "        [-1.3579e+00],\n",
      "        [ 6.1639e-01],\n",
      "        [ 1.0847e-03],\n",
      "        [-6.0650e-01],\n",
      "        [-1.3666e+00],\n",
      "        [ 6.1419e-01],\n",
      "        [-1.3637e+00],\n",
      "        [ 6.1177e-01],\n",
      "        [-9.2384e-02],\n",
      "        [ 6.1177e-01],\n",
      "        [ 6.1804e-01],\n",
      "        [ 6.1763e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 43/10000,\n",
      " train_loss: 0.1273,\n",
      " train_mae: 0.2864,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.3181],\n",
      "        [-1.3181],\n",
      "        [ 0.6027],\n",
      "        [ 0.6021],\n",
      "        [ 0.5387],\n",
      "        [ 0.6010],\n",
      "        [ 0.6040],\n",
      "        [ 0.6043],\n",
      "        [ 0.6040],\n",
      "        [ 0.6036],\n",
      "        [-1.3350],\n",
      "        [-1.2484],\n",
      "        [ 0.6018],\n",
      "        [ 0.3888],\n",
      "        [ 0.6042],\n",
      "        [ 0.3888],\n",
      "        [ 0.6018],\n",
      "        [-0.8649],\n",
      "        [ 0.2320],\n",
      "        [ 0.6039],\n",
      "        [ 0.6033],\n",
      "        [ 0.6034],\n",
      "        [ 0.6062],\n",
      "        [ 0.6062],\n",
      "        [ 0.6050],\n",
      "        [ 0.2320],\n",
      "        [-1.3212],\n",
      "        [ 0.6050],\n",
      "        [-1.3318],\n",
      "        [ 0.6043],\n",
      "        [-1.3275],\n",
      "        [ 0.6018],\n",
      "        [ 0.3888],\n",
      "        [ 0.6033],\n",
      "        [ 0.6014],\n",
      "        [ 0.6062],\n",
      "        [ 0.6033],\n",
      "        [-1.0558],\n",
      "        [ 0.4843],\n",
      "        [-1.3038],\n",
      "        [-1.3143],\n",
      "        [ 0.6043],\n",
      "        [-1.2484],\n",
      "        [ 0.6024],\n",
      "        [ 0.6062],\n",
      "        [-1.3354],\n",
      "        [ 0.5686],\n",
      "        [-0.0923],\n",
      "        [-1.3275],\n",
      "        [ 0.6047],\n",
      "        [-0.0923],\n",
      "        [-0.6959],\n",
      "        [-1.3341],\n",
      "        [ 0.6024],\n",
      "        [-1.3318],\n",
      "        [ 0.5997],\n",
      "        [-0.1908],\n",
      "        [ 0.5997],\n",
      "        [ 0.6062],\n",
      "        [ 0.6058]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 44/10000,\n",
      " train_loss: 0.1217,\n",
      " train_mae: 0.2788,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2810],\n",
      "        [-1.2810],\n",
      "        [ 0.6021],\n",
      "        [ 0.6015],\n",
      "        [ 0.5271],\n",
      "        [ 0.6002],\n",
      "        [ 0.6035],\n",
      "        [ 0.6038],\n",
      "        [ 0.6035],\n",
      "        [ 0.6030],\n",
      "        [-1.2940],\n",
      "        [-1.2275],\n",
      "        [ 0.6011],\n",
      "        [ 0.3520],\n",
      "        [ 0.6036],\n",
      "        [ 0.3520],\n",
      "        [ 0.6011],\n",
      "        [-0.9117],\n",
      "        [ 0.1738],\n",
      "        [ 0.6033],\n",
      "        [ 0.6027],\n",
      "        [ 0.6029],\n",
      "        [ 0.6056],\n",
      "        [ 0.6056],\n",
      "        [ 0.6044],\n",
      "        [ 0.1738],\n",
      "        [-1.2833],\n",
      "        [ 0.6044],\n",
      "        [-1.2914],\n",
      "        [ 0.6038],\n",
      "        [-1.2881],\n",
      "        [ 0.6011],\n",
      "        [ 0.3520],\n",
      "        [ 0.6027],\n",
      "        [ 0.6007],\n",
      "        [ 0.6056],\n",
      "        [ 0.6027],\n",
      "        [-1.0730],\n",
      "        [ 0.4631],\n",
      "        [-1.2701],\n",
      "        [-1.2781],\n",
      "        [ 0.6038],\n",
      "        [-1.2275],\n",
      "        [ 0.6018],\n",
      "        [ 0.6056],\n",
      "        [-1.2944],\n",
      "        [ 0.5623],\n",
      "        [-0.1764],\n",
      "        [-1.2881],\n",
      "        [ 0.6041],\n",
      "        [-0.1764],\n",
      "        [-0.7622],\n",
      "        [-1.2933],\n",
      "        [ 0.6018],\n",
      "        [-1.2914],\n",
      "        [ 0.5988],\n",
      "        [-0.2777],\n",
      "        [ 0.5988],\n",
      "        [ 0.6056],\n",
      "        [ 0.6052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 45/10000,\n",
      " train_loss: 0.1160,\n",
      " train_mae: 0.2709,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2361],\n",
      "        [-1.2361],\n",
      "        [ 0.6122],\n",
      "        [ 0.6116],\n",
      "        [ 0.5244],\n",
      "        [ 0.6101],\n",
      "        [ 0.6137],\n",
      "        [ 0.6140],\n",
      "        [ 0.6137],\n",
      "        [ 0.6132],\n",
      "        [-1.2464],\n",
      "        [-1.1949],\n",
      "        [ 0.6112],\n",
      "        [ 0.3212],\n",
      "        [ 0.6139],\n",
      "        [ 0.3212],\n",
      "        [ 0.6112],\n",
      "        [-0.9365],\n",
      "        [ 0.1213],\n",
      "        [ 0.6136],\n",
      "        [ 0.6129],\n",
      "        [ 0.6131],\n",
      "        [ 0.6158],\n",
      "        [ 0.6158],\n",
      "        [ 0.6146],\n",
      "        [ 0.1213],\n",
      "        [-1.2379],\n",
      "        [ 0.6146],\n",
      "        [-1.2441],\n",
      "        [ 0.6140],\n",
      "        [-1.2415],\n",
      "        [ 0.6112],\n",
      "        [ 0.3212],\n",
      "        [ 0.6129],\n",
      "        [ 0.6107],\n",
      "        [ 0.6158],\n",
      "        [ 0.6129],\n",
      "        [-1.0714],\n",
      "        [ 0.4495],\n",
      "        [-1.2279],\n",
      "        [-1.2339],\n",
      "        [ 0.6140],\n",
      "        [-1.1949],\n",
      "        [ 0.6119],\n",
      "        [ 0.6158],\n",
      "        [-1.2467],\n",
      "        [ 0.5659],\n",
      "        [-0.2496],\n",
      "        [-1.2415],\n",
      "        [ 0.6143],\n",
      "        [-0.2496],\n",
      "        [-0.8065],\n",
      "        [-1.2457],\n",
      "        [ 0.6119],\n",
      "        [-1.2441],\n",
      "        [ 0.6085],\n",
      "        [-0.3515],\n",
      "        [ 0.6085],\n",
      "        [ 0.6158],\n",
      "        [ 0.6154]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 46/10000,\n",
      " train_loss: 0.1102,\n",
      " train_mae: 0.2624,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1879],\n",
      "        [-1.1879],\n",
      "        [ 0.6309],\n",
      "        [ 0.6302],\n",
      "        [ 0.5281],\n",
      "        [ 0.6285],\n",
      "        [ 0.6325],\n",
      "        [ 0.6328],\n",
      "        [ 0.6325],\n",
      "        [ 0.6320],\n",
      "        [-1.1961],\n",
      "        [-1.1559],\n",
      "        [ 0.6297],\n",
      "        [ 0.2939],\n",
      "        [ 0.6326],\n",
      "        [ 0.2939],\n",
      "        [ 0.6297],\n",
      "        [-0.9450],\n",
      "        [ 0.0725],\n",
      "        [ 0.6323],\n",
      "        [ 0.6316],\n",
      "        [ 0.6318],\n",
      "        [ 0.6345],\n",
      "        [ 0.6345],\n",
      "        [ 0.6334],\n",
      "        [ 0.0725],\n",
      "        [-1.1893],\n",
      "        [ 0.6334],\n",
      "        [-1.1941],\n",
      "        [ 0.6328],\n",
      "        [-1.1921],\n",
      "        [ 0.6297],\n",
      "        [ 0.2939],\n",
      "        [ 0.6316],\n",
      "        [ 0.6292],\n",
      "        [ 0.6345],\n",
      "        [ 0.6316],\n",
      "        [-1.0570],\n",
      "        [ 0.4408],\n",
      "        [-1.1815],\n",
      "        [-1.1862],\n",
      "        [ 0.6328],\n",
      "        [-1.1559],\n",
      "        [ 0.6306],\n",
      "        [ 0.6345],\n",
      "        [-1.1964],\n",
      "        [ 0.5768],\n",
      "        [-0.3131],\n",
      "        [-1.1921],\n",
      "        [ 0.6331],\n",
      "        [-0.3131],\n",
      "        [-0.8333],\n",
      "        [-1.1955],\n",
      "        [ 0.6306],\n",
      "        [-1.1941],\n",
      "        [ 0.6267],\n",
      "        [-0.4135],\n",
      "        [ 0.6267],\n",
      "        [ 0.6345],\n",
      "        [ 0.6341]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 47/10000,\n",
      " train_loss: 0.1046,\n",
      " train_mae: 0.2575,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1420],\n",
      "        [-1.1420],\n",
      "        [ 0.6547],\n",
      "        [ 0.6539],\n",
      "        [ 0.5343],\n",
      "        [ 0.6520],\n",
      "        [ 0.6563],\n",
      "        [ 0.6566],\n",
      "        [ 0.6563],\n",
      "        [ 0.6559],\n",
      "        [-1.1487],\n",
      "        [-1.1169],\n",
      "        [ 0.6534],\n",
      "        [ 0.2660],\n",
      "        [ 0.6565],\n",
      "        [ 0.2660],\n",
      "        [ 0.6534],\n",
      "        [-0.9447],\n",
      "        [ 0.0239],\n",
      "        [ 0.6562],\n",
      "        [ 0.6555],\n",
      "        [ 0.6557],\n",
      "        [ 0.6584],\n",
      "        [ 0.6584],\n",
      "        [ 0.6573],\n",
      "        [ 0.0239],\n",
      "        [-1.1431],\n",
      "        [ 0.6573],\n",
      "        [-1.1470],\n",
      "        [ 0.6566],\n",
      "        [-1.1453],\n",
      "        [ 0.6534],\n",
      "        [ 0.2660],\n",
      "        [ 0.6555],\n",
      "        [ 0.6527],\n",
      "        [ 0.6584],\n",
      "        [ 0.6555],\n",
      "        [-1.0375],\n",
      "        [ 0.4329],\n",
      "        [-1.1371],\n",
      "        [-1.1407],\n",
      "        [ 0.6566],\n",
      "        [-1.1169],\n",
      "        [ 0.6543],\n",
      "        [ 0.6584],\n",
      "        [-1.1490],\n",
      "        [ 0.5914],\n",
      "        [-0.3703],\n",
      "        [-1.1453],\n",
      "        [ 0.6569],\n",
      "        [-0.3703],\n",
      "        [-0.8494],\n",
      "        [-1.1482],\n",
      "        [ 0.6543],\n",
      "        [-1.1470],\n",
      "        [ 0.6498],\n",
      "        [-0.4673],\n",
      "        [ 0.6498],\n",
      "        [ 0.6584],\n",
      "        [ 0.6580]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 48/10000,\n",
      " train_loss: 0.0999,\n",
      " train_mae: 0.2556,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1043],\n",
      "        [-1.1043],\n",
      "        [ 0.6798],\n",
      "        [ 0.6789],\n",
      "        [ 0.5387],\n",
      "        [ 0.6767],\n",
      "        [ 0.6816],\n",
      "        [ 0.6819],\n",
      "        [ 0.6816],\n",
      "        [ 0.6811],\n",
      "        [-1.1099],\n",
      "        [-1.0844],\n",
      "        [ 0.6783],\n",
      "        [ 0.2330],\n",
      "        [ 0.6818],\n",
      "        [ 0.2330],\n",
      "        [ 0.6783],\n",
      "        [-0.9432],\n",
      "        [-0.0285],\n",
      "        [ 0.6815],\n",
      "        [ 0.6807],\n",
      "        [ 0.6809],\n",
      "        [ 0.6836],\n",
      "        [ 0.6836],\n",
      "        [ 0.6825],\n",
      "        [-0.0285],\n",
      "        [-1.1051],\n",
      "        [ 0.6825],\n",
      "        [-1.1083],\n",
      "        [ 0.6819],\n",
      "        [-1.1069],\n",
      "        [ 0.6783],\n",
      "        [ 0.2330],\n",
      "        [ 0.6807],\n",
      "        [ 0.6776],\n",
      "        [ 0.6836],\n",
      "        [ 0.6807],\n",
      "        [-1.0202],\n",
      "        [ 0.4212],\n",
      "        [-1.1004],\n",
      "        [-1.1032],\n",
      "        [ 0.6819],\n",
      "        [-1.0844],\n",
      "        [ 0.6794],\n",
      "        [ 0.6836],\n",
      "        [-1.1102],\n",
      "        [ 0.6056],\n",
      "        [-0.4254],\n",
      "        [-1.1069],\n",
      "        [ 0.6822],\n",
      "        [-0.4254],\n",
      "        [-0.8621],\n",
      "        [-1.1094],\n",
      "        [ 0.6794],\n",
      "        [-1.1083],\n",
      "        [ 0.6743],\n",
      "        [-0.5178],\n",
      "        [ 0.6743],\n",
      "        [ 0.6836],\n",
      "        [ 0.6833]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 49/10000,\n",
      " train_loss: 0.0958,\n",
      " train_mae: 0.2540,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0791],\n",
      "        [-1.0791],\n",
      "        [ 0.7032],\n",
      "        [ 0.7022],\n",
      "        [ 0.5374],\n",
      "        [ 0.6996],\n",
      "        [ 0.7051],\n",
      "        [ 0.7054],\n",
      "        [ 0.7051],\n",
      "        [ 0.7046],\n",
      "        [-1.0839],\n",
      "        [-1.0631],\n",
      "        [ 0.7015],\n",
      "        [ 0.1912],\n",
      "        [ 0.7053],\n",
      "        [ 0.1912],\n",
      "        [ 0.7015],\n",
      "        [-0.9466],\n",
      "        [-0.0881],\n",
      "        [ 0.7050],\n",
      "        [ 0.7042],\n",
      "        [ 0.7044],\n",
      "        [ 0.7071],\n",
      "        [ 0.7071],\n",
      "        [ 0.7061],\n",
      "        [-0.0881],\n",
      "        [-1.0798],\n",
      "        [ 0.7061],\n",
      "        [-1.0824],\n",
      "        [ 0.7054],\n",
      "        [-1.0812],\n",
      "        [ 0.7015],\n",
      "        [ 0.1912],\n",
      "        [ 0.7042],\n",
      "        [ 0.7007],\n",
      "        [ 0.7071],\n",
      "        [ 0.7042],\n",
      "        [-1.0108],\n",
      "        [ 0.4019],\n",
      "        [-1.0759],\n",
      "        [-1.0782],\n",
      "        [ 0.7054],\n",
      "        [-1.0631],\n",
      "        [ 0.7027],\n",
      "        [ 0.7071],\n",
      "        [-1.0842],\n",
      "        [ 0.6158],\n",
      "        [-0.4825],\n",
      "        [-1.0812],\n",
      "        [ 0.7057],\n",
      "        [-0.4825],\n",
      "        [-0.8777],\n",
      "        [-1.0834],\n",
      "        [ 0.7027],\n",
      "        [-1.0824],\n",
      "        [ 0.6968],\n",
      "        [-0.5695],\n",
      "        [ 0.6968],\n",
      "        [ 0.7071],\n",
      "        [ 0.7068]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 50/10000,\n",
      " train_loss: 0.0922,\n",
      " train_mae: 0.2505,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0685],\n",
      "        [-1.0685],\n",
      "        [ 0.7227],\n",
      "        [ 0.7216],\n",
      "        [ 0.5280],\n",
      "        [ 0.7186],\n",
      "        [ 0.7249],\n",
      "        [ 0.7252],\n",
      "        [ 0.7249],\n",
      "        [ 0.7243],\n",
      "        [-1.0728],\n",
      "        [-1.0555],\n",
      "        [ 0.7208],\n",
      "        [ 0.1385],\n",
      "        [ 0.7251],\n",
      "        [ 0.1385],\n",
      "        [ 0.7208],\n",
      "        [-0.9586],\n",
      "        [-0.1562],\n",
      "        [ 0.7247],\n",
      "        [ 0.7238],\n",
      "        [ 0.7241],\n",
      "        [ 0.7269],\n",
      "        [ 0.7269],\n",
      "        [ 0.7258],\n",
      "        [-0.1562],\n",
      "        [-1.0691],\n",
      "        [ 0.7258],\n",
      "        [-1.0713],\n",
      "        [ 0.7252],\n",
      "        [-1.0703],\n",
      "        [ 0.7208],\n",
      "        [ 0.1385],\n",
      "        [ 0.7238],\n",
      "        [ 0.7198],\n",
      "        [ 0.7269],\n",
      "        [ 0.7238],\n",
      "        [-1.0124],\n",
      "        [ 0.3724],\n",
      "        [-1.0659],\n",
      "        [-1.0678],\n",
      "        [ 0.7252],\n",
      "        [-1.0555],\n",
      "        [ 0.7222],\n",
      "        [ 0.7269],\n",
      "        [-1.0730],\n",
      "        [ 0.6197],\n",
      "        [-0.5437],\n",
      "        [-1.0703],\n",
      "        [ 0.7255],\n",
      "        [-0.5437],\n",
      "        [-0.8998],\n",
      "        [-1.0723],\n",
      "        [ 0.7222],\n",
      "        [-1.0713],\n",
      "        [ 0.7153],\n",
      "        [-0.6248],\n",
      "        [ 0.7153],\n",
      "        [ 0.7269],\n",
      "        [ 0.7266]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 51/10000,\n",
      " train_loss: 0.0886,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0718],\n",
      "        [-1.0718],\n",
      "        [ 0.7381],\n",
      "        [ 0.7368],\n",
      "        [ 0.5099],\n",
      "        [ 0.7334],\n",
      "        [ 0.7405],\n",
      "        [ 0.7409],\n",
      "        [ 0.7405],\n",
      "        [ 0.7399],\n",
      "        [-1.0757],\n",
      "        [-1.0611],\n",
      "        [ 0.7359],\n",
      "        [ 0.0753],\n",
      "        [ 0.7407],\n",
      "        [ 0.0753],\n",
      "        [ 0.7359],\n",
      "        [-0.9796],\n",
      "        [-0.2319],\n",
      "        [ 0.7403],\n",
      "        [ 0.7394],\n",
      "        [ 0.7397],\n",
      "        [ 0.7425],\n",
      "        [ 0.7425],\n",
      "        [ 0.7415],\n",
      "        [-0.2319],\n",
      "        [-1.0723],\n",
      "        [ 0.7415],\n",
      "        [-1.0743],\n",
      "        [ 0.7409],\n",
      "        [-1.0733],\n",
      "        [ 0.7359],\n",
      "        [ 0.0753],\n",
      "        [ 0.7394],\n",
      "        [ 0.7348],\n",
      "        [ 0.7425],\n",
      "        [ 0.7394],\n",
      "        [-1.0251],\n",
      "        [ 0.3324],\n",
      "        [-1.0697],\n",
      "        [-1.0712],\n",
      "        [ 0.7409],\n",
      "        [-1.0611],\n",
      "        [ 0.7375],\n",
      "        [ 0.7425],\n",
      "        [-1.0759],\n",
      "        [ 0.6168],\n",
      "        [-0.6087],\n",
      "        [-1.0733],\n",
      "        [ 0.7412],\n",
      "        [-0.6087],\n",
      "        [-0.9291],\n",
      "        [-1.0752],\n",
      "        [ 0.7375],\n",
      "        [-1.0743],\n",
      "        [ 0.7295],\n",
      "        [-0.6838],\n",
      "        [ 0.7295],\n",
      "        [ 0.7425],\n",
      "        [ 0.7422]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 52/10000,\n",
      " train_loss: 0.0851,\n",
      " train_mae: 0.2415,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0855],\n",
      "        [-1.0855],\n",
      "        [ 0.7504],\n",
      "        [ 0.7488],\n",
      "        [ 0.4843],\n",
      "        [ 0.7448],\n",
      "        [ 0.7530],\n",
      "        [ 0.7534],\n",
      "        [ 0.7530],\n",
      "        [ 0.7524],\n",
      "        [-1.0891],\n",
      "        [-1.0765],\n",
      "        [ 0.7478],\n",
      "        [ 0.0049],\n",
      "        [ 0.7532],\n",
      "        [ 0.0049],\n",
      "        [ 0.7478],\n",
      "        [-1.0071],\n",
      "        [-0.3114],\n",
      "        [ 0.7528],\n",
      "        [ 0.7518],\n",
      "        [ 0.7521],\n",
      "        [ 0.7551],\n",
      "        [ 0.7551],\n",
      "        [ 0.7540],\n",
      "        [-0.3114],\n",
      "        [-1.0859],\n",
      "        [ 0.7540],\n",
      "        [-1.0877],\n",
      "        [ 0.7534],\n",
      "        [-1.0868],\n",
      "        [ 0.7478],\n",
      "        [ 0.0049],\n",
      "        [ 0.7518],\n",
      "        [ 0.7465],\n",
      "        [ 0.7551],\n",
      "        [ 0.7518],\n",
      "        [-1.0461],\n",
      "        [ 0.2839],\n",
      "        [-1.0837],\n",
      "        [-1.0850],\n",
      "        [ 0.7534],\n",
      "        [-1.0765],\n",
      "        [ 0.7497],\n",
      "        [ 0.7551],\n",
      "        [-1.0894],\n",
      "        [ 0.6080],\n",
      "        [-0.6749],\n",
      "        [-1.0868],\n",
      "        [ 0.7537],\n",
      "        [-0.6749],\n",
      "        [-0.9633],\n",
      "        [-1.0886],\n",
      "        [ 0.7497],\n",
      "        [-1.0877],\n",
      "        [ 0.7403],\n",
      "        [-0.7441],\n",
      "        [ 0.7403],\n",
      "        [ 0.7551],\n",
      "        [ 0.7548]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 53/10000,\n",
      " train_loss: 0.0823,\n",
      " train_mae: 0.2401,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1043],\n",
      "        [-1.1043],\n",
      "        [ 0.7614],\n",
      "        [ 0.7597],\n",
      "        [ 0.4543],\n",
      "        [ 0.7550],\n",
      "        [ 0.7644],\n",
      "        [ 0.7648],\n",
      "        [ 0.7644],\n",
      "        [ 0.7637],\n",
      "        [-1.1077],\n",
      "        [-1.0966],\n",
      "        [ 0.7585],\n",
      "        [-0.0676],\n",
      "        [ 0.7646],\n",
      "        [-0.0676],\n",
      "        [ 0.7585],\n",
      "        [-1.0366],\n",
      "        [-0.3892],\n",
      "        [ 0.7642],\n",
      "        [ 0.7630],\n",
      "        [ 0.7634],\n",
      "        [ 0.7665],\n",
      "        [ 0.7665],\n",
      "        [ 0.7655],\n",
      "        [-0.3892],\n",
      "        [-1.1047],\n",
      "        [ 0.7655],\n",
      "        [-1.1063],\n",
      "        [ 0.7648],\n",
      "        [-1.1055],\n",
      "        [ 0.7585],\n",
      "        [-0.0676],\n",
      "        [ 0.7630],\n",
      "        [ 0.7569],\n",
      "        [ 0.7665],\n",
      "        [ 0.7630],\n",
      "        [-1.0705],\n",
      "        [ 0.2310],\n",
      "        [-1.1028],\n",
      "        [-1.1039],\n",
      "        [ 0.7648],\n",
      "        [-1.0966],\n",
      "        [ 0.7606],\n",
      "        [ 0.7665],\n",
      "        [-1.1080],\n",
      "        [ 0.5958],\n",
      "        [-0.7376],\n",
      "        [-1.1055],\n",
      "        [ 0.7651],\n",
      "        [-0.7376],\n",
      "        [-0.9983],\n",
      "        [-1.1072],\n",
      "        [ 0.7606],\n",
      "        [-1.1063],\n",
      "        [ 0.7497],\n",
      "        [-0.8015],\n",
      "        [ 0.7497],\n",
      "        [ 0.7665],\n",
      "        [ 0.7662]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 54/10000,\n",
      " train_loss: 0.0806,\n",
      " train_mae: 0.2384,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1224],\n",
      "        [-1.1224],\n",
      "        [ 0.7736],\n",
      "        [ 0.7716],\n",
      "        [ 0.4239],\n",
      "        [ 0.7663],\n",
      "        [ 0.7770],\n",
      "        [ 0.7774],\n",
      "        [ 0.7770],\n",
      "        [ 0.7762],\n",
      "        [-1.1257],\n",
      "        [-1.1157],\n",
      "        [ 0.7702],\n",
      "        [-0.1359],\n",
      "        [ 0.7772],\n",
      "        [-0.1359],\n",
      "        [ 0.7702],\n",
      "        [-1.0631],\n",
      "        [-0.4593],\n",
      "        [ 0.7768],\n",
      "        [ 0.7755],\n",
      "        [ 0.7759],\n",
      "        [ 0.7791],\n",
      "        [ 0.7791],\n",
      "        [ 0.7781],\n",
      "        [-0.4593],\n",
      "        [-1.1228],\n",
      "        [ 0.7781],\n",
      "        [-1.1243],\n",
      "        [ 0.7774],\n",
      "        [-1.1235],\n",
      "        [ 0.7702],\n",
      "        [-0.1359],\n",
      "        [ 0.7755],\n",
      "        [ 0.7685],\n",
      "        [ 0.7791],\n",
      "        [ 0.7755],\n",
      "        [-1.0928],\n",
      "        [ 0.1790],\n",
      "        [-1.1211],\n",
      "        [-1.1221],\n",
      "        [ 0.7774],\n",
      "        [-1.1157],\n",
      "        [ 0.7727],\n",
      "        [ 0.7791],\n",
      "        [-1.1260],\n",
      "        [ 0.5833],\n",
      "        [-0.7919],\n",
      "        [-1.1235],\n",
      "        [ 0.7777],\n",
      "        [-0.7919],\n",
      "        [-1.0291],\n",
      "        [-1.1252],\n",
      "        [ 0.7727],\n",
      "        [-1.1243],\n",
      "        [ 0.7602],\n",
      "        [-0.8509],\n",
      "        [ 0.7602],\n",
      "        [ 0.7791],\n",
      "        [ 0.7788]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 55/10000,\n",
      " train_loss: 0.0802,\n",
      " train_mae: 0.2371,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1350],\n",
      "        [-1.1350],\n",
      "        [ 0.7887],\n",
      "        [ 0.7864],\n",
      "        [ 0.3971],\n",
      "        [ 0.7804],\n",
      "        [ 0.7924],\n",
      "        [ 0.7928],\n",
      "        [ 0.7924],\n",
      "        [ 0.7916],\n",
      "        [-1.1382],\n",
      "        [-1.1289],\n",
      "        [ 0.7848],\n",
      "        [-0.1944],\n",
      "        [ 0.7926],\n",
      "        [-0.1944],\n",
      "        [ 0.7848],\n",
      "        [-1.0819],\n",
      "        [-0.5165],\n",
      "        [ 0.7922],\n",
      "        [ 0.7907],\n",
      "        [ 0.7912],\n",
      "        [ 0.7946],\n",
      "        [ 0.7946],\n",
      "        [ 0.7935],\n",
      "        [-0.5165],\n",
      "        [-1.1353],\n",
      "        [ 0.7935],\n",
      "        [-1.1367],\n",
      "        [ 0.7928],\n",
      "        [-1.1360],\n",
      "        [ 0.7848],\n",
      "        [-0.1944],\n",
      "        [ 0.7907],\n",
      "        [ 0.7829],\n",
      "        [ 0.7946],\n",
      "        [ 0.7907],\n",
      "        [-1.1086],\n",
      "        [ 0.1329],\n",
      "        [-1.1337],\n",
      "        [-1.1346],\n",
      "        [ 0.7928],\n",
      "        [-1.1289],\n",
      "        [ 0.7877],\n",
      "        [ 0.7946],\n",
      "        [-1.1385],\n",
      "        [ 0.5736],\n",
      "        [-0.8337],\n",
      "        [-1.1360],\n",
      "        [ 0.7932],\n",
      "        [-0.8337],\n",
      "        [-1.0514],\n",
      "        [-1.1376],\n",
      "        [ 0.7877],\n",
      "        [-1.1367],\n",
      "        [ 0.7734],\n",
      "        [-0.8886],\n",
      "        [ 0.7734],\n",
      "        [ 0.7946],\n",
      "        [ 0.7943]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 56/10000,\n",
      " train_loss: 0.0806,\n",
      " train_mae: 0.2407,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1390],\n",
      "        [-1.1390],\n",
      "        [ 0.8072],\n",
      "        [ 0.8047],\n",
      "        [ 0.3765],\n",
      "        [ 0.7979],\n",
      "        [ 0.8113],\n",
      "        [ 0.8117],\n",
      "        [ 0.8113],\n",
      "        [ 0.8104],\n",
      "        [-1.1421],\n",
      "        [-1.1335],\n",
      "        [ 0.8029],\n",
      "        [-0.2394],\n",
      "        [ 0.8115],\n",
      "        [-0.2394],\n",
      "        [ 0.8029],\n",
      "        [-1.0907],\n",
      "        [-0.5582],\n",
      "        [ 0.8110],\n",
      "        [ 0.8095],\n",
      "        [ 0.8100],\n",
      "        [ 0.8136],\n",
      "        [ 0.8136],\n",
      "        [ 0.8125],\n",
      "        [-0.5582],\n",
      "        [-1.1393],\n",
      "        [ 0.8125],\n",
      "        [-1.1407],\n",
      "        [ 0.8117],\n",
      "        [-1.1399],\n",
      "        [ 0.8029],\n",
      "        [-0.2394],\n",
      "        [ 0.8095],\n",
      "        [ 0.8007],\n",
      "        [ 0.8136],\n",
      "        [ 0.8095],\n",
      "        [-1.1150],\n",
      "        [ 0.0963],\n",
      "        [-1.1378],\n",
      "        [-1.1387],\n",
      "        [ 0.8117],\n",
      "        [-1.1335],\n",
      "        [ 0.8061],\n",
      "        [ 0.8136],\n",
      "        [-1.1425],\n",
      "        [ 0.5684],\n",
      "        [-0.8611],\n",
      "        [-1.1399],\n",
      "        [ 0.8121],\n",
      "        [-0.8611],\n",
      "        [-1.0628],\n",
      "        [-1.1416],\n",
      "        [ 0.8061],\n",
      "        [-1.1407],\n",
      "        [ 0.7901],\n",
      "        [-0.9124],\n",
      "        [ 0.7901],\n",
      "        [ 0.8136],\n",
      "        [ 0.8132]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 57/10000,\n",
      " train_loss: 0.0813,\n",
      " train_mae: 0.2435,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1342],\n",
      "        [-1.1342],\n",
      "        [ 0.8284],\n",
      "        [ 0.8256],\n",
      "        [ 0.3632],\n",
      "        [ 0.8182],\n",
      "        [ 0.8329],\n",
      "        [ 0.8333],\n",
      "        [ 0.8329],\n",
      "        [ 0.8319],\n",
      "        [-1.1374],\n",
      "        [-1.1291],\n",
      "        [ 0.8237],\n",
      "        [-0.2702],\n",
      "        [ 0.8331],\n",
      "        [-0.2702],\n",
      "        [ 0.8237],\n",
      "        [-1.0895],\n",
      "        [-0.5842],\n",
      "        [ 0.8326],\n",
      "        [ 0.8309],\n",
      "        [ 0.8315],\n",
      "        [ 0.8352],\n",
      "        [ 0.8352],\n",
      "        [ 0.8341],\n",
      "        [-0.5842],\n",
      "        [-1.1345],\n",
      "        [ 0.8341],\n",
      "        [-1.1359],\n",
      "        [ 0.8333],\n",
      "        [-1.1351],\n",
      "        [ 0.8237],\n",
      "        [-0.2702],\n",
      "        [ 0.8309],\n",
      "        [ 0.8213],\n",
      "        [ 0.8352],\n",
      "        [ 0.8309],\n",
      "        [-1.1120],\n",
      "        [ 0.0706],\n",
      "        [-1.1332],\n",
      "        [-1.1339],\n",
      "        [ 0.8333],\n",
      "        [-1.1291],\n",
      "        [ 0.8272],\n",
      "        [ 0.8352],\n",
      "        [-1.1377],\n",
      "        [ 0.5681],\n",
      "        [-0.8745],\n",
      "        [-1.1351],\n",
      "        [ 0.8337],\n",
      "        [-0.8745],\n",
      "        [-1.0636],\n",
      "        [-1.1368],\n",
      "        [ 0.8272],\n",
      "        [-1.1359],\n",
      "        [ 0.8096],\n",
      "        [-0.9229],\n",
      "        [ 0.8096],\n",
      "        [ 0.8352],\n",
      "        [ 0.8349]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 58/10000,\n",
      " train_loss: 0.0820,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1229],\n",
      "        [-1.1229],\n",
      "        [ 0.8503],\n",
      "        [ 0.8473],\n",
      "        [ 0.3562],\n",
      "        [ 0.8393],\n",
      "        [ 0.8551],\n",
      "        [ 0.8556],\n",
      "        [ 0.8551],\n",
      "        [ 0.8541],\n",
      "        [-1.1261],\n",
      "        [-1.1180],\n",
      "        [ 0.8452],\n",
      "        [-0.2885],\n",
      "        [ 0.8554],\n",
      "        [-0.2885],\n",
      "        [ 0.8452],\n",
      "        [-1.0806],\n",
      "        [-0.5973],\n",
      "        [ 0.8548],\n",
      "        [ 0.8530],\n",
      "        [ 0.8536],\n",
      "        [ 0.8575],\n",
      "        [ 0.8575],\n",
      "        [ 0.8564],\n",
      "        [-0.5973],\n",
      "        [-1.1231],\n",
      "        [ 0.8564],\n",
      "        [-1.1246],\n",
      "        [ 0.8556],\n",
      "        [-1.1238],\n",
      "        [ 0.8452],\n",
      "        [-0.2885],\n",
      "        [ 0.8530],\n",
      "        [ 0.8426],\n",
      "        [ 0.8575],\n",
      "        [ 0.8530],\n",
      "        [-1.1018],\n",
      "        [ 0.0546],\n",
      "        [-1.1218],\n",
      "        [-1.1226],\n",
      "        [ 0.8556],\n",
      "        [-1.1180],\n",
      "        [ 0.8490],\n",
      "        [ 0.8575],\n",
      "        [-1.1264],\n",
      "        [ 0.5714],\n",
      "        [-0.8769],\n",
      "        [-1.1238],\n",
      "        [ 0.8560],\n",
      "        [-0.8769],\n",
      "        [-1.0562],\n",
      "        [-1.1255],\n",
      "        [ 0.8490],\n",
      "        [-1.1246],\n",
      "        [ 0.8299],\n",
      "        [-0.9230],\n",
      "        [ 0.8299],\n",
      "        [ 0.8575],\n",
      "        [ 0.8572]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 59/10000,\n",
      " train_loss: 0.0829,\n",
      " train_mae: 0.2475,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1087],\n",
      "        [-1.1087],\n",
      "        [ 0.8702],\n",
      "        [ 0.8669],\n",
      "        [ 0.3527],\n",
      "        [ 0.8584],\n",
      "        [ 0.8753],\n",
      "        [ 0.8758],\n",
      "        [ 0.8753],\n",
      "        [ 0.8742],\n",
      "        [-1.1120],\n",
      "        [-1.1040],\n",
      "        [ 0.8647],\n",
      "        [-0.2983],\n",
      "        [ 0.8755],\n",
      "        [-0.2983],\n",
      "        [ 0.8647],\n",
      "        [-1.0682],\n",
      "        [-0.6019],\n",
      "        [ 0.8750],\n",
      "        [ 0.8730],\n",
      "        [ 0.8737],\n",
      "        [ 0.8777],\n",
      "        [ 0.8777],\n",
      "        [ 0.8766],\n",
      "        [-0.6019],\n",
      "        [-1.1090],\n",
      "        [ 0.8766],\n",
      "        [-1.1104],\n",
      "        [ 0.8758],\n",
      "        [-1.1096],\n",
      "        [ 0.8647],\n",
      "        [-0.2983],\n",
      "        [ 0.8730],\n",
      "        [ 0.8619],\n",
      "        [ 0.8777],\n",
      "        [ 0.8730],\n",
      "        [-1.0885],\n",
      "        [ 0.0451],\n",
      "        [-1.1077],\n",
      "        [-1.1084],\n",
      "        [ 0.8758],\n",
      "        [-1.1040],\n",
      "        [ 0.8687],\n",
      "        [ 0.8777],\n",
      "        [-1.1123],\n",
      "        [ 0.5759],\n",
      "        [-0.8727],\n",
      "        [-1.1096],\n",
      "        [ 0.8762],\n",
      "        [-0.8727],\n",
      "        [-1.0448],\n",
      "        [-1.1114],\n",
      "        [ 0.8687],\n",
      "        [-1.1104],\n",
      "        [ 0.8484],\n",
      "        [-0.9171],\n",
      "        [ 0.8484],\n",
      "        [ 0.8777],\n",
      "        [ 0.8774]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 60/10000,\n",
      " train_loss: 0.0838,\n",
      " train_mae: 0.2491,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0960],\n",
      "        [-1.0960],\n",
      "        [ 0.8852],\n",
      "        [ 0.8818],\n",
      "        [ 0.3499],\n",
      "        [ 0.8727],\n",
      "        [ 0.8906],\n",
      "        [ 0.8912],\n",
      "        [ 0.8906],\n",
      "        [ 0.8895],\n",
      "        [-1.0993],\n",
      "        [-1.0913],\n",
      "        [ 0.8794],\n",
      "        [-0.3038],\n",
      "        [ 0.8909],\n",
      "        [-0.3038],\n",
      "        [ 0.8794],\n",
      "        [-1.0565],\n",
      "        [-0.6027],\n",
      "        [ 0.8903],\n",
      "        [ 0.8883],\n",
      "        [ 0.8889],\n",
      "        [ 0.8931],\n",
      "        [ 0.8931],\n",
      "        [ 0.8920],\n",
      "        [-0.6027],\n",
      "        [-1.0962],\n",
      "        [ 0.8920],\n",
      "        [-1.0977],\n",
      "        [ 0.8912],\n",
      "        [-1.0969],\n",
      "        [ 0.8794],\n",
      "        [-0.3038],\n",
      "        [ 0.8883],\n",
      "        [ 0.8765],\n",
      "        [ 0.8931],\n",
      "        [ 0.8883],\n",
      "        [-1.0762],\n",
      "        [ 0.0386],\n",
      "        [-1.0950],\n",
      "        [-1.0957],\n",
      "        [ 0.8912],\n",
      "        [-1.0913],\n",
      "        [ 0.8837],\n",
      "        [ 0.8931],\n",
      "        [-1.0997],\n",
      "        [ 0.5786],\n",
      "        [-0.8668],\n",
      "        [-1.0969],\n",
      "        [ 0.8916],\n",
      "        [-0.8668],\n",
      "        [-1.0338],\n",
      "        [-1.0987],\n",
      "        [ 0.8837],\n",
      "        [-1.0977],\n",
      "        [ 0.8623],\n",
      "        [-0.9099],\n",
      "        [ 0.8623],\n",
      "        [ 0.8931],\n",
      "        [ 0.8928]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 61/10000,\n",
      " train_loss: 0.0847,\n",
      " train_mae: 0.2504,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0880],\n",
      "        [-1.0880],\n",
      "        [ 0.8935],\n",
      "        [ 0.8899],\n",
      "        [ 0.3449],\n",
      "        [ 0.8804],\n",
      "        [ 0.8991],\n",
      "        [ 0.8997],\n",
      "        [ 0.8991],\n",
      "        [ 0.8979],\n",
      "        [-1.0915],\n",
      "        [-1.0833],\n",
      "        [ 0.8874],\n",
      "        [-0.3088],\n",
      "        [ 0.8994],\n",
      "        [-0.3088],\n",
      "        [ 0.8874],\n",
      "        [-1.0490],\n",
      "        [-0.6037],\n",
      "        [ 0.8988],\n",
      "        [ 0.8967],\n",
      "        [ 0.8974],\n",
      "        [ 0.9017],\n",
      "        [ 0.9017],\n",
      "        [ 0.9005],\n",
      "        [-0.6037],\n",
      "        [-1.0882],\n",
      "        [ 0.9005],\n",
      "        [-1.0898],\n",
      "        [ 0.8997],\n",
      "        [-1.0889],\n",
      "        [ 0.8874],\n",
      "        [-0.3088],\n",
      "        [ 0.8967],\n",
      "        [ 0.8843],\n",
      "        [ 0.9017],\n",
      "        [ 0.8967],\n",
      "        [-1.0684],\n",
      "        [ 0.0320],\n",
      "        [-1.0870],\n",
      "        [-1.0877],\n",
      "        [ 0.8997],\n",
      "        [-1.0833],\n",
      "        [ 0.8919],\n",
      "        [ 0.9017],\n",
      "        [-1.0918],\n",
      "        [ 0.5773],\n",
      "        [-0.8630],\n",
      "        [-1.0889],\n",
      "        [ 0.9001],\n",
      "        [-0.8630],\n",
      "        [-1.0267],\n",
      "        [-1.0908],\n",
      "        [ 0.8919],\n",
      "        [-1.0898],\n",
      "        [ 0.8695],\n",
      "        [-0.9052],\n",
      "        [ 0.8695],\n",
      "        [ 0.9017],\n",
      "        [ 0.9013]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 62/10000,\n",
      " train_loss: 0.0853,\n",
      " train_mae: 0.2505,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0864],\n",
      "        [-1.0864],\n",
      "        [ 0.8942],\n",
      "        [ 0.8905],\n",
      "        [ 0.3367],\n",
      "        [ 0.8806],\n",
      "        [ 0.9001],\n",
      "        [ 0.9006],\n",
      "        [ 0.9001],\n",
      "        [ 0.8988],\n",
      "        [-1.0900],\n",
      "        [-1.0816],\n",
      "        [ 0.8879],\n",
      "        [-0.3151],\n",
      "        [ 0.9004],\n",
      "        [-0.3151],\n",
      "        [ 0.8879],\n",
      "        [-1.0473],\n",
      "        [-0.6070],\n",
      "        [ 0.8997],\n",
      "        [ 0.8975],\n",
      "        [ 0.8982],\n",
      "        [ 0.9027],\n",
      "        [ 0.9027],\n",
      "        [ 0.9015],\n",
      "        [-0.6070],\n",
      "        [-1.0866],\n",
      "        [ 0.9015],\n",
      "        [-1.0882],\n",
      "        [ 0.9006],\n",
      "        [-1.0873],\n",
      "        [ 0.8879],\n",
      "        [-0.3151],\n",
      "        [ 0.8975],\n",
      "        [ 0.8847],\n",
      "        [ 0.9027],\n",
      "        [ 0.8975],\n",
      "        [-1.0667],\n",
      "        [ 0.0235],\n",
      "        [-1.0853],\n",
      "        [-1.0861],\n",
      "        [ 0.9006],\n",
      "        [-1.0816],\n",
      "        [ 0.8925],\n",
      "        [ 0.9027],\n",
      "        [-1.0903],\n",
      "        [ 0.5711],\n",
      "        [-0.8631],\n",
      "        [-1.0873],\n",
      "        [ 0.9011],\n",
      "        [-0.8631],\n",
      "        [-1.0251],\n",
      "        [-1.0893],\n",
      "        [ 0.8925],\n",
      "        [-1.0882],\n",
      "        [ 0.8693],\n",
      "        [-0.9048],\n",
      "        [ 0.8693],\n",
      "        [ 0.9027],\n",
      "        [ 0.9023]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 63/10000,\n",
      " train_loss: 0.0853,\n",
      " train_mae: 0.2496,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0906],\n",
      "        [-1.0906],\n",
      "        [ 0.8880],\n",
      "        [ 0.8841],\n",
      "        [ 0.3257],\n",
      "        [ 0.8740],\n",
      "        [ 0.8940],\n",
      "        [ 0.8946],\n",
      "        [ 0.8940],\n",
      "        [ 0.8927],\n",
      "        [-1.0943],\n",
      "        [-1.0857],\n",
      "        [ 0.8814],\n",
      "        [-0.3227],\n",
      "        [ 0.8943],\n",
      "        [-0.3227],\n",
      "        [ 0.8814],\n",
      "        [-1.0510],\n",
      "        [-0.6123],\n",
      "        [ 0.8937],\n",
      "        [ 0.8914],\n",
      "        [ 0.8921],\n",
      "        [ 0.8967],\n",
      "        [ 0.8967],\n",
      "        [ 0.8955],\n",
      "        [-0.6123],\n",
      "        [-1.0909],\n",
      "        [ 0.8955],\n",
      "        [-1.0925],\n",
      "        [ 0.8946],\n",
      "        [-1.0916],\n",
      "        [ 0.8814],\n",
      "        [-0.3227],\n",
      "        [ 0.8914],\n",
      "        [ 0.8781],\n",
      "        [ 0.8967],\n",
      "        [ 0.8914],\n",
      "        [-1.0705],\n",
      "        [ 0.0136],\n",
      "        [-1.0895],\n",
      "        [-1.0903],\n",
      "        [ 0.8946],\n",
      "        [-1.0857],\n",
      "        [ 0.8862],\n",
      "        [ 0.8967],\n",
      "        [-1.0947],\n",
      "        [ 0.5606],\n",
      "        [-0.8668],\n",
      "        [-1.0916],\n",
      "        [ 0.8951],\n",
      "        [-0.8668],\n",
      "        [-1.0287],\n",
      "        [-1.0936],\n",
      "        [ 0.8862],\n",
      "        [-1.0925],\n",
      "        [ 0.8623],\n",
      "        [-0.9084],\n",
      "        [ 0.8623],\n",
      "        [ 0.8967],\n",
      "        [ 0.8963]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 64/10000,\n",
      " train_loss: 0.0846,\n",
      " train_mae: 0.2482,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0984],\n",
      "        [-1.0984],\n",
      "        [ 0.8766],\n",
      "        [ 0.8727],\n",
      "        [ 0.3139],\n",
      "        [ 0.8623],\n",
      "        [ 0.8829],\n",
      "        [ 0.8835],\n",
      "        [ 0.8829],\n",
      "        [ 0.8815],\n",
      "        [-1.1023],\n",
      "        [-1.0933],\n",
      "        [ 0.8700],\n",
      "        [-0.3296],\n",
      "        [ 0.8832],\n",
      "        [-0.3296],\n",
      "        [ 0.8700],\n",
      "        [-1.0578],\n",
      "        [-0.6175],\n",
      "        [ 0.8825],\n",
      "        [ 0.8801],\n",
      "        [ 0.8809],\n",
      "        [ 0.8856],\n",
      "        [ 0.8856],\n",
      "        [ 0.8844],\n",
      "        [-0.6175],\n",
      "        [-1.0987],\n",
      "        [ 0.8844],\n",
      "        [-1.1004],\n",
      "        [ 0.8835],\n",
      "        [-1.0994],\n",
      "        [ 0.8700],\n",
      "        [-0.3296],\n",
      "        [ 0.8801],\n",
      "        [ 0.8666],\n",
      "        [ 0.8856],\n",
      "        [ 0.8801],\n",
      "        [-1.0777],\n",
      "        [ 0.0041],\n",
      "        [-1.0972],\n",
      "        [-1.0980],\n",
      "        [ 0.8835],\n",
      "        [-1.0933],\n",
      "        [ 0.8749],\n",
      "        [ 0.8856],\n",
      "        [-1.1027],\n",
      "        [ 0.5477],\n",
      "        [-0.8719],\n",
      "        [-1.0994],\n",
      "        [ 0.8840],\n",
      "        [-0.8719],\n",
      "        [-1.0351],\n",
      "        [-1.1016],\n",
      "        [ 0.8749],\n",
      "        [-1.1004],\n",
      "        [ 0.8505],\n",
      "        [-0.9137],\n",
      "        [ 0.8505],\n",
      "        [ 0.8856],\n",
      "        [ 0.8852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 65/10000,\n",
      " train_loss: 0.0837,\n",
      " train_mae: 0.2468,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1065],\n",
      "        [-1.1065],\n",
      "        [ 0.8627],\n",
      "        [ 0.8587],\n",
      "        [ 0.3039],\n",
      "        [ 0.8482],\n",
      "        [ 0.8691],\n",
      "        [ 0.8697],\n",
      "        [ 0.8691],\n",
      "        [ 0.8677],\n",
      "        [-1.1106],\n",
      "        [-1.1011],\n",
      "        [ 0.8559],\n",
      "        [-0.3328],\n",
      "        [ 0.8694],\n",
      "        [-0.3328],\n",
      "        [ 0.8559],\n",
      "        [-1.0644],\n",
      "        [-0.6197],\n",
      "        [ 0.8687],\n",
      "        [ 0.8663],\n",
      "        [ 0.8671],\n",
      "        [ 0.8718],\n",
      "        [ 0.8718],\n",
      "        [ 0.8707],\n",
      "        [-0.6197],\n",
      "        [-1.1068],\n",
      "        [ 0.8707],\n",
      "        [-1.1086],\n",
      "        [ 0.8697],\n",
      "        [-1.1076],\n",
      "        [ 0.8559],\n",
      "        [-0.3328],\n",
      "        [ 0.8663],\n",
      "        [ 0.8525],\n",
      "        [ 0.8718],\n",
      "        [ 0.8663],\n",
      "        [-1.0850],\n",
      "        [-0.0022],\n",
      "        [-1.1053],\n",
      "        [-1.1061],\n",
      "        [ 0.8697],\n",
      "        [-1.1011],\n",
      "        [ 0.8609],\n",
      "        [ 0.8718],\n",
      "        [-1.1110],\n",
      "        [ 0.5350],\n",
      "        [-0.8753],\n",
      "        [-1.1076],\n",
      "        [ 0.8702],\n",
      "        [-0.8753],\n",
      "        [-1.0412],\n",
      "        [-1.1098],\n",
      "        [ 0.8609],\n",
      "        [-1.1086],\n",
      "        [ 0.8363],\n",
      "        [-0.9176],\n",
      "        [ 0.8363],\n",
      "        [ 0.8718],\n",
      "        [ 0.8715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 66/10000,\n",
      " train_loss: 0.0827,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1117],\n",
      "        [-1.1117],\n",
      "        [ 0.8488],\n",
      "        [ 0.8447],\n",
      "        [ 0.2984],\n",
      "        [ 0.8342],\n",
      "        [ 0.8553],\n",
      "        [ 0.8559],\n",
      "        [ 0.8553],\n",
      "        [ 0.8539],\n",
      "        [-1.1161],\n",
      "        [-1.1061],\n",
      "        [ 0.8420],\n",
      "        [-0.3295],\n",
      "        [ 0.8556],\n",
      "        [-0.3295],\n",
      "        [ 0.8420],\n",
      "        [-1.0677],\n",
      "        [-0.6158],\n",
      "        [ 0.8549],\n",
      "        [ 0.8524],\n",
      "        [ 0.8532],\n",
      "        [ 0.8580],\n",
      "        [ 0.8580],\n",
      "        [ 0.8568],\n",
      "        [-0.6158],\n",
      "        [-1.1120],\n",
      "        [ 0.8568],\n",
      "        [-1.1140],\n",
      "        [ 0.8559],\n",
      "        [-1.1129],\n",
      "        [ 0.8420],\n",
      "        [-0.3295],\n",
      "        [ 0.8524],\n",
      "        [ 0.8385],\n",
      "        [ 0.8580],\n",
      "        [ 0.8524],\n",
      "        [-1.0891],\n",
      "        [-0.0026],\n",
      "        [-1.1105],\n",
      "        [-1.1114],\n",
      "        [ 0.8559],\n",
      "        [-1.1061],\n",
      "        [ 0.8470],\n",
      "        [ 0.8580],\n",
      "        [-1.1165],\n",
      "        [ 0.5252],\n",
      "        [-0.8738],\n",
      "        [-1.1129],\n",
      "        [ 0.8564],\n",
      "        [-0.8738],\n",
      "        [-1.0436],\n",
      "        [-1.1153],\n",
      "        [ 0.8470],\n",
      "        [-1.1140],\n",
      "        [ 0.8223],\n",
      "        [-0.9168],\n",
      "        [ 0.8223],\n",
      "        [ 0.8580],\n",
      "        [ 0.8577]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 67/10000,\n",
      " train_loss: 0.0817,\n",
      " train_mae: 0.2436,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1122],\n",
      "        [-1.1122],\n",
      "        [ 0.8367],\n",
      "        [ 0.8327],\n",
      "        [ 0.2989],\n",
      "        [ 0.8222],\n",
      "        [ 0.8433],\n",
      "        [ 0.8439],\n",
      "        [ 0.8433],\n",
      "        [ 0.8418],\n",
      "        [-1.1168],\n",
      "        [-1.1061],\n",
      "        [ 0.8299],\n",
      "        [-0.3181],\n",
      "        [ 0.8436],\n",
      "        [-0.3181],\n",
      "        [ 0.8299],\n",
      "        [-1.0656],\n",
      "        [-0.6040],\n",
      "        [ 0.8429],\n",
      "        [ 0.8404],\n",
      "        [ 0.8412],\n",
      "        [ 0.8461],\n",
      "        [ 0.8461],\n",
      "        [ 0.8448],\n",
      "        [-0.6040],\n",
      "        [-1.1125],\n",
      "        [ 0.8448],\n",
      "        [-1.1145],\n",
      "        [ 0.8439],\n",
      "        [-1.1134],\n",
      "        [ 0.8299],\n",
      "        [-0.3181],\n",
      "        [ 0.8404],\n",
      "        [ 0.8265],\n",
      "        [ 0.8461],\n",
      "        [ 0.8404],\n",
      "        [-1.0881],\n",
      "        [ 0.0045],\n",
      "        [-1.1108],\n",
      "        [-1.1118],\n",
      "        [ 0.8439],\n",
      "        [-1.1061],\n",
      "        [ 0.8349],\n",
      "        [ 0.8461],\n",
      "        [-1.1172],\n",
      "        [ 0.5199],\n",
      "        [-0.8654],\n",
      "        [-1.1134],\n",
      "        [ 0.8444],\n",
      "        [-0.8654],\n",
      "        [-1.0405],\n",
      "        [-1.1159],\n",
      "        [ 0.8349],\n",
      "        [-1.1145],\n",
      "        [ 0.8104],\n",
      "        [-0.9095],\n",
      "        [ 0.8104],\n",
      "        [ 0.8461],\n",
      "        [ 0.8457]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 68/10000,\n",
      " train_loss: 0.0806,\n",
      " train_mae: 0.2418,\n",
      " epoch_time_duration: 0.0109\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1074],\n",
      "        [-1.1074],\n",
      "        [ 0.8275],\n",
      "        [ 0.8235],\n",
      "        [ 0.3058],\n",
      "        [ 0.8131],\n",
      "        [ 0.8340],\n",
      "        [ 0.8347],\n",
      "        [ 0.8340],\n",
      "        [ 0.8326],\n",
      "        [-1.1123],\n",
      "        [-1.1009],\n",
      "        [ 0.8207],\n",
      "        [-0.2986],\n",
      "        [ 0.8344],\n",
      "        [-0.2986],\n",
      "        [ 0.8207],\n",
      "        [-1.0578],\n",
      "        [-0.5841],\n",
      "        [ 0.8336],\n",
      "        [ 0.8312],\n",
      "        [ 0.8320],\n",
      "        [ 0.8369],\n",
      "        [ 0.8369],\n",
      "        [ 0.8356],\n",
      "        [-0.5841],\n",
      "        [-1.1078],\n",
      "        [ 0.8356],\n",
      "        [-1.1100],\n",
      "        [ 0.8347],\n",
      "        [-1.1088],\n",
      "        [ 0.8207],\n",
      "        [-0.2986],\n",
      "        [ 0.8312],\n",
      "        [ 0.8173],\n",
      "        [ 0.8369],\n",
      "        [ 0.8312],\n",
      "        [-1.0816],\n",
      "        [ 0.0190],\n",
      "        [-1.1060],\n",
      "        [-1.1070],\n",
      "        [ 0.8347],\n",
      "        [-1.1009],\n",
      "        [ 0.8257],\n",
      "        [ 0.8369],\n",
      "        [-1.1128],\n",
      "        [ 0.5197],\n",
      "        [-0.8498],\n",
      "        [-1.1088],\n",
      "        [ 0.8352],\n",
      "        [-0.8498],\n",
      "        [-1.0314],\n",
      "        [-1.1115],\n",
      "        [ 0.8257],\n",
      "        [-1.1100],\n",
      "        [ 0.8015],\n",
      "        [-0.8952],\n",
      "        [ 0.8015],\n",
      "        [ 0.8369],\n",
      "        [ 0.8365]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 69/10000,\n",
      " train_loss: 0.0794,\n",
      " train_mae: 0.2397,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0990],\n",
      "        [-1.0990],\n",
      "        [ 0.8210],\n",
      "        [ 0.8170],\n",
      "        [ 0.3176],\n",
      "        [ 0.8069],\n",
      "        [ 0.8275],\n",
      "        [ 0.8282],\n",
      "        [ 0.8275],\n",
      "        [ 0.8261],\n",
      "        [-1.1043],\n",
      "        [-1.0919],\n",
      "        [ 0.8143],\n",
      "        [-0.2726],\n",
      "        [ 0.8279],\n",
      "        [-0.2726],\n",
      "        [ 0.8143],\n",
      "        [-1.0457],\n",
      "        [-0.5578],\n",
      "        [ 0.8271],\n",
      "        [ 0.8246],\n",
      "        [ 0.8254],\n",
      "        [ 0.8304],\n",
      "        [ 0.8304],\n",
      "        [ 0.8291],\n",
      "        [-0.5578],\n",
      "        [-1.0995],\n",
      "        [ 0.8291],\n",
      "        [-1.1018],\n",
      "        [ 0.8282],\n",
      "        [-1.1005],\n",
      "        [ 0.8143],\n",
      "        [-0.2726],\n",
      "        [ 0.8246],\n",
      "        [ 0.8110],\n",
      "        [ 0.8304],\n",
      "        [ 0.8246],\n",
      "        [-1.0711],\n",
      "        [ 0.0395],\n",
      "        [-1.0974],\n",
      "        [-1.0986],\n",
      "        [ 0.8282],\n",
      "        [-1.0919],\n",
      "        [ 0.8192],\n",
      "        [ 0.8304],\n",
      "        [-1.1048],\n",
      "        [ 0.5238],\n",
      "        [-0.8285],\n",
      "        [-1.1005],\n",
      "        [ 0.8287],\n",
      "        [-0.8285],\n",
      "        [-1.0177],\n",
      "        [-1.1033],\n",
      "        [ 0.8192],\n",
      "        [-1.1018],\n",
      "        [ 0.7955],\n",
      "        [-0.8754],\n",
      "        [ 0.7955],\n",
      "        [ 0.8304],\n",
      "        [ 0.8300]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 70/10000,\n",
      " train_loss: 0.0782,\n",
      " train_mae: 0.2373,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0896],\n",
      "        [-1.0896],\n",
      "        [ 0.8163],\n",
      "        [ 0.8124],\n",
      "        [ 0.3322],\n",
      "        [ 0.8024],\n",
      "        [ 0.8228],\n",
      "        [ 0.8234],\n",
      "        [ 0.8228],\n",
      "        [ 0.8214],\n",
      "        [-1.0952],\n",
      "        [-1.0818],\n",
      "        [ 0.8097],\n",
      "        [-0.2431],\n",
      "        [ 0.8231],\n",
      "        [-0.2431],\n",
      "        [ 0.8097],\n",
      "        [-1.0320],\n",
      "        [-0.5280],\n",
      "        [ 0.8224],\n",
      "        [ 0.8199],\n",
      "        [ 0.8207],\n",
      "        [ 0.8257],\n",
      "        [ 0.8257],\n",
      "        [ 0.8244],\n",
      "        [-0.5280],\n",
      "        [-1.0901],\n",
      "        [ 0.8244],\n",
      "        [-1.0926],\n",
      "        [ 0.8234],\n",
      "        [-1.0912],\n",
      "        [ 0.8097],\n",
      "        [-0.2431],\n",
      "        [ 0.8199],\n",
      "        [ 0.8065],\n",
      "        [ 0.8257],\n",
      "        [ 0.8199],\n",
      "        [-1.0593],\n",
      "        [ 0.0630],\n",
      "        [-1.0878],\n",
      "        [-1.0891],\n",
      "        [ 0.8234],\n",
      "        [-1.0818],\n",
      "        [ 0.8146],\n",
      "        [ 0.8257],\n",
      "        [-1.0958],\n",
      "        [ 0.5302],\n",
      "        [-0.8043],\n",
      "        [-1.0912],\n",
      "        [ 0.8240],\n",
      "        [-0.8043],\n",
      "        [-1.0021],\n",
      "        [-1.0942],\n",
      "        [ 0.8146],\n",
      "        [-1.0926],\n",
      "        [ 0.7914],\n",
      "        [-0.8528],\n",
      "        [ 0.7914],\n",
      "        [ 0.8257],\n",
      "        [ 0.8253]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 71/10000,\n",
      " train_loss: 0.0772,\n",
      " train_mae: 0.2347,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0823],\n",
      "        [-1.0823],\n",
      "        [ 0.8122],\n",
      "        [ 0.8083],\n",
      "        [ 0.3470],\n",
      "        [ 0.7986],\n",
      "        [ 0.8186],\n",
      "        [ 0.8193],\n",
      "        [ 0.8186],\n",
      "        [ 0.8172],\n",
      "        [-1.0883],\n",
      "        [-1.0736],\n",
      "        [ 0.8057],\n",
      "        [-0.2134],\n",
      "        [ 0.8189],\n",
      "        [-0.2134],\n",
      "        [ 0.8057],\n",
      "        [-1.0197],\n",
      "        [-0.4980],\n",
      "        [ 0.8182],\n",
      "        [ 0.8157],\n",
      "        [ 0.8165],\n",
      "        [ 0.8215],\n",
      "        [ 0.8215],\n",
      "        [ 0.8202],\n",
      "        [-0.4980],\n",
      "        [-1.0828],\n",
      "        [ 0.8202],\n",
      "        [-1.0855],\n",
      "        [ 0.8193],\n",
      "        [-1.0840],\n",
      "        [ 0.8057],\n",
      "        [-0.2134],\n",
      "        [ 0.8157],\n",
      "        [ 0.8025],\n",
      "        [ 0.8215],\n",
      "        [ 0.8157],\n",
      "        [-1.0491],\n",
      "        [ 0.0867],\n",
      "        [-1.0803],\n",
      "        [-1.0817],\n",
      "        [ 0.8193],\n",
      "        [-1.0736],\n",
      "        [ 0.8104],\n",
      "        [ 0.8215],\n",
      "        [-1.0889],\n",
      "        [ 0.5369],\n",
      "        [-0.7803],\n",
      "        [-1.0840],\n",
      "        [ 0.8198],\n",
      "        [-0.7803],\n",
      "        [-0.9878],\n",
      "        [-1.0872],\n",
      "        [ 0.8104],\n",
      "        [-1.0855],\n",
      "        [ 0.7878],\n",
      "        [-0.8307],\n",
      "        [ 0.7878],\n",
      "        [ 0.8215],\n",
      "        [ 0.8211]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 72/10000,\n",
      " train_loss: 0.0763,\n",
      " train_mae: 0.2324,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0796],\n",
      "        [-1.0796],\n",
      "        [ 0.8074],\n",
      "        [ 0.8036],\n",
      "        [ 0.3598],\n",
      "        [ 0.7941],\n",
      "        [ 0.8138],\n",
      "        [ 0.8145],\n",
      "        [ 0.8138],\n",
      "        [ 0.8124],\n",
      "        [-1.0860],\n",
      "        [-1.0700],\n",
      "        [ 0.8010],\n",
      "        [-0.1863],\n",
      "        [ 0.8142],\n",
      "        [-0.1863],\n",
      "        [ 0.8010],\n",
      "        [-1.0114],\n",
      "        [-0.4707],\n",
      "        [ 0.8134],\n",
      "        [ 0.8109],\n",
      "        [ 0.8117],\n",
      "        [ 0.8168],\n",
      "        [ 0.8168],\n",
      "        [ 0.8155],\n",
      "        [-0.4707],\n",
      "        [-1.0801],\n",
      "        [ 0.8155],\n",
      "        [-1.0831],\n",
      "        [ 0.8145],\n",
      "        [-1.0815],\n",
      "        [ 0.8010],\n",
      "        [-0.1863],\n",
      "        [ 0.8109],\n",
      "        [ 0.7979],\n",
      "        [ 0.8168],\n",
      "        [ 0.8109],\n",
      "        [-1.0432],\n",
      "        [ 0.1081],\n",
      "        [-1.0774],\n",
      "        [-1.0790],\n",
      "        [ 0.8145],\n",
      "        [-1.0700],\n",
      "        [ 0.8057],\n",
      "        [ 0.8168],\n",
      "        [-1.0867],\n",
      "        [ 0.5423],\n",
      "        [-0.7593],\n",
      "        [-1.0815],\n",
      "        [ 0.8150],\n",
      "        [-0.7593],\n",
      "        [-0.9772],\n",
      "        [-1.0849],\n",
      "        [ 0.8057],\n",
      "        [-1.0831],\n",
      "        [ 0.7835],\n",
      "        [-0.8117],\n",
      "        [ 0.7835],\n",
      "        [ 0.8168],\n",
      "        [ 0.8164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 73/10000,\n",
      " train_loss: 0.0756,\n",
      " train_mae: 0.2317,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0829],\n",
      "        [-1.0829],\n",
      "        [ 0.8016],\n",
      "        [ 0.7978],\n",
      "        [ 0.3696],\n",
      "        [ 0.7884],\n",
      "        [ 0.8080],\n",
      "        [ 0.8087],\n",
      "        [ 0.8080],\n",
      "        [ 0.8065],\n",
      "        [-1.0899],\n",
      "        [-1.0723],\n",
      "        [ 0.7953],\n",
      "        [-0.1633],\n",
      "        [ 0.8083],\n",
      "        [-0.1633],\n",
      "        [ 0.7953],\n",
      "        [-1.0086],\n",
      "        [-0.4476],\n",
      "        [ 0.8076],\n",
      "        [ 0.8051],\n",
      "        [ 0.8059],\n",
      "        [ 0.8110],\n",
      "        [ 0.8110],\n",
      "        [ 0.8097],\n",
      "        [-0.4476],\n",
      "        [-1.0835],\n",
      "        [ 0.8097],\n",
      "        [-1.0868],\n",
      "        [ 0.8087],\n",
      "        [-1.0850],\n",
      "        [ 0.7953],\n",
      "        [-0.1633],\n",
      "        [ 0.8051],\n",
      "        [ 0.7922],\n",
      "        [ 0.8110],\n",
      "        [ 0.8051],\n",
      "        [-1.0429],\n",
      "        [ 0.1257],\n",
      "        [-1.0805],\n",
      "        [-1.0822],\n",
      "        [ 0.8087],\n",
      "        [-1.0723],\n",
      "        [ 0.7999],\n",
      "        [ 0.8110],\n",
      "        [-1.0906],\n",
      "        [ 0.5453],\n",
      "        [-0.7427],\n",
      "        [-1.0850],\n",
      "        [ 0.8092],\n",
      "        [-0.7427],\n",
      "        [-0.9719],\n",
      "        [-1.0887],\n",
      "        [ 0.7999],\n",
      "        [-1.0868],\n",
      "        [ 0.7781],\n",
      "        [-0.7972],\n",
      "        [ 0.7781],\n",
      "        [ 0.8110],\n",
      "        [ 0.8106]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 74/10000,\n",
      " train_loss: 0.0748,\n",
      " train_mae: 0.2306,\n",
      " epoch_time_duration: 0.0230\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0921],\n",
      "        [-1.0921],\n",
      "        [ 0.7948],\n",
      "        [ 0.7911],\n",
      "        [ 0.3764],\n",
      "        [ 0.7817],\n",
      "        [ 0.8013],\n",
      "        [ 0.8019],\n",
      "        [ 0.8013],\n",
      "        [ 0.7998],\n",
      "        [-1.0997],\n",
      "        [-1.0803],\n",
      "        [ 0.7885],\n",
      "        [-0.1446],\n",
      "        [ 0.8016],\n",
      "        [-0.1446],\n",
      "        [ 0.7885],\n",
      "        [-1.0109],\n",
      "        [-0.4289],\n",
      "        [ 0.8008],\n",
      "        [ 0.7983],\n",
      "        [ 0.7991],\n",
      "        [ 0.8043],\n",
      "        [ 0.8043],\n",
      "        [ 0.8030],\n",
      "        [-0.4289],\n",
      "        [-1.0927],\n",
      "        [ 0.8030],\n",
      "        [-1.0963],\n",
      "        [ 0.8019],\n",
      "        [-1.0944],\n",
      "        [ 0.7885],\n",
      "        [-0.1446],\n",
      "        [ 0.7983],\n",
      "        [ 0.7855],\n",
      "        [ 0.8043],\n",
      "        [ 0.7983],\n",
      "        [-1.0481],\n",
      "        [ 0.1394],\n",
      "        [-1.0894],\n",
      "        [-1.0913],\n",
      "        [ 0.8019],\n",
      "        [-1.0803],\n",
      "        [ 0.7931],\n",
      "        [ 0.8043],\n",
      "        [-1.1004],\n",
      "        [ 0.5461],\n",
      "        [-0.7307],\n",
      "        [-1.0944],\n",
      "        [ 0.8025],\n",
      "        [-0.7307],\n",
      "        [-0.9715],\n",
      "        [-1.0984],\n",
      "        [ 0.7931],\n",
      "        [-1.0963],\n",
      "        [ 0.7716],\n",
      "        [-0.7873],\n",
      "        [ 0.7716],\n",
      "        [ 0.8043],\n",
      "        [ 0.8039]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 75/10000,\n",
      " train_loss: 0.0740,\n",
      " train_mae: 0.2292,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1056],\n",
      "        [-1.1056],\n",
      "        [ 0.7880],\n",
      "        [ 0.7842],\n",
      "        [ 0.3811],\n",
      "        [ 0.7750],\n",
      "        [ 0.7945],\n",
      "        [ 0.7952],\n",
      "        [ 0.7945],\n",
      "        [ 0.7930],\n",
      "        [-1.1139],\n",
      "        [-1.0925],\n",
      "        [ 0.7817],\n",
      "        [-0.1291],\n",
      "        [ 0.7949],\n",
      "        [-0.1291],\n",
      "        [ 0.7817],\n",
      "        [-1.0170],\n",
      "        [-0.4134],\n",
      "        [ 0.7941],\n",
      "        [ 0.7915],\n",
      "        [ 0.7923],\n",
      "        [ 0.7976],\n",
      "        [ 0.7976],\n",
      "        [ 0.7963],\n",
      "        [-0.4134],\n",
      "        [-1.1063],\n",
      "        [ 0.7963],\n",
      "        [-1.1102],\n",
      "        [ 0.7952],\n",
      "        [-1.1081],\n",
      "        [ 0.7817],\n",
      "        [-0.1291],\n",
      "        [ 0.7915],\n",
      "        [ 0.7787],\n",
      "        [ 0.7976],\n",
      "        [ 0.7915],\n",
      "        [-1.0572],\n",
      "        [ 0.1504],\n",
      "        [-1.1026],\n",
      "        [-1.1047],\n",
      "        [ 0.7952],\n",
      "        [-1.0925],\n",
      "        [ 0.7863],\n",
      "        [ 0.7976],\n",
      "        [-1.1146],\n",
      "        [ 0.5456],\n",
      "        [-0.7218],\n",
      "        [-1.1081],\n",
      "        [ 0.7958],\n",
      "        [-0.7218],\n",
      "        [-0.9747],\n",
      "        [-1.1125],\n",
      "        [ 0.7863],\n",
      "        [-1.1102],\n",
      "        [ 0.7650],\n",
      "        [-0.7807],\n",
      "        [ 0.7650],\n",
      "        [ 0.7976],\n",
      "        [ 0.7972]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 76/10000,\n",
      " train_loss: 0.0732,\n",
      " train_mae: 0.2276,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1211],\n",
      "        [-1.1211],\n",
      "        [ 0.7824],\n",
      "        [ 0.7786],\n",
      "        [ 0.3853],\n",
      "        [ 0.7693],\n",
      "        [ 0.7889],\n",
      "        [ 0.7897],\n",
      "        [ 0.7889],\n",
      "        [ 0.7874],\n",
      "        [-1.1301],\n",
      "        [-1.1066],\n",
      "        [ 0.7761],\n",
      "        [-0.1151],\n",
      "        [ 0.7893],\n",
      "        [-0.1151],\n",
      "        [ 0.7761],\n",
      "        [-1.0245],\n",
      "        [-0.3992],\n",
      "        [ 0.7885],\n",
      "        [ 0.7859],\n",
      "        [ 0.7867],\n",
      "        [ 0.7921],\n",
      "        [ 0.7921],\n",
      "        [ 0.7907],\n",
      "        [-0.3992],\n",
      "        [-1.1219],\n",
      "        [ 0.7907],\n",
      "        [-1.1262],\n",
      "        [ 0.7897],\n",
      "        [-1.1240],\n",
      "        [ 0.7761],\n",
      "        [-0.1151],\n",
      "        [ 0.7859],\n",
      "        [ 0.7730],\n",
      "        [ 0.7921],\n",
      "        [ 0.7859],\n",
      "        [-1.0679],\n",
      "        [ 0.1602],\n",
      "        [-1.1178],\n",
      "        [-1.1202],\n",
      "        [ 0.7897],\n",
      "        [-1.1066],\n",
      "        [ 0.7806],\n",
      "        [ 0.7921],\n",
      "        [-1.1309],\n",
      "        [ 0.5451],\n",
      "        [-0.7140],\n",
      "        [-1.1240],\n",
      "        [ 0.7902],\n",
      "        [-0.7140],\n",
      "        [-0.9793],\n",
      "        [-1.1287],\n",
      "        [ 0.7806],\n",
      "        [-1.1262],\n",
      "        [ 0.7594],\n",
      "        [-0.7750],\n",
      "        [ 0.7594],\n",
      "        [ 0.7921],\n",
      "        [ 0.7917]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 77/10000,\n",
      " train_loss: 0.0724,\n",
      " train_mae: 0.2260,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1363],\n",
      "        [-1.1363],\n",
      "        [ 0.7790],\n",
      "        [ 0.7752],\n",
      "        [ 0.3904],\n",
      "        [ 0.7659],\n",
      "        [ 0.7857],\n",
      "        [ 0.7864],\n",
      "        [ 0.7857],\n",
      "        [ 0.7841],\n",
      "        [-1.1461],\n",
      "        [-1.1201],\n",
      "        [ 0.7727],\n",
      "        [-0.1006],\n",
      "        [ 0.7861],\n",
      "        [-0.1006],\n",
      "        [ 0.7727],\n",
      "        [-1.0310],\n",
      "        [-0.3844],\n",
      "        [ 0.7853],\n",
      "        [ 0.7826],\n",
      "        [ 0.7834],\n",
      "        [ 0.7889],\n",
      "        [ 0.7889],\n",
      "        [ 0.7875],\n",
      "        [-0.3844],\n",
      "        [-1.1372],\n",
      "        [ 0.7875],\n",
      "        [-1.1419],\n",
      "        [ 0.7864],\n",
      "        [-1.1394],\n",
      "        [ 0.7727],\n",
      "        [-0.1006],\n",
      "        [ 0.7826],\n",
      "        [ 0.7696],\n",
      "        [ 0.7889],\n",
      "        [ 0.7826],\n",
      "        [-1.0779],\n",
      "        [ 0.1706],\n",
      "        [-1.1326],\n",
      "        [-1.1352],\n",
      "        [ 0.7864],\n",
      "        [-1.1201],\n",
      "        [ 0.7773],\n",
      "        [ 0.7889],\n",
      "        [-1.1470],\n",
      "        [ 0.5461],\n",
      "        [-0.7052],\n",
      "        [-1.1394],\n",
      "        [ 0.7870],\n",
      "        [-0.7052],\n",
      "        [-0.9827],\n",
      "        [-1.1446],\n",
      "        [ 0.7773],\n",
      "        [-1.1419],\n",
      "        [ 0.7560],\n",
      "        [-0.7683],\n",
      "        [ 0.7560],\n",
      "        [ 0.7889],\n",
      "        [ 0.7885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 78/10000,\n",
      " train_loss: 0.0716,\n",
      " train_mae: 0.2246,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1493],\n",
      "        [-1.1493],\n",
      "        [ 0.7786],\n",
      "        [ 0.7748],\n",
      "        [ 0.3974],\n",
      "        [ 0.7655],\n",
      "        [ 0.7855],\n",
      "        [ 0.7862],\n",
      "        [ 0.7855],\n",
      "        [ 0.7839],\n",
      "        [-1.1601],\n",
      "        [-1.1314],\n",
      "        [ 0.7722],\n",
      "        [-0.0847],\n",
      "        [ 0.7859],\n",
      "        [-0.0847],\n",
      "        [ 0.7722],\n",
      "        [-1.0350],\n",
      "        [-0.3678],\n",
      "        [ 0.7850],\n",
      "        [ 0.7823],\n",
      "        [ 0.7832],\n",
      "        [ 0.7887],\n",
      "        [ 0.7887],\n",
      "        [ 0.7873],\n",
      "        [-0.3678],\n",
      "        [-1.1503],\n",
      "        [ 0.7873],\n",
      "        [-1.1556],\n",
      "        [ 0.7862],\n",
      "        [-1.1528],\n",
      "        [ 0.7722],\n",
      "        [-0.0847],\n",
      "        [ 0.7823],\n",
      "        [ 0.7692],\n",
      "        [ 0.7887],\n",
      "        [ 0.7823],\n",
      "        [-1.0854],\n",
      "        [ 0.1824],\n",
      "        [-1.1452],\n",
      "        [-1.1481],\n",
      "        [ 0.7862],\n",
      "        [-1.1314],\n",
      "        [ 0.7769],\n",
      "        [ 0.7887],\n",
      "        [-1.1610],\n",
      "        [ 0.5494],\n",
      "        [-0.6938],\n",
      "        [-1.1528],\n",
      "        [ 0.7868],\n",
      "        [-0.6938],\n",
      "        [-0.9835],\n",
      "        [-1.1584],\n",
      "        [ 0.7769],\n",
      "        [-1.1556],\n",
      "        [ 0.7556],\n",
      "        [-0.7590],\n",
      "        [ 0.7556],\n",
      "        [ 0.7887],\n",
      "        [ 0.7883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 79/10000,\n",
      " train_loss: 0.0708,\n",
      " train_mae: 0.2233,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1595],\n",
      "        [-1.1595],\n",
      "        [ 0.7812],\n",
      "        [ 0.7773],\n",
      "        [ 0.4064],\n",
      "        [ 0.7680],\n",
      "        [ 0.7883],\n",
      "        [ 0.7890],\n",
      "        [ 0.7883],\n",
      "        [ 0.7866],\n",
      "        [-1.1713],\n",
      "        [-1.1397],\n",
      "        [ 0.7748],\n",
      "        [-0.0671],\n",
      "        [ 0.7887],\n",
      "        [-0.0671],\n",
      "        [ 0.7748],\n",
      "        [-1.0356],\n",
      "        [-0.3491],\n",
      "        [ 0.7878],\n",
      "        [ 0.7850],\n",
      "        [ 0.7859],\n",
      "        [ 0.7916],\n",
      "        [ 0.7916],\n",
      "        [ 0.7902],\n",
      "        [-0.3491],\n",
      "        [-1.1606],\n",
      "        [ 0.7902],\n",
      "        [-1.1664],\n",
      "        [ 0.7890],\n",
      "        [-1.1634],\n",
      "        [ 0.7748],\n",
      "        [-0.0671],\n",
      "        [ 0.7850],\n",
      "        [ 0.7717],\n",
      "        [ 0.7916],\n",
      "        [ 0.7850],\n",
      "        [-1.0897],\n",
      "        [ 0.1959],\n",
      "        [-1.1549],\n",
      "        [-1.1582],\n",
      "        [ 0.7890],\n",
      "        [-1.1397],\n",
      "        [ 0.7795],\n",
      "        [ 0.7916],\n",
      "        [-1.1723],\n",
      "        [ 0.5549],\n",
      "        [-0.6797],\n",
      "        [-1.1634],\n",
      "        [ 0.7897],\n",
      "        [-0.6797],\n",
      "        [-0.9810],\n",
      "        [-1.1695],\n",
      "        [ 0.7795],\n",
      "        [-1.1664],\n",
      "        [ 0.7580],\n",
      "        [-0.7467],\n",
      "        [ 0.7580],\n",
      "        [ 0.7916],\n",
      "        [ 0.7912]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 80/10000,\n",
      " train_loss: 0.0701,\n",
      " train_mae: 0.2220,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1671],\n",
      "        [-1.1671],\n",
      "        [ 0.7862],\n",
      "        [ 0.7822],\n",
      "        [ 0.4164],\n",
      "        [ 0.7727],\n",
      "        [ 0.7934],\n",
      "        [ 0.7942],\n",
      "        [ 0.7934],\n",
      "        [ 0.7917],\n",
      "        [-1.1800],\n",
      "        [-1.1454],\n",
      "        [ 0.7796],\n",
      "        [-0.0489],\n",
      "        [ 0.7938],\n",
      "        [-0.0489],\n",
      "        [ 0.7796],\n",
      "        [-1.0335],\n",
      "        [-0.3294],\n",
      "        [ 0.7929],\n",
      "        [ 0.7900],\n",
      "        [ 0.7909],\n",
      "        [ 0.7968],\n",
      "        [ 0.7968],\n",
      "        [ 0.7954],\n",
      "        [-0.3294],\n",
      "        [-1.1684],\n",
      "        [ 0.7954],\n",
      "        [-1.1747],\n",
      "        [ 0.7942],\n",
      "        [-1.1714],\n",
      "        [ 0.7796],\n",
      "        [-0.0489],\n",
      "        [ 0.7900],\n",
      "        [ 0.7765],\n",
      "        [ 0.7968],\n",
      "        [ 0.7900],\n",
      "        [-1.0912],\n",
      "        [ 0.2102],\n",
      "        [-1.1621],\n",
      "        [-1.1657],\n",
      "        [ 0.7942],\n",
      "        [-1.1454],\n",
      "        [ 0.7844],\n",
      "        [ 0.7968],\n",
      "        [-1.1811],\n",
      "        [ 0.5620],\n",
      "        [-0.6636],\n",
      "        [-1.1714],\n",
      "        [ 0.7948],\n",
      "        [-0.6636],\n",
      "        [-0.9758],\n",
      "        [-1.1781],\n",
      "        [ 0.7844],\n",
      "        [-1.1747],\n",
      "        [ 0.7627],\n",
      "        [-0.7323],\n",
      "        [ 0.7627],\n",
      "        [ 0.7968],\n",
      "        [ 0.7964]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 81/10000,\n",
      " train_loss: 0.0693,\n",
      " train_mae: 0.2209,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1734],\n",
      "        [-1.1734],\n",
      "        [ 0.7923],\n",
      "        [ 0.7882],\n",
      "        [ 0.4262],\n",
      "        [ 0.7786],\n",
      "        [ 0.7997],\n",
      "        [ 0.8006],\n",
      "        [ 0.7997],\n",
      "        [ 0.7980],\n",
      "        [-1.1875],\n",
      "        [-1.1496],\n",
      "        [ 0.7856],\n",
      "        [-0.0316],\n",
      "        [ 0.8002],\n",
      "        [-0.0316],\n",
      "        [ 0.7856],\n",
      "        [-1.0300],\n",
      "        [-0.3103],\n",
      "        [ 0.7992],\n",
      "        [ 0.7963],\n",
      "        [ 0.7972],\n",
      "        [ 0.8033],\n",
      "        [ 0.8033],\n",
      "        [ 0.8018],\n",
      "        [-0.3103],\n",
      "        [-1.1748],\n",
      "        [ 0.8018],\n",
      "        [-1.1818],\n",
      "        [ 0.8006],\n",
      "        [-1.1782],\n",
      "        [ 0.7856],\n",
      "        [-0.0316],\n",
      "        [ 0.7963],\n",
      "        [ 0.7824],\n",
      "        [ 0.8033],\n",
      "        [ 0.7963],\n",
      "        [-1.0912],\n",
      "        [ 0.2237],\n",
      "        [-1.1678],\n",
      "        [-1.1718],\n",
      "        [ 0.8006],\n",
      "        [-1.1496],\n",
      "        [ 0.7905],\n",
      "        [ 0.8033],\n",
      "        [-1.1887],\n",
      "        [ 0.5693],\n",
      "        [-0.6472],\n",
      "        [-1.1782],\n",
      "        [ 0.8012],\n",
      "        [-0.6472],\n",
      "        [-0.9692],\n",
      "        [-1.1854],\n",
      "        [ 0.7905],\n",
      "        [-1.1818],\n",
      "        [ 0.7685],\n",
      "        [-0.7173],\n",
      "        [ 0.7685],\n",
      "        [ 0.8033],\n",
      "        [ 0.8029]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 82/10000,\n",
      " train_loss: 0.0686,\n",
      " train_mae: 0.2201,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1797],\n",
      "        [-1.1797],\n",
      "        [ 0.7983],\n",
      "        [ 0.7941],\n",
      "        [ 0.4342],\n",
      "        [ 0.7842],\n",
      "        [ 0.8060],\n",
      "        [ 0.8068],\n",
      "        [ 0.8060],\n",
      "        [ 0.8042],\n",
      "        [-1.1951],\n",
      "        [-1.1537],\n",
      "        [ 0.7914],\n",
      "        [-0.0170],\n",
      "        [ 0.8064],\n",
      "        [-0.0170],\n",
      "        [ 0.7914],\n",
      "        [-1.0266],\n",
      "        [-0.2937],\n",
      "        [ 0.8055],\n",
      "        [ 0.8024],\n",
      "        [ 0.8033],\n",
      "        [ 0.8097],\n",
      "        [ 0.8097],\n",
      "        [ 0.8081],\n",
      "        [-0.2937],\n",
      "        [-1.1812],\n",
      "        [ 0.8081],\n",
      "        [-1.1889],\n",
      "        [ 0.8068],\n",
      "        [-1.1849],\n",
      "        [ 0.7914],\n",
      "        [-0.0170],\n",
      "        [ 0.8024],\n",
      "        [ 0.7881],\n",
      "        [ 0.8097],\n",
      "        [ 0.8024],\n",
      "        [-1.0913],\n",
      "        [ 0.2348],\n",
      "        [-1.1736],\n",
      "        [-1.1780],\n",
      "        [ 0.8068],\n",
      "        [-1.1537],\n",
      "        [ 0.7964],\n",
      "        [ 0.8097],\n",
      "        [-1.1963],\n",
      "        [ 0.5754],\n",
      "        [-0.6324],\n",
      "        [-1.1849],\n",
      "        [ 0.8075],\n",
      "        [-0.6324],\n",
      "        [-0.9630],\n",
      "        [-1.1928],\n",
      "        [ 0.7964],\n",
      "        [-1.1889],\n",
      "        [ 0.7739],\n",
      "        [-0.7037],\n",
      "        [ 0.7739],\n",
      "        [ 0.8097],\n",
      "        [ 0.8092]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 83/10000,\n",
      " train_loss: 0.0680,\n",
      " train_mae: 0.2192,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1871],\n",
      "        [-1.1871],\n",
      "        [ 0.8030],\n",
      "        [ 0.7987],\n",
      "        [ 0.4390],\n",
      "        [ 0.7885],\n",
      "        [ 0.8111],\n",
      "        [ 0.8120],\n",
      "        [ 0.8111],\n",
      "        [ 0.8092],\n",
      "        [-1.2039],\n",
      "        [-1.1590],\n",
      "        [ 0.7959],\n",
      "        [-0.0066],\n",
      "        [ 0.8116],\n",
      "        [-0.0066],\n",
      "        [ 0.7959],\n",
      "        [-1.0247],\n",
      "        [-0.2812],\n",
      "        [ 0.8105],\n",
      "        [ 0.8073],\n",
      "        [ 0.8083],\n",
      "        [ 0.8149],\n",
      "        [ 0.8149],\n",
      "        [ 0.8133],\n",
      "        [-0.2812],\n",
      "        [-1.1888],\n",
      "        [ 0.8133],\n",
      "        [-1.1971],\n",
      "        [ 0.8120],\n",
      "        [-1.1928],\n",
      "        [ 0.7959],\n",
      "        [-0.0066],\n",
      "        [ 0.8073],\n",
      "        [ 0.7925],\n",
      "        [ 0.8149],\n",
      "        [ 0.8073],\n",
      "        [-1.0925],\n",
      "        [ 0.2421],\n",
      "        [-1.1804],\n",
      "        [-1.1852],\n",
      "        [ 0.8120],\n",
      "        [-1.1590],\n",
      "        [ 0.8011],\n",
      "        [ 0.8149],\n",
      "        [-1.2052],\n",
      "        [ 0.5789],\n",
      "        [-0.6208],\n",
      "        [-1.1928],\n",
      "        [ 0.8127],\n",
      "        [-0.6208],\n",
      "        [-0.9586],\n",
      "        [-1.2014],\n",
      "        [ 0.8011],\n",
      "        [-1.1971],\n",
      "        [ 0.7780],\n",
      "        [-0.6930],\n",
      "        [ 0.7780],\n",
      "        [ 0.8149],\n",
      "        [ 0.8145]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 84/10000,\n",
      " train_loss: 0.0674,\n",
      " train_mae: 0.2188,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1960e+00],\n",
      "        [-1.1960e+00],\n",
      "        [ 8.0600e-01],\n",
      "        [ 8.0148e-01],\n",
      "        [ 4.4013e-01],\n",
      "        [ 7.9094e-01],\n",
      "        [ 8.1445e-01],\n",
      "        [ 8.1541e-01],\n",
      "        [ 8.1445e-01],\n",
      "        [ 8.1242e-01],\n",
      "        [-1.2142e+00],\n",
      "        [-1.1657e+00],\n",
      "        [ 7.9856e-01],\n",
      "        [-1.1252e-03],\n",
      "        [ 8.1496e-01],\n",
      "        [-1.1252e-03],\n",
      "        [ 7.9856e-01],\n",
      "        [-1.0248e+00],\n",
      "        [-2.7352e-01],\n",
      "        [ 8.1387e-01],\n",
      "        [ 8.1046e-01],\n",
      "        [ 8.1152e-01],\n",
      "        [ 8.1846e-01],\n",
      "        [ 8.1846e-01],\n",
      "        [ 8.1682e-01],\n",
      "        [-2.7352e-01],\n",
      "        [-1.1978e+00],\n",
      "        [ 8.1682e-01],\n",
      "        [-1.2069e+00],\n",
      "        [ 8.1541e-01],\n",
      "        [-1.2022e+00],\n",
      "        [ 7.9856e-01],\n",
      "        [-1.1252e-03],\n",
      "        [ 8.1046e-01],\n",
      "        [ 7.9508e-01],\n",
      "        [ 8.1846e-01],\n",
      "        [ 8.1046e-01],\n",
      "        [-1.0956e+00],\n",
      "        [ 2.4500e-01],\n",
      "        [-1.1888e+00],\n",
      "        [-1.1939e+00],\n",
      "        [ 8.1541e-01],\n",
      "        [-1.1657e+00],\n",
      "        [ 8.0393e-01],\n",
      "        [ 8.1846e-01],\n",
      "        [-1.2157e+00],\n",
      "        [ 5.7941e-01],\n",
      "        [-6.1313e-01],\n",
      "        [-1.2022e+00],\n",
      "        [ 8.1617e-01],\n",
      "        [-6.1313e-01],\n",
      "        [-9.5654e-01],\n",
      "        [-1.2116e+00],\n",
      "        [ 8.0393e-01],\n",
      "        [-1.2069e+00],\n",
      "        [ 7.8014e-01],\n",
      "        [-6.8595e-01],\n",
      "        [ 7.8014e-01],\n",
      "        [ 8.1846e-01],\n",
      "        [ 8.1800e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 85/10000,\n",
      " train_loss: 0.0668,\n",
      " train_mae: 0.2182,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2059e+00],\n",
      "        [-1.2059e+00],\n",
      "        [ 8.0719e-01],\n",
      "        [ 8.0244e-01],\n",
      "        [ 4.3762e-01],\n",
      "        [ 7.9146e-01],\n",
      "        [ 8.1611e-01],\n",
      "        [ 8.1712e-01],\n",
      "        [ 8.1611e-01],\n",
      "        [ 8.1396e-01],\n",
      "        [-1.2256e+00],\n",
      "        [-1.1735e+00],\n",
      "        [ 7.9939e-01],\n",
      "        [-1.9079e-04],\n",
      "        [ 8.1664e-01],\n",
      "        [-1.9079e-04],\n",
      "        [ 7.9939e-01],\n",
      "        [-1.0267e+00],\n",
      "        [-2.7033e-01],\n",
      "        [ 8.1549e-01],\n",
      "        [ 8.1189e-01],\n",
      "        [ 8.1301e-01],\n",
      "        [ 8.2032e-01],\n",
      "        [ 8.2032e-01],\n",
      "        [ 8.1861e-01],\n",
      "        [-2.7033e-01],\n",
      "        [-1.2078e+00],\n",
      "        [ 8.1861e-01],\n",
      "        [-1.2177e+00],\n",
      "        [ 8.1712e-01],\n",
      "        [-1.2126e+00],\n",
      "        [ 7.9939e-01],\n",
      "        [-1.9079e-04],\n",
      "        [ 8.1189e-01],\n",
      "        [ 7.9577e-01],\n",
      "        [ 8.2032e-01],\n",
      "        [ 8.1189e-01],\n",
      "        [-1.0999e+00],\n",
      "        [ 2.4370e-01],\n",
      "        [-1.1981e+00],\n",
      "        [-1.2036e+00],\n",
      "        [ 8.1712e-01],\n",
      "        [-1.1735e+00],\n",
      "        [ 8.0502e-01],\n",
      "        [ 8.2032e-01],\n",
      "        [-1.2272e+00],\n",
      "        [ 5.7683e-01],\n",
      "        [-6.0911e-01],\n",
      "        [-1.2126e+00],\n",
      "        [ 8.1793e-01],\n",
      "        [-6.0911e-01],\n",
      "        [-9.5654e-01],\n",
      "        [-1.2227e+00],\n",
      "        [ 8.0502e-01],\n",
      "        [-1.2177e+00],\n",
      "        [ 7.8028e-01],\n",
      "        [-6.8225e-01],\n",
      "        [ 7.8028e-01],\n",
      "        [ 8.2032e-01],\n",
      "        [ 8.1985e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 86/10000,\n",
      " train_loss: 0.0661,\n",
      " train_mae: 0.2174,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2155],\n",
      "        [-1.2155],\n",
      "        [ 0.8071],\n",
      "        [ 0.8021],\n",
      "        [ 0.4323],\n",
      "        [ 0.7906],\n",
      "        [ 0.8166],\n",
      "        [ 0.8177],\n",
      "        [ 0.8166],\n",
      "        [ 0.8143],\n",
      "        [-1.2369],\n",
      "        [-1.1811],\n",
      "        [ 0.7989],\n",
      "        [-0.0028],\n",
      "        [ 0.8171],\n",
      "        [-0.0028],\n",
      "        [ 0.7989],\n",
      "        [-1.0290],\n",
      "        [-0.2705],\n",
      "        [ 0.8159],\n",
      "        [ 0.8121],\n",
      "        [ 0.8133],\n",
      "        [ 0.8210],\n",
      "        [ 0.8210],\n",
      "        [ 0.8192],\n",
      "        [-0.2705],\n",
      "        [-1.2176],\n",
      "        [ 0.8192],\n",
      "        [-1.2283],\n",
      "        [ 0.8177],\n",
      "        [-1.2228],\n",
      "        [ 0.7989],\n",
      "        [-0.0028],\n",
      "        [ 0.8121],\n",
      "        [ 0.7951],\n",
      "        [ 0.8210],\n",
      "        [ 0.8121],\n",
      "        [-1.1044],\n",
      "        [ 0.2391],\n",
      "        [-1.2071],\n",
      "        [-1.2131],\n",
      "        [ 0.8177],\n",
      "        [-1.1811],\n",
      "        [ 0.8048],\n",
      "        [ 0.8210],\n",
      "        [-1.2386],\n",
      "        [ 0.5718],\n",
      "        [-0.6076],\n",
      "        [-1.2228],\n",
      "        [ 0.8185],\n",
      "        [-0.6076],\n",
      "        [-0.9574],\n",
      "        [-1.2338],\n",
      "        [ 0.8048],\n",
      "        [-1.2283],\n",
      "        [ 0.7790],\n",
      "        [-0.6808],\n",
      "        [ 0.7790],\n",
      "        [ 0.8210],\n",
      "        [ 0.8205]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 87/10000,\n",
      " train_loss: 0.0654,\n",
      " train_mae: 0.2163,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2234],\n",
      "        [-1.2234],\n",
      "        [ 0.8065],\n",
      "        [ 0.8012],\n",
      "        [ 0.4252],\n",
      "        [ 0.7891],\n",
      "        [ 0.8166],\n",
      "        [ 0.8178],\n",
      "        [ 0.8166],\n",
      "        [ 0.8142],\n",
      "        [-1.2465],\n",
      "        [-1.1871],\n",
      "        [ 0.7979],\n",
      "        [-0.0074],\n",
      "        [ 0.8172],\n",
      "        [-0.0074],\n",
      "        [ 0.7979],\n",
      "        [-1.0305],\n",
      "        [-0.2724],\n",
      "        [ 0.8159],\n",
      "        [ 0.8118],\n",
      "        [ 0.8131],\n",
      "        [ 0.8213],\n",
      "        [ 0.8213],\n",
      "        [ 0.8195],\n",
      "        [-0.2724],\n",
      "        [-1.2257],\n",
      "        [ 0.8195],\n",
      "        [-1.2372],\n",
      "        [ 0.8178],\n",
      "        [-1.2313],\n",
      "        [ 0.7979],\n",
      "        [-0.0074],\n",
      "        [ 0.8118],\n",
      "        [ 0.7939],\n",
      "        [ 0.8213],\n",
      "        [ 0.8118],\n",
      "        [-1.1075],\n",
      "        [ 0.2326],\n",
      "        [-1.2145],\n",
      "        [-1.2209],\n",
      "        [ 0.8178],\n",
      "        [-1.1871],\n",
      "        [ 0.8041],\n",
      "        [ 0.8213],\n",
      "        [-1.2484],\n",
      "        [ 0.5654],\n",
      "        [-0.6070],\n",
      "        [-1.2313],\n",
      "        [ 0.8187],\n",
      "        [-0.6070],\n",
      "        [-0.9578],\n",
      "        [-1.2432],\n",
      "        [ 0.8041],\n",
      "        [-1.2372],\n",
      "        [ 0.7770],\n",
      "        [-0.6799],\n",
      "        [ 0.7770],\n",
      "        [ 0.8213],\n",
      "        [ 0.8208]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 88/10000,\n",
      " train_loss: 0.0646,\n",
      " train_mae: 0.2150,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2284],\n",
      "        [-1.2284],\n",
      "        [ 0.8062],\n",
      "        [ 0.8006],\n",
      "        [ 0.4175],\n",
      "        [ 0.7878],\n",
      "        [ 0.8170],\n",
      "        [ 0.8182],\n",
      "        [ 0.8170],\n",
      "        [ 0.8144],\n",
      "        [-1.2533],\n",
      "        [-1.1902],\n",
      "        [ 0.7970],\n",
      "        [-0.0127],\n",
      "        [ 0.8177],\n",
      "        [-0.0127],\n",
      "        [ 0.7970],\n",
      "        [-1.0296],\n",
      "        [-0.2747],\n",
      "        [ 0.8162],\n",
      "        [ 0.8118],\n",
      "        [ 0.8132],\n",
      "        [ 0.8220],\n",
      "        [ 0.8220],\n",
      "        [ 0.8200],\n",
      "        [-0.2747],\n",
      "        [-1.2309],\n",
      "        [ 0.8200],\n",
      "        [-1.2433],\n",
      "        [ 0.8182],\n",
      "        [-1.2368],\n",
      "        [ 0.7970],\n",
      "        [-0.0127],\n",
      "        [ 0.8118],\n",
      "        [ 0.7928],\n",
      "        [ 0.8220],\n",
      "        [ 0.8118],\n",
      "        [-1.1081],\n",
      "        [ 0.2253],\n",
      "        [-1.2190],\n",
      "        [-1.2257],\n",
      "        [ 0.8182],\n",
      "        [-1.1902],\n",
      "        [ 0.8036],\n",
      "        [ 0.8220],\n",
      "        [-1.2553],\n",
      "        [ 0.5585],\n",
      "        [-0.6058],\n",
      "        [-1.2368],\n",
      "        [ 0.8192],\n",
      "        [-0.6058],\n",
      "        [-0.9561],\n",
      "        [-1.2497],\n",
      "        [ 0.8036],\n",
      "        [-1.2433],\n",
      "        [ 0.7751],\n",
      "        [-0.6782],\n",
      "        [ 0.7751],\n",
      "        [ 0.8220],\n",
      "        [ 0.8215]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 89/10000,\n",
      " train_loss: 0.0638,\n",
      " train_mae: 0.2134,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2298],\n",
      "        [-1.2298],\n",
      "        [ 0.8065],\n",
      "        [ 0.8005],\n",
      "        [ 0.4097],\n",
      "        [ 0.7870],\n",
      "        [ 0.8181],\n",
      "        [ 0.8195],\n",
      "        [ 0.8181],\n",
      "        [ 0.8153],\n",
      "        [-1.2567],\n",
      "        [-1.1897],\n",
      "        [ 0.7967],\n",
      "        [-0.0177],\n",
      "        [ 0.8188],\n",
      "        [-0.0177],\n",
      "        [ 0.7967],\n",
      "        [-1.0258],\n",
      "        [-0.2762],\n",
      "        [ 0.8173],\n",
      "        [ 0.8126],\n",
      "        [ 0.8140],\n",
      "        [ 0.8235],\n",
      "        [ 0.8235],\n",
      "        [ 0.8214],\n",
      "        [-0.2762],\n",
      "        [-1.2324],\n",
      "        [ 0.8214],\n",
      "        [-1.2458],\n",
      "        [ 0.8195],\n",
      "        [-1.2388],\n",
      "        [ 0.7967],\n",
      "        [-0.0177],\n",
      "        [ 0.8126],\n",
      "        [ 0.7923],\n",
      "        [ 0.8235],\n",
      "        [ 0.8126],\n",
      "        [-1.1054],\n",
      "        [ 0.2180],\n",
      "        [-1.2198],\n",
      "        [-1.2269],\n",
      "        [ 0.8195],\n",
      "        [-1.1897],\n",
      "        [ 0.8038],\n",
      "        [ 0.8235],\n",
      "        [-1.2588],\n",
      "        [ 0.5517],\n",
      "        [-0.6031],\n",
      "        [-1.2388],\n",
      "        [ 0.8205],\n",
      "        [-0.6031],\n",
      "        [-0.9518],\n",
      "        [-1.2527],\n",
      "        [ 0.8038],\n",
      "        [-1.2458],\n",
      "        [ 0.7737],\n",
      "        [-0.6749],\n",
      "        [ 0.7737],\n",
      "        [ 0.8235],\n",
      "        [ 0.8229]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 90/10000,\n",
      " train_loss: 0.0628,\n",
      " train_mae: 0.2116,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2278],\n",
      "        [-1.2278],\n",
      "        [ 0.8075],\n",
      "        [ 0.8012],\n",
      "        [ 0.4021],\n",
      "        [ 0.7869],\n",
      "        [ 0.8200],\n",
      "        [ 0.8215],\n",
      "        [ 0.8200],\n",
      "        [ 0.8170],\n",
      "        [-1.2567],\n",
      "        [-1.1858],\n",
      "        [ 0.7971],\n",
      "        [-0.0223],\n",
      "        [ 0.8208],\n",
      "        [-0.0223],\n",
      "        [ 0.7971],\n",
      "        [-1.0190],\n",
      "        [-0.2770],\n",
      "        [ 0.8192],\n",
      "        [ 0.8140],\n",
      "        [ 0.8156],\n",
      "        [ 0.8258],\n",
      "        [ 0.8258],\n",
      "        [ 0.8236],\n",
      "        [-0.2770],\n",
      "        [-1.2306],\n",
      "        [ 0.8236],\n",
      "        [-1.2449],\n",
      "        [ 0.8215],\n",
      "        [-1.2374],\n",
      "        [ 0.7971],\n",
      "        [-0.0223],\n",
      "        [ 0.8140],\n",
      "        [ 0.7924],\n",
      "        [ 0.8258],\n",
      "        [ 0.8140],\n",
      "        [-1.0995],\n",
      "        [ 0.2110],\n",
      "        [-1.2172],\n",
      "        [-1.2247],\n",
      "        [ 0.8215],\n",
      "        [-1.1858],\n",
      "        [ 0.8046],\n",
      "        [ 0.8258],\n",
      "        [-1.2591],\n",
      "        [ 0.5451],\n",
      "        [-0.5989],\n",
      "        [-1.2374],\n",
      "        [ 0.8226],\n",
      "        [-0.5989],\n",
      "        [-0.9448],\n",
      "        [-1.2524],\n",
      "        [ 0.8046],\n",
      "        [-1.2449],\n",
      "        [ 0.7728],\n",
      "        [-0.6697],\n",
      "        [ 0.7728],\n",
      "        [ 0.8258],\n",
      "        [ 0.8252]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 91/10000,\n",
      " train_loss: 0.0618,\n",
      " train_mae: 0.2096,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2232],\n",
      "        [-1.2232],\n",
      "        [ 0.8089],\n",
      "        [ 0.8021],\n",
      "        [ 0.3943],\n",
      "        [ 0.7869],\n",
      "        [ 0.8224],\n",
      "        [ 0.8240],\n",
      "        [ 0.8224],\n",
      "        [ 0.8190],\n",
      "        [-1.2544],\n",
      "        [-1.1794],\n",
      "        [ 0.7978],\n",
      "        [-0.0269],\n",
      "        [ 0.8232],\n",
      "        [-0.0269],\n",
      "        [ 0.7978],\n",
      "        [-1.0102],\n",
      "        [-0.2774],\n",
      "        [ 0.8214],\n",
      "        [ 0.8159],\n",
      "        [ 0.8176],\n",
      "        [ 0.8285],\n",
      "        [ 0.8285],\n",
      "        [ 0.8262],\n",
      "        [-0.2774],\n",
      "        [-1.2262],\n",
      "        [ 0.8262],\n",
      "        [-1.2416],\n",
      "        [ 0.8240],\n",
      "        [-1.2335],\n",
      "        [ 0.7978],\n",
      "        [-0.0269],\n",
      "        [ 0.8159],\n",
      "        [ 0.7928],\n",
      "        [ 0.8285],\n",
      "        [ 0.8159],\n",
      "        [-1.0913],\n",
      "        [ 0.2038],\n",
      "        [-1.2121],\n",
      "        [-1.2200],\n",
      "        [ 0.8240],\n",
      "        [-1.1794],\n",
      "        [ 0.8057],\n",
      "        [ 0.8285],\n",
      "        [-1.2570],\n",
      "        [ 0.5381],\n",
      "        [-0.5937],\n",
      "        [-1.2335],\n",
      "        [ 0.8252],\n",
      "        [-0.5937],\n",
      "        [-0.9361],\n",
      "        [-1.2497],\n",
      "        [ 0.8057],\n",
      "        [-1.2416],\n",
      "        [ 0.7720],\n",
      "        [-0.6635],\n",
      "        [ 0.7720],\n",
      "        [ 0.8285],\n",
      "        [ 0.8279]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 92/10000,\n",
      " train_loss: 0.0607,\n",
      " train_mae: 0.2074,\n",
      " epoch_time_duration: 0.0153\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2175],\n",
      "        [-1.2175],\n",
      "        [ 0.8100],\n",
      "        [ 0.8026],\n",
      "        [ 0.3854],\n",
      "        [ 0.7865],\n",
      "        [ 0.8246],\n",
      "        [ 0.8263],\n",
      "        [ 0.8246],\n",
      "        [ 0.8209],\n",
      "        [-1.2511],\n",
      "        [-1.1719],\n",
      "        [ 0.7981],\n",
      "        [-0.0323],\n",
      "        [ 0.8255],\n",
      "        [-0.0323],\n",
      "        [ 0.7981],\n",
      "        [-1.0007],\n",
      "        [-0.2784],\n",
      "        [ 0.8235],\n",
      "        [ 0.8175],\n",
      "        [ 0.8193],\n",
      "        [ 0.8312],\n",
      "        [ 0.8312],\n",
      "        [ 0.8287],\n",
      "        [-0.2784],\n",
      "        [-1.2206],\n",
      "        [ 0.8287],\n",
      "        [-1.2371],\n",
      "        [ 0.8263],\n",
      "        [-1.2284],\n",
      "        [ 0.7981],\n",
      "        [-0.0323],\n",
      "        [ 0.8175],\n",
      "        [ 0.7927],\n",
      "        [ 0.8312],\n",
      "        [ 0.8175],\n",
      "        [-1.0821],\n",
      "        [ 0.1956],\n",
      "        [-1.2057],\n",
      "        [-1.2140],\n",
      "        [ 0.8263],\n",
      "        [-1.1719],\n",
      "        [ 0.8066],\n",
      "        [ 0.8312],\n",
      "        [-1.2539],\n",
      "        [ 0.5303],\n",
      "        [-0.5888],\n",
      "        [-1.2284],\n",
      "        [ 0.8276],\n",
      "        [-0.5888],\n",
      "        [-0.9267],\n",
      "        [-1.2460],\n",
      "        [ 0.8066],\n",
      "        [-1.2371],\n",
      "        [ 0.7708],\n",
      "        [-0.6574],\n",
      "        [ 0.7708],\n",
      "        [ 0.8312],\n",
      "        [ 0.8306]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 93/10000,\n",
      " train_loss: 0.0595,\n",
      " train_mae: 0.2050,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2119],\n",
      "        [-1.2119],\n",
      "        [ 0.8102],\n",
      "        [ 0.8023],\n",
      "        [ 0.3748],\n",
      "        [ 0.7851],\n",
      "        [ 0.8261],\n",
      "        [ 0.8279],\n",
      "        [ 0.8261],\n",
      "        [ 0.8221],\n",
      "        [-1.2482],\n",
      "        [-1.1645],\n",
      "        [ 0.7974],\n",
      "        [-0.0394],\n",
      "        [ 0.8271],\n",
      "        [-0.0394],\n",
      "        [ 0.7974],\n",
      "        [-0.9916],\n",
      "        [-0.2810],\n",
      "        [ 0.8249],\n",
      "        [ 0.8183],\n",
      "        [ 0.8204],\n",
      "        [ 0.8333],\n",
      "        [ 0.8333],\n",
      "        [ 0.8306],\n",
      "        [-0.2810],\n",
      "        [-1.2152],\n",
      "        [ 0.8306],\n",
      "        [-1.2330],\n",
      "        [ 0.8279],\n",
      "        [-1.2236],\n",
      "        [ 0.7974],\n",
      "        [-0.0394],\n",
      "        [ 0.8183],\n",
      "        [ 0.7917],\n",
      "        [ 0.8333],\n",
      "        [ 0.8183],\n",
      "        [-1.0733],\n",
      "        [ 0.1856],\n",
      "        [-1.1995],\n",
      "        [-1.2083],\n",
      "        [ 0.8279],\n",
      "        [-1.1645],\n",
      "        [ 0.8065],\n",
      "        [ 0.8333],\n",
      "        [-1.2513],\n",
      "        [ 0.5208],\n",
      "        [-0.5850],\n",
      "        [-1.2236],\n",
      "        [ 0.8294],\n",
      "        [-0.5850],\n",
      "        [-0.9180],\n",
      "        [-1.2427],\n",
      "        [ 0.8065],\n",
      "        [-1.2330],\n",
      "        [ 0.7685],\n",
      "        [-0.6524],\n",
      "        [ 0.7685],\n",
      "        [ 0.8333],\n",
      "        [ 0.8326]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 94/10000,\n",
      " train_loss: 0.0583,\n",
      " train_mae: 0.2027,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2074],\n",
      "        [-1.2074],\n",
      "        [ 0.8092],\n",
      "        [ 0.8008],\n",
      "        [ 0.3621],\n",
      "        [ 0.7823],\n",
      "        [ 0.8265],\n",
      "        [ 0.8286],\n",
      "        [ 0.8265],\n",
      "        [ 0.8222],\n",
      "        [-1.2468],\n",
      "        [-1.1581],\n",
      "        [ 0.7955],\n",
      "        [-0.0486],\n",
      "        [ 0.8276],\n",
      "        [-0.0486],\n",
      "        [ 0.7955],\n",
      "        [-0.9839],\n",
      "        [-0.2857],\n",
      "        [ 0.8253],\n",
      "        [ 0.8181],\n",
      "        [ 0.8203],\n",
      "        [ 0.8344],\n",
      "        [ 0.8344],\n",
      "        [ 0.8315],\n",
      "        [-0.2857],\n",
      "        [-1.2109],\n",
      "        [ 0.8315],\n",
      "        [-1.2300],\n",
      "        [ 0.8286],\n",
      "        [-1.2198],\n",
      "        [ 0.7955],\n",
      "        [-0.0486],\n",
      "        [ 0.8181],\n",
      "        [ 0.7894],\n",
      "        [ 0.8344],\n",
      "        [ 0.8181],\n",
      "        [-1.0656],\n",
      "        [ 0.1735],\n",
      "        [-1.1944],\n",
      "        [-1.2036],\n",
      "        [ 0.8286],\n",
      "        [-1.1581],\n",
      "        [ 0.8053],\n",
      "        [ 0.8344],\n",
      "        [-1.2501],\n",
      "        [ 0.5092],\n",
      "        [-0.5832],\n",
      "        [-1.2198],\n",
      "        [ 0.8302],\n",
      "        [-0.5832],\n",
      "        [-0.9107],\n",
      "        [-1.2406],\n",
      "        [ 0.8053],\n",
      "        [-1.2300],\n",
      "        [ 0.7647],\n",
      "        [-0.6492],\n",
      "        [ 0.7647],\n",
      "        [ 0.8344],\n",
      "        [ 0.8337]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 95/10000,\n",
      " train_loss: 0.0571,\n",
      " train_mae: 0.2003,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2044],\n",
      "        [-1.2044],\n",
      "        [ 0.8072],\n",
      "        [ 0.7980],\n",
      "        [ 0.3474],\n",
      "        [ 0.7782],\n",
      "        [ 0.8261],\n",
      "        [ 0.8284],\n",
      "        [ 0.8261],\n",
      "        [ 0.8213],\n",
      "        [-1.2471],\n",
      "        [-1.1531],\n",
      "        [ 0.7923],\n",
      "        [-0.0599],\n",
      "        [ 0.8273],\n",
      "        [-0.0599],\n",
      "        [ 0.7923],\n",
      "        [-0.9777],\n",
      "        [-0.2923],\n",
      "        [ 0.8247],\n",
      "        [ 0.8168],\n",
      "        [ 0.8192],\n",
      "        [ 0.8347],\n",
      "        [ 0.8347],\n",
      "        [ 0.8316],\n",
      "        [-0.2923],\n",
      "        [-1.2081],\n",
      "        [ 0.8316],\n",
      "        [-1.2287],\n",
      "        [ 0.8284],\n",
      "        [-1.2176],\n",
      "        [ 0.7923],\n",
      "        [-0.0599],\n",
      "        [ 0.8168],\n",
      "        [ 0.7858],\n",
      "        [ 0.8347],\n",
      "        [ 0.8168],\n",
      "        [-1.0593],\n",
      "        [ 0.1594],\n",
      "        [-1.1907],\n",
      "        [-1.2003],\n",
      "        [ 0.8284],\n",
      "        [-1.1531],\n",
      "        [ 0.8029],\n",
      "        [ 0.8347],\n",
      "        [-1.2508],\n",
      "        [ 0.4957],\n",
      "        [-0.5832],\n",
      "        [-1.2176],\n",
      "        [ 0.8302],\n",
      "        [-0.5832],\n",
      "        [-0.9051],\n",
      "        [-1.2403],\n",
      "        [ 0.8029],\n",
      "        [-1.2287],\n",
      "        [ 0.7595],\n",
      "        [-0.6478],\n",
      "        [ 0.7595],\n",
      "        [ 0.8347],\n",
      "        [ 0.8340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 96/10000,\n",
      " train_loss: 0.0558,\n",
      " train_mae: 0.1978,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2024],\n",
      "        [-1.2024],\n",
      "        [ 0.8044],\n",
      "        [ 0.7945],\n",
      "        [ 0.3313],\n",
      "        [ 0.7732],\n",
      "        [ 0.8251],\n",
      "        [ 0.8276],\n",
      "        [ 0.8251],\n",
      "        [ 0.8198],\n",
      "        [-1.2490],\n",
      "        [-1.1491],\n",
      "        [ 0.7884],\n",
      "        [-0.0723],\n",
      "        [ 0.8265],\n",
      "        [-0.0723],\n",
      "        [ 0.7884],\n",
      "        [-0.9725],\n",
      "        [-0.3001],\n",
      "        [ 0.8236],\n",
      "        [ 0.8149],\n",
      "        [ 0.8175],\n",
      "        [ 0.8346],\n",
      "        [ 0.8346],\n",
      "        [ 0.8312],\n",
      "        [-0.3001],\n",
      "        [-1.2063],\n",
      "        [ 0.8312],\n",
      "        [-1.2287],\n",
      "        [ 0.8276],\n",
      "        [-1.2166],\n",
      "        [ 0.7884],\n",
      "        [-0.0723],\n",
      "        [ 0.8149],\n",
      "        [ 0.7813],\n",
      "        [ 0.8346],\n",
      "        [ 0.8149],\n",
      "        [-1.0541],\n",
      "        [ 0.1440],\n",
      "        [-1.1880],\n",
      "        [-1.1981],\n",
      "        [ 0.8276],\n",
      "        [-1.1491],\n",
      "        [ 0.7998],\n",
      "        [ 0.8346],\n",
      "        [-1.2531],\n",
      "        [ 0.4807],\n",
      "        [-0.5844],\n",
      "        [-1.2166],\n",
      "        [ 0.8296],\n",
      "        [-0.5844],\n",
      "        [-0.9005],\n",
      "        [-1.2415],\n",
      "        [ 0.7998],\n",
      "        [-1.2287],\n",
      "        [ 0.7533],\n",
      "        [-0.6476],\n",
      "        [ 0.7533],\n",
      "        [ 0.8346],\n",
      "        [ 0.8338]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 97/10000,\n",
      " train_loss: 0.0545,\n",
      " train_mae: 0.1951,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2009],\n",
      "        [-1.2009],\n",
      "        [ 0.8015],\n",
      "        [ 0.7907],\n",
      "        [ 0.3147],\n",
      "        [ 0.7679],\n",
      "        [ 0.8242],\n",
      "        [ 0.8270],\n",
      "        [ 0.8242],\n",
      "        [ 0.8184],\n",
      "        [-1.2519],\n",
      "        [-1.1454],\n",
      "        [ 0.7841],\n",
      "        [-0.0849],\n",
      "        [ 0.8257],\n",
      "        [-0.0849],\n",
      "        [ 0.7841],\n",
      "        [-0.9674],\n",
      "        [-0.3079],\n",
      "        [ 0.8225],\n",
      "        [ 0.8130],\n",
      "        [ 0.8158],\n",
      "        [ 0.8348],\n",
      "        [ 0.8348],\n",
      "        [ 0.8310],\n",
      "        [-0.3079],\n",
      "        [-1.2051],\n",
      "        [ 0.8310],\n",
      "        [-1.2293],\n",
      "        [ 0.8270],\n",
      "        [-1.2161],\n",
      "        [ 0.7841],\n",
      "        [-0.0849],\n",
      "        [ 0.8130],\n",
      "        [ 0.7766],\n",
      "        [ 0.8348],\n",
      "        [ 0.8130],\n",
      "        [-1.0490],\n",
      "        [ 0.1283],\n",
      "        [-1.1857],\n",
      "        [-1.1963],\n",
      "        [ 0.8270],\n",
      "        [-1.1454],\n",
      "        [ 0.7965],\n",
      "        [ 0.8348],\n",
      "        [-1.2566],\n",
      "        [ 0.4652],\n",
      "        [-0.5857],\n",
      "        [-1.2161],\n",
      "        [ 0.8292],\n",
      "        [-0.5857],\n",
      "        [-0.8960],\n",
      "        [-1.2436],\n",
      "        [ 0.7965],\n",
      "        [-1.2293],\n",
      "        [ 0.7467],\n",
      "        [-0.6475],\n",
      "        [ 0.7467],\n",
      "        [ 0.8348],\n",
      "        [ 0.8338]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 98/10000,\n",
      " train_loss: 0.0531,\n",
      " train_mae: 0.1922,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1991],\n",
      "        [-1.1991],\n",
      "        [ 0.7990],\n",
      "        [ 0.7874],\n",
      "        [ 0.2986],\n",
      "        [ 0.7629],\n",
      "        [ 0.8240],\n",
      "        [ 0.8271],\n",
      "        [ 0.8240],\n",
      "        [ 0.8175],\n",
      "        [-1.2554],\n",
      "        [-1.1411],\n",
      "        [ 0.7803],\n",
      "        [-0.0965],\n",
      "        [ 0.8257],\n",
      "        [-0.0965],\n",
      "        [ 0.7803],\n",
      "        [-0.9616],\n",
      "        [-0.3147],\n",
      "        [ 0.8221],\n",
      "        [ 0.8116],\n",
      "        [ 0.8148],\n",
      "        [ 0.8357],\n",
      "        [ 0.8357],\n",
      "        [ 0.8316],\n",
      "        [-0.3147],\n",
      "        [-1.2036],\n",
      "        [ 0.8316],\n",
      "        [-1.2301],\n",
      "        [ 0.8271],\n",
      "        [-1.2155],\n",
      "        [ 0.7803],\n",
      "        [-0.0965],\n",
      "        [ 0.8116],\n",
      "        [ 0.7721],\n",
      "        [ 0.8357],\n",
      "        [ 0.8116],\n",
      "        [-1.0432],\n",
      "        [ 0.1134],\n",
      "        [-1.1829],\n",
      "        [-1.1942],\n",
      "        [ 0.8271],\n",
      "        [-1.1411],\n",
      "        [ 0.7936],\n",
      "        [ 0.8357],\n",
      "        [-1.2606],\n",
      "        [ 0.4499],\n",
      "        [-0.5859],\n",
      "        [-1.2155],\n",
      "        [ 0.8296],\n",
      "        [-0.5859],\n",
      "        [-0.8907],\n",
      "        [-1.2460],\n",
      "        [ 0.7936],\n",
      "        [-1.2301],\n",
      "        [ 0.7403],\n",
      "        [-0.6463],\n",
      "        [ 0.7403],\n",
      "        [ 0.8357],\n",
      "        [ 0.8347]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 99/10000,\n",
      " train_loss: 0.0517,\n",
      " train_mae: 0.1892,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1965],\n",
      "        [-1.1965],\n",
      "        [ 0.7975],\n",
      "        [ 0.7848],\n",
      "        [ 0.2837],\n",
      "        [ 0.7585],\n",
      "        [ 0.8249],\n",
      "        [ 0.8284],\n",
      "        [ 0.8249],\n",
      "        [ 0.8177],\n",
      "        [-1.2590],\n",
      "        [-1.1357],\n",
      "        [ 0.7772],\n",
      "        [-0.1063],\n",
      "        [ 0.8268],\n",
      "        [-0.1063],\n",
      "        [ 0.7772],\n",
      "        [-0.9543],\n",
      "        [-0.3196],\n",
      "        [ 0.8228],\n",
      "        [ 0.8112],\n",
      "        [ 0.8147],\n",
      "        [ 0.8379],\n",
      "        [ 0.8379],\n",
      "        [ 0.8333],\n",
      "        [-0.3196],\n",
      "        [-1.2013],\n",
      "        [ 0.8333],\n",
      "        [-1.2305],\n",
      "        [ 0.8284],\n",
      "        [-1.2143],\n",
      "        [ 0.7772],\n",
      "        [-0.1063],\n",
      "        [ 0.8112],\n",
      "        [ 0.7685],\n",
      "        [ 0.8379],\n",
      "        [ 0.8112],\n",
      "        [-1.0360],\n",
      "        [ 0.1000],\n",
      "        [-1.1793],\n",
      "        [-1.1912],\n",
      "        [ 0.8284],\n",
      "        [-1.1357],\n",
      "        [ 0.7916],\n",
      "        [ 0.8379],\n",
      "        [-1.2649],\n",
      "        [ 0.4355],\n",
      "        [-0.5843],\n",
      "        [-1.2143],\n",
      "        [ 0.8311],\n",
      "        [-0.5843],\n",
      "        [-0.8838],\n",
      "        [-1.2484],\n",
      "        [ 0.7916],\n",
      "        [-1.2305],\n",
      "        [ 0.7345],\n",
      "        [-0.6434],\n",
      "        [ 0.7345],\n",
      "        [ 0.8379],\n",
      "        [ 0.8368]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 100/10000,\n",
      " train_loss: 0.0502,\n",
      " train_mae: 0.1859,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1931],\n",
      "        [-1.1931],\n",
      "        [ 0.7968],\n",
      "        [ 0.7832],\n",
      "        [ 0.2702],\n",
      "        [ 0.7550],\n",
      "        [ 0.8270],\n",
      "        [ 0.8309],\n",
      "        [ 0.8270],\n",
      "        [ 0.8190],\n",
      "        [-1.2631],\n",
      "        [-1.1291],\n",
      "        [ 0.7749],\n",
      "        [-0.1142],\n",
      "        [ 0.8290],\n",
      "        [-0.1142],\n",
      "        [ 0.7749],\n",
      "        [-0.9453],\n",
      "        [-0.3224],\n",
      "        [ 0.8246],\n",
      "        [ 0.8118],\n",
      "        [ 0.8156],\n",
      "        [ 0.8415],\n",
      "        [ 0.8415],\n",
      "        [ 0.8364],\n",
      "        [-0.3224],\n",
      "        [-1.1983],\n",
      "        [ 0.8364],\n",
      "        [-1.2306],\n",
      "        [ 0.8309],\n",
      "        [-1.2126],\n",
      "        [ 0.7749],\n",
      "        [-0.1142],\n",
      "        [ 0.8118],\n",
      "        [ 0.7656],\n",
      "        [ 0.8415],\n",
      "        [ 0.8118],\n",
      "        [-1.0274],\n",
      "        [ 0.0883],\n",
      "        [-1.1747],\n",
      "        [-1.1875],\n",
      "        [ 0.8309],\n",
      "        [-1.1291],\n",
      "        [ 0.7904],\n",
      "        [ 0.8415],\n",
      "        [-1.2698],\n",
      "        [ 0.4222],\n",
      "        [-0.5807],\n",
      "        [-1.2126],\n",
      "        [ 0.8339],\n",
      "        [-0.5807],\n",
      "        [-0.8752],\n",
      "        [-1.2510],\n",
      "        [ 0.7904],\n",
      "        [-1.2306],\n",
      "        [ 0.7295],\n",
      "        [-0.6386],\n",
      "        [ 0.7295],\n",
      "        [ 0.8415],\n",
      "        [ 0.8403]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 101/10000,\n",
      " train_loss: 0.0486,\n",
      " train_mae: 0.1823,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1894],\n",
      "        [-1.1894],\n",
      "        [ 0.7969],\n",
      "        [ 0.7821],\n",
      "        [ 0.2579],\n",
      "        [ 0.7519],\n",
      "        [ 0.8300],\n",
      "        [ 0.8343],\n",
      "        [ 0.8300],\n",
      "        [ 0.8211],\n",
      "        [-1.2684],\n",
      "        [-1.1216],\n",
      "        [ 0.7732],\n",
      "        [-0.1203],\n",
      "        [ 0.8322],\n",
      "        [-0.1203],\n",
      "        [ 0.7732],\n",
      "        [-0.9351],\n",
      "        [-0.3235],\n",
      "        [ 0.8274],\n",
      "        [ 0.8132],\n",
      "        [ 0.8174],\n",
      "        [ 0.8462],\n",
      "        [ 0.8462],\n",
      "        [ 0.8405],\n",
      "        [-0.3235],\n",
      "        [-1.1951],\n",
      "        [ 0.8405],\n",
      "        [-1.2311],\n",
      "        [ 0.8343],\n",
      "        [-1.2108],\n",
      "        [ 0.7732],\n",
      "        [-0.1203],\n",
      "        [ 0.8132],\n",
      "        [ 0.7632],\n",
      "        [ 0.8462],\n",
      "        [ 0.8132],\n",
      "        [-1.0176],\n",
      "        [ 0.0781],\n",
      "        [-1.1696],\n",
      "        [-1.1833],\n",
      "        [ 0.8343],\n",
      "        [-1.1216],\n",
      "        [ 0.7899],\n",
      "        [ 0.8462],\n",
      "        [-1.2762],\n",
      "        [ 0.4098],\n",
      "        [-0.5755],\n",
      "        [-1.2108],\n",
      "        [ 0.8377],\n",
      "        [-0.5755],\n",
      "        [-0.8653],\n",
      "        [-1.2545],\n",
      "        [ 0.7899],\n",
      "        [-1.2311],\n",
      "        [ 0.7249],\n",
      "        [-0.6321],\n",
      "        [ 0.7249],\n",
      "        [ 0.8462],\n",
      "        [ 0.8448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 102/10000,\n",
      " train_loss: 0.0468,\n",
      " train_mae: 0.1784,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1860],\n",
      "        [-1.1860],\n",
      "        [ 0.7971],\n",
      "        [ 0.7811],\n",
      "        [ 0.2461],\n",
      "        [ 0.7488],\n",
      "        [ 0.8334],\n",
      "        [ 0.8382],\n",
      "        [ 0.8334],\n",
      "        [ 0.8236],\n",
      "        [-1.2762],\n",
      "        [-1.1140],\n",
      "        [ 0.7716],\n",
      "        [-0.1255],\n",
      "        [ 0.8360],\n",
      "        [-0.1255],\n",
      "        [ 0.7716],\n",
      "        [-0.9243],\n",
      "        [-0.3236],\n",
      "        [ 0.8305],\n",
      "        [ 0.8149],\n",
      "        [ 0.8195],\n",
      "        [ 0.8516],\n",
      "        [ 0.8516],\n",
      "        [ 0.8452],\n",
      "        [-0.3236],\n",
      "        [-1.1923],\n",
      "        [ 0.8452],\n",
      "        [-1.2330],\n",
      "        [ 0.8382],\n",
      "        [-1.2098],\n",
      "        [ 0.7716],\n",
      "        [-0.1255],\n",
      "        [ 0.8149],\n",
      "        [ 0.7609],\n",
      "        [ 0.8516],\n",
      "        [ 0.8149],\n",
      "        [-1.0074],\n",
      "        [ 0.0688],\n",
      "        [-1.1646],\n",
      "        [-1.1794],\n",
      "        [ 0.8382],\n",
      "        [-1.1140],\n",
      "        [ 0.7895],\n",
      "        [ 0.8516],\n",
      "        [-1.2853],\n",
      "        [ 0.3976],\n",
      "        [-0.5695],\n",
      "        [-1.2098],\n",
      "        [ 0.8421],\n",
      "        [-0.5695],\n",
      "        [-0.8547],\n",
      "        [-1.2600],\n",
      "        [ 0.7895],\n",
      "        [-1.2330],\n",
      "        [ 0.7202],\n",
      "        [-0.6249],\n",
      "        [ 0.7202],\n",
      "        [ 0.8516],\n",
      "        [ 0.8501]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 103/10000,\n",
      " train_loss: 0.0450,\n",
      " train_mae: 0.1740,\n",
      " epoch_time_duration: 0.0101\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1838],\n",
      "        [-1.1838],\n",
      "        [ 0.7969],\n",
      "        [ 0.7797],\n",
      "        [ 0.2343],\n",
      "        [ 0.7452],\n",
      "        [ 0.8368],\n",
      "        [ 0.8423],\n",
      "        [ 0.8368],\n",
      "        [ 0.8260],\n",
      "        [-1.2878],\n",
      "        [-1.1069],\n",
      "        [ 0.7694],\n",
      "        [-0.1304],\n",
      "        [ 0.8397],\n",
      "        [-0.1304],\n",
      "        [ 0.7694],\n",
      "        [-0.9136],\n",
      "        [-0.3235],\n",
      "        [ 0.8336],\n",
      "        [ 0.8163],\n",
      "        [ 0.8214],\n",
      "        [ 0.8573],\n",
      "        [ 0.8573],\n",
      "        [ 0.8501],\n",
      "        [-0.3235],\n",
      "        [-1.1907],\n",
      "        [ 0.8501],\n",
      "        [-1.2370],\n",
      "        [ 0.8423],\n",
      "        [-1.2104],\n",
      "        [ 0.7694],\n",
      "        [-0.1304],\n",
      "        [ 0.8163],\n",
      "        [ 0.7580],\n",
      "        [ 0.8573],\n",
      "        [ 0.8163],\n",
      "        [-0.9973],\n",
      "        [ 0.0596],\n",
      "        [-1.1605],\n",
      "        [-1.1765],\n",
      "        [ 0.8423],\n",
      "        [-1.1069],\n",
      "        [ 0.7888],\n",
      "        [ 0.8573],\n",
      "        [-1.2985],\n",
      "        [ 0.3851],\n",
      "        [-0.5633],\n",
      "        [-1.2104],\n",
      "        [ 0.8466],\n",
      "        [-0.5633],\n",
      "        [-0.8442],\n",
      "        [-1.2687],\n",
      "        [ 0.7888],\n",
      "        [-1.2370],\n",
      "        [ 0.7149],\n",
      "        [-0.6175],\n",
      "        [ 0.7149],\n",
      "        [ 0.8573],\n",
      "        [ 0.8556]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 104/10000,\n",
      " train_loss: 0.0430,\n",
      " train_mae: 0.1693,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1830],\n",
      "        [-1.1830],\n",
      "        [ 0.7960],\n",
      "        [ 0.7774],\n",
      "        [ 0.2220],\n",
      "        [ 0.7406],\n",
      "        [ 0.8399],\n",
      "        [ 0.8460],\n",
      "        [ 0.8399],\n",
      "        [ 0.8279],\n",
      "        [-1.3045],\n",
      "        [-1.1005],\n",
      "        [ 0.7664],\n",
      "        [-0.1356],\n",
      "        [ 0.8431],\n",
      "        [-0.1356],\n",
      "        [ 0.7664],\n",
      "        [-0.9033],\n",
      "        [-0.3236],\n",
      "        [ 0.8363],\n",
      "        [ 0.8172],\n",
      "        [ 0.8228],\n",
      "        [ 0.8630],\n",
      "        [ 0.8630],\n",
      "        [ 0.8548],\n",
      "        [-0.3236],\n",
      "        [-1.1908],\n",
      "        [ 0.8548],\n",
      "        [-1.2442],\n",
      "        [ 0.8460],\n",
      "        [-1.2131],\n",
      "        [ 0.7664],\n",
      "        [-0.1356],\n",
      "        [ 0.8172],\n",
      "        [ 0.7542],\n",
      "        [ 0.8630],\n",
      "        [ 0.8172],\n",
      "        [-0.9877],\n",
      "        [ 0.0501],\n",
      "        [-1.1575],\n",
      "        [-1.1750],\n",
      "        [ 0.8460],\n",
      "        [-1.1005],\n",
      "        [ 0.7872],\n",
      "        [ 0.8630],\n",
      "        [-1.3172],\n",
      "        [ 0.3719],\n",
      "        [-0.5573],\n",
      "        [-1.2131],\n",
      "        [ 0.8509],\n",
      "        [-0.5573],\n",
      "        [-0.8340],\n",
      "        [-1.2817],\n",
      "        [ 0.7872],\n",
      "        [-1.2442],\n",
      "        [ 0.7086],\n",
      "        [-0.6104],\n",
      "        [ 0.7086],\n",
      "        [ 0.8630],\n",
      "        [ 0.8611]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 105/10000,\n",
      " train_loss: 0.0408,\n",
      " train_mae: 0.1639,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1838],\n",
      "        [-1.1838],\n",
      "        [ 0.7943],\n",
      "        [ 0.7742],\n",
      "        [ 0.2090],\n",
      "        [ 0.7349],\n",
      "        [ 0.8426],\n",
      "        [ 0.8494],\n",
      "        [ 0.8426],\n",
      "        [ 0.8292],\n",
      "        [-1.3275],\n",
      "        [-1.0947],\n",
      "        [ 0.7625],\n",
      "        [-0.1410],\n",
      "        [ 0.8462],\n",
      "        [-0.1410],\n",
      "        [ 0.7625],\n",
      "        [-0.8933],\n",
      "        [-0.3239],\n",
      "        [ 0.8386],\n",
      "        [ 0.8175],\n",
      "        [ 0.8236],\n",
      "        [ 0.8687],\n",
      "        [ 0.8687],\n",
      "        [ 0.8594],\n",
      "        [-0.3239],\n",
      "        [-1.1925],\n",
      "        [ 0.8594],\n",
      "        [-1.2549],\n",
      "        [ 0.8494],\n",
      "        [-1.2182],\n",
      "        [ 0.7625],\n",
      "        [-0.1410],\n",
      "        [ 0.8175],\n",
      "        [ 0.7494],\n",
      "        [ 0.8687],\n",
      "        [ 0.8175],\n",
      "        [-0.9784],\n",
      "        [ 0.0401],\n",
      "        [-1.1556],\n",
      "        [-1.1748],\n",
      "        [ 0.8494],\n",
      "        [-1.0947],\n",
      "        [ 0.7848],\n",
      "        [ 0.8687],\n",
      "        [-1.3427],\n",
      "        [ 0.3578],\n",
      "        [-0.5517],\n",
      "        [-1.2182],\n",
      "        [ 0.8549],\n",
      "        [-0.5517],\n",
      "        [-0.8240],\n",
      "        [-1.3000],\n",
      "        [ 0.7848],\n",
      "        [-1.2549],\n",
      "        [ 0.7012],\n",
      "        [-0.6036],\n",
      "        [ 0.7012],\n",
      "        [ 0.8687],\n",
      "        [ 0.8665]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 106/10000,\n",
      " train_loss: 0.0384,\n",
      " train_mae: 0.1577,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1856],\n",
      "        [-1.1856],\n",
      "        [ 0.7920],\n",
      "        [ 0.7703],\n",
      "        [ 0.1959],\n",
      "        [ 0.7284],\n",
      "        [ 0.8450],\n",
      "        [ 0.8526],\n",
      "        [ 0.8450],\n",
      "        [ 0.8301],\n",
      "        [-1.3575],\n",
      "        [-1.0888],\n",
      "        [ 0.7577],\n",
      "        [-0.1463],\n",
      "        [ 0.8490],\n",
      "        [-0.1463],\n",
      "        [ 0.7577],\n",
      "        [-0.8827],\n",
      "        [-0.3240],\n",
      "        [ 0.8405],\n",
      "        [ 0.8172],\n",
      "        [ 0.8240],\n",
      "        [ 0.8746],\n",
      "        [ 0.8746],\n",
      "        [ 0.8640],\n",
      "        [-0.3240],\n",
      "        [-1.1955],\n",
      "        [ 0.8640],\n",
      "        [-1.2693],\n",
      "        [ 0.8526],\n",
      "        [-1.2254],\n",
      "        [ 0.7577],\n",
      "        [-0.1463],\n",
      "        [ 0.8172],\n",
      "        [ 0.7438],\n",
      "        [ 0.8746],\n",
      "        [ 0.8172],\n",
      "        [-0.9687],\n",
      "        [ 0.0302],\n",
      "        [-1.1541],\n",
      "        [-1.1754],\n",
      "        [ 0.8526],\n",
      "        [-1.0888],\n",
      "        [ 0.7817],\n",
      "        [ 0.8746],\n",
      "        [-1.3759],\n",
      "        [ 0.3433],\n",
      "        [-0.5457],\n",
      "        [-1.2254],\n",
      "        [ 0.8589],\n",
      "        [-0.5457],\n",
      "        [-0.8136],\n",
      "        [-1.3242],\n",
      "        [ 0.7817],\n",
      "        [-1.2693],\n",
      "        [ 0.6928],\n",
      "        [-0.5964],\n",
      "        [ 0.6928],\n",
      "        [ 0.8746],\n",
      "        [ 0.8721]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 107/10000,\n",
      " train_loss: 0.0357,\n",
      " train_mae: 0.1506,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1876],\n",
      "        [-1.1876],\n",
      "        [ 0.7893],\n",
      "        [ 0.7659],\n",
      "        [ 0.1833],\n",
      "        [ 0.7213],\n",
      "        [ 0.8475],\n",
      "        [ 0.8561],\n",
      "        [ 0.8475],\n",
      "        [ 0.8309],\n",
      "        [-1.3955],\n",
      "        [-1.0816],\n",
      "        [ 0.7524],\n",
      "        [-0.1506],\n",
      "        [ 0.8521],\n",
      "        [-0.1506],\n",
      "        [ 0.7524],\n",
      "        [-0.8707],\n",
      "        [-0.3229],\n",
      "        [ 0.8426],\n",
      "        [ 0.8167],\n",
      "        [ 0.8242],\n",
      "        [ 0.8811],\n",
      "        [ 0.8811],\n",
      "        [ 0.8690],\n",
      "        [-0.3229],\n",
      "        [-1.1991],\n",
      "        [ 0.8690],\n",
      "        [-1.2876],\n",
      "        [ 0.8561],\n",
      "        [-1.2343],\n",
      "        [ 0.7524],\n",
      "        [-0.1506],\n",
      "        [ 0.8167],\n",
      "        [ 0.7376],\n",
      "        [ 0.8811],\n",
      "        [ 0.8167],\n",
      "        [-0.9574],\n",
      "        [ 0.0211],\n",
      "        [-1.1521],\n",
      "        [-1.1760],\n",
      "        [ 0.8561],\n",
      "        [-1.0816],\n",
      "        [ 0.7782],\n",
      "        [ 0.8811],\n",
      "        [-1.4177],\n",
      "        [ 0.3289],\n",
      "        [-0.5384],\n",
      "        [-1.2343],\n",
      "        [ 0.8632],\n",
      "        [-0.5384],\n",
      "        [-0.8017],\n",
      "        [-1.3549],\n",
      "        [ 0.7782],\n",
      "        [-1.2876],\n",
      "        [ 0.6839],\n",
      "        [-0.5879],\n",
      "        [ 0.6839],\n",
      "        [ 0.8811],\n",
      "        [ 0.8782]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 108/10000,\n",
      " train_loss: 0.0329,\n",
      " train_mae: 0.1425,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1892],\n",
      "        [-1.1892],\n",
      "        [ 0.7866],\n",
      "        [ 0.7615],\n",
      "        [ 0.1717],\n",
      "        [ 0.7141],\n",
      "        [ 0.8506],\n",
      "        [ 0.8602],\n",
      "        [ 0.8506],\n",
      "        [ 0.8321],\n",
      "        [-1.4421],\n",
      "        [-1.0720],\n",
      "        [ 0.7471],\n",
      "        [-0.1532],\n",
      "        [ 0.8556],\n",
      "        [-0.1532],\n",
      "        [ 0.7471],\n",
      "        [-0.8560],\n",
      "        [-0.3200],\n",
      "        [ 0.8450],\n",
      "        [ 0.8165],\n",
      "        [ 0.8247],\n",
      "        [ 0.8887],\n",
      "        [ 0.8887],\n",
      "        [ 0.8748],\n",
      "        [-0.3200],\n",
      "        [-1.2026],\n",
      "        [ 0.8748],\n",
      "        [-1.3100],\n",
      "        [ 0.8602],\n",
      "        [-1.2446],\n",
      "        [ 0.7471],\n",
      "        [-0.1532],\n",
      "        [ 0.8165],\n",
      "        [ 0.7313],\n",
      "        [ 0.8887],\n",
      "        [ 0.8165],\n",
      "        [-0.9434],\n",
      "        [ 0.0134],\n",
      "        [-1.1487],\n",
      "        [-1.1758],\n",
      "        [ 0.8602],\n",
      "        [-1.0720],\n",
      "        [ 0.7746],\n",
      "        [ 0.8887],\n",
      "        [-1.4687],\n",
      "        [ 0.3152],\n",
      "        [-0.5290],\n",
      "        [-1.2446],\n",
      "        [ 0.8682],\n",
      "        [-0.5290],\n",
      "        [-0.7873],\n",
      "        [-1.3928],\n",
      "        [ 0.7746],\n",
      "        [-1.3100],\n",
      "        [ 0.6749],\n",
      "        [-0.5772],\n",
      "        [ 0.6749],\n",
      "        [ 0.8887],\n",
      "        [ 0.8854]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 109/10000,\n",
      " train_loss: 0.0300,\n",
      " train_mae: 0.1332,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1896],\n",
      "        [-1.1896],\n",
      "        [ 0.7842],\n",
      "        [ 0.7573],\n",
      "        [ 0.1617],\n",
      "        [ 0.7071],\n",
      "        [ 0.8543],\n",
      "        [ 0.8652],\n",
      "        [ 0.8543],\n",
      "        [ 0.8338],\n",
      "        [-1.4966],\n",
      "        [-1.0592],\n",
      "        [ 0.7419],\n",
      "        [-0.1536],\n",
      "        [ 0.8600],\n",
      "        [-0.1536],\n",
      "        [ 0.7419],\n",
      "        [-0.8379],\n",
      "        [-0.3146],\n",
      "        [ 0.8481],\n",
      "        [ 0.8166],\n",
      "        [ 0.8256],\n",
      "        [ 0.8977],\n",
      "        [ 0.8977],\n",
      "        [ 0.8817],\n",
      "        [-0.3146],\n",
      "        [-1.2055],\n",
      "        [ 0.8817],\n",
      "        [-1.3364],\n",
      "        [ 0.8652],\n",
      "        [-1.2561],\n",
      "        [ 0.7419],\n",
      "        [-0.1536],\n",
      "        [ 0.8166],\n",
      "        [ 0.7252],\n",
      "        [ 0.8977],\n",
      "        [ 0.8166],\n",
      "        [-0.9259],\n",
      "        [ 0.0076],\n",
      "        [-1.1431],\n",
      "        [-1.1741],\n",
      "        [ 0.8652],\n",
      "        [-1.0592],\n",
      "        [ 0.7713],\n",
      "        [ 0.8977],\n",
      "        [-1.5278],\n",
      "        [ 0.3027],\n",
      "        [-0.5168],\n",
      "        [-1.2561],\n",
      "        [ 0.8742],\n",
      "        [-0.5168],\n",
      "        [-0.7696],\n",
      "        [-1.4377],\n",
      "        [ 0.7713],\n",
      "        [-1.3364],\n",
      "        [ 0.6660],\n",
      "        [-0.5637],\n",
      "        [ 0.6660],\n",
      "        [ 0.8977],\n",
      "        [ 0.8939]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 110/10000,\n",
      " train_loss: 0.0271,\n",
      " train_mae: 0.1228,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1884],\n",
      "        [-1.1884],\n",
      "        [ 0.7820],\n",
      "        [ 0.7532],\n",
      "        [ 0.1533],\n",
      "        [ 0.7001],\n",
      "        [ 0.8588],\n",
      "        [ 0.8709],\n",
      "        [ 0.8588],\n",
      "        [ 0.8360],\n",
      "        [-1.5562],\n",
      "        [-1.0425],\n",
      "        [ 0.7369],\n",
      "        [-0.1517],\n",
      "        [ 0.8651],\n",
      "        [-0.1517],\n",
      "        [ 0.7369],\n",
      "        [-0.8160],\n",
      "        [-0.3066],\n",
      "        [ 0.8518],\n",
      "        [ 0.8171],\n",
      "        [ 0.8270],\n",
      "        [ 0.9081],\n",
      "        [ 0.9081],\n",
      "        [ 0.8896],\n",
      "        [-0.3066],\n",
      "        [-1.2072],\n",
      "        [ 0.8896],\n",
      "        [-1.3662],\n",
      "        [ 0.8709],\n",
      "        [-1.2682],\n",
      "        [ 0.7369],\n",
      "        [-0.1517],\n",
      "        [ 0.8171],\n",
      "        [ 0.7192],\n",
      "        [ 0.9081],\n",
      "        [ 0.8171],\n",
      "        [-0.9044],\n",
      "        [ 0.0038],\n",
      "        [-1.1346],\n",
      "        [-1.1702],\n",
      "        [ 0.8709],\n",
      "        [-1.0425],\n",
      "        [ 0.7682],\n",
      "        [ 0.9081],\n",
      "        [-1.5917],\n",
      "        [ 0.2914],\n",
      "        [-0.5016],\n",
      "        [-1.2682],\n",
      "        [ 0.8811],\n",
      "        [-0.5016],\n",
      "        [-0.7483],\n",
      "        [-1.4877],\n",
      "        [ 0.7682],\n",
      "        [-1.3662],\n",
      "        [ 0.6573],\n",
      "        [-0.5470],\n",
      "        [ 0.6573],\n",
      "        [ 0.9081],\n",
      "        [ 0.9037]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 111/10000,\n",
      " train_loss: 0.0243,\n",
      " train_mae: 0.1128,\n",
      " epoch_time_duration: 0.0134\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1848e+00],\n",
      "        [-1.1848e+00],\n",
      "        [ 7.7957e-01],\n",
      "        [ 7.4874e-01],\n",
      "        [ 1.4594e-01],\n",
      "        [ 6.9280e-01],\n",
      "        [ 8.6350e-01],\n",
      "        [ 8.7713e-01],\n",
      "        [ 8.6350e-01],\n",
      "        [ 8.3826e-01],\n",
      "        [-1.6150e+00],\n",
      "        [-1.0217e+00],\n",
      "        [ 7.3146e-01],\n",
      "        [-1.4820e-01],\n",
      "        [ 8.7060e-01],\n",
      "        [-1.4820e-01],\n",
      "        [ 7.3146e-01],\n",
      "        [-7.9048e-01],\n",
      "        [-2.9678e-01],\n",
      "        [ 8.5578e-01],\n",
      "        [ 8.1760e-01],\n",
      "        [ 8.2835e-01],\n",
      "        [ 9.1968e-01],\n",
      "        [ 9.1968e-01],\n",
      "        [ 8.9839e-01],\n",
      "        [-2.9678e-01],\n",
      "        [-1.2068e+00],\n",
      "        [ 8.9839e-01],\n",
      "        [-1.3967e+00],\n",
      "        [ 8.7713e-01],\n",
      "        [-1.2795e+00],\n",
      "        [ 7.3146e-01],\n",
      "        [-1.4820e-01],\n",
      "        [ 8.1760e-01],\n",
      "        [ 7.1284e-01],\n",
      "        [ 9.1968e-01],\n",
      "        [ 8.1760e-01],\n",
      "        [-8.7891e-01],\n",
      "        [ 1.2798e-03],\n",
      "        [-1.1227e+00],\n",
      "        [-1.1635e+00],\n",
      "        [ 8.7713e-01],\n",
      "        [-1.0217e+00],\n",
      "        [ 7.6475e-01],\n",
      "        [ 9.1968e-01],\n",
      "        [-1.6539e+00],\n",
      "        [ 2.8074e-01],\n",
      "        [-4.8410e-01],\n",
      "        [-1.2795e+00],\n",
      "        [ 8.8865e-01],\n",
      "        [-4.8410e-01],\n",
      "        [-7.2367e-01],\n",
      "        [-1.5382e+00],\n",
      "        [ 7.6475e-01],\n",
      "        [-1.3967e+00],\n",
      "        [ 6.4821e-01],\n",
      "        [-5.2790e-01],\n",
      "        [ 6.4821e-01],\n",
      "        [ 9.1968e-01],\n",
      "        [ 9.1456e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 112/10000,\n",
      " train_loss: 0.0220,\n",
      " train_mae: 0.1066,\n",
      " epoch_time_duration: 0.0112\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1776e+00],\n",
      "        [-1.1776e+00],\n",
      "        [ 7.7601e-01],\n",
      "        [ 7.4310e-01],\n",
      "        [ 1.3837e-01],\n",
      "        [ 6.8420e-01],\n",
      "        [ 8.6775e-01],\n",
      "        [ 8.8304e-01],\n",
      "        [ 8.6775e-01],\n",
      "        [ 8.3976e-01],\n",
      "        [-1.6649e+00],\n",
      "        [-9.9711e-01],\n",
      "        [ 7.2480e-01],\n",
      "        [-1.4433e-01],\n",
      "        [ 8.7569e-01],\n",
      "        [-1.4433e-01],\n",
      "        [ 7.2480e-01],\n",
      "        [-7.6243e-01],\n",
      "        [-2.8626e-01],\n",
      "        [ 8.5914e-01],\n",
      "        [ 8.1712e-01],\n",
      "        [ 8.2888e-01],\n",
      "        [ 9.3181e-01],\n",
      "        [ 9.3181e-01],\n",
      "        [ 9.0720e-01],\n",
      "        [-2.8626e-01],\n",
      "        [-1.2030e+00],\n",
      "        [ 9.0720e-01],\n",
      "        [-1.4234e+00],\n",
      "        [ 8.8304e-01],\n",
      "        [-1.2876e+00],\n",
      "        [ 7.2480e-01],\n",
      "        [-1.4433e-01],\n",
      "        [ 8.1712e-01],\n",
      "        [ 7.0518e-01],\n",
      "        [ 9.3181e-01],\n",
      "        [ 8.1712e-01],\n",
      "        [-8.5035e-01],\n",
      "        [-1.1157e-03],\n",
      "        [-1.1071e+00],\n",
      "        [-1.1532e+00],\n",
      "        [ 8.8304e-01],\n",
      "        [-9.9711e-01],\n",
      "        [ 7.6015e-01],\n",
      "        [ 9.3181e-01],\n",
      "        [-1.7058e+00],\n",
      "        [ 2.6960e-01],\n",
      "        [-4.6541e-01],\n",
      "        [-1.2876e+00],\n",
      "        [ 8.9607e-01],\n",
      "        [-4.6541e-01],\n",
      "        [-6.9688e-01],\n",
      "        [-1.5821e+00],\n",
      "        [ 7.6015e-01],\n",
      "        [-1.4234e+00],\n",
      "        [ 6.3787e-01],\n",
      "        [-5.0745e-01],\n",
      "        [ 6.3787e-01],\n",
      "        [ 9.3181e-01],\n",
      "        [ 9.2585e-01]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 113/10000,\n",
      " train_loss: 0.0199,\n",
      " train_mae: 0.1011,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1657],\n",
      "        [-1.1657],\n",
      "        [ 0.7700],\n",
      "        [ 0.7349],\n",
      "        [ 0.1290],\n",
      "        [ 0.6729],\n",
      "        [ 0.8703],\n",
      "        [ 0.8875],\n",
      "        [ 0.8703],\n",
      "        [ 0.8393],\n",
      "        [-1.6989],\n",
      "        [-0.9696],\n",
      "        [ 0.7156],\n",
      "        [-0.1419],\n",
      "        [ 0.8792],\n",
      "        [-0.1419],\n",
      "        [ 0.7156],\n",
      "        [-0.7336],\n",
      "        [-0.2770],\n",
      "        [ 0.8607],\n",
      "        [ 0.8145],\n",
      "        [ 0.8273],\n",
      "        [ 0.9435],\n",
      "        [ 0.9435],\n",
      "        [ 0.9150],\n",
      "        [-0.2770],\n",
      "        [-1.1942],\n",
      "        [ 0.9150],\n",
      "        [-1.4411],\n",
      "        [ 0.8875],\n",
      "        [-1.2895],\n",
      "        [ 0.7156],\n",
      "        [-0.1419],\n",
      "        [ 0.8145],\n",
      "        [ 0.6949],\n",
      "        [ 0.9435],\n",
      "        [ 0.8145],\n",
      "        [-0.8203],\n",
      "        [-0.0052],\n",
      "        [-1.0874],\n",
      "        [-1.1385],\n",
      "        [ 0.8875],\n",
      "        [-0.9696],\n",
      "        [ 0.7531],\n",
      "        [ 0.9435],\n",
      "        [-1.7407],\n",
      "        [ 0.2564],\n",
      "        [-0.4475],\n",
      "        [-1.2895],\n",
      "        [ 0.9023],\n",
      "        [-0.4475],\n",
      "        [-0.6698],\n",
      "        [-1.6125],\n",
      "        [ 0.7531],\n",
      "        [-1.4411],\n",
      "        [ 0.6249],\n",
      "        [-0.4876],\n",
      "        [ 0.6249],\n",
      "        [ 0.9435],\n",
      "        [ 0.9365]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 114/10000,\n",
      " train_loss: 0.0181,\n",
      " train_mae: 0.0956,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1489],\n",
      "        [-1.1489],\n",
      "        [ 0.7601],\n",
      "        [ 0.7227],\n",
      "        [ 0.1158],\n",
      "        [ 0.6575],\n",
      "        [ 0.8698],\n",
      "        [ 0.8891],\n",
      "        [ 0.8698],\n",
      "        [ 0.8354],\n",
      "        [-1.7145],\n",
      "        [-0.9410],\n",
      "        [ 0.7022],\n",
      "        [-0.1431],\n",
      "        [ 0.8798],\n",
      "        [-0.1431],\n",
      "        [ 0.7022],\n",
      "        [-0.7064],\n",
      "        [-0.2712],\n",
      "        [ 0.8591],\n",
      "        [ 0.8082],\n",
      "        [ 0.8222],\n",
      "        [ 0.9535],\n",
      "        [ 0.9535],\n",
      "        [ 0.9204],\n",
      "        [-0.2712],\n",
      "        [-1.1798],\n",
      "        [ 0.9204],\n",
      "        [-1.4467],\n",
      "        [ 0.8891],\n",
      "        [-1.2834],\n",
      "        [ 0.7022],\n",
      "        [-0.1431],\n",
      "        [ 0.8082],\n",
      "        [ 0.6805],\n",
      "        [ 0.9535],\n",
      "        [ 0.8082],\n",
      "        [-0.7910],\n",
      "        [-0.0129],\n",
      "        [-1.0646],\n",
      "        [-1.1195],\n",
      "        [ 0.8891],\n",
      "        [-0.9410],\n",
      "        [ 0.7420],\n",
      "        [ 0.9535],\n",
      "        [-1.7565],\n",
      "        [ 0.2393],\n",
      "        [-0.4327],\n",
      "        [-1.2834],\n",
      "        [ 0.9059],\n",
      "        [-0.4327],\n",
      "        [-0.6447],\n",
      "        [-1.6265],\n",
      "        [ 0.7420],\n",
      "        [-1.4467],\n",
      "        [ 0.6077],\n",
      "        [-0.4708],\n",
      "        [ 0.6077],\n",
      "        [ 0.9535],\n",
      "        [ 0.9454]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 115/10000,\n",
      " train_loss: 0.0163,\n",
      " train_mae: 0.0899,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1287],\n",
      "        [-1.1287],\n",
      "        [ 0.7452],\n",
      "        [ 0.7053],\n",
      "        [ 0.0975],\n",
      "        [ 0.6368],\n",
      "        [ 0.8651],\n",
      "        [ 0.8868],\n",
      "        [ 0.8651],\n",
      "        [ 0.8269],\n",
      "        [-1.7144],\n",
      "        [-0.9136],\n",
      "        [ 0.6836],\n",
      "        [-0.1496],\n",
      "        [ 0.8763],\n",
      "        [-0.1496],\n",
      "        [ 0.6836],\n",
      "        [-0.6832],\n",
      "        [-0.2706],\n",
      "        [ 0.8531],\n",
      "        [ 0.7971],\n",
      "        [ 0.8124],\n",
      "        [ 0.9609],\n",
      "        [ 0.9609],\n",
      "        [ 0.9224],\n",
      "        [-0.2706],\n",
      "        [-1.1613],\n",
      "        [ 0.9224],\n",
      "        [-1.4413],\n",
      "        [ 0.8868],\n",
      "        [-1.2705],\n",
      "        [ 0.6836],\n",
      "        [-0.1496],\n",
      "        [ 0.7971],\n",
      "        [ 0.6608],\n",
      "        [ 0.9609],\n",
      "        [ 0.7971],\n",
      "        [-0.7651],\n",
      "        [-0.0258],\n",
      "        [-1.0405],\n",
      "        [-1.0978],\n",
      "        [ 0.8868],\n",
      "        [-0.9136],\n",
      "        [ 0.7258],\n",
      "        [ 0.9609],\n",
      "        [-1.7562],\n",
      "        [ 0.2171],\n",
      "        [-0.4231],\n",
      "        [-1.2705],\n",
      "        [ 0.9058],\n",
      "        [-0.4231],\n",
      "        [-0.6242],\n",
      "        [-1.6257],\n",
      "        [ 0.7258],\n",
      "        [-1.4413],\n",
      "        [ 0.5851],\n",
      "        [-0.4591],\n",
      "        [ 0.5851],\n",
      "        [ 0.9609],\n",
      "        [ 0.9514]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 116/10000,\n",
      " train_loss: 0.0145,\n",
      " train_mae: 0.0841,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1079],\n",
      "        [-1.1079],\n",
      "        [ 0.7253],\n",
      "        [ 0.6829],\n",
      "        [ 0.0743],\n",
      "        [ 0.6110],\n",
      "        [ 0.8561],\n",
      "        [ 0.8804],\n",
      "        [ 0.8561],\n",
      "        [ 0.8138],\n",
      "        [-1.7042],\n",
      "        [-0.8896],\n",
      "        [ 0.6600],\n",
      "        [-0.1615],\n",
      "        [ 0.8686],\n",
      "        [-0.1615],\n",
      "        [ 0.6600],\n",
      "        [-0.6656],\n",
      "        [-0.2759],\n",
      "        [ 0.8428],\n",
      "        [ 0.7813],\n",
      "        [ 0.7980],\n",
      "        [ 0.9655],\n",
      "        [ 0.9655],\n",
      "        [ 0.9208],\n",
      "        [-0.2759],\n",
      "        [-1.1414],\n",
      "        [ 0.9208],\n",
      "        [-1.4289],\n",
      "        [ 0.8804],\n",
      "        [-1.2538],\n",
      "        [ 0.6600],\n",
      "        [-0.1615],\n",
      "        [ 0.7813],\n",
      "        [ 0.6361],\n",
      "        [ 0.9655],\n",
      "        [ 0.7813],\n",
      "        [-0.7442],\n",
      "        [-0.0438],\n",
      "        [-1.0175],\n",
      "        [-1.0761],\n",
      "        [ 0.8804],\n",
      "        [-0.8896],\n",
      "        [ 0.7046],\n",
      "        [ 0.9655],\n",
      "        [-1.7457],\n",
      "        [ 0.1901],\n",
      "        [-0.4195],\n",
      "        [-1.2538],\n",
      "        [ 0.9018],\n",
      "        [-0.4195],\n",
      "        [-0.6094],\n",
      "        [-1.6156],\n",
      "        [ 0.7046],\n",
      "        [-1.4289],\n",
      "        [ 0.5575],\n",
      "        [-0.4534],\n",
      "        [ 0.5575],\n",
      "        [ 0.9655],\n",
      "        [ 0.9543]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 117/10000,\n",
      " train_loss: 0.0130,\n",
      " train_mae: 0.0786,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0888],\n",
      "        [-1.0888],\n",
      "        [ 0.7028],\n",
      "        [ 0.6578],\n",
      "        [ 0.0484],\n",
      "        [ 0.5827],\n",
      "        [ 0.8445],\n",
      "        [ 0.8715],\n",
      "        [ 0.8445],\n",
      "        [ 0.7981],\n",
      "        [-1.6901],\n",
      "        [-0.8699],\n",
      "        [ 0.6338],\n",
      "        [-0.1770],\n",
      "        [ 0.8584],\n",
      "        [-0.1770],\n",
      "        [ 0.6338],\n",
      "        [-0.6534],\n",
      "        [-0.2853],\n",
      "        [ 0.8299],\n",
      "        [ 0.7628],\n",
      "        [ 0.7809],\n",
      "        [ 0.9683],\n",
      "        [ 0.9683],\n",
      "        [ 0.9171],\n",
      "        [-0.2853],\n",
      "        [-1.1229],\n",
      "        [ 0.9171],\n",
      "        [-1.4145],\n",
      "        [ 0.8715],\n",
      "        [-1.2372],\n",
      "        [ 0.6338],\n",
      "        [-0.1770],\n",
      "        [ 0.7628],\n",
      "        [ 0.6088],\n",
      "        [ 0.9683],\n",
      "        [ 0.7628],\n",
      "        [-0.7285],\n",
      "        [-0.0650],\n",
      "        [-0.9975],\n",
      "        [-1.0567],\n",
      "        [ 0.8715],\n",
      "        [-0.8699],\n",
      "        [ 0.6808],\n",
      "        [ 0.9683],\n",
      "        [-1.7312],\n",
      "        [ 0.1606],\n",
      "        [-0.4207],\n",
      "        [-1.2372],\n",
      "        [ 0.8956],\n",
      "        [-0.4207],\n",
      "        [-0.6000],\n",
      "        [-1.6020],\n",
      "        [ 0.6808],\n",
      "        [-1.4145],\n",
      "        [ 0.5275],\n",
      "        [-0.4527],\n",
      "        [ 0.5275],\n",
      "        [ 0.9683],\n",
      "        [ 0.9554]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 118/10000,\n",
      " train_loss: 0.0120,\n",
      " train_mae: 0.0751,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0730],\n",
      "        [-1.0730],\n",
      "        [ 0.6820],\n",
      "        [ 0.6347],\n",
      "        [ 0.0240],\n",
      "        [ 0.5566],\n",
      "        [ 0.8343],\n",
      "        [ 0.8639],\n",
      "        [ 0.8343],\n",
      "        [ 0.7838],\n",
      "        [-1.6770],\n",
      "        [-0.8540],\n",
      "        [ 0.6096],\n",
      "        [-0.1925],\n",
      "        [ 0.8495],\n",
      "        [-0.1925],\n",
      "        [ 0.6096],\n",
      "        [-0.6447],\n",
      "        [-0.2956],\n",
      "        [ 0.8183],\n",
      "        [ 0.7458],\n",
      "        [ 0.7653],\n",
      "        [ 0.9724],\n",
      "        [ 0.9724],\n",
      "        [ 0.9146],\n",
      "        [-0.2956],\n",
      "        [-1.1075],\n",
      "        [ 0.9146],\n",
      "        [-1.4022],\n",
      "        [ 0.8639],\n",
      "        [-1.2232],\n",
      "        [ 0.6096],\n",
      "        [-0.1925],\n",
      "        [ 0.7458],\n",
      "        [ 0.5836],\n",
      "        [ 0.9724],\n",
      "        [ 0.7458],\n",
      "        [-0.7166],\n",
      "        [-0.0854],\n",
      "        [-0.9809],\n",
      "        [-1.0405],\n",
      "        [ 0.8639],\n",
      "        [-0.8540],\n",
      "        [ 0.6588],\n",
      "        [ 0.9724],\n",
      "        [-1.7175],\n",
      "        [ 0.1333],\n",
      "        [-0.4240],\n",
      "        [-1.2232],\n",
      "        [ 0.8906],\n",
      "        [-0.4240],\n",
      "        [-0.5940],\n",
      "        [-1.5897],\n",
      "        [ 0.6588],\n",
      "        [-1.4022],\n",
      "        [ 0.4998],\n",
      "        [-0.4543],\n",
      "        [ 0.4998],\n",
      "        [ 0.9724],\n",
      "        [ 0.9577]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 119/10000,\n",
      " train_loss: 0.0114,\n",
      " train_mae: 0.0730,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0610],\n",
      "        [-1.0610],\n",
      "        [ 0.6685],\n",
      "        [ 0.6191],\n",
      "        [ 0.0057],\n",
      "        [ 0.5383],\n",
      "        [ 0.8303],\n",
      "        [ 0.8623],\n",
      "        [ 0.8303],\n",
      "        [ 0.7762],\n",
      "        [-1.6680],\n",
      "        [-0.8409],\n",
      "        [ 0.5931],\n",
      "        [-0.2042],\n",
      "        [ 0.8467],\n",
      "        [-0.2042],\n",
      "        [ 0.5931],\n",
      "        [-0.6374],\n",
      "        [-0.3033],\n",
      "        [ 0.8131],\n",
      "        [ 0.7358],\n",
      "        [ 0.7564],\n",
      "        [ 0.9814],\n",
      "        [ 0.9814],\n",
      "        [ 0.9175],\n",
      "        [-0.3033],\n",
      "        [-1.0960],\n",
      "        [ 0.9175],\n",
      "        [-1.3947],\n",
      "        [ 0.8623],\n",
      "        [-1.2137],\n",
      "        [ 0.5931],\n",
      "        [-0.2042],\n",
      "        [ 0.7358],\n",
      "        [ 0.5661],\n",
      "        [ 0.9814],\n",
      "        [ 0.7358],\n",
      "        [-0.7066],\n",
      "        [-0.1007],\n",
      "        [-0.9677],\n",
      "        [-1.0281],\n",
      "        [ 0.8623],\n",
      "        [-0.8409],\n",
      "        [ 0.6443],\n",
      "        [ 0.9814],\n",
      "        [-1.7078],\n",
      "        [ 0.1128],\n",
      "        [-0.4263],\n",
      "        [-1.2137],\n",
      "        [ 0.8913],\n",
      "        [-0.4263],\n",
      "        [-0.5887],\n",
      "        [-1.5819],\n",
      "        [ 0.6443],\n",
      "        [-1.3947],\n",
      "        [ 0.4800],\n",
      "        [-0.4552],\n",
      "        [ 0.4800],\n",
      "        [ 0.9814],\n",
      "        [ 0.9651]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 120/10000,\n",
      " train_loss: 0.0109,\n",
      " train_mae: 0.0706,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0538],\n",
      "        [-1.0538],\n",
      "        [ 0.6663],\n",
      "        [ 0.6150],\n",
      "        [-0.0042],\n",
      "        [ 0.5316],\n",
      "        [ 0.8363],\n",
      "        [ 0.8703],\n",
      "        [ 0.8363],\n",
      "        [ 0.7791],\n",
      "        [-1.6656],\n",
      "        [-0.8301],\n",
      "        [ 0.5881],\n",
      "        [-0.2102],\n",
      "        [ 0.8537],\n",
      "        [-0.2102],\n",
      "        [ 0.5881],\n",
      "        [-0.6303],\n",
      "        [-0.3067],\n",
      "        [ 0.8180],\n",
      "        [ 0.7366],\n",
      "        [ 0.7583],\n",
      "        [ 0.9983],\n",
      "        [ 0.9983],\n",
      "        [ 0.9293],\n",
      "        [-0.3067],\n",
      "        [-1.0898],\n",
      "        [ 0.9293],\n",
      "        [-1.3944],\n",
      "        [ 0.8703],\n",
      "        [-1.2104],\n",
      "        [ 0.5881],\n",
      "        [-0.2102],\n",
      "        [ 0.7366],\n",
      "        [ 0.5602],\n",
      "        [ 0.9983],\n",
      "        [ 0.7366],\n",
      "        [-0.6976],\n",
      "        [-0.1089],\n",
      "        [-0.9583],\n",
      "        [-1.0200],\n",
      "        [ 0.8703],\n",
      "        [-0.8301],\n",
      "        [ 0.6411],\n",
      "        [ 0.9983],\n",
      "        [-1.7043],\n",
      "        [ 0.1019],\n",
      "        [-0.4259],\n",
      "        [-1.2104],\n",
      "        [ 0.9013],\n",
      "        [-0.4259],\n",
      "        [-0.5831],\n",
      "        [-1.5811],\n",
      "        [ 0.6411],\n",
      "        [-1.3944],\n",
      "        [ 0.4719],\n",
      "        [-0.4539],\n",
      "        [ 0.4719],\n",
      "        [ 0.9983],\n",
      "        [ 0.9806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 121/10000,\n",
      " train_loss: 0.0100,\n",
      " train_mae: 0.0672,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0533],\n",
      "        [-1.0533],\n",
      "        [ 0.6752],\n",
      "        [ 0.6221],\n",
      "        [-0.0071],\n",
      "        [ 0.5361],\n",
      "        [ 0.8523],\n",
      "        [ 0.8880],\n",
      "        [ 0.8523],\n",
      "        [ 0.7925],\n",
      "        [-1.6715],\n",
      "        [-0.8229],\n",
      "        [ 0.5943],\n",
      "        [-0.2119],\n",
      "        [ 0.8706],\n",
      "        [-0.2119],\n",
      "        [ 0.5943],\n",
      "        [-0.6244],\n",
      "        [-0.3071],\n",
      "        [ 0.8333],\n",
      "        [ 0.7483],\n",
      "        [ 0.7708],\n",
      "        [ 1.0229],\n",
      "        [ 1.0229],\n",
      "        [ 0.9501],\n",
      "        [-0.3071],\n",
      "        [-1.0906],\n",
      "        [ 0.9501],\n",
      "        [-1.4034],\n",
      "        [ 0.8880],\n",
      "        [-1.2155],\n",
      "        [ 0.5943],\n",
      "        [-0.2119],\n",
      "        [ 0.7483],\n",
      "        [ 0.5656],\n",
      "        [ 1.0229],\n",
      "        [ 0.7483],\n",
      "        [-0.6907],\n",
      "        [-0.1114],\n",
      "        [-0.9542],\n",
      "        [-1.0181],\n",
      "        [ 0.8880],\n",
      "        [-0.8229],\n",
      "        [ 0.6491],\n",
      "        [ 1.0229],\n",
      "        [-1.7087],\n",
      "        [ 0.0992],\n",
      "        [-0.4243],\n",
      "        [-1.2155],\n",
      "        [ 0.9206],\n",
      "        [-0.4243],\n",
      "        [-0.5782],\n",
      "        [-1.5892],\n",
      "        [ 0.6491],\n",
      "        [-1.4034],\n",
      "        [ 0.4747],\n",
      "        [-0.4517],\n",
      "        [ 0.4747],\n",
      "        [ 1.0229],\n",
      "        [ 1.0042]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 122/10000,\n",
      " train_loss: 0.0085,\n",
      " train_mae: 0.0637,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0614],\n",
      "        [-1.0614],\n",
      "        [ 0.6907],\n",
      "        [ 0.6357],\n",
      "        [-0.0077],\n",
      "        [ 0.5468],\n",
      "        [ 0.8746],\n",
      "        [ 0.9118],\n",
      "        [ 0.8746],\n",
      "        [ 0.8124],\n",
      "        [-1.6859],\n",
      "        [-0.8214],\n",
      "        [ 0.6069],\n",
      "        [-0.2134],\n",
      "        [ 0.8936],\n",
      "        [-0.2134],\n",
      "        [ 0.6069],\n",
      "        [-0.6223],\n",
      "        [-0.3083],\n",
      "        [ 0.8548],\n",
      "        [ 0.7665],\n",
      "        [ 0.7899],\n",
      "        [ 1.0521],\n",
      "        [ 1.0521],\n",
      "        [ 0.9764],\n",
      "        [-0.3083],\n",
      "        [-1.1005],\n",
      "        [ 0.9764],\n",
      "        [-1.4228],\n",
      "        [ 0.9118],\n",
      "        [-1.2307],\n",
      "        [ 0.6069],\n",
      "        [-0.2134],\n",
      "        [ 0.7665],\n",
      "        [ 0.5773],\n",
      "        [ 1.0521],\n",
      "        [ 0.7665],\n",
      "        [-0.6881],\n",
      "        [-0.1127],\n",
      "        [-0.9575],\n",
      "        [-1.0245],\n",
      "        [ 0.9118],\n",
      "        [-0.8214],\n",
      "        [ 0.6637],\n",
      "        [ 1.0521],\n",
      "        [-1.7213],\n",
      "        [ 0.0999],\n",
      "        [-0.4246],\n",
      "        [-1.2307],\n",
      "        [ 0.9456],\n",
      "        [-0.4246],\n",
      "        [-0.5767],\n",
      "        [-1.6067],\n",
      "        [ 0.6637],\n",
      "        [-1.4228],\n",
      "        [ 0.4837],\n",
      "        [-0.4518],\n",
      "        [ 0.4837],\n",
      "        [ 1.0521],\n",
      "        [ 1.0327]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 123/10000,\n",
      " train_loss: 0.0070,\n",
      " train_mae: 0.0624,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0779],\n",
      "        [-1.0779],\n",
      "        [ 0.7063],\n",
      "        [ 0.6493],\n",
      "        [-0.0112],\n",
      "        [ 0.5573],\n",
      "        [ 0.8971],\n",
      "        [ 0.9357],\n",
      "        [ 0.8971],\n",
      "        [ 0.8326],\n",
      "        [-1.7061],\n",
      "        [-0.8266],\n",
      "        [ 0.6194],\n",
      "        [-0.2188],\n",
      "        [ 0.9169],\n",
      "        [-0.2188],\n",
      "        [ 0.6194],\n",
      "        [-0.6259],\n",
      "        [-0.3140],\n",
      "        [ 0.8765],\n",
      "        [ 0.7849],\n",
      "        [ 0.8092],\n",
      "        [ 1.0812],\n",
      "        [ 1.0812],\n",
      "        [ 1.0028],\n",
      "        [-0.3140],\n",
      "        [-1.1190],\n",
      "        [ 1.0028],\n",
      "        [-1.4502],\n",
      "        [ 0.9357],\n",
      "        [-1.2548],\n",
      "        [ 0.6194],\n",
      "        [-0.2188],\n",
      "        [ 0.7849],\n",
      "        [ 0.5888],\n",
      "        [ 1.0812],\n",
      "        [ 0.7849],\n",
      "        [-0.6913],\n",
      "        [-0.1175],\n",
      "        [-0.9685],\n",
      "        [-1.0391],\n",
      "        [ 0.9357],\n",
      "        [-0.8266],\n",
      "        [ 0.6782],\n",
      "        [ 1.0812],\n",
      "        [-1.7394],\n",
      "        [ 0.0981],\n",
      "        [-0.4298],\n",
      "        [-1.2548],\n",
      "        [ 0.9708],\n",
      "        [-0.4298],\n",
      "        [-0.5806],\n",
      "        [-1.6307],\n",
      "        [ 0.6782],\n",
      "        [-1.4502],\n",
      "        [ 0.4920],\n",
      "        [-0.4568],\n",
      "        [ 0.4920],\n",
      "        [ 1.0812],\n",
      "        [ 1.0611]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 124/10000,\n",
      " train_loss: 0.0060,\n",
      " train_mae: 0.0625,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0989],\n",
      "        [-1.0989],\n",
      "        [ 0.7165],\n",
      "        [ 0.6574],\n",
      "        [-0.0208],\n",
      "        [ 0.5620],\n",
      "        [ 0.9150],\n",
      "        [ 0.9551],\n",
      "        [ 0.9150],\n",
      "        [ 0.8478],\n",
      "        [-1.7255],\n",
      "        [-0.8365],\n",
      "        [ 0.6264],\n",
      "        [-0.2300],\n",
      "        [ 0.9355],\n",
      "        [-0.2300],\n",
      "        [ 0.6264],\n",
      "        [-0.6343],\n",
      "        [-0.3251],\n",
      "        [ 0.8935],\n",
      "        [ 0.7982],\n",
      "        [ 0.8235],\n",
      "        [ 1.1062],\n",
      "        [ 1.1062],\n",
      "        [ 1.0248],\n",
      "        [-0.3251],\n",
      "        [-1.1418],\n",
      "        [ 1.0248],\n",
      "        [-1.4790],\n",
      "        [ 0.9551],\n",
      "        [-1.2821],\n",
      "        [ 0.6264],\n",
      "        [-0.2300],\n",
      "        [ 0.7982],\n",
      "        [ 0.5946],\n",
      "        [ 1.1062],\n",
      "        [ 0.7982],\n",
      "        [-0.6994],\n",
      "        [-0.1281],\n",
      "        [-0.9843],\n",
      "        [-1.0583],\n",
      "        [ 0.9551],\n",
      "        [-0.8365],\n",
      "        [ 0.6874],\n",
      "        [ 1.1062],\n",
      "        [-1.7565],\n",
      "        [ 0.0903],\n",
      "        [-0.4403],\n",
      "        [-1.2821],\n",
      "        [ 0.9916],\n",
      "        [-0.4403],\n",
      "        [-0.5894],\n",
      "        [-1.6543],\n",
      "        [ 0.6874],\n",
      "        [-1.4790],\n",
      "        [ 0.4945],\n",
      "        [-0.4670],\n",
      "        [ 0.4945],\n",
      "        [ 1.1062],\n",
      "        [ 1.0853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 125/10000,\n",
      " train_loss: 0.0055,\n",
      " train_mae: 0.0632,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1170],\n",
      "        [-1.1170],\n",
      "        [ 0.7192],\n",
      "        [ 0.6578],\n",
      "        [-0.0356],\n",
      "        [ 0.5591],\n",
      "        [ 0.9257],\n",
      "        [ 0.9676],\n",
      "        [ 0.9257],\n",
      "        [ 0.8557],\n",
      "        [-1.7356],\n",
      "        [-0.8467],\n",
      "        [ 0.6257],\n",
      "        [-0.2452],\n",
      "        [ 0.9471],\n",
      "        [-0.2452],\n",
      "        [ 0.6257],\n",
      "        [-0.6443],\n",
      "        [-0.3396],\n",
      "        [ 0.9033],\n",
      "        [ 0.8040],\n",
      "        [ 0.8303],\n",
      "        [ 1.1254],\n",
      "        [ 1.1254],\n",
      "        [ 1.0403],\n",
      "        [-0.3396],\n",
      "        [-1.1611],\n",
      "        [ 1.0403],\n",
      "        [-1.4997],\n",
      "        [ 0.9676],\n",
      "        [-1.3039],\n",
      "        [ 0.6257],\n",
      "        [-0.2452],\n",
      "        [ 0.8040],\n",
      "        [ 0.5928],\n",
      "        [ 1.1254],\n",
      "        [ 0.8040],\n",
      "        [-0.7087],\n",
      "        [-0.1434],\n",
      "        [-0.9987],\n",
      "        [-1.0751],\n",
      "        [ 0.9676],\n",
      "        [-0.8467],\n",
      "        [ 0.6889],\n",
      "        [ 1.1254],\n",
      "        [-1.7645],\n",
      "        [ 0.0765],\n",
      "        [-0.4535],\n",
      "        [-1.3039],\n",
      "        [ 1.0057],\n",
      "        [-0.4535],\n",
      "        [-0.6002],\n",
      "        [-1.6686],\n",
      "        [ 0.6889],\n",
      "        [-1.4997],\n",
      "        [ 0.4895],\n",
      "        [-0.4798],\n",
      "        [ 0.4895],\n",
      "        [ 1.1254],\n",
      "        [ 1.1036]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 126/10000,\n",
      " train_loss: 0.0052,\n",
      " train_mae: 0.0627,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1252],\n",
      "        [-1.1252],\n",
      "        [ 0.7148],\n",
      "        [ 0.6514],\n",
      "        [-0.0526],\n",
      "        [ 0.5498],\n",
      "        [ 0.9297],\n",
      "        [ 0.9734],\n",
      "        [ 0.9297],\n",
      "        [ 0.8566],\n",
      "        [-1.7299],\n",
      "        [-0.8521],\n",
      "        [ 0.6184],\n",
      "        [-0.2606],\n",
      "        [ 0.9520],\n",
      "        [-0.2606],\n",
      "        [ 0.6184],\n",
      "        [-0.6516],\n",
      "        [-0.3536],\n",
      "        [ 0.9063],\n",
      "        [ 0.8029],\n",
      "        [ 0.8303],\n",
      "        [ 1.1390],\n",
      "        [ 1.1390],\n",
      "        [ 1.0497],\n",
      "        [-0.3536],\n",
      "        [-1.1696],\n",
      "        [ 1.0497],\n",
      "        [-1.5045],\n",
      "        [ 0.9734],\n",
      "        [-1.3123],\n",
      "        [ 0.6184],\n",
      "        [-0.2606],\n",
      "        [ 0.8029],\n",
      "        [ 0.5845],\n",
      "        [ 1.1390],\n",
      "        [ 0.8029],\n",
      "        [-0.7148],\n",
      "        [-0.1599],\n",
      "        [-1.0056],\n",
      "        [-1.0829],\n",
      "        [ 0.9734],\n",
      "        [-0.8521],\n",
      "        [ 0.6836],\n",
      "        [ 1.1390],\n",
      "        [-1.7569],\n",
      "        [ 0.0596],\n",
      "        [-0.4652],\n",
      "        [-1.3123],\n",
      "        [ 1.0134],\n",
      "        [-0.4652],\n",
      "        [-0.6085],\n",
      "        [-1.6666],\n",
      "        [ 0.6836],\n",
      "        [-1.5045],\n",
      "        [ 0.4783],\n",
      "        [-0.4909],\n",
      "        [ 0.4783],\n",
      "        [ 1.1390],\n",
      "        [ 1.1161]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 127/10000,\n",
      " train_loss: 0.0049,\n",
      " train_mae: 0.0598,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1206],\n",
      "        [-1.1206],\n",
      "        [ 0.7059],\n",
      "        [ 0.6407],\n",
      "        [-0.0680],\n",
      "        [ 0.5367],\n",
      "        [ 0.9285],\n",
      "        [ 0.9742],\n",
      "        [ 0.9285],\n",
      "        [ 0.8525],\n",
      "        [-1.7071],\n",
      "        [-0.8497],\n",
      "        [ 0.6068],\n",
      "        [-0.2726],\n",
      "        [ 0.9519],\n",
      "        [-0.2726],\n",
      "        [ 0.6068],\n",
      "        [-0.6532],\n",
      "        [-0.3636],\n",
      "        [ 0.9042],\n",
      "        [ 0.7968],\n",
      "        [ 0.8251],\n",
      "        [ 1.1483],\n",
      "        [ 1.1483],\n",
      "        [ 1.0542],\n",
      "        [-0.3636],\n",
      "        [-1.1645],\n",
      "        [ 1.0542],\n",
      "        [-1.4918],\n",
      "        [ 0.9742],\n",
      "        [-1.3049],\n",
      "        [ 0.6068],\n",
      "        [-0.2726],\n",
      "        [ 0.7968],\n",
      "        [ 0.5721],\n",
      "        [ 1.1483],\n",
      "        [ 0.7968],\n",
      "        [-0.7148],\n",
      "        [-0.1738],\n",
      "        [-1.0020],\n",
      "        [-1.0788],\n",
      "        [ 0.9742],\n",
      "        [-0.8497],\n",
      "        [ 0.6737],\n",
      "        [ 1.1483],\n",
      "        [-1.7326],\n",
      "        [ 0.0432],\n",
      "        [-0.4722],\n",
      "        [-1.3049],\n",
      "        [ 1.0161],\n",
      "        [-0.4722],\n",
      "        [-0.6113],\n",
      "        [-1.6470],\n",
      "        [ 0.6737],\n",
      "        [-1.4918],\n",
      "        [ 0.4640],\n",
      "        [-0.4972],\n",
      "        [ 0.4640],\n",
      "        [ 1.1483],\n",
      "        [ 1.1241]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 128/10000,\n",
      " train_loss: 0.0043,\n",
      " train_mae: 0.0557,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1064],\n",
      "        [-1.1064],\n",
      "        [ 0.6948],\n",
      "        [ 0.6282],\n",
      "        [-0.0797],\n",
      "        [ 0.5227],\n",
      "        [ 0.9242],\n",
      "        [ 0.9718],\n",
      "        [ 0.9242],\n",
      "        [ 0.8455],\n",
      "        [-1.6725],\n",
      "        [-0.8405],\n",
      "        [ 0.5937],\n",
      "        [-0.2798],\n",
      "        [ 0.9485],\n",
      "        [-0.2798],\n",
      "        [ 0.5937],\n",
      "        [-0.6489],\n",
      "        [-0.3682],\n",
      "        [ 0.8990],\n",
      "        [ 0.7880],\n",
      "        [ 0.8172],\n",
      "        [ 1.1546],\n",
      "        [ 1.1546],\n",
      "        [ 1.0554],\n",
      "        [-0.3682],\n",
      "        [-1.1494],\n",
      "        [ 1.0554],\n",
      "        [-1.4668],\n",
      "        [ 0.9718],\n",
      "        [-1.2862],\n",
      "        [ 0.5937],\n",
      "        [-0.2798],\n",
      "        [ 0.7880],\n",
      "        [ 0.5585],\n",
      "        [ 1.1546],\n",
      "        [ 0.7880],\n",
      "        [-0.7087],\n",
      "        [-0.1834],\n",
      "        [-0.9901],\n",
      "        [-1.0654],\n",
      "        [ 0.9718],\n",
      "        [-0.8405],\n",
      "        [ 0.6619],\n",
      "        [ 1.1546],\n",
      "        [-1.6968],\n",
      "        [ 0.0297],\n",
      "        [-0.4736],\n",
      "        [-1.2862],\n",
      "        [ 1.0155],\n",
      "        [-0.4736],\n",
      "        [-0.6082],\n",
      "        [-1.6154],\n",
      "        [ 0.6619],\n",
      "        [-1.4668],\n",
      "        [ 0.4492],\n",
      "        [-0.4978],\n",
      "        [ 0.4492],\n",
      "        [ 1.1546],\n",
      "        [ 1.1290]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 129/10000,\n",
      " train_loss: 0.0038,\n",
      " train_mae: 0.0520,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0898],\n",
      "        [-1.0898],\n",
      "        [ 0.6835],\n",
      "        [ 0.6159],\n",
      "        [-0.0876],\n",
      "        [ 0.5094],\n",
      "        [ 0.9185],\n",
      "        [ 0.9678],\n",
      "        [ 0.9185],\n",
      "        [ 0.8374],\n",
      "        [-1.6357],\n",
      "        [-0.8284],\n",
      "        [ 0.5811],\n",
      "        [-0.2826],\n",
      "        [ 0.9436],\n",
      "        [-0.2826],\n",
      "        [ 0.5811],\n",
      "        [-0.6408],\n",
      "        [-0.3686],\n",
      "        [ 0.8925],\n",
      "        [ 0.7786],\n",
      "        [ 0.8085],\n",
      "        [ 1.1588],\n",
      "        [ 1.1588],\n",
      "        [ 1.0548],\n",
      "        [-0.3686],\n",
      "        [-1.1319],\n",
      "        [ 1.0548],\n",
      "        [-1.4396],\n",
      "        [ 0.9678],\n",
      "        [-1.2652],\n",
      "        [ 0.5811],\n",
      "        [-0.2826],\n",
      "        [ 0.7786],\n",
      "        [ 0.5456],\n",
      "        [ 1.1588],\n",
      "        [ 0.7786],\n",
      "        [-0.6991],\n",
      "        [-0.1888],\n",
      "        [-0.9756],\n",
      "        [-1.0496],\n",
      "        [ 0.9678],\n",
      "        [-0.8284],\n",
      "        [ 0.6501],\n",
      "        [ 1.1588],\n",
      "        [-1.6587],\n",
      "        [ 0.0198],\n",
      "        [-0.4707],\n",
      "        [-1.2652],\n",
      "        [ 1.0132],\n",
      "        [-0.4707],\n",
      "        [-0.6013],\n",
      "        [-1.5816],\n",
      "        [ 0.6501],\n",
      "        [-1.4396],\n",
      "        [ 0.4356],\n",
      "        [-0.4942],\n",
      "        [ 0.4356],\n",
      "        [ 1.1588],\n",
      "        [ 1.1319]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 130/10000,\n",
      " train_loss: 0.0036,\n",
      " train_mae: 0.0484,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0784],\n",
      "        [-1.0784],\n",
      "        [ 0.6736],\n",
      "        [ 0.6054],\n",
      "        [-0.0923],\n",
      "        [ 0.4984],\n",
      "        [ 0.9131],\n",
      "        [ 0.9637],\n",
      "        [ 0.9131],\n",
      "        [ 0.8300],\n",
      "        [-1.6063],\n",
      "        [-0.8177],\n",
      "        [ 0.5703],\n",
      "        [-0.2828],\n",
      "        [ 0.9389],\n",
      "        [-0.2828],\n",
      "        [ 0.5703],\n",
      "        [-0.6321],\n",
      "        [-0.3666],\n",
      "        [ 0.8864],\n",
      "        [ 0.7700],\n",
      "        [ 0.8005],\n",
      "        [ 1.1621],\n",
      "        [ 1.1621],\n",
      "        [ 1.0537],\n",
      "        [-0.3666],\n",
      "        [-1.1201],\n",
      "        [ 1.0537],\n",
      "        [-1.4200],\n",
      "        [ 0.9637],\n",
      "        [-1.2511],\n",
      "        [ 0.5703],\n",
      "        [-0.2828],\n",
      "        [ 0.7700],\n",
      "        [ 0.5346],\n",
      "        [ 1.1621],\n",
      "        [ 0.7700],\n",
      "        [-0.6894],\n",
      "        [-0.1912],\n",
      "        [-0.9648],\n",
      "        [-1.0385],\n",
      "        [ 0.9637],\n",
      "        [-0.8177],\n",
      "        [ 0.6399],\n",
      "        [ 1.1621],\n",
      "        [-1.6278],\n",
      "        [ 0.0130],\n",
      "        [-0.4660],\n",
      "        [-1.2511],\n",
      "        [ 1.0106],\n",
      "        [-0.4660],\n",
      "        [-0.5934],\n",
      "        [-1.5553],\n",
      "        [ 0.6399],\n",
      "        [-1.4200],\n",
      "        [ 0.4246],\n",
      "        [-0.4889],\n",
      "        [ 0.4246],\n",
      "        [ 1.1621],\n",
      "        [ 1.1340]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 131/10000,\n",
      " train_loss: 0.0036,\n",
      " train_mae: 0.0469,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0776],\n",
      "        [-1.0776],\n",
      "        [ 0.6667],\n",
      "        [ 0.5981],\n",
      "        [-0.0946],\n",
      "        [ 0.4907],\n",
      "        [ 0.9096],\n",
      "        [ 0.9614],\n",
      "        [ 0.9096],\n",
      "        [ 0.8250],\n",
      "        [-1.5903],\n",
      "        [-0.8120],\n",
      "        [ 0.5628],\n",
      "        [-0.2816],\n",
      "        [ 0.9359],\n",
      "        [-0.2816],\n",
      "        [ 0.5628],\n",
      "        [-0.6249],\n",
      "        [-0.3637],\n",
      "        [ 0.8823],\n",
      "        [ 0.7642],\n",
      "        [ 0.7950],\n",
      "        [ 1.1658],\n",
      "        [ 1.1658],\n",
      "        [ 1.0537],\n",
      "        [-0.3637],\n",
      "        [-1.1195],\n",
      "        [ 1.0537],\n",
      "        [-1.4144],\n",
      "        [ 0.9614],\n",
      "        [-1.2499],\n",
      "        [ 0.5628],\n",
      "        [-0.2816],\n",
      "        [ 0.7642],\n",
      "        [ 0.5270],\n",
      "        [ 1.1658],\n",
      "        [ 0.7642],\n",
      "        [-0.6821],\n",
      "        [-0.1918],\n",
      "        [-0.9622],\n",
      "        [-1.0372],\n",
      "        [ 0.9614],\n",
      "        [-0.8120],\n",
      "        [ 0.6327],\n",
      "        [ 1.1658],\n",
      "        [-1.6102],\n",
      "        [ 0.0090],\n",
      "        [-0.4613],\n",
      "        [-1.2499],\n",
      "        [ 1.0094],\n",
      "        [-0.4613],\n",
      "        [-0.5866],\n",
      "        [-1.5427],\n",
      "        [ 0.6327],\n",
      "        [-1.4144],\n",
      "        [ 0.4170],\n",
      "        [-0.4837],\n",
      "        [ 0.4170],\n",
      "        [ 1.1658],\n",
      "        [ 1.1366]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 132/10000,\n",
      " train_loss: 0.0035,\n",
      " train_mae: 0.0446,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.0887],\n",
      "        [-1.0887],\n",
      "        [ 0.6641],\n",
      "        [ 0.5951],\n",
      "        [-0.0944],\n",
      "        [ 0.4875],\n",
      "        [ 0.9095],\n",
      "        [ 0.9621],\n",
      "        [ 0.9095],\n",
      "        [ 0.8238],\n",
      "        [-1.5885],\n",
      "        [-0.8121],\n",
      "        [ 0.5597],\n",
      "        [-0.2793],\n",
      "        [ 0.9363],\n",
      "        [-0.2793],\n",
      "        [ 0.5597],\n",
      "        [-0.6199],\n",
      "        [-0.3603],\n",
      "        [ 0.8819],\n",
      "        [ 0.7623],\n",
      "        [ 0.7935],\n",
      "        [ 1.1711],\n",
      "        [ 1.1711],\n",
      "        [ 1.0563],\n",
      "        [-0.3603],\n",
      "        [-1.1316],\n",
      "        [ 1.0563],\n",
      "        [-1.4235],\n",
      "        [ 0.9621],\n",
      "        [-1.2630],\n",
      "        [ 0.5597],\n",
      "        [-0.2793],\n",
      "        [ 0.7623],\n",
      "        [ 0.5239],\n",
      "        [ 1.1711],\n",
      "        [ 0.7623],\n",
      "        [-0.6778],\n",
      "        [-0.1905],\n",
      "        [-0.9693],\n",
      "        [-1.0471],\n",
      "        [ 0.9621],\n",
      "        [-0.8121],\n",
      "        [ 0.6299],\n",
      "        [ 1.1711],\n",
      "        [-1.6068],\n",
      "        [ 0.0081],\n",
      "        [-0.4568],\n",
      "        [-1.2630],\n",
      "        [ 1.0111],\n",
      "        [-0.4568],\n",
      "        [-0.5815],\n",
      "        [-1.5445],\n",
      "        [ 0.6299],\n",
      "        [-1.4235],\n",
      "        [ 0.4138],\n",
      "        [-0.4791],\n",
      "        [ 0.4138],\n",
      "        [ 1.1711],\n",
      "        [ 1.1412]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 133/10000,\n",
      " train_loss: 0.0032,\n",
      " train_mae: 0.0420,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1096],\n",
      "        [-1.1096],\n",
      "        [ 0.6661],\n",
      "        [ 0.5969],\n",
      "        [-0.0913],\n",
      "        [ 0.4890],\n",
      "        [ 0.9134],\n",
      "        [ 0.9666],\n",
      "        [ 0.9134],\n",
      "        [ 0.8269],\n",
      "        [-1.5970],\n",
      "        [-0.8171],\n",
      "        [ 0.5614],\n",
      "        [-0.2752],\n",
      "        [ 0.9404],\n",
      "        [-0.2752],\n",
      "        [ 0.5614],\n",
      "        [-0.6162],\n",
      "        [-0.3558],\n",
      "        [ 0.8854],\n",
      "        [ 0.7649],\n",
      "        [ 0.7963],\n",
      "        [ 1.1787],\n",
      "        [ 1.1787],\n",
      "        [ 1.0620],\n",
      "        [-0.3558],\n",
      "        [-1.1539],\n",
      "        [ 1.0620],\n",
      "        [-1.4434],\n",
      "        [ 0.9666],\n",
      "        [-1.2869],\n",
      "        [ 0.5614],\n",
      "        [-0.2752],\n",
      "        [ 0.7649],\n",
      "        [ 0.5254],\n",
      "        [ 1.1787],\n",
      "        [ 0.7649],\n",
      "        [-0.6757],\n",
      "        [-0.1869],\n",
      "        [-0.9844],\n",
      "        [-1.0663],\n",
      "        [ 0.9666],\n",
      "        [-0.8171],\n",
      "        [ 0.6318],\n",
      "        [ 1.1787],\n",
      "        [-1.6135],\n",
      "        [ 0.0106],\n",
      "        [-0.4520],\n",
      "        [-1.2869],\n",
      "        [ 1.0161],\n",
      "        [-0.4520],\n",
      "        [-0.5771],\n",
      "        [-1.5568],\n",
      "        [ 0.6318],\n",
      "        [-1.4434],\n",
      "        [ 0.4152],\n",
      "        [-0.4742],\n",
      "        [ 0.4152],\n",
      "        [ 1.1787],\n",
      "        [ 1.1482]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 134/10000,\n",
      " train_loss: 0.0027,\n",
      " train_mae: 0.0409,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1354],\n",
      "        [-1.1354],\n",
      "        [ 0.6714],\n",
      "        [ 0.6020],\n",
      "        [-0.0855],\n",
      "        [ 0.4940],\n",
      "        [ 0.9198],\n",
      "        [ 0.9733],\n",
      "        [ 0.9198],\n",
      "        [ 0.8327],\n",
      "        [-1.6089],\n",
      "        [-0.8244],\n",
      "        [ 0.5664],\n",
      "        [-0.2689],\n",
      "        [ 0.9470],\n",
      "        [-0.2689],\n",
      "        [ 0.5664],\n",
      "        [-0.6122],\n",
      "        [-0.3495],\n",
      "        [ 0.8916],\n",
      "        [ 0.7705],\n",
      "        [ 0.8020],\n",
      "        [ 1.1876],\n",
      "        [ 1.1876],\n",
      "        [ 1.0696],\n",
      "        [-0.3495],\n",
      "        [-1.1811],\n",
      "        [ 1.0696],\n",
      "        [-1.4669],\n",
      "        [ 0.9733],\n",
      "        [-1.3153],\n",
      "        [ 0.5664],\n",
      "        [-0.2689],\n",
      "        [ 0.7705],\n",
      "        [ 0.5304],\n",
      "        [ 1.1876],\n",
      "        [ 0.7705],\n",
      "        [-0.6740],\n",
      "        [-0.1808],\n",
      "        [-1.0038],\n",
      "        [-1.0902],\n",
      "        [ 0.9733],\n",
      "        [-0.8244],\n",
      "        [ 0.6370],\n",
      "        [ 1.1876],\n",
      "        [-1.6238],\n",
      "        [ 0.0162],\n",
      "        [-0.4458],\n",
      "        [-1.3153],\n",
      "        [ 1.0233],\n",
      "        [-0.4458],\n",
      "        [-0.5722],\n",
      "        [-1.5724],\n",
      "        [ 0.6370],\n",
      "        [-1.4669],\n",
      "        [ 0.4202],\n",
      "        [-0.4681],\n",
      "        [ 0.4202],\n",
      "        [ 1.1876],\n",
      "        [ 1.1567]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 135/10000,\n",
      " train_loss: 0.0023,\n",
      " train_mae: 0.0408,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1596],\n",
      "        [-1.1596],\n",
      "        [ 0.6769],\n",
      "        [ 0.6075],\n",
      "        [-0.0780],\n",
      "        [ 0.4997],\n",
      "        [ 0.9259],\n",
      "        [ 0.9797],\n",
      "        [ 0.9259],\n",
      "        [ 0.8385],\n",
      "        [-1.6173],\n",
      "        [-0.8311],\n",
      "        [ 0.5720],\n",
      "        [-0.2608],\n",
      "        [ 0.9532],\n",
      "        [-0.2608],\n",
      "        [ 0.5720],\n",
      "        [-0.6068],\n",
      "        [-0.3413],\n",
      "        [ 0.8976],\n",
      "        [ 0.7761],\n",
      "        [ 0.8077],\n",
      "        [ 1.1957],\n",
      "        [ 1.1957],\n",
      "        [ 1.0766],\n",
      "        [-0.3413],\n",
      "        [-1.2063],\n",
      "        [ 1.0766],\n",
      "        [-1.4864],\n",
      "        [ 0.9797],\n",
      "        [-1.3405],\n",
      "        [ 0.5720],\n",
      "        [-0.2608],\n",
      "        [ 0.7761],\n",
      "        [ 0.5360],\n",
      "        [ 1.1957],\n",
      "        [ 0.7761],\n",
      "        [-0.6710],\n",
      "        [-0.1730],\n",
      "        [-1.0225],\n",
      "        [-1.1130],\n",
      "        [ 0.9797],\n",
      "        [-0.8311],\n",
      "        [ 0.6425],\n",
      "        [ 1.1957],\n",
      "        [-1.6308],\n",
      "        [ 0.0234],\n",
      "        [-0.4379],\n",
      "        [-1.3405],\n",
      "        [ 1.0299],\n",
      "        [-0.4379],\n",
      "        [-0.5657],\n",
      "        [-1.5842],\n",
      "        [ 0.6425],\n",
      "        [-1.4864],\n",
      "        [ 0.4260],\n",
      "        [-0.4603],\n",
      "        [ 0.4260],\n",
      "        [ 1.1957],\n",
      "        [ 1.1645]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 136/10000,\n",
      " train_loss: 0.0022,\n",
      " train_mae: 0.0406,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1771],\n",
      "        [-1.1771],\n",
      "        [ 0.6794],\n",
      "        [ 0.6102],\n",
      "        [-0.0705],\n",
      "        [ 0.5028],\n",
      "        [ 0.9285],\n",
      "        [ 0.9825],\n",
      "        [ 0.9285],\n",
      "        [ 0.8409],\n",
      "        [-1.6173],\n",
      "        [-0.8348],\n",
      "        [ 0.5748],\n",
      "        [-0.2521],\n",
      "        [ 0.9559],\n",
      "        [-0.2521],\n",
      "        [ 0.5748],\n",
      "        [-0.5995],\n",
      "        [-0.3322],\n",
      "        [ 0.9001],\n",
      "        [ 0.7785],\n",
      "        [ 0.8101],\n",
      "        [ 1.2006],\n",
      "        [ 1.2006],\n",
      "        [ 1.0801],\n",
      "        [-0.3322],\n",
      "        [-1.2243],\n",
      "        [ 1.0801],\n",
      "        [-1.4963],\n",
      "        [ 0.9825],\n",
      "        [-1.3569],\n",
      "        [ 0.5748],\n",
      "        [-0.2521],\n",
      "        [ 0.7785],\n",
      "        [ 0.5390],\n",
      "        [ 1.2006],\n",
      "        [ 0.7785],\n",
      "        [-0.6660],\n",
      "        [-0.1648],\n",
      "        [-1.0363],\n",
      "        [-1.1296],\n",
      "        [ 0.9825],\n",
      "        [-0.8348],\n",
      "        [ 0.6451],\n",
      "        [ 1.2006],\n",
      "        [-1.6295],\n",
      "        [ 0.0300],\n",
      "        [-0.4285],\n",
      "        [-1.3569],\n",
      "        [ 1.0331],\n",
      "        [-0.4285],\n",
      "        [-0.5575],\n",
      "        [-1.5870],\n",
      "        [ 0.6451],\n",
      "        [-1.4963],\n",
      "        [ 0.4296],\n",
      "        [-0.4510],\n",
      "        [ 0.4296],\n",
      "        [ 1.2006],\n",
      "        [ 1.1690]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 137/10000,\n",
      " train_loss: 0.0021,\n",
      " train_mae: 0.0387,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1855],\n",
      "        [-1.1855],\n",
      "        [ 0.6766],\n",
      "        [ 0.6079],\n",
      "        [-0.0647],\n",
      "        [ 0.5013],\n",
      "        [ 0.9255],\n",
      "        [ 0.9799],\n",
      "        [ 0.9255],\n",
      "        [ 0.8378],\n",
      "        [-1.6071],\n",
      "        [-0.8346],\n",
      "        [ 0.5727],\n",
      "        [-0.2439],\n",
      "        [ 0.9531],\n",
      "        [-0.2439],\n",
      "        [ 0.5727],\n",
      "        [-0.5907],\n",
      "        [-0.3231],\n",
      "        [ 0.8971],\n",
      "        [ 0.7754],\n",
      "        [ 0.8070],\n",
      "        [ 1.2005],\n",
      "        [ 1.2005],\n",
      "        [ 1.0782],\n",
      "        [-0.3231],\n",
      "        [-1.2324],\n",
      "        [ 1.0782],\n",
      "        [-1.4949],\n",
      "        [ 0.9799],\n",
      "        [-1.3621],\n",
      "        [ 0.5727],\n",
      "        [-0.2439],\n",
      "        [ 0.7754],\n",
      "        [ 0.5372],\n",
      "        [ 1.2005],\n",
      "        [ 0.7754],\n",
      "        [-0.6589],\n",
      "        [-0.1577],\n",
      "        [-1.0430],\n",
      "        [-1.1378],\n",
      "        [ 0.9799],\n",
      "        [-0.8346],\n",
      "        [ 0.6425],\n",
      "        [ 1.2005],\n",
      "        [-1.6184],\n",
      "        [ 0.0344],\n",
      "        [-0.4188],\n",
      "        [-1.3621],\n",
      "        [ 1.0308],\n",
      "        [-0.4188],\n",
      "        [-0.5480],\n",
      "        [-1.5792],\n",
      "        [ 0.6425],\n",
      "        [-1.4949],\n",
      "        [ 0.4288],\n",
      "        [-0.4412],\n",
      "        [ 0.4288],\n",
      "        [ 1.2005],\n",
      "        [ 1.1684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 138/10000,\n",
      " train_loss: 0.0020,\n",
      " train_mae: 0.0352,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1857],\n",
      "        [-1.1857],\n",
      "        [ 0.6691],\n",
      "        [ 0.6008],\n",
      "        [-0.0610],\n",
      "        [ 0.4954],\n",
      "        [ 0.9175],\n",
      "        [ 0.9721],\n",
      "        [ 0.9175],\n",
      "        [ 0.8296],\n",
      "        [-1.5889],\n",
      "        [-0.8310],\n",
      "        [ 0.5661],\n",
      "        [-0.2369],\n",
      "        [ 0.9452],\n",
      "        [-0.2369],\n",
      "        [ 0.5661],\n",
      "        [-0.5812],\n",
      "        [-0.3149],\n",
      "        [ 0.8890],\n",
      "        [ 0.7674],\n",
      "        [ 0.7988],\n",
      "        [ 1.1959],\n",
      "        [ 1.1959],\n",
      "        [ 1.0715],\n",
      "        [-0.3149],\n",
      "        [-1.2319],\n",
      "        [ 1.0715],\n",
      "        [-1.4841],\n",
      "        [ 0.9721],\n",
      "        [-1.3579],\n",
      "        [ 0.5661],\n",
      "        [-0.2369],\n",
      "        [ 0.7674],\n",
      "        [ 0.5309],\n",
      "        [ 1.1959],\n",
      "        [ 0.7674],\n",
      "        [-0.6506],\n",
      "        [-0.1523],\n",
      "        [-1.0434],\n",
      "        [-1.1384],\n",
      "        [ 0.9721],\n",
      "        [-0.8310],\n",
      "        [ 0.6352],\n",
      "        [ 1.1959],\n",
      "        [-1.5993],\n",
      "        [ 0.0362],\n",
      "        [-0.4094],\n",
      "        [-1.3579],\n",
      "        [ 1.0235],\n",
      "        [-0.4094],\n",
      "        [-0.5383],\n",
      "        [-1.5630],\n",
      "        [ 0.6352],\n",
      "        [-1.4841],\n",
      "        [ 0.4239],\n",
      "        [-0.4317],\n",
      "        [ 0.4239],\n",
      "        [ 1.1959],\n",
      "        [ 1.1630]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 139/10000,\n",
      " train_loss: 0.0018,\n",
      " train_mae: 0.0324,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1814],\n",
      "        [-1.1814],\n",
      "        [ 0.6596],\n",
      "        [ 0.5920],\n",
      "        [-0.0587],\n",
      "        [ 0.4878],\n",
      "        [ 0.9075],\n",
      "        [ 0.9623],\n",
      "        [ 0.9075],\n",
      "        [ 0.8195],\n",
      "        [-1.5669],\n",
      "        [-0.8260],\n",
      "        [ 0.5576],\n",
      "        [-0.2313],\n",
      "        [ 0.9353],\n",
      "        [-0.2313],\n",
      "        [ 0.5576],\n",
      "        [-0.5723],\n",
      "        [-0.3079],\n",
      "        [ 0.8789],\n",
      "        [ 0.7573],\n",
      "        [ 0.7887],\n",
      "        [ 1.1891],\n",
      "        [ 1.1891],\n",
      "        [ 1.0626],\n",
      "        [-0.3079],\n",
      "        [-1.2266],\n",
      "        [ 1.0626],\n",
      "        [-1.4686],\n",
      "        [ 0.9623],\n",
      "        [-1.3486],\n",
      "        [ 0.5576],\n",
      "        [-0.2313],\n",
      "        [ 0.7573],\n",
      "        [ 0.5228],\n",
      "        [ 1.1891],\n",
      "        [ 0.7573],\n",
      "        [-0.6423],\n",
      "        [-0.1482],\n",
      "        [-1.0405],\n",
      "        [-1.1349],\n",
      "        [ 0.9623],\n",
      "        [-0.8260],\n",
      "        [ 0.6260],\n",
      "        [ 1.1891],\n",
      "        [-1.5767],\n",
      "        [ 0.0365],\n",
      "        [-0.4011],\n",
      "        [-1.3486],\n",
      "        [ 1.0141],\n",
      "        [-0.4011],\n",
      "        [-0.5292],\n",
      "        [-1.5426],\n",
      "        [ 0.6260],\n",
      "        [-1.4686],\n",
      "        [ 0.4172],\n",
      "        [-0.4231],\n",
      "        [ 0.4172],\n",
      "        [ 1.1891],\n",
      "        [ 1.1556]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 140/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0313,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1775],\n",
      "        [-1.1775],\n",
      "        [ 0.6523],\n",
      "        [ 0.5851],\n",
      "        [-0.0566],\n",
      "        [ 0.4819],\n",
      "        [ 0.8995],\n",
      "        [ 0.9546],\n",
      "        [ 0.8995],\n",
      "        [ 0.8115],\n",
      "        [-1.5466],\n",
      "        [-0.8223],\n",
      "        [ 0.5510],\n",
      "        [-0.2264],\n",
      "        [ 0.9275],\n",
      "        [-0.2264],\n",
      "        [ 0.5510],\n",
      "        [-0.5649],\n",
      "        [-0.3020],\n",
      "        [ 0.8709],\n",
      "        [ 0.7495],\n",
      "        [ 0.7808],\n",
      "        [ 1.1839],\n",
      "        [ 1.1839],\n",
      "        [ 1.0557],\n",
      "        [-0.3020],\n",
      "        [-1.2217],\n",
      "        [ 1.0557],\n",
      "        [-1.4539],\n",
      "        [ 0.9546],\n",
      "        [-1.3396],\n",
      "        [ 0.5510],\n",
      "        [-0.2264],\n",
      "        [ 0.7495],\n",
      "        [ 0.5166],\n",
      "        [ 1.1839],\n",
      "        [ 0.7495],\n",
      "        [-0.6357],\n",
      "        [-0.1446],\n",
      "        [-1.0382],\n",
      "        [-1.1317],\n",
      "        [ 0.9546],\n",
      "        [-0.8223],\n",
      "        [ 0.6189],\n",
      "        [ 1.1839],\n",
      "        [-1.5558],\n",
      "        [ 0.0371],\n",
      "        [-0.3941],\n",
      "        [-1.3396],\n",
      "        [ 1.0067],\n",
      "        [-0.3941],\n",
      "        [-0.5216],\n",
      "        [-1.5237],\n",
      "        [ 0.6189],\n",
      "        [-1.4539],\n",
      "        [ 0.4121],\n",
      "        [-0.4159],\n",
      "        [ 0.4121],\n",
      "        [ 1.1839],\n",
      "        [ 1.1498]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 141/10000,\n",
      " train_loss: 0.0018,\n",
      " train_mae: 0.0310,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1782],\n",
      "        [-1.1782],\n",
      "        [ 0.6498],\n",
      "        [ 0.5828],\n",
      "        [-0.0540],\n",
      "        [ 0.4802],\n",
      "        [ 0.8969],\n",
      "        [ 0.9521],\n",
      "        [ 0.8969],\n",
      "        [ 0.8087],\n",
      "        [-1.5327],\n",
      "        [-0.8224],\n",
      "        [ 0.5489],\n",
      "        [-0.2223],\n",
      "        [ 0.9249],\n",
      "        [-0.2223],\n",
      "        [ 0.5489],\n",
      "        [-0.5604],\n",
      "        [-0.2974],\n",
      "        [ 0.8682],\n",
      "        [ 0.7468],\n",
      "        [ 0.7781],\n",
      "        [ 1.1831],\n",
      "        [ 1.1831],\n",
      "        [ 1.0537],\n",
      "        [-0.2974],\n",
      "        [-1.2215],\n",
      "        [ 1.0537],\n",
      "        [-1.4450],\n",
      "        [ 0.9521],\n",
      "        [-1.3358],\n",
      "        [ 0.5489],\n",
      "        [-0.2223],\n",
      "        [ 0.7468],\n",
      "        [ 0.5146],\n",
      "        [ 1.1831],\n",
      "        [ 0.7468],\n",
      "        [-0.6321],\n",
      "        [-0.1412],\n",
      "        [-1.0402],\n",
      "        [-1.1331],\n",
      "        [ 0.9521],\n",
      "        [-0.8224],\n",
      "        [ 0.6165],\n",
      "        [ 1.1831],\n",
      "        [-1.5414],\n",
      "        [ 0.0389],\n",
      "        [-0.3891],\n",
      "        [-1.3358],\n",
      "        [ 1.0044],\n",
      "        [-0.3891],\n",
      "        [-0.5167],\n",
      "        [-1.5111],\n",
      "        [ 0.6165],\n",
      "        [-1.4450],\n",
      "        [ 0.4108],\n",
      "        [-0.4108],\n",
      "        [ 0.4108],\n",
      "        [ 1.1831],\n",
      "        [ 1.1486]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 142/10000,\n",
      " train_loss: 0.0018,\n",
      " train_mae: 0.0312,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1860],\n",
      "        [-1.1860],\n",
      "        [ 0.6521],\n",
      "        [ 0.5851],\n",
      "        [-0.0515],\n",
      "        [ 0.4824],\n",
      "        [ 0.8996],\n",
      "        [ 0.9551],\n",
      "        [ 0.8996],\n",
      "        [ 0.8113],\n",
      "        [-1.5277],\n",
      "        [-0.8279],\n",
      "        [ 0.5511],\n",
      "        [-0.2198],\n",
      "        [ 0.9277],\n",
      "        [-0.2198],\n",
      "        [ 0.5511],\n",
      "        [-0.5597],\n",
      "        [-0.2949],\n",
      "        [ 0.8709],\n",
      "        [ 0.7492],\n",
      "        [ 0.7806],\n",
      "        [ 1.1870],\n",
      "        [ 1.1870],\n",
      "        [ 1.0570],\n",
      "        [-0.2949],\n",
      "        [-1.2286],\n",
      "        [ 1.0570],\n",
      "        [-1.4445],\n",
      "        [ 0.9551],\n",
      "        [-1.3398],\n",
      "        [ 0.5511],\n",
      "        [-0.2198],\n",
      "        [ 0.7492],\n",
      "        [ 0.5169],\n",
      "        [ 1.1870],\n",
      "        [ 0.7492],\n",
      "        [-0.6329],\n",
      "        [-0.1387],\n",
      "        [-1.0487],\n",
      "        [-1.1414],\n",
      "        [ 0.9551],\n",
      "        [-0.8279],\n",
      "        [ 0.6188],\n",
      "        [ 1.1870],\n",
      "        [-1.5359],\n",
      "        [ 0.0413],\n",
      "        [-0.3868],\n",
      "        [-1.3398],\n",
      "        [ 1.0075],\n",
      "        [-0.3868],\n",
      "        [-0.5154],\n",
      "        [-1.5072],\n",
      "        [ 0.6188],\n",
      "        [-1.4445],\n",
      "        [ 0.4130],\n",
      "        [-0.4086],\n",
      "        [ 0.4130],\n",
      "        [ 1.1870],\n",
      "        [ 1.1524]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 143/10000,\n",
      " train_loss: 0.0018,\n",
      " train_mae: 0.0323,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2001],\n",
      "        [-1.2001],\n",
      "        [ 0.6568],\n",
      "        [ 0.5895],\n",
      "        [-0.0505],\n",
      "        [ 0.4863],\n",
      "        [ 0.9054],\n",
      "        [ 0.9611],\n",
      "        [ 0.9054],\n",
      "        [ 0.8167],\n",
      "        [-1.5307],\n",
      "        [-0.8385],\n",
      "        [ 0.5554],\n",
      "        [-0.2197],\n",
      "        [ 0.9336],\n",
      "        [-0.2197],\n",
      "        [ 0.5554],\n",
      "        [-0.5630],\n",
      "        [-0.2952],\n",
      "        [ 0.8766],\n",
      "        [ 0.7544],\n",
      "        [ 0.7859],\n",
      "        [ 1.1937],\n",
      "        [ 1.1937],\n",
      "        [ 1.0633],\n",
      "        [-0.2952],\n",
      "        [-1.2421],\n",
      "        [ 1.0633],\n",
      "        [-1.4514],\n",
      "        [ 0.9611],\n",
      "        [-1.3507],\n",
      "        [ 0.5554],\n",
      "        [-0.2197],\n",
      "        [ 0.7544],\n",
      "        [ 0.5210],\n",
      "        [ 1.1937],\n",
      "        [ 0.7544],\n",
      "        [-0.6380],\n",
      "        [-0.1381],\n",
      "        [-1.0631],\n",
      "        [-1.1558],\n",
      "        [ 0.9611],\n",
      "        [-0.8385],\n",
      "        [ 0.6234],\n",
      "        [ 1.1937],\n",
      "        [-1.5385],\n",
      "        [ 0.0428],\n",
      "        [-0.3877],\n",
      "        [-1.3507],\n",
      "        [ 1.0137],\n",
      "        [-0.3877],\n",
      "        [-0.5178],\n",
      "        [-1.5112],\n",
      "        [ 0.6234],\n",
      "        [-1.4514],\n",
      "        [ 0.4166],\n",
      "        [-0.4097],\n",
      "        [ 0.4166],\n",
      "        [ 1.1937],\n",
      "        [ 1.1590]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 144/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0337,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2164],\n",
      "        [-1.2164],\n",
      "        [ 0.6611],\n",
      "        [ 0.5934],\n",
      "        [-0.0514],\n",
      "        [ 0.4895],\n",
      "        [ 0.9112],\n",
      "        [ 0.9671],\n",
      "        [ 0.9112],\n",
      "        [ 0.8220],\n",
      "        [-1.5373],\n",
      "        [-0.8517],\n",
      "        [ 0.5590],\n",
      "        [-0.2219],\n",
      "        [ 0.9395],\n",
      "        [-0.2219],\n",
      "        [ 0.5590],\n",
      "        [-0.5690],\n",
      "        [-0.2980],\n",
      "        [ 0.8822],\n",
      "        [ 0.7593],\n",
      "        [ 0.7910],\n",
      "        [ 1.2004],\n",
      "        [ 1.2004],\n",
      "        [ 1.0697],\n",
      "        [-0.2980],\n",
      "        [-1.2578],\n",
      "        [ 1.0697],\n",
      "        [-1.4614],\n",
      "        [ 0.9671],\n",
      "        [-1.3641],\n",
      "        [ 0.5590],\n",
      "        [-0.2219],\n",
      "        [ 0.7593],\n",
      "        [ 0.5243],\n",
      "        [ 1.2004],\n",
      "        [ 0.7593],\n",
      "        [-0.6457],\n",
      "        [-0.1397],\n",
      "        [-1.0798],\n",
      "        [-1.1725],\n",
      "        [ 0.9671],\n",
      "        [-0.8517],\n",
      "        [ 0.6275],\n",
      "        [ 1.2004],\n",
      "        [-1.5448],\n",
      "        [ 0.0426],\n",
      "        [-0.3913],\n",
      "        [-1.3641],\n",
      "        [ 1.0199],\n",
      "        [-0.3913],\n",
      "        [-0.5230],\n",
      "        [-1.5187],\n",
      "        [ 0.6275],\n",
      "        [-1.4614],\n",
      "        [ 0.4192],\n",
      "        [-0.4135],\n",
      "        [ 0.4192],\n",
      "        [ 1.2004],\n",
      "        [ 1.1656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 145/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0352,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2291],\n",
      "        [-1.2291],\n",
      "        [ 0.6634],\n",
      "        [ 0.5952],\n",
      "        [-0.0539],\n",
      "        [ 0.4906],\n",
      "        [ 0.9149],\n",
      "        [ 0.9710],\n",
      "        [ 0.9149],\n",
      "        [ 0.8252],\n",
      "        [-1.5414],\n",
      "        [-0.8632],\n",
      "        [ 0.5606],\n",
      "        [-0.2254],\n",
      "        [ 0.9433],\n",
      "        [-0.2254],\n",
      "        [ 0.5606],\n",
      "        [-0.5753],\n",
      "        [-0.3019],\n",
      "        [ 0.8857],\n",
      "        [ 0.7622],\n",
      "        [ 0.7940],\n",
      "        [ 1.2053],\n",
      "        [ 1.2053],\n",
      "        [ 1.0741],\n",
      "        [-0.3019],\n",
      "        [-1.2700],\n",
      "        [ 1.0741],\n",
      "        [-1.4683],\n",
      "        [ 0.9710],\n",
      "        [-1.3739],\n",
      "        [ 0.5606],\n",
      "        [-0.2254],\n",
      "        [ 0.7622],\n",
      "        [ 0.5257],\n",
      "        [ 1.2053],\n",
      "        [ 0.7622],\n",
      "        [-0.6533],\n",
      "        [-0.1427],\n",
      "        [-1.0933],\n",
      "        [-1.1856],\n",
      "        [ 0.9710],\n",
      "        [-0.8632],\n",
      "        [ 0.6295],\n",
      "        [ 1.2053],\n",
      "        [-1.5487],\n",
      "        [ 0.0407],\n",
      "        [-0.3958],\n",
      "        [-1.3739],\n",
      "        [ 1.0242],\n",
      "        [-0.3958],\n",
      "        [-0.5287],\n",
      "        [-1.5235],\n",
      "        [ 0.6295],\n",
      "        [-1.4683],\n",
      "        [ 0.4199],\n",
      "        [-0.4181],\n",
      "        [ 0.4199],\n",
      "        [ 1.2053],\n",
      "        [ 1.1704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 146/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0355,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2337],\n",
      "        [-1.2337],\n",
      "        [ 0.6633],\n",
      "        [ 0.5948],\n",
      "        [-0.0565],\n",
      "        [ 0.4897],\n",
      "        [ 0.9160],\n",
      "        [ 0.9724],\n",
      "        [ 0.9160],\n",
      "        [ 0.8259],\n",
      "        [-1.5384],\n",
      "        [-0.8695],\n",
      "        [ 0.5600],\n",
      "        [-0.2284],\n",
      "        [ 0.9446],\n",
      "        [-0.2284],\n",
      "        [ 0.5600],\n",
      "        [-0.5794],\n",
      "        [-0.3051],\n",
      "        [ 0.8866],\n",
      "        [ 0.7625],\n",
      "        [ 0.7945],\n",
      "        [ 1.2079],\n",
      "        [ 1.2079],\n",
      "        [ 1.0760],\n",
      "        [-0.3051],\n",
      "        [-1.2739],\n",
      "        [ 1.0760],\n",
      "        [-1.4675],\n",
      "        [ 0.9724],\n",
      "        [-1.3757],\n",
      "        [ 0.5600],\n",
      "        [-0.2284],\n",
      "        [ 0.7625],\n",
      "        [ 0.5250],\n",
      "        [ 1.2079],\n",
      "        [ 0.7625],\n",
      "        [-0.6580],\n",
      "        [-0.1456],\n",
      "        [-1.0994],\n",
      "        [-1.1908],\n",
      "        [ 0.9724],\n",
      "        [-0.8695],\n",
      "        [ 0.6292],\n",
      "        [ 1.2079],\n",
      "        [-1.5455],\n",
      "        [ 0.0383],\n",
      "        [-0.3991],\n",
      "        [-1.3757],\n",
      "        [ 1.0258],\n",
      "        [-0.3991],\n",
      "        [-0.5325],\n",
      "        [-1.5211],\n",
      "        [ 0.6292],\n",
      "        [-1.4675],\n",
      "        [ 0.4187],\n",
      "        [-0.4216],\n",
      "        [ 0.4187],\n",
      "        [ 1.2079],\n",
      "        [ 1.1728]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 147/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0348,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2294],\n",
      "        [-1.2294],\n",
      "        [ 0.6614],\n",
      "        [ 0.5928],\n",
      "        [-0.0585],\n",
      "        [ 0.4875],\n",
      "        [ 0.9149],\n",
      "        [ 0.9716],\n",
      "        [ 0.9149],\n",
      "        [ 0.8244],\n",
      "        [-1.5276],\n",
      "        [-0.8696],\n",
      "        [ 0.5579],\n",
      "        [-0.2301],\n",
      "        [ 0.9436],\n",
      "        [-0.2301],\n",
      "        [ 0.5579],\n",
      "        [-0.5804],\n",
      "        [-0.3066],\n",
      "        [ 0.8854],\n",
      "        [ 0.7609],\n",
      "        [ 0.7930],\n",
      "        [ 1.2084],\n",
      "        [ 1.2084],\n",
      "        [ 1.0757],\n",
      "        [-0.3066],\n",
      "        [-1.2689],\n",
      "        [ 1.0757],\n",
      "        [-1.4583],\n",
      "        [ 0.9716],\n",
      "        [-1.3686],\n",
      "        [ 0.5579],\n",
      "        [-0.2301],\n",
      "        [ 0.7609],\n",
      "        [ 0.5228],\n",
      "        [ 1.2084],\n",
      "        [ 0.7609],\n",
      "        [-0.6589],\n",
      "        [-0.1474],\n",
      "        [-1.0972],\n",
      "        [-1.1873],\n",
      "        [ 0.9716],\n",
      "        [-0.8696],\n",
      "        [ 0.6273],\n",
      "        [ 1.2084],\n",
      "        [-1.5345],\n",
      "        [ 0.0362],\n",
      "        [-0.4005],\n",
      "        [-1.3686],\n",
      "        [ 1.0252],\n",
      "        [-0.4005],\n",
      "        [-0.5336],\n",
      "        [-1.5106],\n",
      "        [ 0.6273],\n",
      "        [-1.4583],\n",
      "        [ 0.4165],\n",
      "        [-0.4229],\n",
      "        [ 0.4165],\n",
      "        [ 1.2084],\n",
      "        [ 1.1731]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 148/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0334,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2198],\n",
      "        [-1.2198],\n",
      "        [ 0.6583],\n",
      "        [ 0.5897],\n",
      "        [-0.0600],\n",
      "        [ 0.4846],\n",
      "        [ 0.9123],\n",
      "        [ 0.9692],\n",
      "        [ 0.9123],\n",
      "        [ 0.8216],\n",
      "        [-1.5127],\n",
      "        [-0.8656],\n",
      "        [ 0.5549],\n",
      "        [-0.2308],\n",
      "        [ 0.9411],\n",
      "        [-0.2308],\n",
      "        [ 0.5549],\n",
      "        [-0.5794],\n",
      "        [-0.3070],\n",
      "        [ 0.8828],\n",
      "        [ 0.7579],\n",
      "        [ 0.7901],\n",
      "        [ 1.2074],\n",
      "        [ 1.2074],\n",
      "        [ 1.0739],\n",
      "        [-0.3070],\n",
      "        [-1.2586],\n",
      "        [ 1.0739],\n",
      "        [-1.4445],\n",
      "        [ 0.9692],\n",
      "        [-1.3564],\n",
      "        [ 0.5549],\n",
      "        [-0.2308],\n",
      "        [ 0.7579],\n",
      "        [ 0.5198],\n",
      "        [ 1.2074],\n",
      "        [ 0.7579],\n",
      "        [-0.6573],\n",
      "        [-0.1485],\n",
      "        [-1.0899],\n",
      "        [-1.1785],\n",
      "        [ 0.9692],\n",
      "        [-0.8656],\n",
      "        [ 0.6242],\n",
      "        [ 1.2074],\n",
      "        [-1.5195],\n",
      "        [ 0.0344],\n",
      "        [-0.4005],\n",
      "        [-1.3564],\n",
      "        [ 1.0231],\n",
      "        [-0.4005],\n",
      "        [-0.5329],\n",
      "        [-1.4959],\n",
      "        [ 0.6242],\n",
      "        [-1.4445],\n",
      "        [ 0.4136],\n",
      "        [-0.4227],\n",
      "        [ 0.4136],\n",
      "        [ 1.2074],\n",
      "        [ 1.1719]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 149/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0320,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2105],\n",
      "        [-1.2105],\n",
      "        [ 0.6549],\n",
      "        [ 0.5864],\n",
      "        [-0.0614],\n",
      "        [ 0.4813],\n",
      "        [ 0.9092],\n",
      "        [ 0.9663],\n",
      "        [ 0.9092],\n",
      "        [ 0.8184],\n",
      "        [-1.4995],\n",
      "        [-0.8614],\n",
      "        [ 0.5516],\n",
      "        [-0.2314],\n",
      "        [ 0.9381],\n",
      "        [-0.2314],\n",
      "        [ 0.5516],\n",
      "        [-0.5782],\n",
      "        [-0.3073],\n",
      "        [ 0.8796],\n",
      "        [ 0.7546],\n",
      "        [ 0.7868],\n",
      "        [ 1.2058],\n",
      "        [ 1.2058],\n",
      "        [ 1.0714],\n",
      "        [-0.3073],\n",
      "        [-1.2486],\n",
      "        [ 1.0714],\n",
      "        [-1.4320],\n",
      "        [ 0.9663],\n",
      "        [-1.3451],\n",
      "        [ 0.5516],\n",
      "        [-0.2314],\n",
      "        [ 0.7546],\n",
      "        [ 0.5166],\n",
      "        [ 1.2058],\n",
      "        [ 0.7546],\n",
      "        [-0.6555],\n",
      "        [-0.1495],\n",
      "        [-1.0825],\n",
      "        [-1.1697],\n",
      "        [ 0.9663],\n",
      "        [-0.8614],\n",
      "        [ 0.6208],\n",
      "        [ 1.2058],\n",
      "        [-1.5063],\n",
      "        [ 0.0326],\n",
      "        [-0.4003],\n",
      "        [-1.3451],\n",
      "        [ 1.0204],\n",
      "        [-0.4003],\n",
      "        [-0.5321],\n",
      "        [-1.4829],\n",
      "        [ 0.6208],\n",
      "        [-1.4320],\n",
      "        [ 0.4105],\n",
      "        [-0.4225],\n",
      "        [ 0.4105],\n",
      "        [ 1.2058],\n",
      "        [ 1.1700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 150/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2058],\n",
      "        [-1.2058],\n",
      "        [ 0.6523],\n",
      "        [ 0.5838],\n",
      "        [-0.0629],\n",
      "        [ 0.4788],\n",
      "        [ 0.9070],\n",
      "        [ 0.9642],\n",
      "        [ 0.9070],\n",
      "        [ 0.8159],\n",
      "        [-1.4929],\n",
      "        [-0.8597],\n",
      "        [ 0.5490],\n",
      "        [-0.2326],\n",
      "        [ 0.9360],\n",
      "        [-0.2326],\n",
      "        [ 0.5490],\n",
      "        [-0.5784],\n",
      "        [-0.3082],\n",
      "        [ 0.8773],\n",
      "        [ 0.7521],\n",
      "        [ 0.7843],\n",
      "        [ 1.2048],\n",
      "        [ 1.2048],\n",
      "        [ 1.0697],\n",
      "        [-0.3082],\n",
      "        [-1.2436],\n",
      "        [ 1.0697],\n",
      "        [-1.4257],\n",
      "        [ 0.9642],\n",
      "        [-1.3393],\n",
      "        [ 0.5490],\n",
      "        [-0.2326],\n",
      "        [ 0.7521],\n",
      "        [ 0.5140],\n",
      "        [ 1.2048],\n",
      "        [ 0.7521],\n",
      "        [-0.6553],\n",
      "        [-0.1508],\n",
      "        [-1.0789],\n",
      "        [-1.1654],\n",
      "        [ 0.9642],\n",
      "        [-0.8597],\n",
      "        [ 0.6182],\n",
      "        [ 1.2048],\n",
      "        [-1.4997],\n",
      "        [ 0.0308],\n",
      "        [-0.4010],\n",
      "        [-1.3393],\n",
      "        [ 1.0185],\n",
      "        [-0.4010],\n",
      "        [-0.5324],\n",
      "        [-1.4764],\n",
      "        [ 0.6182],\n",
      "        [-1.4257],\n",
      "        [ 0.4081],\n",
      "        [-0.4232],\n",
      "        [ 0.4081],\n",
      "        [ 1.2048],\n",
      "        [ 1.1688]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 151/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2072],\n",
      "        [-1.2072],\n",
      "        [ 0.6518],\n",
      "        [ 0.5831],\n",
      "        [-0.0641],\n",
      "        [ 0.4780],\n",
      "        [ 0.9068],\n",
      "        [ 0.9642],\n",
      "        [ 0.9068],\n",
      "        [ 0.8156],\n",
      "        [-1.4945],\n",
      "        [-0.8615],\n",
      "        [ 0.5483],\n",
      "        [-0.2339],\n",
      "        [ 0.9359],\n",
      "        [-0.2339],\n",
      "        [ 0.5483],\n",
      "        [-0.5802],\n",
      "        [-0.3096],\n",
      "        [ 0.8771],\n",
      "        [ 0.7516],\n",
      "        [ 0.7839],\n",
      "        [ 1.2055],\n",
      "        [ 1.2055],\n",
      "        [ 1.0700],\n",
      "        [-0.3096],\n",
      "        [-1.2450],\n",
      "        [ 1.0700],\n",
      "        [-1.4271],\n",
      "        [ 0.9642],\n",
      "        [-1.3407],\n",
      "        [ 0.5483],\n",
      "        [-0.2339],\n",
      "        [ 0.7516],\n",
      "        [ 0.5133],\n",
      "        [ 1.2055],\n",
      "        [ 0.7516],\n",
      "        [-0.6571],\n",
      "        [-0.1520],\n",
      "        [-1.0805],\n",
      "        [-1.1669],\n",
      "        [ 0.9642],\n",
      "        [-0.8615],\n",
      "        [ 0.6176],\n",
      "        [ 1.2055],\n",
      "        [-1.5012],\n",
      "        [ 0.0297],\n",
      "        [-0.4025],\n",
      "        [-1.3407],\n",
      "        [ 1.0186],\n",
      "        [-0.4025],\n",
      "        [-0.5341],\n",
      "        [-1.4779],\n",
      "        [ 0.6176],\n",
      "        [-1.4271],\n",
      "        [ 0.4072],\n",
      "        [-0.4247],\n",
      "        [ 0.4072],\n",
      "        [ 1.2055],\n",
      "        [ 1.1693]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 152/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0318,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2131],\n",
      "        [-1.2131],\n",
      "        [ 0.6537],\n",
      "        [ 0.5849],\n",
      "        [-0.0641],\n",
      "        [ 0.4796],\n",
      "        [ 0.9092],\n",
      "        [ 0.9666],\n",
      "        [ 0.9092],\n",
      "        [ 0.8178],\n",
      "        [-1.5022],\n",
      "        [-0.8655],\n",
      "        [ 0.5500],\n",
      "        [-0.2346],\n",
      "        [ 0.9383],\n",
      "        [-0.2346],\n",
      "        [ 0.5500],\n",
      "        [-0.5826],\n",
      "        [-0.3107],\n",
      "        [ 0.8794],\n",
      "        [ 0.7538],\n",
      "        [ 0.7861],\n",
      "        [ 1.2081],\n",
      "        [ 1.2081],\n",
      "        [ 1.0725],\n",
      "        [-0.3107],\n",
      "        [-1.2511],\n",
      "        [ 1.0725],\n",
      "        [-1.4344],\n",
      "        [ 0.9666],\n",
      "        [-1.3474],\n",
      "        [ 0.5500],\n",
      "        [-0.2346],\n",
      "        [ 0.7538],\n",
      "        [ 0.5149],\n",
      "        [ 1.2081],\n",
      "        [ 0.7538],\n",
      "        [-0.6599],\n",
      "        [-0.1524],\n",
      "        [-1.0856],\n",
      "        [-1.1725],\n",
      "        [ 0.9666],\n",
      "        [-0.8655],\n",
      "        [ 0.6195],\n",
      "        [ 1.2081],\n",
      "        [-1.5090],\n",
      "        [ 0.0300],\n",
      "        [-0.4040],\n",
      "        [-1.3474],\n",
      "        [ 1.0211],\n",
      "        [-0.4040],\n",
      "        [-0.5362],\n",
      "        [-1.4855],\n",
      "        [ 0.6195],\n",
      "        [-1.4344],\n",
      "        [ 0.4086],\n",
      "        [-0.4263],\n",
      "        [ 0.4086],\n",
      "        [ 1.2081],\n",
      "        [ 1.1720]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 153/10000,\n",
      " train_loss: 0.0017,\n",
      " train_mae: 0.0329,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2200],\n",
      "        [-1.2200],\n",
      "        [ 0.6572],\n",
      "        [ 0.5882],\n",
      "        [-0.0629],\n",
      "        [ 0.4827],\n",
      "        [ 0.9129],\n",
      "        [ 0.9704],\n",
      "        [ 0.9129],\n",
      "        [ 0.8215],\n",
      "        [-1.5123],\n",
      "        [-0.8695],\n",
      "        [ 0.5533],\n",
      "        [-0.2342],\n",
      "        [ 0.9420],\n",
      "        [-0.2342],\n",
      "        [ 0.5533],\n",
      "        [-0.5844],\n",
      "        [-0.3107],\n",
      "        [ 0.8831],\n",
      "        [ 0.7574],\n",
      "        [ 0.7897],\n",
      "        [ 1.2118],\n",
      "        [ 1.2118],\n",
      "        [ 1.0762],\n",
      "        [-0.3107],\n",
      "        [-1.2584],\n",
      "        [ 1.0762],\n",
      "        [-1.4437],\n",
      "        [ 0.9704],\n",
      "        [-1.3557],\n",
      "        [ 0.5533],\n",
      "        [-0.2342],\n",
      "        [ 0.7574],\n",
      "        [ 0.5181],\n",
      "        [ 1.2118],\n",
      "        [ 0.7574],\n",
      "        [-0.6624],\n",
      "        [-0.1517],\n",
      "        [-1.0914],\n",
      "        [-1.1790],\n",
      "        [ 0.9704],\n",
      "        [-0.8695],\n",
      "        [ 0.6229],\n",
      "        [ 1.2118],\n",
      "        [-1.5192],\n",
      "        [ 0.0316],\n",
      "        [-0.4047],\n",
      "        [-1.3557],\n",
      "        [ 1.0249],\n",
      "        [-0.4047],\n",
      "        [-0.5378],\n",
      "        [-1.4954],\n",
      "        [ 0.6229],\n",
      "        [-1.4437],\n",
      "        [ 0.4116],\n",
      "        [-0.4271],\n",
      "        [ 0.4116],\n",
      "        [ 1.2118],\n",
      "        [ 1.1756]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 154/10000,\n",
      " train_loss: 0.0016,\n",
      " train_mae: 0.0337,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2246],\n",
      "        [-1.2246],\n",
      "        [ 0.6602],\n",
      "        [ 0.5912],\n",
      "        [-0.0611],\n",
      "        [ 0.4856],\n",
      "        [ 0.9159],\n",
      "        [ 0.9733],\n",
      "        [ 0.9159],\n",
      "        [ 0.8245],\n",
      "        [-1.5210],\n",
      "        [-0.8714],\n",
      "        [ 0.5562],\n",
      "        [-0.2330],\n",
      "        [ 0.9450],\n",
      "        [-0.2330],\n",
      "        [ 0.5562],\n",
      "        [-0.5849],\n",
      "        [-0.3098],\n",
      "        [ 0.8861],\n",
      "        [ 0.7604],\n",
      "        [ 0.7927],\n",
      "        [ 1.2146],\n",
      "        [ 1.2146],\n",
      "        [ 1.0791],\n",
      "        [-0.3098],\n",
      "        [-1.2634],\n",
      "        [ 1.0791],\n",
      "        [-1.4512],\n",
      "        [ 0.9733],\n",
      "        [-1.3619],\n",
      "        [ 0.5562],\n",
      "        [-0.2330],\n",
      "        [ 0.7604],\n",
      "        [ 0.5210],\n",
      "        [ 1.2146],\n",
      "        [ 0.7604],\n",
      "        [-0.6633],\n",
      "        [-0.1501],\n",
      "        [-1.0948],\n",
      "        [-1.1832],\n",
      "        [ 0.9733],\n",
      "        [-0.8714],\n",
      "        [ 0.6259],\n",
      "        [ 1.2146],\n",
      "        [-1.5280],\n",
      "        [ 0.0337],\n",
      "        [-0.4042],\n",
      "        [-1.3619],\n",
      "        [ 1.0278],\n",
      "        [-0.4042],\n",
      "        [-0.5380],\n",
      "        [-1.5038],\n",
      "        [ 0.6259],\n",
      "        [-1.4512],\n",
      "        [ 0.4144],\n",
      "        [-0.4267],\n",
      "        [ 0.4144],\n",
      "        [ 1.2146],\n",
      "        [ 1.1785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 155/10000,\n",
      " train_loss: 0.0016,\n",
      " train_mae: 0.0337,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2249],\n",
      "        [-1.2249],\n",
      "        [ 0.6609],\n",
      "        [ 0.5920],\n",
      "        [-0.0594],\n",
      "        [ 0.4866],\n",
      "        [ 0.9162],\n",
      "        [ 0.9736],\n",
      "        [ 0.9162],\n",
      "        [ 0.8249],\n",
      "        [-1.5259],\n",
      "        [-0.8703],\n",
      "        [ 0.5571],\n",
      "        [-0.2313],\n",
      "        [ 0.9453],\n",
      "        [-0.2313],\n",
      "        [ 0.5571],\n",
      "        [-0.5839],\n",
      "        [-0.3083],\n",
      "        [ 0.8865],\n",
      "        [ 0.7609],\n",
      "        [ 0.7932],\n",
      "        [ 1.2149],\n",
      "        [ 1.2149],\n",
      "        [ 1.0794],\n",
      "        [-0.3083],\n",
      "        [-1.2642],\n",
      "        [ 1.0794],\n",
      "        [-1.4547],\n",
      "        [ 0.9736],\n",
      "        [-1.3639],\n",
      "        [ 0.5571],\n",
      "        [-0.2313],\n",
      "        [ 0.7609],\n",
      "        [ 0.5220],\n",
      "        [ 1.2149],\n",
      "        [ 0.7609],\n",
      "        [-0.6622],\n",
      "        [-0.1484],\n",
      "        [-1.0942],\n",
      "        [-1.1832],\n",
      "        [ 0.9736],\n",
      "        [-0.8703],\n",
      "        [ 0.6266],\n",
      "        [ 1.2149],\n",
      "        [-1.5330],\n",
      "        [ 0.0354],\n",
      "        [-0.4028],\n",
      "        [-1.3639],\n",
      "        [ 1.0281],\n",
      "        [-0.4028],\n",
      "        [-0.5369],\n",
      "        [-1.5083],\n",
      "        [ 0.6266],\n",
      "        [-1.4547],\n",
      "        [ 0.4155],\n",
      "        [-0.4254],\n",
      "        [ 0.4155],\n",
      "        [ 1.2149],\n",
      "        [ 1.1788]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 156/10000,\n",
      " train_loss: 0.0016,\n",
      " train_mae: 0.0328,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2208],\n",
      "        [-1.2208],\n",
      "        [ 0.6589],\n",
      "        [ 0.5903],\n",
      "        [-0.0582],\n",
      "        [ 0.4853],\n",
      "        [ 0.9137],\n",
      "        [ 0.9710],\n",
      "        [ 0.9137],\n",
      "        [ 0.8225],\n",
      "        [-1.5266],\n",
      "        [-0.8661],\n",
      "        [ 0.5556],\n",
      "        [-0.2297],\n",
      "        [ 0.9427],\n",
      "        [-0.2297],\n",
      "        [ 0.5556],\n",
      "        [-0.5815],\n",
      "        [-0.3064],\n",
      "        [ 0.8840],\n",
      "        [ 0.7587],\n",
      "        [ 0.7909],\n",
      "        [ 1.2127],\n",
      "        [ 1.2127],\n",
      "        [ 1.0769],\n",
      "        [-0.3064],\n",
      "        [-1.2604],\n",
      "        [ 1.0769],\n",
      "        [-1.4538],\n",
      "        [ 0.9710],\n",
      "        [-1.3614],\n",
      "        [ 0.5556],\n",
      "        [-0.2297],\n",
      "        [ 0.7587],\n",
      "        [ 0.5205],\n",
      "        [ 1.2127],\n",
      "        [ 0.7587],\n",
      "        [-0.6595],\n",
      "        [-0.1470],\n",
      "        [-1.0895],\n",
      "        [-1.1788],\n",
      "        [ 0.9710],\n",
      "        [-0.8661],\n",
      "        [ 0.6248],\n",
      "        [ 1.2127],\n",
      "        [-1.5340],\n",
      "        [ 0.0361],\n",
      "        [-0.4008],\n",
      "        [-1.3614],\n",
      "        [ 1.0255],\n",
      "        [-0.4008],\n",
      "        [-0.5347],\n",
      "        [-1.5087],\n",
      "        [ 0.6248],\n",
      "        [-1.4538],\n",
      "        [ 0.4146],\n",
      "        [-0.4233],\n",
      "        [ 0.4146],\n",
      "        [ 1.2127],\n",
      "        [ 1.1764]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 157/10000,\n",
      " train_loss: 0.0015,\n",
      " train_mae: 0.0314,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2138],\n",
      "        [-1.2138],\n",
      "        [ 0.6556],\n",
      "        [ 0.5873],\n",
      "        [-0.0574],\n",
      "        [ 0.4829],\n",
      "        [ 0.9096],\n",
      "        [ 0.9669],\n",
      "        [ 0.9096],\n",
      "        [ 0.8186],\n",
      "        [-1.5247],\n",
      "        [-0.8602],\n",
      "        [ 0.5527],\n",
      "        [-0.2279],\n",
      "        [ 0.9386],\n",
      "        [-0.2279],\n",
      "        [ 0.5527],\n",
      "        [-0.5783],\n",
      "        [-0.3044],\n",
      "        [ 0.8799],\n",
      "        [ 0.7550],\n",
      "        [ 0.7871],\n",
      "        [ 1.2089],\n",
      "        [ 1.2089],\n",
      "        [ 1.0728],\n",
      "        [-0.3044],\n",
      "        [-1.2537],\n",
      "        [ 1.0728],\n",
      "        [-1.4501],\n",
      "        [ 0.9669],\n",
      "        [-1.3559],\n",
      "        [ 0.5527],\n",
      "        [-0.2279],\n",
      "        [ 0.7550],\n",
      "        [ 0.5179],\n",
      "        [ 1.2089],\n",
      "        [ 0.7550],\n",
      "        [-0.6557],\n",
      "        [-0.1456],\n",
      "        [-1.0822],\n",
      "        [-1.1716],\n",
      "        [ 0.9669],\n",
      "        [-0.8602],\n",
      "        [ 0.6216],\n",
      "        [ 1.2089],\n",
      "        [-1.5322],\n",
      "        [ 0.0364],\n",
      "        [-0.3984],\n",
      "        [-1.3559],\n",
      "        [ 1.0213],\n",
      "        [-0.3984],\n",
      "        [-0.5318],\n",
      "        [-1.5062],\n",
      "        [ 0.6216],\n",
      "        [-1.4501],\n",
      "        [ 0.4125],\n",
      "        [-0.4209],\n",
      "        [ 0.4125],\n",
      "        [ 1.2089],\n",
      "        [ 1.1726]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 158/10000,\n",
      " train_loss: 0.0015,\n",
      " train_mae: 0.0304,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2064],\n",
      "        [-1.2064],\n",
      "        [ 0.6529],\n",
      "        [ 0.5849],\n",
      "        [-0.0563],\n",
      "        [ 0.4810],\n",
      "        [ 0.9062],\n",
      "        [ 0.9634],\n",
      "        [ 0.9062],\n",
      "        [ 0.8154],\n",
      "        [-1.5226],\n",
      "        [-0.8541],\n",
      "        [ 0.5505],\n",
      "        [-0.2261],\n",
      "        [ 0.9351],\n",
      "        [-0.2261],\n",
      "        [ 0.5505],\n",
      "        [-0.5752],\n",
      "        [-0.3023],\n",
      "        [ 0.8765],\n",
      "        [ 0.7519],\n",
      "        [ 0.7839],\n",
      "        [ 1.2057],\n",
      "        [ 1.2057],\n",
      "        [ 1.0693],\n",
      "        [-0.3023],\n",
      "        [-1.2465],\n",
      "        [ 1.0693],\n",
      "        [-1.4460],\n",
      "        [ 0.9634],\n",
      "        [-1.3500],\n",
      "        [ 0.5505],\n",
      "        [-0.2261],\n",
      "        [ 0.7519],\n",
      "        [ 0.5158],\n",
      "        [ 1.2057],\n",
      "        [ 0.7519],\n",
      "        [-0.6518],\n",
      "        [-0.1442],\n",
      "        [-1.0745],\n",
      "        [-1.1640],\n",
      "        [ 0.9634],\n",
      "        [-0.8541],\n",
      "        [ 0.6191],\n",
      "        [ 1.2057],\n",
      "        [-1.5304],\n",
      "        [ 0.0370],\n",
      "        [-0.3961],\n",
      "        [-1.3500],\n",
      "        [ 1.0178],\n",
      "        [-0.3961],\n",
      "        [-0.5289],\n",
      "        [-1.5036],\n",
      "        [ 0.6191],\n",
      "        [-1.4460],\n",
      "        [ 0.4110],\n",
      "        [-0.4185],\n",
      "        [ 0.4110],\n",
      "        [ 1.2057],\n",
      "        [ 1.1692]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 159/10000,\n",
      " train_loss: 0.0015,\n",
      " train_mae: 0.0300,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2011],\n",
      "        [-1.2011],\n",
      "        [ 0.6521],\n",
      "        [ 0.5843],\n",
      "        [-0.0550],\n",
      "        [ 0.4807],\n",
      "        [ 0.9048],\n",
      "        [ 0.9620],\n",
      "        [ 0.9048],\n",
      "        [ 0.8142],\n",
      "        [-1.5230],\n",
      "        [-0.8495],\n",
      "        [ 0.5500],\n",
      "        [-0.2245],\n",
      "        [ 0.9338],\n",
      "        [-0.2245],\n",
      "        [ 0.5500],\n",
      "        [-0.5730],\n",
      "        [-0.3006],\n",
      "        [ 0.8753],\n",
      "        [ 0.7508],\n",
      "        [ 0.7828],\n",
      "        [ 1.2044],\n",
      "        [ 1.2044],\n",
      "        [ 1.0678],\n",
      "        [-0.3006],\n",
      "        [-1.2416],\n",
      "        [ 1.0678],\n",
      "        [-1.4444],\n",
      "        [ 0.9620],\n",
      "        [-1.3464],\n",
      "        [ 0.5500],\n",
      "        [-0.2245],\n",
      "        [ 0.7508],\n",
      "        [ 0.5154],\n",
      "        [ 1.2044],\n",
      "        [ 0.7508],\n",
      "        [-0.6492],\n",
      "        [-0.1427],\n",
      "        [-1.0688],\n",
      "        [-1.1585],\n",
      "        [ 0.9620],\n",
      "        [-0.8495],\n",
      "        [ 0.6184],\n",
      "        [ 1.2044],\n",
      "        [-1.5310],\n",
      "        [ 0.0381],\n",
      "        [-0.3943],\n",
      "        [-1.3464],\n",
      "        [ 1.0164],\n",
      "        [-0.3943],\n",
      "        [-0.5270],\n",
      "        [-1.5035],\n",
      "        [ 0.6184],\n",
      "        [-1.4444],\n",
      "        [ 0.4109],\n",
      "        [-0.4167],\n",
      "        [ 0.4109],\n",
      "        [ 1.2044],\n",
      "        [ 1.1679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 160/10000,\n",
      " train_loss: 0.0015,\n",
      " train_mae: 0.0299,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1996],\n",
      "        [-1.1996],\n",
      "        [ 0.6531],\n",
      "        [ 0.5854],\n",
      "        [-0.0540],\n",
      "        [ 0.4818],\n",
      "        [ 0.9057],\n",
      "        [ 0.9628],\n",
      "        [ 0.9057],\n",
      "        [ 0.8151],\n",
      "        [-1.5274],\n",
      "        [-0.8477],\n",
      "        [ 0.5511],\n",
      "        [-0.2237],\n",
      "        [ 0.9346],\n",
      "        [-0.2237],\n",
      "        [ 0.5511],\n",
      "        [-0.5727],\n",
      "        [-0.3000],\n",
      "        [ 0.8761],\n",
      "        [ 0.7518],\n",
      "        [ 0.7837],\n",
      "        [ 1.2052],\n",
      "        [ 1.2052],\n",
      "        [ 1.0686],\n",
      "        [-0.3000],\n",
      "        [-1.2405],\n",
      "        [ 1.0686],\n",
      "        [-1.4467],\n",
      "        [ 0.9628],\n",
      "        [-1.3468],\n",
      "        [ 0.5511],\n",
      "        [-0.2237],\n",
      "        [ 0.7518],\n",
      "        [ 0.5166],\n",
      "        [ 1.2052],\n",
      "        [ 0.7518],\n",
      "        [-0.6486],\n",
      "        [-0.1417],\n",
      "        [-1.0666],\n",
      "        [-1.1566],\n",
      "        [ 0.9628],\n",
      "        [-0.8477],\n",
      "        [ 0.6194],\n",
      "        [ 1.2052],\n",
      "        [-1.5356],\n",
      "        [ 0.0392],\n",
      "        [-0.3939],\n",
      "        [-1.3468],\n",
      "        [ 1.0171],\n",
      "        [-0.3939],\n",
      "        [-0.5267],\n",
      "        [-1.5073],\n",
      "        [ 0.6194],\n",
      "        [-1.4467],\n",
      "        [ 0.4121],\n",
      "        [-0.4163],\n",
      "        [ 0.4121],\n",
      "        [ 1.2052],\n",
      "        [ 1.1686]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 161/10000,\n",
      " train_loss: 0.0015,\n",
      " train_mae: 0.0301,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2014],\n",
      "        [-1.2014],\n",
      "        [ 0.6550],\n",
      "        [ 0.5872],\n",
      "        [-0.0538],\n",
      "        [ 0.4834],\n",
      "        [ 0.9077],\n",
      "        [ 0.9648],\n",
      "        [ 0.9077],\n",
      "        [ 0.8171],\n",
      "        [-1.5353],\n",
      "        [-0.8487],\n",
      "        [ 0.5528],\n",
      "        [-0.2242],\n",
      "        [ 0.9366],\n",
      "        [-0.2242],\n",
      "        [ 0.5528],\n",
      "        [-0.5743],\n",
      "        [-0.3008],\n",
      "        [ 0.8781],\n",
      "        [ 0.7537],\n",
      "        [ 0.7857],\n",
      "        [ 1.2070],\n",
      "        [ 1.2070],\n",
      "        [ 1.0705],\n",
      "        [-0.3008],\n",
      "        [-1.2427],\n",
      "        [ 1.0705],\n",
      "        [-1.4526],\n",
      "        [ 0.9648],\n",
      "        [-1.3506],\n",
      "        [ 0.5528],\n",
      "        [-0.2242],\n",
      "        [ 0.7537],\n",
      "        [ 0.5182],\n",
      "        [ 1.2070],\n",
      "        [ 0.7537],\n",
      "        [-0.6501],\n",
      "        [-0.1419],\n",
      "        [-1.0675],\n",
      "        [-1.1580],\n",
      "        [ 0.9648],\n",
      "        [-0.8487],\n",
      "        [ 0.6212],\n",
      "        [ 1.2070],\n",
      "        [-1.5437],\n",
      "        [ 0.0398],\n",
      "        [-0.3951],\n",
      "        [-1.3506],\n",
      "        [ 1.0191],\n",
      "        [-0.3951],\n",
      "        [-0.5283],\n",
      "        [-1.5147],\n",
      "        [ 0.6212],\n",
      "        [-1.4526],\n",
      "        [ 0.4136],\n",
      "        [-0.4176],\n",
      "        [ 0.4136],\n",
      "        [ 1.2070],\n",
      "        [ 1.1705]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 162/10000,\n",
      " train_loss: 0.0014,\n",
      " train_mae: 0.0305,\n",
      " epoch_time_duration: 0.0131\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2045],\n",
      "        [-1.2045],\n",
      "        [ 0.6566],\n",
      "        [ 0.5887],\n",
      "        [-0.0545],\n",
      "        [ 0.4847],\n",
      "        [ 0.9096],\n",
      "        [ 0.9668],\n",
      "        [ 0.9096],\n",
      "        [ 0.8190],\n",
      "        [-1.5443],\n",
      "        [-0.8510],\n",
      "        [ 0.5542],\n",
      "        [-0.2258],\n",
      "        [ 0.9386],\n",
      "        [-0.2258],\n",
      "        [ 0.5542],\n",
      "        [-0.5772],\n",
      "        [-0.3028],\n",
      "        [ 0.8801],\n",
      "        [ 0.7555],\n",
      "        [ 0.7875],\n",
      "        [ 1.2090],\n",
      "        [ 1.2090],\n",
      "        [ 1.0726],\n",
      "        [-0.3028],\n",
      "        [-1.2463],\n",
      "        [ 1.0726],\n",
      "        [-1.4597],\n",
      "        [ 0.9668],\n",
      "        [-1.3557],\n",
      "        [ 0.5542],\n",
      "        [-0.2258],\n",
      "        [ 0.7555],\n",
      "        [ 0.5195],\n",
      "        [ 1.2090],\n",
      "        [ 0.7555],\n",
      "        [-0.6530],\n",
      "        [-0.1431],\n",
      "        [-1.0698],\n",
      "        [-1.1608],\n",
      "        [ 0.9668],\n",
      "        [-0.8510],\n",
      "        [ 0.6228],\n",
      "        [ 1.2090],\n",
      "        [-1.5529],\n",
      "        [ 0.0394],\n",
      "        [-0.3975],\n",
      "        [-1.3557],\n",
      "        [ 1.0211],\n",
      "        [-0.3975],\n",
      "        [-0.5312],\n",
      "        [-1.5232],\n",
      "        [ 0.6228],\n",
      "        [-1.4597],\n",
      "        [ 0.4146],\n",
      "        [-0.4201],\n",
      "        [ 0.4146],\n",
      "        [ 1.2090],\n",
      "        [ 1.1725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 163/10000,\n",
      " train_loss: 0.0014,\n",
      " train_mae: 0.0307,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2061],\n",
      "        [-1.2061],\n",
      "        [ 0.6576],\n",
      "        [ 0.5895],\n",
      "        [-0.0557],\n",
      "        [ 0.4853],\n",
      "        [ 0.9110],\n",
      "        [ 0.9682],\n",
      "        [ 0.9110],\n",
      "        [ 0.8202],\n",
      "        [-1.5514],\n",
      "        [-0.8526],\n",
      "        [ 0.5550],\n",
      "        [-0.2277],\n",
      "        [ 0.9399],\n",
      "        [-0.2277],\n",
      "        [ 0.5550],\n",
      "        [-0.5801],\n",
      "        [-0.3050],\n",
      "        [ 0.8813],\n",
      "        [ 0.7566],\n",
      "        [ 0.7887],\n",
      "        [ 1.2104],\n",
      "        [ 1.2104],\n",
      "        [ 1.0740],\n",
      "        [-0.3050],\n",
      "        [-1.2482],\n",
      "        [ 1.0740],\n",
      "        [-1.4648],\n",
      "        [ 0.9682],\n",
      "        [-1.3589],\n",
      "        [ 0.5550],\n",
      "        [-0.2277],\n",
      "        [ 0.7566],\n",
      "        [ 0.5202],\n",
      "        [ 1.2104],\n",
      "        [ 0.7566],\n",
      "        [-0.6557],\n",
      "        [-0.1446],\n",
      "        [-1.0708],\n",
      "        [-1.1621],\n",
      "        [ 0.9682],\n",
      "        [-0.8526],\n",
      "        [ 0.6237],\n",
      "        [ 1.2104],\n",
      "        [-1.5602],\n",
      "        [ 0.0386],\n",
      "        [-0.4001],\n",
      "        [-1.3589],\n",
      "        [ 1.0225],\n",
      "        [-0.4001],\n",
      "        [-0.5341],\n",
      "        [-1.5298],\n",
      "        [ 0.6237],\n",
      "        [-1.4648],\n",
      "        [ 0.4150],\n",
      "        [-0.4228],\n",
      "        [ 0.4150],\n",
      "        [ 1.2104],\n",
      "        [ 1.1739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 164/10000,\n",
      " train_loss: 0.0014,\n",
      " train_mae: 0.0306,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.2042],\n",
      "        [-1.2042],\n",
      "        [ 0.6578],\n",
      "        [ 0.5897],\n",
      "        [-0.0568],\n",
      "        [ 0.4853],\n",
      "        [ 0.9115],\n",
      "        [ 0.9687],\n",
      "        [ 0.9115],\n",
      "        [ 0.8206],\n",
      "        [-1.5545],\n",
      "        [-0.8521],\n",
      "        [ 0.5551],\n",
      "        [-0.2292],\n",
      "        [ 0.9404],\n",
      "        [-0.2292],\n",
      "        [ 0.5551],\n",
      "        [-0.5819],\n",
      "        [-0.3067],\n",
      "        [ 0.8818],\n",
      "        [ 0.7570],\n",
      "        [ 0.7891],\n",
      "        [ 1.2111],\n",
      "        [ 1.2111],\n",
      "        [ 1.0746],\n",
      "        [-0.3067],\n",
      "        [-1.2465],\n",
      "        [ 1.0746],\n",
      "        [-1.4660],\n",
      "        [ 0.9687],\n",
      "        [-1.3583],\n",
      "        [ 0.5551],\n",
      "        [-0.2292],\n",
      "        [ 0.7570],\n",
      "        [ 0.5203],\n",
      "        [ 1.2111],\n",
      "        [ 0.7570],\n",
      "        [-0.6571],\n",
      "        [-0.1459],\n",
      "        [-1.0689],\n",
      "        [-1.1601],\n",
      "        [ 0.9687],\n",
      "        [-0.8521],\n",
      "        [ 0.6239],\n",
      "        [ 1.2111],\n",
      "        [-1.5635],\n",
      "        [ 0.0378],\n",
      "        [-0.4021],\n",
      "        [-1.3583],\n",
      "        [ 1.0231],\n",
      "        [-0.4021],\n",
      "        [-0.5360],\n",
      "        [-1.5324],\n",
      "        [ 0.6239],\n",
      "        [-1.4660],\n",
      "        [ 0.4150],\n",
      "        [-0.4248],\n",
      "        [ 0.4150],\n",
      "        [ 1.2111],\n",
      "        [ 1.1746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 165/10000,\n",
      " train_loss: 0.0014,\n",
      " train_mae: 0.0302,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1989],\n",
      "        [-1.1989],\n",
      "        [ 0.6575],\n",
      "        [ 0.5893],\n",
      "        [-0.0575],\n",
      "        [ 0.4849],\n",
      "        [ 0.9112],\n",
      "        [ 0.9684],\n",
      "        [ 0.9112],\n",
      "        [ 0.8203],\n",
      "        [-1.5535],\n",
      "        [-0.8496],\n",
      "        [ 0.5547],\n",
      "        [-0.2301],\n",
      "        [ 0.9401],\n",
      "        [-0.2301],\n",
      "        [ 0.5547],\n",
      "        [-0.5826],\n",
      "        [-0.3077],\n",
      "        [ 0.8815],\n",
      "        [ 0.7567],\n",
      "        [ 0.7887],\n",
      "        [ 1.2110],\n",
      "        [ 1.2110],\n",
      "        [ 1.0744],\n",
      "        [-0.3077],\n",
      "        [-1.2413],\n",
      "        [ 1.0744],\n",
      "        [-1.4631],\n",
      "        [ 0.9684],\n",
      "        [-1.3538],\n",
      "        [ 0.5547],\n",
      "        [-0.2301],\n",
      "        [ 0.7567],\n",
      "        [ 0.5199],\n",
      "        [ 1.2110],\n",
      "        [ 0.7567],\n",
      "        [-0.6571],\n",
      "        [-0.1467],\n",
      "        [-1.0640],\n",
      "        [-1.1548],\n",
      "        [ 0.9684],\n",
      "        [-0.8496],\n",
      "        [ 0.6235],\n",
      "        [ 1.2110],\n",
      "        [-1.5628],\n",
      "        [ 0.0372],\n",
      "        [-0.4031],\n",
      "        [-1.3538],\n",
      "        [ 1.0229],\n",
      "        [-0.4031],\n",
      "        [-0.5369],\n",
      "        [-1.5309],\n",
      "        [ 0.6235],\n",
      "        [-1.4631],\n",
      "        [ 0.4145],\n",
      "        [-0.4259],\n",
      "        [ 0.4145],\n",
      "        [ 1.2110],\n",
      "        [ 1.1744]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 166/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0295,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1921],\n",
      "        [-1.1921],\n",
      "        [ 0.6565],\n",
      "        [ 0.5884],\n",
      "        [-0.0582],\n",
      "        [ 0.4840],\n",
      "        [ 0.9102],\n",
      "        [ 0.9675],\n",
      "        [ 0.9102],\n",
      "        [ 0.8193],\n",
      "        [-1.5506],\n",
      "        [-0.8462],\n",
      "        [ 0.5538],\n",
      "        [-0.2308],\n",
      "        [ 0.9392],\n",
      "        [-0.2308],\n",
      "        [ 0.5538],\n",
      "        [-0.5827],\n",
      "        [-0.3084],\n",
      "        [ 0.8805],\n",
      "        [ 0.7557],\n",
      "        [ 0.7878],\n",
      "        [ 1.2102],\n",
      "        [ 1.2102],\n",
      "        [ 1.0735],\n",
      "        [-0.3084],\n",
      "        [-1.2345],\n",
      "        [ 1.0735],\n",
      "        [-1.4583],\n",
      "        [ 0.9675],\n",
      "        [-1.3476],\n",
      "        [ 0.5538],\n",
      "        [-0.2308],\n",
      "        [ 0.7557],\n",
      "        [ 0.5190],\n",
      "        [ 1.2102],\n",
      "        [ 0.7557],\n",
      "        [-0.6565],\n",
      "        [-0.1474],\n",
      "        [-1.0579],\n",
      "        [-1.1481],\n",
      "        [ 0.9675],\n",
      "        [-0.8462],\n",
      "        [ 0.6226],\n",
      "        [ 1.2102],\n",
      "        [-1.5601],\n",
      "        [ 0.0365],\n",
      "        [-0.4039],\n",
      "        [-1.3476],\n",
      "        [ 1.0219],\n",
      "        [-0.4039],\n",
      "        [-0.5373],\n",
      "        [-1.5275],\n",
      "        [ 0.6226],\n",
      "        [-1.4583],\n",
      "        [ 0.4137],\n",
      "        [-0.4266],\n",
      "        [ 0.4137],\n",
      "        [ 1.2102],\n",
      "        [ 1.1736]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 167/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0289,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1863],\n",
      "        [-1.1863],\n",
      "        [ 0.6553],\n",
      "        [ 0.5872],\n",
      "        [-0.0591],\n",
      "        [ 0.4829],\n",
      "        [ 0.9090],\n",
      "        [ 0.9663],\n",
      "        [ 0.9090],\n",
      "        [ 0.8181],\n",
      "        [-1.5484],\n",
      "        [-0.8436],\n",
      "        [ 0.5527],\n",
      "        [-0.2318],\n",
      "        [ 0.9380],\n",
      "        [-0.2318],\n",
      "        [ 0.5527],\n",
      "        [-0.5833],\n",
      "        [-0.3095],\n",
      "        [ 0.8793],\n",
      "        [ 0.7545],\n",
      "        [ 0.7866],\n",
      "        [ 1.2092],\n",
      "        [ 1.2092],\n",
      "        [ 1.0723],\n",
      "        [-0.3095],\n",
      "        [-1.2286],\n",
      "        [ 1.0723],\n",
      "        [-1.4543],\n",
      "        [ 0.9663],\n",
      "        [-1.3423],\n",
      "        [ 0.5527],\n",
      "        [-0.2318],\n",
      "        [ 0.7545],\n",
      "        [ 0.5179],\n",
      "        [ 1.2092],\n",
      "        [ 0.7545],\n",
      "        [-0.6564],\n",
      "        [-0.1484],\n",
      "        [-1.0528],\n",
      "        [-1.1425],\n",
      "        [ 0.9663],\n",
      "        [-0.8436],\n",
      "        [ 0.6214],\n",
      "        [ 1.2092],\n",
      "        [-1.5581],\n",
      "        [ 0.0355],\n",
      "        [-0.4049],\n",
      "        [-1.3423],\n",
      "        [ 1.0208],\n",
      "        [-0.4049],\n",
      "        [-0.5381],\n",
      "        [-1.5248],\n",
      "        [ 0.6214],\n",
      "        [-1.4543],\n",
      "        [ 0.4126],\n",
      "        [-0.4276],\n",
      "        [ 0.4126],\n",
      "        [ 1.2092],\n",
      "        [ 1.1726]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 168/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0287,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1830],\n",
      "        [-1.1830],\n",
      "        [ 0.6546],\n",
      "        [ 0.5864],\n",
      "        [-0.0602],\n",
      "        [ 0.4821],\n",
      "        [ 0.9083],\n",
      "        [ 0.9656],\n",
      "        [ 0.9083],\n",
      "        [ 0.8174],\n",
      "        [-1.5486],\n",
      "        [-0.8427],\n",
      "        [ 0.5519],\n",
      "        [-0.2332],\n",
      "        [ 0.9373],\n",
      "        [-0.2332],\n",
      "        [ 0.5519],\n",
      "        [-0.5847],\n",
      "        [-0.3110],\n",
      "        [ 0.8786],\n",
      "        [ 0.7538],\n",
      "        [ 0.7858],\n",
      "        [ 1.2087],\n",
      "        [ 1.2087],\n",
      "        [ 1.0717],\n",
      "        [-0.3110],\n",
      "        [-1.2254],\n",
      "        [ 1.0717],\n",
      "        [-1.4529],\n",
      "        [ 0.9656],\n",
      "        [-1.3396],\n",
      "        [ 0.5519],\n",
      "        [-0.2332],\n",
      "        [ 0.7538],\n",
      "        [ 0.5171],\n",
      "        [ 1.2087],\n",
      "        [ 0.7538],\n",
      "        [-0.6574],\n",
      "        [-0.1496],\n",
      "        [-1.0500],\n",
      "        [-1.1393],\n",
      "        [ 0.9656],\n",
      "        [-0.8427],\n",
      "        [ 0.6207],\n",
      "        [ 1.2087],\n",
      "        [-1.5585],\n",
      "        [ 0.0345],\n",
      "        [-0.4065],\n",
      "        [-1.3396],\n",
      "        [ 1.0201],\n",
      "        [-0.4065],\n",
      "        [-0.5397],\n",
      "        [-1.5245],\n",
      "        [ 0.6207],\n",
      "        [-1.4529],\n",
      "        [ 0.4118],\n",
      "        [-0.4292],\n",
      "        [ 0.4118],\n",
      "        [ 1.2087],\n",
      "        [ 1.1720]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 169/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0287,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1825],\n",
      "        [-1.1825],\n",
      "        [ 0.6549],\n",
      "        [ 0.5867],\n",
      "        [-0.0611],\n",
      "        [ 0.4823],\n",
      "        [ 0.9088],\n",
      "        [ 0.9661],\n",
      "        [ 0.9088],\n",
      "        [ 0.8178],\n",
      "        [-1.5516],\n",
      "        [-0.8435],\n",
      "        [ 0.5521],\n",
      "        [-0.2345],\n",
      "        [ 0.9378],\n",
      "        [-0.2345],\n",
      "        [ 0.5521],\n",
      "        [-0.5868],\n",
      "        [-0.3126],\n",
      "        [ 0.8791],\n",
      "        [ 0.7542],\n",
      "        [ 0.7863],\n",
      "        [ 1.2092],\n",
      "        [ 1.2092],\n",
      "        [ 1.0722],\n",
      "        [-0.3126],\n",
      "        [-1.2250],\n",
      "        [ 1.0722],\n",
      "        [-1.4543],\n",
      "        [ 0.9661],\n",
      "        [-1.3398],\n",
      "        [ 0.5521],\n",
      "        [-0.2345],\n",
      "        [ 0.7542],\n",
      "        [ 0.5173],\n",
      "        [ 1.2092],\n",
      "        [ 0.7542],\n",
      "        [-0.6593],\n",
      "        [-0.1507],\n",
      "        [-1.0497],\n",
      "        [-1.1387],\n",
      "        [ 0.9661],\n",
      "        [-0.8435],\n",
      "        [ 0.6210],\n",
      "        [ 1.2092],\n",
      "        [-1.5616],\n",
      "        [ 0.0339],\n",
      "        [-0.4084],\n",
      "        [-1.3398],\n",
      "        [ 1.0206],\n",
      "        [-0.4084],\n",
      "        [-0.5418],\n",
      "        [-1.5270],\n",
      "        [ 0.6210],\n",
      "        [-1.4543],\n",
      "        [ 0.4119],\n",
      "        [-0.4312],\n",
      "        [ 0.4119],\n",
      "        [ 1.2092],\n",
      "        [ 1.1725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 170/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0290,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1838],\n",
      "        [-1.1838],\n",
      "        [ 0.6564],\n",
      "        [ 0.5881],\n",
      "        [-0.0613],\n",
      "        [ 0.4835],\n",
      "        [ 0.9103],\n",
      "        [ 0.9676],\n",
      "        [ 0.9103],\n",
      "        [ 0.8193],\n",
      "        [-1.5562],\n",
      "        [-0.8453],\n",
      "        [ 0.5535],\n",
      "        [-0.2355],\n",
      "        [ 0.9393],\n",
      "        [-0.2355],\n",
      "        [ 0.5535],\n",
      "        [-0.5890],\n",
      "        [-0.3138],\n",
      "        [ 0.8806],\n",
      "        [ 0.7557],\n",
      "        [ 0.7878],\n",
      "        [ 1.2105],\n",
      "        [ 1.2105],\n",
      "        [ 1.0736],\n",
      "        [-0.3138],\n",
      "        [-1.2264],\n",
      "        [ 1.0736],\n",
      "        [-1.4575],\n",
      "        [ 0.9676],\n",
      "        [-1.3418],\n",
      "        [ 0.5535],\n",
      "        [-0.2355],\n",
      "        [ 0.7557],\n",
      "        [ 0.5186],\n",
      "        [ 1.2105],\n",
      "        [ 0.7557],\n",
      "        [-0.6616],\n",
      "        [-0.1513],\n",
      "        [-1.0509],\n",
      "        [-1.1399],\n",
      "        [ 0.9676],\n",
      "        [-0.8453],\n",
      "        [ 0.6224],\n",
      "        [ 1.2105],\n",
      "        [-1.5664],\n",
      "        [ 0.0340],\n",
      "        [-0.4101],\n",
      "        [-1.3418],\n",
      "        [ 1.0221],\n",
      "        [-0.4101],\n",
      "        [-0.5440],\n",
      "        [-1.5313],\n",
      "        [ 0.6224],\n",
      "        [-1.4575],\n",
      "        [ 0.4130],\n",
      "        [-0.4330],\n",
      "        [ 0.4130],\n",
      "        [ 1.2105],\n",
      "        [ 1.1739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 171/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0294,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1854],\n",
      "        [-1.1854],\n",
      "        [ 0.6581],\n",
      "        [ 0.5898],\n",
      "        [-0.0611],\n",
      "        [ 0.4851],\n",
      "        [ 0.9120],\n",
      "        [ 0.9693],\n",
      "        [ 0.9120],\n",
      "        [ 0.8211],\n",
      "        [-1.5611],\n",
      "        [-0.8470],\n",
      "        [ 0.5551],\n",
      "        [-0.2359],\n",
      "        [ 0.9410],\n",
      "        [-0.2359],\n",
      "        [ 0.5551],\n",
      "        [-0.5909],\n",
      "        [-0.3146],\n",
      "        [ 0.8824],\n",
      "        [ 0.7574],\n",
      "        [ 0.7895],\n",
      "        [ 1.2119],\n",
      "        [ 1.2119],\n",
      "        [ 1.0753],\n",
      "        [-0.3146],\n",
      "        [-1.2282],\n",
      "        [ 1.0753],\n",
      "        [-1.4611],\n",
      "        [ 0.9693],\n",
      "        [-1.3443],\n",
      "        [ 0.5551],\n",
      "        [-0.2359],\n",
      "        [ 0.7574],\n",
      "        [ 0.5202],\n",
      "        [ 1.2119],\n",
      "        [ 0.7574],\n",
      "        [-0.6635],\n",
      "        [-0.1514],\n",
      "        [-1.0523],\n",
      "        [-1.1414],\n",
      "        [ 0.9693],\n",
      "        [-0.8470],\n",
      "        [ 0.6241],\n",
      "        [ 1.2119],\n",
      "        [-1.5714],\n",
      "        [ 0.0346],\n",
      "        [-0.4113],\n",
      "        [-1.3443],\n",
      "        [ 1.0238],\n",
      "        [-0.4113],\n",
      "        [-0.5457],\n",
      "        [-1.5358],\n",
      "        [ 0.6241],\n",
      "        [-1.4611],\n",
      "        [ 0.4145],\n",
      "        [-0.4343],\n",
      "        [ 0.4145],\n",
      "        [ 1.2119],\n",
      "        [ 1.1753]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 172/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0295,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1861],\n",
      "        [-1.1861],\n",
      "        [ 0.6592],\n",
      "        [ 0.5909],\n",
      "        [-0.0606],\n",
      "        [ 0.4862],\n",
      "        [ 0.9129],\n",
      "        [ 0.9701],\n",
      "        [ 0.9129],\n",
      "        [ 0.8221],\n",
      "        [-1.5647],\n",
      "        [-0.8480],\n",
      "        [ 0.5562],\n",
      "        [-0.2359],\n",
      "        [ 0.9419],\n",
      "        [-0.2359],\n",
      "        [ 0.5562],\n",
      "        [-0.5921],\n",
      "        [-0.3149],\n",
      "        [ 0.8833],\n",
      "        [ 0.7585],\n",
      "        [ 0.7905],\n",
      "        [ 1.2125],\n",
      "        [ 1.2125],\n",
      "        [ 1.0760],\n",
      "        [-0.3149],\n",
      "        [-1.2290],\n",
      "        [ 1.0760],\n",
      "        [-1.4634],\n",
      "        [ 0.9701],\n",
      "        [-1.3457],\n",
      "        [ 0.5562],\n",
      "        [-0.2359],\n",
      "        [ 0.7585],\n",
      "        [ 0.5213],\n",
      "        [ 1.2125],\n",
      "        [ 0.7585],\n",
      "        [-0.6648],\n",
      "        [-0.1511],\n",
      "        [-1.0529],\n",
      "        [-1.1421],\n",
      "        [ 0.9701],\n",
      "        [-0.8480],\n",
      "        [ 0.6252],\n",
      "        [ 1.2125],\n",
      "        [-1.5752],\n",
      "        [ 0.0352],\n",
      "        [-0.4120],\n",
      "        [-1.3457],\n",
      "        [ 1.0245],\n",
      "        [-0.4120],\n",
      "        [-0.5468],\n",
      "        [-1.5390],\n",
      "        [ 0.6252],\n",
      "        [-1.4634],\n",
      "        [ 0.4155],\n",
      "        [-0.4350],\n",
      "        [ 0.4155],\n",
      "        [ 1.2125],\n",
      "        [ 1.1760]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 173/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0293,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1853],\n",
      "        [-1.1853],\n",
      "        [ 0.6591],\n",
      "        [ 0.5909],\n",
      "        [-0.0601],\n",
      "        [ 0.4864],\n",
      "        [ 0.9125],\n",
      "        [ 0.9696],\n",
      "        [ 0.9125],\n",
      "        [ 0.8217],\n",
      "        [-1.5663],\n",
      "        [-0.8478],\n",
      "        [ 0.5563],\n",
      "        [-0.2356],\n",
      "        [ 0.9414],\n",
      "        [-0.2356],\n",
      "        [ 0.5563],\n",
      "        [-0.5925],\n",
      "        [-0.3147],\n",
      "        [ 0.8829],\n",
      "        [ 0.7582],\n",
      "        [ 0.7903],\n",
      "        [ 1.2118],\n",
      "        [ 1.2118],\n",
      "        [ 1.0753],\n",
      "        [-0.3147],\n",
      "        [-1.2282],\n",
      "        [ 1.0753],\n",
      "        [-1.4639],\n",
      "        [ 0.9696],\n",
      "        [-1.3453],\n",
      "        [ 0.5563],\n",
      "        [-0.2356],\n",
      "        [ 0.7582],\n",
      "        [ 0.5214],\n",
      "        [ 1.2118],\n",
      "        [ 0.7582],\n",
      "        [-0.6651],\n",
      "        [-0.1507],\n",
      "        [-1.0521],\n",
      "        [-1.1412],\n",
      "        [ 0.9696],\n",
      "        [-0.8478],\n",
      "        [ 0.6252],\n",
      "        [ 1.2118],\n",
      "        [-1.5769],\n",
      "        [ 0.0358],\n",
      "        [-0.4120],\n",
      "        [-1.3453],\n",
      "        [ 1.0239],\n",
      "        [-0.4120],\n",
      "        [-0.5471],\n",
      "        [-1.5403],\n",
      "        [ 0.6252],\n",
      "        [-1.4639],\n",
      "        [ 0.4158],\n",
      "        [-0.4351],\n",
      "        [ 0.4158],\n",
      "        [ 1.2118],\n",
      "        [ 1.1753]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 174/10000,\n",
      " train_loss: 0.0013,\n",
      " train_mae: 0.0288,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1829],\n",
      "        [-1.1829],\n",
      "        [ 0.6582],\n",
      "        [ 0.5902],\n",
      "        [-0.0594],\n",
      "        [ 0.4859],\n",
      "        [ 0.9110],\n",
      "        [ 0.9681],\n",
      "        [ 0.9110],\n",
      "        [ 0.8205],\n",
      "        [-1.5660],\n",
      "        [-0.8466],\n",
      "        [ 0.5557],\n",
      "        [-0.2348],\n",
      "        [ 0.9399],\n",
      "        [-0.2348],\n",
      "        [ 0.5557],\n",
      "        [-0.5920],\n",
      "        [-0.3140],\n",
      "        [ 0.8815],\n",
      "        [ 0.7571],\n",
      "        [ 0.7891],\n",
      "        [ 1.2101],\n",
      "        [ 1.2101],\n",
      "        [ 1.0737],\n",
      "        [-0.3140],\n",
      "        [-1.2258],\n",
      "        [ 1.0737],\n",
      "        [-1.4625],\n",
      "        [ 0.9681],\n",
      "        [-1.3432],\n",
      "        [ 0.5557],\n",
      "        [-0.2348],\n",
      "        [ 0.7571],\n",
      "        [ 0.5209],\n",
      "        [ 1.2101],\n",
      "        [ 0.7571],\n",
      "        [-0.6646],\n",
      "        [-0.1499],\n",
      "        [-1.0501],\n",
      "        [-1.1389],\n",
      "        [ 0.9681],\n",
      "        [-0.8466],\n",
      "        [ 0.6244],\n",
      "        [ 1.2101],\n",
      "        [-1.5768],\n",
      "        [ 0.0363],\n",
      "        [-0.4114],\n",
      "        [-1.3432],\n",
      "        [ 1.0224],\n",
      "        [-0.4114],\n",
      "        [-0.5467],\n",
      "        [-1.5397],\n",
      "        [ 0.6244],\n",
      "        [-1.4625],\n",
      "        [ 0.4155],\n",
      "        [-0.4345],\n",
      "        [ 0.4155],\n",
      "        [ 1.2101],\n",
      "        [ 1.1736]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 175/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0283,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1799],\n",
      "        [-1.1799],\n",
      "        [ 0.6573],\n",
      "        [ 0.5894],\n",
      "        [-0.0584],\n",
      "        [ 0.4855],\n",
      "        [ 0.9095],\n",
      "        [ 0.9664],\n",
      "        [ 0.9095],\n",
      "        [ 0.8191],\n",
      "        [-1.5646],\n",
      "        [-0.8449],\n",
      "        [ 0.5550],\n",
      "        [-0.2337],\n",
      "        [ 0.9383],\n",
      "        [-0.2337],\n",
      "        [ 0.5550],\n",
      "        [-0.5911],\n",
      "        [-0.3128],\n",
      "        [ 0.8800],\n",
      "        [ 0.7559],\n",
      "        [ 0.7878],\n",
      "        [ 1.2083],\n",
      "        [ 1.2083],\n",
      "        [ 1.0719],\n",
      "        [-0.3128],\n",
      "        [-1.2228],\n",
      "        [ 1.0719],\n",
      "        [-1.4602],\n",
      "        [ 0.9664],\n",
      "        [-1.3403],\n",
      "        [ 0.5550],\n",
      "        [-0.2337],\n",
      "        [ 0.7559],\n",
      "        [ 0.5204],\n",
      "        [ 1.2083],\n",
      "        [ 0.7559],\n",
      "        [-0.6635],\n",
      "        [-0.1488],\n",
      "        [-1.0474],\n",
      "        [-1.1360],\n",
      "        [ 0.9664],\n",
      "        [-0.8449],\n",
      "        [ 0.6235],\n",
      "        [ 1.2083],\n",
      "        [-1.5756],\n",
      "        [ 0.0371],\n",
      "        [-0.4103],\n",
      "        [-1.3403],\n",
      "        [ 1.0206],\n",
      "        [-0.4103],\n",
      "        [-0.5457],\n",
      "        [-1.5381],\n",
      "        [ 0.6235],\n",
      "        [-1.4602],\n",
      "        [ 0.4154],\n",
      "        [-0.4334],\n",
      "        [ 0.4154],\n",
      "        [ 1.2083],\n",
      "        [ 1.1717]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 176/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0280,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1775],\n",
      "        [-1.1775],\n",
      "        [ 0.6569],\n",
      "        [ 0.5892],\n",
      "        [-0.0571],\n",
      "        [ 0.4856],\n",
      "        [ 0.9085],\n",
      "        [ 0.9653],\n",
      "        [ 0.9085],\n",
      "        [ 0.8183],\n",
      "        [-1.5636],\n",
      "        [-0.8435],\n",
      "        [ 0.5549],\n",
      "        [-0.2323],\n",
      "        [ 0.9372],\n",
      "        [-0.2323],\n",
      "        [ 0.5549],\n",
      "        [-0.5901],\n",
      "        [-0.3115],\n",
      "        [ 0.8790],\n",
      "        [ 0.7552],\n",
      "        [ 0.7871],\n",
      "        [ 1.2069],\n",
      "        [ 1.2069],\n",
      "        [ 1.0706],\n",
      "        [-0.3115],\n",
      "        [-1.2203],\n",
      "        [ 1.0706],\n",
      "        [-1.4583],\n",
      "        [ 0.9653],\n",
      "        [-1.3379],\n",
      "        [ 0.5549],\n",
      "        [-0.2323],\n",
      "        [ 0.7552],\n",
      "        [ 0.5204],\n",
      "        [ 1.2069],\n",
      "        [ 0.7552],\n",
      "        [-0.6626],\n",
      "        [-0.1475],\n",
      "        [-1.0452],\n",
      "        [-1.1336],\n",
      "        [ 0.9653],\n",
      "        [-0.8435],\n",
      "        [ 0.6232],\n",
      "        [ 1.2069],\n",
      "        [-1.5746],\n",
      "        [ 0.0383],\n",
      "        [-0.4091],\n",
      "        [-1.3379],\n",
      "        [ 1.0194],\n",
      "        [-0.4091],\n",
      "        [-0.5447],\n",
      "        [-1.5367],\n",
      "        [ 0.6232],\n",
      "        [-1.4583],\n",
      "        [ 0.4156],\n",
      "        [-0.4323],\n",
      "        [ 0.4156],\n",
      "        [ 1.2069],\n",
      "        [ 1.1704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 177/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0278,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6571],\n",
      "        [ 0.5896],\n",
      "        [-0.0559],\n",
      "        [ 0.4862],\n",
      "        [ 0.9082],\n",
      "        [ 0.9650],\n",
      "        [ 0.9082],\n",
      "        [ 0.8182],\n",
      "        [-1.5639],\n",
      "        [-0.8432],\n",
      "        [ 0.5554],\n",
      "        [-0.2312],\n",
      "        [ 0.9369],\n",
      "        [-0.2312],\n",
      "        [ 0.5554],\n",
      "        [-0.5898],\n",
      "        [-0.3105],\n",
      "        [ 0.8788],\n",
      "        [ 0.7553],\n",
      "        [ 0.7870],\n",
      "        [ 1.2063],\n",
      "        [ 1.2063],\n",
      "        [ 1.0701],\n",
      "        [-0.3105],\n",
      "        [-1.2195],\n",
      "        [ 1.0701],\n",
      "        [-1.4580],\n",
      "        [ 0.9650],\n",
      "        [-1.3372],\n",
      "        [ 0.5554],\n",
      "        [-0.2312],\n",
      "        [ 0.7553],\n",
      "        [ 0.5209],\n",
      "        [ 1.2063],\n",
      "        [ 0.7553],\n",
      "        [-0.6624],\n",
      "        [-0.1463],\n",
      "        [-1.0446],\n",
      "        [-1.1328],\n",
      "        [ 0.9650],\n",
      "        [-0.8432],\n",
      "        [ 0.6236],\n",
      "        [ 1.2063],\n",
      "        [-1.5751],\n",
      "        [ 0.0395],\n",
      "        [-0.4083],\n",
      "        [-1.3372],\n",
      "        [ 1.0190],\n",
      "        [-0.4083],\n",
      "        [-0.5443],\n",
      "        [-1.5369],\n",
      "        [ 0.6236],\n",
      "        [-1.4580],\n",
      "        [ 0.4164],\n",
      "        [-0.4316],\n",
      "        [ 0.4164],\n",
      "        [ 1.2063],\n",
      "        [ 1.1698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 178/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0278,\n",
      " epoch_time_duration: 0.0268\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1777],\n",
      "        [-1.1777],\n",
      "        [ 0.6578],\n",
      "        [ 0.5903],\n",
      "        [-0.0551],\n",
      "        [ 0.4870],\n",
      "        [ 0.9085],\n",
      "        [ 0.9652],\n",
      "        [ 0.9085],\n",
      "        [ 0.8186],\n",
      "        [-1.5660],\n",
      "        [-0.8442],\n",
      "        [ 0.5561],\n",
      "        [-0.2307],\n",
      "        [ 0.9372],\n",
      "        [-0.2307],\n",
      "        [ 0.5561],\n",
      "        [-0.5904],\n",
      "        [-0.3102],\n",
      "        [ 0.8792],\n",
      "        [ 0.7558],\n",
      "        [ 0.7875],\n",
      "        [ 1.2062],\n",
      "        [ 1.2062],\n",
      "        [ 1.0702],\n",
      "        [-0.3102],\n",
      "        [-1.2206],\n",
      "        [ 1.0702],\n",
      "        [-1.4596],\n",
      "        [ 0.9652],\n",
      "        [-1.3385],\n",
      "        [ 0.5561],\n",
      "        [-0.2307],\n",
      "        [ 0.7558],\n",
      "        [ 0.5217],\n",
      "        [ 1.2062],\n",
      "        [ 0.7558],\n",
      "        [-0.6632],\n",
      "        [-0.1456],\n",
      "        [-1.0456],\n",
      "        [-1.1339],\n",
      "        [ 0.9652],\n",
      "        [-0.8442],\n",
      "        [ 0.6242],\n",
      "        [ 1.2062],\n",
      "        [-1.5772],\n",
      "        [ 0.0404],\n",
      "        [-0.4083],\n",
      "        [-1.3385],\n",
      "        [ 1.0191],\n",
      "        [-0.4083],\n",
      "        [-0.5448],\n",
      "        [-1.5388],\n",
      "        [ 0.6242],\n",
      "        [-1.4596],\n",
      "        [ 0.4173],\n",
      "        [-0.4316],\n",
      "        [ 0.4173],\n",
      "        [ 1.2062],\n",
      "        [ 1.1697]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 179/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0279,\n",
      " epoch_time_duration: 0.0121\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1800],\n",
      "        [-1.1800],\n",
      "        [ 0.6585],\n",
      "        [ 0.5911],\n",
      "        [-0.0547],\n",
      "        [ 0.4878],\n",
      "        [ 0.9090],\n",
      "        [ 0.9656],\n",
      "        [ 0.9090],\n",
      "        [ 0.8192],\n",
      "        [-1.5688],\n",
      "        [-0.8462],\n",
      "        [ 0.5569],\n",
      "        [-0.2307],\n",
      "        [ 0.9376],\n",
      "        [-0.2307],\n",
      "        [ 0.5569],\n",
      "        [-0.5917],\n",
      "        [-0.3104],\n",
      "        [ 0.8797],\n",
      "        [ 0.7564],\n",
      "        [ 0.7881],\n",
      "        [ 1.2064],\n",
      "        [ 1.2064],\n",
      "        [ 1.0705],\n",
      "        [-0.3104],\n",
      "        [-1.2229],\n",
      "        [ 1.0705],\n",
      "        [-1.4621],\n",
      "        [ 0.9656],\n",
      "        [-1.3408],\n",
      "        [ 0.5569],\n",
      "        [-0.2307],\n",
      "        [ 0.7564],\n",
      "        [ 0.5225],\n",
      "        [ 1.2064],\n",
      "        [ 0.7564],\n",
      "        [-0.6648],\n",
      "        [-0.1454],\n",
      "        [-1.0478],\n",
      "        [-1.1361],\n",
      "        [ 0.9656],\n",
      "        [-0.8462],\n",
      "        [ 0.6250],\n",
      "        [ 1.2064],\n",
      "        [-1.5801],\n",
      "        [ 0.0410],\n",
      "        [-0.4088],\n",
      "        [-1.3408],\n",
      "        [ 1.0195],\n",
      "        [-0.4088],\n",
      "        [-0.5459],\n",
      "        [-1.5415],\n",
      "        [ 0.6250],\n",
      "        [-1.4621],\n",
      "        [ 0.4181],\n",
      "        [-0.4323],\n",
      "        [ 0.4181],\n",
      "        [ 1.2064],\n",
      "        [ 1.1699]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 180/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0281,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1820],\n",
      "        [-1.1820],\n",
      "        [ 0.6591],\n",
      "        [ 0.5918],\n",
      "        [-0.0544],\n",
      "        [ 0.4885],\n",
      "        [ 0.9095],\n",
      "        [ 0.9660],\n",
      "        [ 0.9095],\n",
      "        [ 0.8198],\n",
      "        [-1.5712],\n",
      "        [-0.8482],\n",
      "        [ 0.5576],\n",
      "        [-0.2308],\n",
      "        [ 0.9381],\n",
      "        [-0.2308],\n",
      "        [ 0.5576],\n",
      "        [-0.5931],\n",
      "        [-0.3108],\n",
      "        [ 0.8802],\n",
      "        [ 0.7570],\n",
      "        [ 0.7887],\n",
      "        [ 1.2066],\n",
      "        [ 1.2066],\n",
      "        [ 1.0709],\n",
      "        [-0.3108],\n",
      "        [-1.2249],\n",
      "        [ 1.0709],\n",
      "        [-1.4642],\n",
      "        [ 0.9660],\n",
      "        [-1.3428],\n",
      "        [ 0.5576],\n",
      "        [-0.2308],\n",
      "        [ 0.7570],\n",
      "        [ 0.5232],\n",
      "        [ 1.2066],\n",
      "        [ 0.7570],\n",
      "        [-0.6664],\n",
      "        [-0.1453],\n",
      "        [-1.0499],\n",
      "        [-1.1382],\n",
      "        [ 0.9660],\n",
      "        [-0.8482],\n",
      "        [ 0.6256],\n",
      "        [ 1.2066],\n",
      "        [-1.5825],\n",
      "        [ 0.0414],\n",
      "        [-0.4095],\n",
      "        [-1.3428],\n",
      "        [ 1.0199],\n",
      "        [-0.4095],\n",
      "        [-0.5471],\n",
      "        [-1.5438],\n",
      "        [ 0.6256],\n",
      "        [-1.4642],\n",
      "        [ 0.4188],\n",
      "        [-0.4331],\n",
      "        [ 0.4188],\n",
      "        [ 1.2066],\n",
      "        [ 1.1702]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 181/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0282,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1828],\n",
      "        [-1.1828],\n",
      "        [ 0.6596],\n",
      "        [ 0.5923],\n",
      "        [-0.0540],\n",
      "        [ 0.4891],\n",
      "        [ 0.9098],\n",
      "        [ 0.9663],\n",
      "        [ 0.9098],\n",
      "        [ 0.8202],\n",
      "        [-1.5718],\n",
      "        [-0.8494],\n",
      "        [ 0.5582],\n",
      "        [-0.2307],\n",
      "        [ 0.9384],\n",
      "        [-0.2307],\n",
      "        [ 0.5582],\n",
      "        [-0.5941],\n",
      "        [-0.3109],\n",
      "        [ 0.8805],\n",
      "        [ 0.7575],\n",
      "        [ 0.7891],\n",
      "        [ 1.2067],\n",
      "        [ 1.2067],\n",
      "        [ 1.0710],\n",
      "        [-0.3109],\n",
      "        [-1.2256],\n",
      "        [ 1.0710],\n",
      "        [-1.4648],\n",
      "        [ 0.9663],\n",
      "        [-1.3434],\n",
      "        [ 0.5582],\n",
      "        [-0.2307],\n",
      "        [ 0.7575],\n",
      "        [ 0.5238],\n",
      "        [ 1.2067],\n",
      "        [ 0.7575],\n",
      "        [-0.6675],\n",
      "        [-0.1450],\n",
      "        [-1.0509],\n",
      "        [-1.1390],\n",
      "        [ 0.9663],\n",
      "        [-0.8494],\n",
      "        [ 0.6262],\n",
      "        [ 1.2067],\n",
      "        [-1.5831],\n",
      "        [ 0.0419],\n",
      "        [-0.4099],\n",
      "        [-1.3434],\n",
      "        [ 1.0201],\n",
      "        [-0.4099],\n",
      "        [-0.5479],\n",
      "        [-1.5444],\n",
      "        [ 0.6262],\n",
      "        [-1.4648],\n",
      "        [ 0.4194],\n",
      "        [-0.4335],\n",
      "        [ 0.4194],\n",
      "        [ 1.2067],\n",
      "        [ 1.1703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 182/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0281,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1821],\n",
      "        [-1.1821],\n",
      "        [ 0.6598],\n",
      "        [ 0.5926],\n",
      "        [-0.0535],\n",
      "        [ 0.4895],\n",
      "        [ 0.9097],\n",
      "        [ 0.9662],\n",
      "        [ 0.9097],\n",
      "        [ 0.8202],\n",
      "        [-1.5706],\n",
      "        [-0.8497],\n",
      "        [ 0.5584],\n",
      "        [-0.2305],\n",
      "        [ 0.9383],\n",
      "        [-0.2305],\n",
      "        [ 0.5584],\n",
      "        [-0.5945],\n",
      "        [-0.3108],\n",
      "        [ 0.8805],\n",
      "        [ 0.7575],\n",
      "        [ 0.7891],\n",
      "        [ 1.2064],\n",
      "        [ 1.2064],\n",
      "        [ 1.0708],\n",
      "        [-0.3108],\n",
      "        [-1.2248],\n",
      "        [ 1.0708],\n",
      "        [-1.4635],\n",
      "        [ 0.9662],\n",
      "        [-1.3423],\n",
      "        [ 0.5584],\n",
      "        [-0.2305],\n",
      "        [ 0.7575],\n",
      "        [ 0.5241],\n",
      "        [ 1.2064],\n",
      "        [ 0.7575],\n",
      "        [-0.6680],\n",
      "        [-0.1447],\n",
      "        [-1.0506],\n",
      "        [-1.1385],\n",
      "        [ 0.9662],\n",
      "        [-0.8497],\n",
      "        [ 0.6264],\n",
      "        [ 1.2064],\n",
      "        [-1.5819],\n",
      "        [ 0.0424],\n",
      "        [-0.4100],\n",
      "        [-1.3423],\n",
      "        [ 1.0199],\n",
      "        [-0.4100],\n",
      "        [-0.5483],\n",
      "        [-1.5431],\n",
      "        [ 0.6264],\n",
      "        [-1.4635],\n",
      "        [ 0.4198],\n",
      "        [-0.4337],\n",
      "        [ 0.4198],\n",
      "        [ 1.2064],\n",
      "        [ 1.1700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 183/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0278,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1805],\n",
      "        [-1.1805],\n",
      "        [ 0.6595],\n",
      "        [ 0.5924],\n",
      "        [-0.0533],\n",
      "        [ 0.4894],\n",
      "        [ 0.9092],\n",
      "        [ 0.9656],\n",
      "        [ 0.9092],\n",
      "        [ 0.8197],\n",
      "        [-1.5682],\n",
      "        [-0.8496],\n",
      "        [ 0.5583],\n",
      "        [-0.2302],\n",
      "        [ 0.9377],\n",
      "        [-0.2302],\n",
      "        [ 0.5583],\n",
      "        [-0.5947],\n",
      "        [-0.3106],\n",
      "        [ 0.8800],\n",
      "        [ 0.7571],\n",
      "        [ 0.7887],\n",
      "        [ 1.2058],\n",
      "        [ 1.2058],\n",
      "        [ 1.0702],\n",
      "        [-0.3106],\n",
      "        [-1.2230],\n",
      "        [ 1.0702],\n",
      "        [-1.4611],\n",
      "        [ 0.9656],\n",
      "        [-1.3401],\n",
      "        [ 0.5583],\n",
      "        [-0.2302],\n",
      "        [ 0.7571],\n",
      "        [ 0.5239],\n",
      "        [ 1.2058],\n",
      "        [ 0.7571],\n",
      "        [-0.6683],\n",
      "        [-0.1444],\n",
      "        [-1.0496],\n",
      "        [-1.1371],\n",
      "        [ 0.9656],\n",
      "        [-0.8496],\n",
      "        [ 0.6261],\n",
      "        [ 1.2058],\n",
      "        [-1.5796],\n",
      "        [ 0.0427],\n",
      "        [-0.4100],\n",
      "        [-1.3401],\n",
      "        [ 1.0193],\n",
      "        [-0.4100],\n",
      "        [-0.5485],\n",
      "        [-1.5407],\n",
      "        [ 0.6261],\n",
      "        [-1.4611],\n",
      "        [ 0.4198],\n",
      "        [-0.4337],\n",
      "        [ 0.4198],\n",
      "        [ 1.2058],\n",
      "        [ 1.1694]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 184/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0276,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1790],\n",
      "        [-1.1790],\n",
      "        [ 0.6590],\n",
      "        [ 0.5919],\n",
      "        [-0.0532],\n",
      "        [ 0.4890],\n",
      "        [ 0.9084],\n",
      "        [ 0.9648],\n",
      "        [ 0.9084],\n",
      "        [ 0.8190],\n",
      "        [-1.5657],\n",
      "        [-0.8495],\n",
      "        [ 0.5578],\n",
      "        [-0.2302],\n",
      "        [ 0.9369],\n",
      "        [-0.2302],\n",
      "        [ 0.5578],\n",
      "        [-0.5951],\n",
      "        [-0.3107],\n",
      "        [ 0.8792],\n",
      "        [ 0.7565],\n",
      "        [ 0.7880],\n",
      "        [ 1.2050],\n",
      "        [ 1.2050],\n",
      "        [ 1.0693],\n",
      "        [-0.3107],\n",
      "        [-1.2213],\n",
      "        [ 1.0693],\n",
      "        [-1.4586],\n",
      "        [ 0.9648],\n",
      "        [-1.3380],\n",
      "        [ 0.5578],\n",
      "        [-0.2302],\n",
      "        [ 0.7565],\n",
      "        [ 0.5235],\n",
      "        [ 1.2050],\n",
      "        [ 0.7565],\n",
      "        [-0.6686],\n",
      "        [-0.1444],\n",
      "        [-1.0487],\n",
      "        [-1.1357],\n",
      "        [ 0.9648],\n",
      "        [-0.8495],\n",
      "        [ 0.6256],\n",
      "        [ 1.2050],\n",
      "        [-1.5771],\n",
      "        [ 0.0427],\n",
      "        [-0.4102],\n",
      "        [-1.3380],\n",
      "        [ 1.0185],\n",
      "        [-0.4102],\n",
      "        [-0.5488],\n",
      "        [-1.5382],\n",
      "        [ 0.6256],\n",
      "        [-1.4586],\n",
      "        [ 0.4195],\n",
      "        [-0.4339],\n",
      "        [ 0.4195],\n",
      "        [ 1.2050],\n",
      "        [ 1.1686]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 185/10000,\n",
      " train_loss: 0.0012,\n",
      " train_mae: 0.0275,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6586],\n",
      "        [ 0.5916],\n",
      "        [-0.0533],\n",
      "        [ 0.4888],\n",
      "        [ 0.9079],\n",
      "        [ 0.9642],\n",
      "        [ 0.9079],\n",
      "        [ 0.8185],\n",
      "        [-1.5640],\n",
      "        [-0.8500],\n",
      "        [ 0.5576],\n",
      "        [-0.2305],\n",
      "        [ 0.9364],\n",
      "        [-0.2305],\n",
      "        [ 0.5576],\n",
      "        [-0.5959],\n",
      "        [-0.3110],\n",
      "        [ 0.8787],\n",
      "        [ 0.7561],\n",
      "        [ 0.7876],\n",
      "        [ 1.2044],\n",
      "        [ 1.2044],\n",
      "        [ 1.0688],\n",
      "        [-0.3110],\n",
      "        [-1.2205],\n",
      "        [ 1.0688],\n",
      "        [-1.4570],\n",
      "        [ 0.9642],\n",
      "        [-1.3367],\n",
      "        [ 0.5576],\n",
      "        [-0.2305],\n",
      "        [ 0.7561],\n",
      "        [ 0.5233],\n",
      "        [ 1.2044],\n",
      "        [ 0.7561],\n",
      "        [-0.6694],\n",
      "        [-0.1445],\n",
      "        [-1.0485],\n",
      "        [-1.1352],\n",
      "        [ 0.9642],\n",
      "        [-0.8500],\n",
      "        [ 0.6253],\n",
      "        [ 1.2044],\n",
      "        [-1.5754],\n",
      "        [ 0.0426],\n",
      "        [-0.4107],\n",
      "        [-1.3367],\n",
      "        [ 1.0179],\n",
      "        [-0.4107],\n",
      "        [-0.5495],\n",
      "        [-1.5365],\n",
      "        [ 0.6253],\n",
      "        [-1.4570],\n",
      "        [ 0.4193],\n",
      "        [-0.4344],\n",
      "        [ 0.4193],\n",
      "        [ 1.2044],\n",
      "        [ 1.1680]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 186/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0275,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1787],\n",
      "        [-1.1787],\n",
      "        [ 0.6588],\n",
      "        [ 0.5918],\n",
      "        [-0.0533],\n",
      "        [ 0.4890],\n",
      "        [ 0.9080],\n",
      "        [ 0.9643],\n",
      "        [ 0.9080],\n",
      "        [ 0.8187],\n",
      "        [-1.5635],\n",
      "        [-0.8512],\n",
      "        [ 0.5578],\n",
      "        [-0.2308],\n",
      "        [ 0.9365],\n",
      "        [-0.2308],\n",
      "        [ 0.5578],\n",
      "        [-0.5969],\n",
      "        [-0.3115],\n",
      "        [ 0.8788],\n",
      "        [ 0.7562],\n",
      "        [ 0.7877],\n",
      "        [ 1.2045],\n",
      "        [ 1.2045],\n",
      "        [ 1.0688],\n",
      "        [-0.3115],\n",
      "        [-1.2207],\n",
      "        [ 1.0688],\n",
      "        [-1.4566],\n",
      "        [ 0.9643],\n",
      "        [-1.3366],\n",
      "        [ 0.5578],\n",
      "        [-0.2308],\n",
      "        [ 0.7562],\n",
      "        [ 0.5235],\n",
      "        [ 1.2045],\n",
      "        [ 0.7562],\n",
      "        [-0.6706],\n",
      "        [-0.1447],\n",
      "        [-1.0492],\n",
      "        [-1.1357],\n",
      "        [ 0.9643],\n",
      "        [-0.8512],\n",
      "        [ 0.6255],\n",
      "        [ 1.2045],\n",
      "        [-1.5749],\n",
      "        [ 0.0427],\n",
      "        [-0.4113],\n",
      "        [-1.3366],\n",
      "        [ 1.0180],\n",
      "        [-0.4113],\n",
      "        [-0.5505],\n",
      "        [-1.5359],\n",
      "        [ 0.6255],\n",
      "        [-1.4566],\n",
      "        [ 0.4195],\n",
      "        [-0.4351],\n",
      "        [ 0.4195],\n",
      "        [ 1.2045],\n",
      "        [ 1.1681]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 187/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0276,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1799],\n",
      "        [-1.1799],\n",
      "        [ 0.6595],\n",
      "        [ 0.5925],\n",
      "        [-0.0532],\n",
      "        [ 0.4896],\n",
      "        [ 0.9086],\n",
      "        [ 0.9650],\n",
      "        [ 0.9086],\n",
      "        [ 0.8194],\n",
      "        [-1.5639],\n",
      "        [-0.8528],\n",
      "        [ 0.5584],\n",
      "        [-0.2310],\n",
      "        [ 0.9371],\n",
      "        [-0.2310],\n",
      "        [ 0.5584],\n",
      "        [-0.5982],\n",
      "        [-0.3119],\n",
      "        [ 0.8795],\n",
      "        [ 0.7569],\n",
      "        [ 0.7884],\n",
      "        [ 1.2050],\n",
      "        [ 1.2050],\n",
      "        [ 1.0694],\n",
      "        [-0.3119],\n",
      "        [-1.2218],\n",
      "        [ 1.0694],\n",
      "        [-1.4572],\n",
      "        [ 0.9650],\n",
      "        [-1.3374],\n",
      "        [ 0.5584],\n",
      "        [-0.2310],\n",
      "        [ 0.7569],\n",
      "        [ 0.5242],\n",
      "        [ 1.2050],\n",
      "        [ 0.7569],\n",
      "        [-0.6720],\n",
      "        [-0.1447],\n",
      "        [-1.0507],\n",
      "        [-1.1370],\n",
      "        [ 0.9650],\n",
      "        [-0.8528],\n",
      "        [ 0.6262],\n",
      "        [ 1.2050],\n",
      "        [-1.5753],\n",
      "        [ 0.0430],\n",
      "        [-0.4120],\n",
      "        [-1.3374],\n",
      "        [ 1.0186],\n",
      "        [-0.4120],\n",
      "        [-0.5516],\n",
      "        [-1.5364],\n",
      "        [ 0.6262],\n",
      "        [-1.4572],\n",
      "        [ 0.4201],\n",
      "        [-0.4359],\n",
      "        [ 0.4201],\n",
      "        [ 1.2050],\n",
      "        [ 1.1686]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 188/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0278,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1814],\n",
      "        [-1.1814],\n",
      "        [ 0.6603],\n",
      "        [ 0.5932],\n",
      "        [-0.0530],\n",
      "        [ 0.4904],\n",
      "        [ 0.9094],\n",
      "        [ 0.9657],\n",
      "        [ 0.9094],\n",
      "        [ 0.8201],\n",
      "        [-1.5647],\n",
      "        [-0.8545],\n",
      "        [ 0.5592],\n",
      "        [-0.2312],\n",
      "        [ 0.9379],\n",
      "        [-0.2312],\n",
      "        [ 0.5592],\n",
      "        [-0.5994],\n",
      "        [-0.3123],\n",
      "        [ 0.8802],\n",
      "        [ 0.7577],\n",
      "        [ 0.7892],\n",
      "        [ 1.2057],\n",
      "        [ 1.2057],\n",
      "        [ 1.0701],\n",
      "        [-0.3123],\n",
      "        [-1.2232],\n",
      "        [ 1.0701],\n",
      "        [-1.4581],\n",
      "        [ 0.9657],\n",
      "        [-1.3386],\n",
      "        [ 0.5592],\n",
      "        [-0.2312],\n",
      "        [ 0.7577],\n",
      "        [ 0.5249],\n",
      "        [ 1.2057],\n",
      "        [ 0.7577],\n",
      "        [-0.6734],\n",
      "        [-0.1447],\n",
      "        [-1.0523],\n",
      "        [-1.1386],\n",
      "        [ 0.9657],\n",
      "        [-0.8545],\n",
      "        [ 0.6269],\n",
      "        [ 1.2057],\n",
      "        [-1.5760],\n",
      "        [ 0.0433],\n",
      "        [-0.4127],\n",
      "        [-1.3386],\n",
      "        [ 1.0193],\n",
      "        [-0.4127],\n",
      "        [-0.5527],\n",
      "        [-1.5372],\n",
      "        [ 0.6269],\n",
      "        [-1.4581],\n",
      "        [ 0.4208],\n",
      "        [-0.4366],\n",
      "        [ 0.4208],\n",
      "        [ 1.2057],\n",
      "        [ 1.1693]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 189/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0278,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1825],\n",
      "        [-1.1825],\n",
      "        [ 0.6607],\n",
      "        [ 0.5936],\n",
      "        [-0.0528],\n",
      "        [ 0.4908],\n",
      "        [ 0.9097],\n",
      "        [ 0.9660],\n",
      "        [ 0.9097],\n",
      "        [ 0.8205],\n",
      "        [-1.5652],\n",
      "        [-0.8559],\n",
      "        [ 0.5596],\n",
      "        [-0.2312],\n",
      "        [ 0.9382],\n",
      "        [-0.2312],\n",
      "        [ 0.5596],\n",
      "        [-0.6004],\n",
      "        [-0.3125],\n",
      "        [ 0.8806],\n",
      "        [ 0.7581],\n",
      "        [ 0.7895],\n",
      "        [ 1.2059],\n",
      "        [ 1.2059],\n",
      "        [ 1.0704],\n",
      "        [-0.3125],\n",
      "        [-1.2243],\n",
      "        [ 1.0704],\n",
      "        [-1.4587],\n",
      "        [ 0.9660],\n",
      "        [-1.3395],\n",
      "        [ 0.5596],\n",
      "        [-0.2312],\n",
      "        [ 0.7581],\n",
      "        [ 0.5253],\n",
      "        [ 1.2059],\n",
      "        [ 0.7581],\n",
      "        [-0.6746],\n",
      "        [-0.1446],\n",
      "        [-1.0537],\n",
      "        [-1.1398],\n",
      "        [ 0.9660],\n",
      "        [-0.8559],\n",
      "        [ 0.6273],\n",
      "        [ 1.2059],\n",
      "        [-1.5766],\n",
      "        [ 0.0436],\n",
      "        [-0.4132],\n",
      "        [-1.3395],\n",
      "        [ 1.0196],\n",
      "        [-0.4132],\n",
      "        [-0.5536],\n",
      "        [-1.5377],\n",
      "        [ 0.6273],\n",
      "        [-1.4587],\n",
      "        [ 0.4213],\n",
      "        [-0.4372],\n",
      "        [ 0.4213],\n",
      "        [ 1.2059],\n",
      "        [ 1.1695]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 190/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0277,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1828],\n",
      "        [-1.1828],\n",
      "        [ 0.6606],\n",
      "        [ 0.5936],\n",
      "        [-0.0526],\n",
      "        [ 0.4909],\n",
      "        [ 0.9095],\n",
      "        [ 0.9657],\n",
      "        [ 0.9095],\n",
      "        [ 0.8203],\n",
      "        [-1.5650],\n",
      "        [-0.8566],\n",
      "        [ 0.5597],\n",
      "        [-0.2311],\n",
      "        [ 0.9379],\n",
      "        [-0.2311],\n",
      "        [ 0.5597],\n",
      "        [-0.6009],\n",
      "        [-0.3125],\n",
      "        [ 0.8804],\n",
      "        [ 0.7579],\n",
      "        [ 0.7894],\n",
      "        [ 1.2056],\n",
      "        [ 1.2056],\n",
      "        [ 1.0701],\n",
      "        [-0.3125],\n",
      "        [-1.2246],\n",
      "        [ 1.0701],\n",
      "        [-1.4585],\n",
      "        [ 0.9657],\n",
      "        [-1.3395],\n",
      "        [ 0.5597],\n",
      "        [-0.2311],\n",
      "        [ 0.7579],\n",
      "        [ 0.5254],\n",
      "        [ 1.2056],\n",
      "        [ 0.7579],\n",
      "        [-0.6752],\n",
      "        [-0.1444],\n",
      "        [-1.0542],\n",
      "        [-1.1402],\n",
      "        [ 0.9657],\n",
      "        [-0.8566],\n",
      "        [ 0.6273],\n",
      "        [ 1.2056],\n",
      "        [-1.5764],\n",
      "        [ 0.0439],\n",
      "        [-0.4133],\n",
      "        [-1.3395],\n",
      "        [ 1.0193],\n",
      "        [-0.4133],\n",
      "        [-0.5540],\n",
      "        [-1.5375],\n",
      "        [ 0.6273],\n",
      "        [-1.4585],\n",
      "        [ 0.4214],\n",
      "        [-0.4373],\n",
      "        [ 0.4214],\n",
      "        [ 1.2056],\n",
      "        [ 1.1692]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 191/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0276,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1823],\n",
      "        [-1.1823],\n",
      "        [ 0.6603],\n",
      "        [ 0.5934],\n",
      "        [-0.0521],\n",
      "        [ 0.4908],\n",
      "        [ 0.9089],\n",
      "        [ 0.9651],\n",
      "        [ 0.9089],\n",
      "        [ 0.8198],\n",
      "        [-1.5639],\n",
      "        [-0.8567],\n",
      "        [ 0.5595],\n",
      "        [-0.2307],\n",
      "        [ 0.9373],\n",
      "        [-0.2307],\n",
      "        [ 0.5595],\n",
      "        [-0.6009],\n",
      "        [-0.3121],\n",
      "        [ 0.8798],\n",
      "        [ 0.7575],\n",
      "        [ 0.7889],\n",
      "        [ 1.2050],\n",
      "        [ 1.2050],\n",
      "        [ 1.0695],\n",
      "        [-0.3121],\n",
      "        [-1.2240],\n",
      "        [ 1.0695],\n",
      "        [-1.4575],\n",
      "        [ 0.9651],\n",
      "        [-1.3387],\n",
      "        [ 0.5595],\n",
      "        [-0.2307],\n",
      "        [ 0.7575],\n",
      "        [ 0.5252],\n",
      "        [ 1.2050],\n",
      "        [ 0.7575],\n",
      "        [-0.6753],\n",
      "        [-0.1440],\n",
      "        [-1.0540],\n",
      "        [-1.1398],\n",
      "        [ 0.9651],\n",
      "        [-0.8567],\n",
      "        [ 0.6270],\n",
      "        [ 1.2050],\n",
      "        [-1.5754],\n",
      "        [ 0.0443],\n",
      "        [-0.4130],\n",
      "        [-1.3387],\n",
      "        [ 1.0187],\n",
      "        [-0.4130],\n",
      "        [-0.5539],\n",
      "        [-1.5364],\n",
      "        [ 0.6270],\n",
      "        [-1.4575],\n",
      "        [ 0.4214],\n",
      "        [-0.4371],\n",
      "        [ 0.4214],\n",
      "        [ 1.2050],\n",
      "        [ 1.1686]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 192/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0274,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1814],\n",
      "        [-1.1814],\n",
      "        [ 0.6600],\n",
      "        [ 0.5932],\n",
      "        [-0.0515],\n",
      "        [ 0.4908],\n",
      "        [ 0.9083],\n",
      "        [ 0.9645],\n",
      "        [ 0.9083],\n",
      "        [ 0.8193],\n",
      "        [-1.5626],\n",
      "        [-0.8564],\n",
      "        [ 0.5593],\n",
      "        [-0.2300],\n",
      "        [ 0.9367],\n",
      "        [-0.2300],\n",
      "        [ 0.5593],\n",
      "        [-0.6006],\n",
      "        [-0.3114],\n",
      "        [ 0.8793],\n",
      "        [ 0.7571],\n",
      "        [ 0.7885],\n",
      "        [ 1.2044],\n",
      "        [ 1.2044],\n",
      "        [ 1.0688],\n",
      "        [-0.3114],\n",
      "        [-1.2229],\n",
      "        [ 1.0688],\n",
      "        [-1.4561],\n",
      "        [ 0.9645],\n",
      "        [-1.3374],\n",
      "        [ 0.5593],\n",
      "        [-0.2300],\n",
      "        [ 0.7571],\n",
      "        [ 0.5252],\n",
      "        [ 1.2044],\n",
      "        [ 0.7571],\n",
      "        [-0.6750],\n",
      "        [-0.1433],\n",
      "        [-1.0533],\n",
      "        [-1.1389],\n",
      "        [ 0.9645],\n",
      "        [-0.8564],\n",
      "        [ 0.6268],\n",
      "        [ 1.2044],\n",
      "        [-1.5740],\n",
      "        [ 0.0448],\n",
      "        [-0.4124],\n",
      "        [-1.3374],\n",
      "        [ 1.0180],\n",
      "        [-0.4124],\n",
      "        [-0.5535],\n",
      "        [-1.5351],\n",
      "        [ 0.6268],\n",
      "        [-1.4561],\n",
      "        [ 0.4215],\n",
      "        [-0.4365],\n",
      "        [ 0.4215],\n",
      "        [ 1.2044],\n",
      "        [ 1.1679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 193/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0272,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1807],\n",
      "        [-1.1807],\n",
      "        [ 0.6599],\n",
      "        [ 0.5932],\n",
      "        [-0.0508],\n",
      "        [ 0.4909],\n",
      "        [ 0.9079],\n",
      "        [ 0.9641],\n",
      "        [ 0.9079],\n",
      "        [ 0.8190],\n",
      "        [-1.5616],\n",
      "        [-0.8561],\n",
      "        [ 0.5593],\n",
      "        [-0.2292],\n",
      "        [ 0.9363],\n",
      "        [-0.2292],\n",
      "        [ 0.5593],\n",
      "        [-0.6002],\n",
      "        [-0.3107],\n",
      "        [ 0.8789],\n",
      "        [ 0.7568],\n",
      "        [ 0.7882],\n",
      "        [ 1.2039],\n",
      "        [ 1.2039],\n",
      "        [ 1.0683],\n",
      "        [-0.3107],\n",
      "        [-1.2222],\n",
      "        [ 1.0683],\n",
      "        [-1.4551],\n",
      "        [ 0.9641],\n",
      "        [-1.3365],\n",
      "        [ 0.5593],\n",
      "        [-0.2292],\n",
      "        [ 0.7568],\n",
      "        [ 0.5252],\n",
      "        [ 1.2039],\n",
      "        [ 0.7568],\n",
      "        [-0.6748],\n",
      "        [-0.1425],\n",
      "        [-1.0529],\n",
      "        [-1.1383],\n",
      "        [ 0.9641],\n",
      "        [-0.8561],\n",
      "        [ 0.6267],\n",
      "        [ 1.2039],\n",
      "        [-1.5731],\n",
      "        [ 0.0455],\n",
      "        [-0.4118],\n",
      "        [-1.3365],\n",
      "        [ 1.0175],\n",
      "        [-0.4118],\n",
      "        [-0.5531],\n",
      "        [-1.5340],\n",
      "        [ 0.6267],\n",
      "        [-1.4551],\n",
      "        [ 0.4217],\n",
      "        [-0.4359],\n",
      "        [ 0.4217],\n",
      "        [ 1.2039],\n",
      "        [ 1.1674]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 194/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0271,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1807],\n",
      "        [-1.1807],\n",
      "        [ 0.6599],\n",
      "        [ 0.5933],\n",
      "        [-0.0502],\n",
      "        [ 0.4911],\n",
      "        [ 0.9077],\n",
      "        [ 0.9638],\n",
      "        [ 0.9077],\n",
      "        [ 0.8188],\n",
      "        [-1.5615],\n",
      "        [-0.8564],\n",
      "        [ 0.5595],\n",
      "        [-0.2287],\n",
      "        [ 0.9361],\n",
      "        [-0.2287],\n",
      "        [ 0.5595],\n",
      "        [-0.6002],\n",
      "        [-0.3102],\n",
      "        [ 0.8787],\n",
      "        [ 0.7567],\n",
      "        [ 0.7881],\n",
      "        [ 1.2036],\n",
      "        [ 1.2036],\n",
      "        [ 1.0680],\n",
      "        [-0.3102],\n",
      "        [-1.2222],\n",
      "        [ 1.0680],\n",
      "        [-1.4549],\n",
      "        [ 0.9638],\n",
      "        [-1.3364],\n",
      "        [ 0.5595],\n",
      "        [-0.2287],\n",
      "        [ 0.7567],\n",
      "        [ 0.5254],\n",
      "        [ 1.2036],\n",
      "        [ 0.7567],\n",
      "        [-0.6749],\n",
      "        [-0.1419],\n",
      "        [-1.0530],\n",
      "        [-1.1384],\n",
      "        [ 0.9638],\n",
      "        [-0.8564],\n",
      "        [ 0.6268],\n",
      "        [ 1.2036],\n",
      "        [-1.5730],\n",
      "        [ 0.0461],\n",
      "        [-0.4114],\n",
      "        [-1.3364],\n",
      "        [ 1.0173],\n",
      "        [-0.4114],\n",
      "        [-0.5530],\n",
      "        [-1.5339],\n",
      "        [ 0.6268],\n",
      "        [-1.4549],\n",
      "        [ 0.4219],\n",
      "        [-0.4356],\n",
      "        [ 0.4219],\n",
      "        [ 1.2036],\n",
      "        [ 1.1672]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 195/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0271,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1815],\n",
      "        [-1.1815],\n",
      "        [ 0.6600],\n",
      "        [ 0.5934],\n",
      "        [-0.0498],\n",
      "        [ 0.4913],\n",
      "        [ 0.9077],\n",
      "        [ 0.9638],\n",
      "        [ 0.9077],\n",
      "        [ 0.8189],\n",
      "        [-1.5624],\n",
      "        [-0.8572],\n",
      "        [ 0.5597],\n",
      "        [-0.2284],\n",
      "        [ 0.9361],\n",
      "        [-0.2284],\n",
      "        [ 0.5597],\n",
      "        [-0.6005],\n",
      "        [-0.3100],\n",
      "        [ 0.8787],\n",
      "        [ 0.7568],\n",
      "        [ 0.7881],\n",
      "        [ 1.2036],\n",
      "        [ 1.2036],\n",
      "        [ 1.0680],\n",
      "        [-0.3100],\n",
      "        [-1.2230],\n",
      "        [ 1.0680],\n",
      "        [-1.4557],\n",
      "        [ 0.9638],\n",
      "        [-1.3371],\n",
      "        [ 0.5597],\n",
      "        [-0.2284],\n",
      "        [ 0.7568],\n",
      "        [ 0.5256],\n",
      "        [ 1.2036],\n",
      "        [ 0.7568],\n",
      "        [-0.6754],\n",
      "        [-0.1416],\n",
      "        [-1.0539],\n",
      "        [-1.1392],\n",
      "        [ 0.9638],\n",
      "        [-0.8572],\n",
      "        [ 0.6269],\n",
      "        [ 1.2036],\n",
      "        [-1.5739],\n",
      "        [ 0.0465],\n",
      "        [-0.4114],\n",
      "        [-1.3371],\n",
      "        [ 1.0172],\n",
      "        [-0.4114],\n",
      "        [-0.5532],\n",
      "        [-1.5347],\n",
      "        [ 0.6269],\n",
      "        [-1.4557],\n",
      "        [ 0.4222],\n",
      "        [-0.4356],\n",
      "        [ 0.4222],\n",
      "        [ 1.2036],\n",
      "        [ 1.1671]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 196/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0271,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1827],\n",
      "        [-1.1827],\n",
      "        [ 0.6603],\n",
      "        [ 0.5937],\n",
      "        [-0.0495],\n",
      "        [ 0.4916],\n",
      "        [ 0.9079],\n",
      "        [ 0.9639],\n",
      "        [ 0.9079],\n",
      "        [ 0.8191],\n",
      "        [-1.5636],\n",
      "        [-0.8582],\n",
      "        [ 0.5600],\n",
      "        [-0.2282],\n",
      "        [ 0.9362],\n",
      "        [-0.2282],\n",
      "        [ 0.5600],\n",
      "        [-0.6011],\n",
      "        [-0.3099],\n",
      "        [ 0.8789],\n",
      "        [ 0.7570],\n",
      "        [ 0.7883],\n",
      "        [ 1.2038],\n",
      "        [ 1.2038],\n",
      "        [ 1.0681],\n",
      "        [-0.3099],\n",
      "        [-1.2241],\n",
      "        [ 1.0681],\n",
      "        [-1.4568],\n",
      "        [ 0.9639],\n",
      "        [-1.3382],\n",
      "        [ 0.5600],\n",
      "        [-0.2282],\n",
      "        [ 0.7570],\n",
      "        [ 0.5259],\n",
      "        [ 1.2038],\n",
      "        [ 0.7570],\n",
      "        [-0.6761],\n",
      "        [-0.1413],\n",
      "        [-1.0550],\n",
      "        [-1.1403],\n",
      "        [ 0.9639],\n",
      "        [-0.8582],\n",
      "        [ 0.6272],\n",
      "        [ 1.2038],\n",
      "        [-1.5752],\n",
      "        [ 0.0468],\n",
      "        [-0.4115],\n",
      "        [-1.3382],\n",
      "        [ 1.0174],\n",
      "        [-0.4115],\n",
      "        [-0.5537],\n",
      "        [-1.5359],\n",
      "        [ 0.6272],\n",
      "        [-1.4568],\n",
      "        [ 0.4226],\n",
      "        [-0.4358],\n",
      "        [ 0.4226],\n",
      "        [ 1.2038],\n",
      "        [ 1.1673]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 197/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0271,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1835],\n",
      "        [-1.1835],\n",
      "        [ 0.6606],\n",
      "        [ 0.5940],\n",
      "        [-0.0491],\n",
      "        [ 0.4920],\n",
      "        [ 0.9081],\n",
      "        [ 0.9642],\n",
      "        [ 0.9081],\n",
      "        [ 0.8193],\n",
      "        [-1.5646],\n",
      "        [-0.8590],\n",
      "        [ 0.5603],\n",
      "        [-0.2280],\n",
      "        [ 0.9364],\n",
      "        [-0.2280],\n",
      "        [ 0.5603],\n",
      "        [-0.6015],\n",
      "        [-0.3099],\n",
      "        [ 0.8791],\n",
      "        [ 0.7573],\n",
      "        [ 0.7886],\n",
      "        [ 1.2040],\n",
      "        [ 1.2040],\n",
      "        [ 1.0683],\n",
      "        [-0.3099],\n",
      "        [-1.2249],\n",
      "        [ 1.0683],\n",
      "        [-1.4576],\n",
      "        [ 0.9642],\n",
      "        [-1.3390],\n",
      "        [ 0.5603],\n",
      "        [-0.2280],\n",
      "        [ 0.7573],\n",
      "        [ 0.5262],\n",
      "        [ 1.2040],\n",
      "        [ 0.7573],\n",
      "        [-0.6767],\n",
      "        [-0.1411],\n",
      "        [-1.0558],\n",
      "        [-1.1412],\n",
      "        [ 0.9642],\n",
      "        [-0.8590],\n",
      "        [ 0.6275],\n",
      "        [ 1.2040],\n",
      "        [-1.5761],\n",
      "        [ 0.0472],\n",
      "        [-0.4116],\n",
      "        [-1.3390],\n",
      "        [ 1.0176],\n",
      "        [-0.4116],\n",
      "        [-0.5540],\n",
      "        [-1.5368],\n",
      "        [ 0.6275],\n",
      "        [-1.4576],\n",
      "        [ 0.4229],\n",
      "        [-0.4359],\n",
      "        [ 0.4229],\n",
      "        [ 1.2040],\n",
      "        [ 1.1675]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 198/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0270,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1836],\n",
      "        [-1.1836],\n",
      "        [ 0.6608],\n",
      "        [ 0.5942],\n",
      "        [-0.0488],\n",
      "        [ 0.4922],\n",
      "        [ 0.9082],\n",
      "        [ 0.9642],\n",
      "        [ 0.9082],\n",
      "        [ 0.8194],\n",
      "        [-1.5648],\n",
      "        [-0.8594],\n",
      "        [ 0.5605],\n",
      "        [-0.2278],\n",
      "        [ 0.9365],\n",
      "        [-0.2278],\n",
      "        [ 0.5605],\n",
      "        [-0.6018],\n",
      "        [-0.3097],\n",
      "        [ 0.8792],\n",
      "        [ 0.7574],\n",
      "        [ 0.7887],\n",
      "        [ 1.2042],\n",
      "        [ 1.2042],\n",
      "        [ 1.0684],\n",
      "        [-0.3097],\n",
      "        [-1.2250],\n",
      "        [ 1.0684],\n",
      "        [-1.4577],\n",
      "        [ 0.9642],\n",
      "        [-1.3391],\n",
      "        [ 0.5605],\n",
      "        [-0.2278],\n",
      "        [ 0.7574],\n",
      "        [ 0.5265],\n",
      "        [ 1.2042],\n",
      "        [ 0.7574],\n",
      "        [-0.6770],\n",
      "        [-0.1407],\n",
      "        [-1.0561],\n",
      "        [-1.1414],\n",
      "        [ 0.9642],\n",
      "        [-0.8594],\n",
      "        [ 0.6277],\n",
      "        [ 1.2042],\n",
      "        [-1.5764],\n",
      "        [ 0.0476],\n",
      "        [-0.4115],\n",
      "        [-1.3391],\n",
      "        [ 1.0177],\n",
      "        [-0.4115],\n",
      "        [-0.5542],\n",
      "        [-1.5370],\n",
      "        [ 0.6277],\n",
      "        [-1.4577],\n",
      "        [ 0.4232],\n",
      "        [-0.4359],\n",
      "        [ 0.4232],\n",
      "        [ 1.2042],\n",
      "        [ 1.1676]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 199/10000,\n",
      " train_loss: 0.0011,\n",
      " train_mae: 0.0269,\n",
      " epoch_time_duration: 0.0178\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1832],\n",
      "        [-1.1832],\n",
      "        [ 0.6607],\n",
      "        [ 0.5942],\n",
      "        [-0.0485],\n",
      "        [ 0.4922],\n",
      "        [ 0.9080],\n",
      "        [ 0.9641],\n",
      "        [ 0.9080],\n",
      "        [ 0.8193],\n",
      "        [-1.5644],\n",
      "        [-0.8594],\n",
      "        [ 0.5605],\n",
      "        [-0.2275],\n",
      "        [ 0.9363],\n",
      "        [-0.2275],\n",
      "        [ 0.5605],\n",
      "        [-0.6018],\n",
      "        [-0.3095],\n",
      "        [ 0.8790],\n",
      "        [ 0.7573],\n",
      "        [ 0.7885],\n",
      "        [ 1.2041],\n",
      "        [ 1.2041],\n",
      "        [ 1.0682],\n",
      "        [-0.3095],\n",
      "        [-1.2245],\n",
      "        [ 1.0682],\n",
      "        [-1.4571],\n",
      "        [ 0.9641],\n",
      "        [-1.3384],\n",
      "        [ 0.5605],\n",
      "        [-0.2275],\n",
      "        [ 0.7573],\n",
      "        [ 0.5265],\n",
      "        [ 1.2041],\n",
      "        [ 0.7573],\n",
      "        [-0.6772],\n",
      "        [-0.1405],\n",
      "        [-1.0558],\n",
      "        [-1.1409],\n",
      "        [ 0.9641],\n",
      "        [-0.8594],\n",
      "        [ 0.6276],\n",
      "        [ 1.2041],\n",
      "        [-1.5761],\n",
      "        [ 0.0478],\n",
      "        [-0.4114],\n",
      "        [-1.3384],\n",
      "        [ 1.0175],\n",
      "        [-0.4114],\n",
      "        [-0.5542],\n",
      "        [-1.5366],\n",
      "        [ 0.6276],\n",
      "        [-1.4571],\n",
      "        [ 0.4233],\n",
      "        [-0.4358],\n",
      "        [ 0.4233],\n",
      "        [ 1.2041],\n",
      "        [ 1.1675]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 200/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0268,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1824],\n",
      "        [-1.1824],\n",
      "        [ 0.6603],\n",
      "        [ 0.5939],\n",
      "        [-0.0484],\n",
      "        [ 0.4920],\n",
      "        [ 0.9076],\n",
      "        [ 0.9637],\n",
      "        [ 0.9076],\n",
      "        [ 0.8189],\n",
      "        [-1.5637],\n",
      "        [-0.8593],\n",
      "        [ 0.5602],\n",
      "        [-0.2274],\n",
      "        [ 0.9360],\n",
      "        [-0.2274],\n",
      "        [ 0.5602],\n",
      "        [-0.6019],\n",
      "        [-0.3094],\n",
      "        [ 0.8786],\n",
      "        [ 0.7569],\n",
      "        [ 0.7882],\n",
      "        [ 1.2038],\n",
      "        [ 1.2038],\n",
      "        [ 1.0679],\n",
      "        [-0.3094],\n",
      "        [-1.2236],\n",
      "        [ 1.0679],\n",
      "        [-1.4562],\n",
      "        [ 0.9637],\n",
      "        [-1.3375],\n",
      "        [ 0.5602],\n",
      "        [-0.2274],\n",
      "        [ 0.7569],\n",
      "        [ 0.5262],\n",
      "        [ 1.2038],\n",
      "        [ 0.7569],\n",
      "        [-0.6772],\n",
      "        [-0.1403],\n",
      "        [-1.0553],\n",
      "        [-1.1402],\n",
      "        [ 0.9637],\n",
      "        [-0.8593],\n",
      "        [ 0.6273],\n",
      "        [ 1.2038],\n",
      "        [-1.5754],\n",
      "        [ 0.0479],\n",
      "        [-0.4113],\n",
      "        [-1.3375],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5542],\n",
      "        [-1.5357],\n",
      "        [ 0.6273],\n",
      "        [-1.4562],\n",
      "        [ 0.4231],\n",
      "        [-0.4357],\n",
      "        [ 0.4231],\n",
      "        [ 1.2038],\n",
      "        [ 1.1672]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 201/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0267,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1816],\n",
      "        [-1.1816],\n",
      "        [ 0.6600],\n",
      "        [ 0.5936],\n",
      "        [-0.0484],\n",
      "        [ 0.4918],\n",
      "        [ 0.9072],\n",
      "        [ 0.9633],\n",
      "        [ 0.9072],\n",
      "        [ 0.8185],\n",
      "        [-1.5631],\n",
      "        [-0.8592],\n",
      "        [ 0.5599],\n",
      "        [-0.2274],\n",
      "        [ 0.9356],\n",
      "        [-0.2274],\n",
      "        [ 0.5599],\n",
      "        [-0.6020],\n",
      "        [-0.3094],\n",
      "        [ 0.8783],\n",
      "        [ 0.7566],\n",
      "        [ 0.7878],\n",
      "        [ 1.2036],\n",
      "        [ 1.2036],\n",
      "        [ 1.0676],\n",
      "        [-0.3094],\n",
      "        [-1.2228],\n",
      "        [ 1.0676],\n",
      "        [-1.4553],\n",
      "        [ 0.9633],\n",
      "        [-1.3366],\n",
      "        [ 0.5599],\n",
      "        [-0.2274],\n",
      "        [ 0.7566],\n",
      "        [ 0.5260],\n",
      "        [ 1.2036],\n",
      "        [ 0.7566],\n",
      "        [-0.6774],\n",
      "        [-0.1403],\n",
      "        [-1.0548],\n",
      "        [-1.1396],\n",
      "        [ 0.9633],\n",
      "        [-0.8592],\n",
      "        [ 0.6270],\n",
      "        [ 1.2036],\n",
      "        [-1.5748],\n",
      "        [ 0.0479],\n",
      "        [-0.4114],\n",
      "        [-1.3366],\n",
      "        [ 1.0168],\n",
      "        [-0.4114],\n",
      "        [-0.5544],\n",
      "        [-1.5350],\n",
      "        [ 0.6270],\n",
      "        [-1.4553],\n",
      "        [ 0.4229],\n",
      "        [-0.4358],\n",
      "        [ 0.4229],\n",
      "        [ 1.2036],\n",
      "        [ 1.1670]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 202/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0266,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1812],\n",
      "        [-1.1812],\n",
      "        [ 0.6599],\n",
      "        [ 0.5935],\n",
      "        [-0.0484],\n",
      "        [ 0.4917],\n",
      "        [ 0.9072],\n",
      "        [ 0.9633],\n",
      "        [ 0.9072],\n",
      "        [ 0.8184],\n",
      "        [-1.5628],\n",
      "        [-0.8594],\n",
      "        [ 0.5598],\n",
      "        [-0.2274],\n",
      "        [ 0.9355],\n",
      "        [-0.2274],\n",
      "        [ 0.5598],\n",
      "        [-0.6024],\n",
      "        [-0.3094],\n",
      "        [ 0.8782],\n",
      "        [ 0.7565],\n",
      "        [ 0.7877],\n",
      "        [ 1.2037],\n",
      "        [ 1.2037],\n",
      "        [ 1.0676],\n",
      "        [-0.3094],\n",
      "        [-1.2224],\n",
      "        [ 1.0676],\n",
      "        [-1.4549],\n",
      "        [ 0.9633],\n",
      "        [-1.3360],\n",
      "        [ 0.5598],\n",
      "        [-0.2274],\n",
      "        [ 0.7565],\n",
      "        [ 0.5259],\n",
      "        [ 1.2037],\n",
      "        [ 0.7565],\n",
      "        [-0.6777],\n",
      "        [-0.1403],\n",
      "        [-1.0546],\n",
      "        [-1.1392],\n",
      "        [ 0.9633],\n",
      "        [-0.8594],\n",
      "        [ 0.6269],\n",
      "        [ 1.2037],\n",
      "        [-1.5746],\n",
      "        [ 0.0479],\n",
      "        [-0.4115],\n",
      "        [-1.3360],\n",
      "        [ 1.0167],\n",
      "        [-0.4115],\n",
      "        [-0.5547],\n",
      "        [-1.5347],\n",
      "        [ 0.6269],\n",
      "        [-1.4549],\n",
      "        [ 0.4229],\n",
      "        [-0.4360],\n",
      "        [ 0.4229],\n",
      "        [ 1.2037],\n",
      "        [ 1.1671]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 203/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0266,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1813],\n",
      "        [-1.1813],\n",
      "        [ 0.6601],\n",
      "        [ 0.5937],\n",
      "        [-0.0484],\n",
      "        [ 0.4919],\n",
      "        [ 0.9074],\n",
      "        [ 0.9635],\n",
      "        [ 0.9074],\n",
      "        [ 0.8186],\n",
      "        [-1.5632],\n",
      "        [-0.8598],\n",
      "        [ 0.5600],\n",
      "        [-0.2275],\n",
      "        [ 0.9358],\n",
      "        [-0.2275],\n",
      "        [ 0.5600],\n",
      "        [-0.6029],\n",
      "        [-0.3096],\n",
      "        [ 0.8784],\n",
      "        [ 0.7567],\n",
      "        [ 0.7879],\n",
      "        [ 1.2041],\n",
      "        [ 1.2041],\n",
      "        [ 1.0679],\n",
      "        [-0.3096],\n",
      "        [-1.2224],\n",
      "        [ 1.0679],\n",
      "        [-1.4549],\n",
      "        [ 0.9635],\n",
      "        [-1.3360],\n",
      "        [ 0.5600],\n",
      "        [-0.2275],\n",
      "        [ 0.7567],\n",
      "        [ 0.5260],\n",
      "        [ 1.2041],\n",
      "        [ 0.7567],\n",
      "        [-0.6782],\n",
      "        [-0.1404],\n",
      "        [-1.0548],\n",
      "        [-1.1393],\n",
      "        [ 0.9635],\n",
      "        [-0.8598],\n",
      "        [ 0.6271],\n",
      "        [ 1.2041],\n",
      "        [-1.5749],\n",
      "        [ 0.0479],\n",
      "        [-0.4118],\n",
      "        [-1.3360],\n",
      "        [ 1.0170],\n",
      "        [-0.4118],\n",
      "        [-0.5551],\n",
      "        [-1.5349],\n",
      "        [ 0.6271],\n",
      "        [-1.4549],\n",
      "        [ 0.4230],\n",
      "        [-0.4363],\n",
      "        [ 0.4230],\n",
      "        [ 1.2041],\n",
      "        [ 1.1674]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 204/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0266,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1816],\n",
      "        [-1.1816],\n",
      "        [ 0.6603],\n",
      "        [ 0.5939],\n",
      "        [-0.0484],\n",
      "        [ 0.4920],\n",
      "        [ 0.9077],\n",
      "        [ 0.9638],\n",
      "        [ 0.9077],\n",
      "        [ 0.8189],\n",
      "        [-1.5639],\n",
      "        [-0.8605],\n",
      "        [ 0.5602],\n",
      "        [-0.2277],\n",
      "        [ 0.9361],\n",
      "        [-0.2277],\n",
      "        [ 0.5602],\n",
      "        [-0.6035],\n",
      "        [-0.3099],\n",
      "        [ 0.8787],\n",
      "        [ 0.7569],\n",
      "        [ 0.7882],\n",
      "        [ 1.2046],\n",
      "        [ 1.2046],\n",
      "        [ 1.0683],\n",
      "        [-0.3099],\n",
      "        [-1.2227],\n",
      "        [ 1.0683],\n",
      "        [-1.4554],\n",
      "        [ 0.9638],\n",
      "        [-1.3363],\n",
      "        [ 0.5602],\n",
      "        [-0.2277],\n",
      "        [ 0.7569],\n",
      "        [ 0.5262],\n",
      "        [ 1.2046],\n",
      "        [ 0.7569],\n",
      "        [-0.6789],\n",
      "        [-0.1405],\n",
      "        [-1.0553],\n",
      "        [-1.1397],\n",
      "        [ 0.9638],\n",
      "        [-0.8605],\n",
      "        [ 0.6273],\n",
      "        [ 1.2046],\n",
      "        [-1.5757],\n",
      "        [ 0.0479],\n",
      "        [-0.4122],\n",
      "        [-1.3363],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5557],\n",
      "        [-1.5356],\n",
      "        [ 0.6273],\n",
      "        [-1.4554],\n",
      "        [ 0.4231],\n",
      "        [-0.4367],\n",
      "        [ 0.4231],\n",
      "        [ 1.2046],\n",
      "        [ 1.1679]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 205/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0266,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1820],\n",
      "        [-1.1820],\n",
      "        [ 0.6604],\n",
      "        [ 0.5940],\n",
      "        [-0.0485],\n",
      "        [ 0.4921],\n",
      "        [ 0.9079],\n",
      "        [ 0.9641],\n",
      "        [ 0.9079],\n",
      "        [ 0.8191],\n",
      "        [-1.5646],\n",
      "        [-0.8611],\n",
      "        [ 0.5603],\n",
      "        [-0.2279],\n",
      "        [ 0.9363],\n",
      "        [-0.2279],\n",
      "        [ 0.5603],\n",
      "        [-0.6041],\n",
      "        [-0.3102],\n",
      "        [ 0.8789],\n",
      "        [ 0.7571],\n",
      "        [ 0.7883],\n",
      "        [ 1.2050],\n",
      "        [ 1.2050],\n",
      "        [ 1.0686],\n",
      "        [-0.3102],\n",
      "        [-1.2230],\n",
      "        [ 1.0686],\n",
      "        [-1.4558],\n",
      "        [ 0.9641],\n",
      "        [-1.3367],\n",
      "        [ 0.5603],\n",
      "        [-0.2279],\n",
      "        [ 0.7571],\n",
      "        [ 0.5263],\n",
      "        [ 1.2050],\n",
      "        [ 0.7571],\n",
      "        [-0.6796],\n",
      "        [-0.1407],\n",
      "        [-1.0557],\n",
      "        [-1.1401],\n",
      "        [ 0.9641],\n",
      "        [-0.8611],\n",
      "        [ 0.6274],\n",
      "        [ 1.2050],\n",
      "        [-1.5765],\n",
      "        [ 0.0479],\n",
      "        [-0.4127],\n",
      "        [-1.3367],\n",
      "        [ 1.0176],\n",
      "        [-0.4127],\n",
      "        [-0.5563],\n",
      "        [-1.5362],\n",
      "        [ 0.6274],\n",
      "        [-1.4558],\n",
      "        [ 0.4232],\n",
      "        [-0.4372],\n",
      "        [ 0.4232],\n",
      "        [ 1.2050],\n",
      "        [ 1.1683]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 206/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0265,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1820],\n",
      "        [-1.1820],\n",
      "        [ 0.6604],\n",
      "        [ 0.5940],\n",
      "        [-0.0486],\n",
      "        [ 0.4921],\n",
      "        [ 0.9079],\n",
      "        [ 0.9641],\n",
      "        [ 0.9079],\n",
      "        [ 0.8191],\n",
      "        [-1.5651],\n",
      "        [-0.8615],\n",
      "        [ 0.5603],\n",
      "        [-0.2281],\n",
      "        [ 0.9363],\n",
      "        [-0.2281],\n",
      "        [ 0.5603],\n",
      "        [-0.6046],\n",
      "        [-0.3104],\n",
      "        [ 0.8789],\n",
      "        [ 0.7570],\n",
      "        [ 0.7883],\n",
      "        [ 1.2052],\n",
      "        [ 1.2052],\n",
      "        [ 1.0687],\n",
      "        [-0.3104],\n",
      "        [-1.2230],\n",
      "        [ 1.0687],\n",
      "        [-1.4560],\n",
      "        [ 0.9641],\n",
      "        [-1.3367],\n",
      "        [ 0.5603],\n",
      "        [-0.2281],\n",
      "        [ 0.7570],\n",
      "        [ 0.5263],\n",
      "        [ 1.2052],\n",
      "        [ 0.7570],\n",
      "        [-0.6800],\n",
      "        [-0.1407],\n",
      "        [-1.0559],\n",
      "        [-1.1401],\n",
      "        [ 0.9641],\n",
      "        [-0.8615],\n",
      "        [ 0.6274],\n",
      "        [ 1.2052],\n",
      "        [-1.5770],\n",
      "        [ 0.0479],\n",
      "        [-0.4129],\n",
      "        [-1.3367],\n",
      "        [ 1.0177],\n",
      "        [-0.4129],\n",
      "        [-0.5567],\n",
      "        [-1.5366],\n",
      "        [ 0.6274],\n",
      "        [-1.4560],\n",
      "        [ 0.4232],\n",
      "        [-0.4375],\n",
      "        [ 0.4232],\n",
      "        [ 1.2052],\n",
      "        [ 1.1685]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 207/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0264,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1816],\n",
      "        [-1.1816],\n",
      "        [ 0.6603],\n",
      "        [ 0.5938],\n",
      "        [-0.0485],\n",
      "        [ 0.4920],\n",
      "        [ 0.9078],\n",
      "        [ 0.9640],\n",
      "        [ 0.9078],\n",
      "        [ 0.8189],\n",
      "        [-1.5651],\n",
      "        [-0.8615],\n",
      "        [ 0.5601],\n",
      "        [-0.2280],\n",
      "        [ 0.9362],\n",
      "        [-0.2280],\n",
      "        [ 0.5601],\n",
      "        [-0.6047],\n",
      "        [-0.3104],\n",
      "        [ 0.8787],\n",
      "        [ 0.7569],\n",
      "        [ 0.7882],\n",
      "        [ 1.2053],\n",
      "        [ 1.2053],\n",
      "        [ 1.0686],\n",
      "        [-0.3104],\n",
      "        [-1.2226],\n",
      "        [ 1.0686],\n",
      "        [-1.4557],\n",
      "        [ 0.9640],\n",
      "        [-1.3362],\n",
      "        [ 0.5601],\n",
      "        [-0.2280],\n",
      "        [ 0.7569],\n",
      "        [ 0.5262],\n",
      "        [ 1.2053],\n",
      "        [ 0.7569],\n",
      "        [-0.6802],\n",
      "        [-0.1407],\n",
      "        [-1.0556],\n",
      "        [-1.1397],\n",
      "        [ 0.9640],\n",
      "        [-0.8615],\n",
      "        [ 0.6272],\n",
      "        [ 1.2053],\n",
      "        [-1.5770],\n",
      "        [ 0.0479],\n",
      "        [-0.4129],\n",
      "        [-1.3362],\n",
      "        [ 1.0176],\n",
      "        [-0.4129],\n",
      "        [-0.5568],\n",
      "        [-1.5365],\n",
      "        [ 0.6272],\n",
      "        [-1.4557],\n",
      "        [ 0.4231],\n",
      "        [-0.4375],\n",
      "        [ 0.4231],\n",
      "        [ 1.2053],\n",
      "        [ 1.1685]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 208/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0263,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1809],\n",
      "        [-1.1809],\n",
      "        [ 0.6601],\n",
      "        [ 0.5937],\n",
      "        [-0.0483],\n",
      "        [ 0.4919],\n",
      "        [ 0.9076],\n",
      "        [ 0.9638],\n",
      "        [ 0.9076],\n",
      "        [ 0.8187],\n",
      "        [-1.5648],\n",
      "        [-0.8612],\n",
      "        [ 0.5600],\n",
      "        [-0.2278],\n",
      "        [ 0.9360],\n",
      "        [-0.2278],\n",
      "        [ 0.5600],\n",
      "        [-0.6046],\n",
      "        [-0.3102],\n",
      "        [ 0.8785],\n",
      "        [ 0.7567],\n",
      "        [ 0.7880],\n",
      "        [ 1.2053],\n",
      "        [ 1.2053],\n",
      "        [ 1.0685],\n",
      "        [-0.3102],\n",
      "        [-1.2218],\n",
      "        [ 1.0685],\n",
      "        [-1.4551],\n",
      "        [ 0.9638],\n",
      "        [-1.3355],\n",
      "        [ 0.5600],\n",
      "        [-0.2278],\n",
      "        [ 0.7567],\n",
      "        [ 0.5261],\n",
      "        [ 1.2053],\n",
      "        [ 0.7567],\n",
      "        [-0.6801],\n",
      "        [-0.1405],\n",
      "        [-1.0550],\n",
      "        [-1.1391],\n",
      "        [ 0.9638],\n",
      "        [-0.8612],\n",
      "        [ 0.6271],\n",
      "        [ 1.2053],\n",
      "        [-1.5769],\n",
      "        [ 0.0481],\n",
      "        [-0.4128],\n",
      "        [-1.3355],\n",
      "        [ 1.0175],\n",
      "        [-0.4128],\n",
      "        [-0.5567],\n",
      "        [-1.5361],\n",
      "        [ 0.6271],\n",
      "        [-1.4551],\n",
      "        [ 0.4231],\n",
      "        [-0.4373],\n",
      "        [ 0.4231],\n",
      "        [ 1.2053],\n",
      "        [ 1.1684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 209/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0262,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1802],\n",
      "        [-1.1802],\n",
      "        [ 0.6599],\n",
      "        [ 0.5936],\n",
      "        [-0.0481],\n",
      "        [ 0.4918],\n",
      "        [ 0.9074],\n",
      "        [ 0.9636],\n",
      "        [ 0.9074],\n",
      "        [ 0.8185],\n",
      "        [-1.5647],\n",
      "        [-0.8610],\n",
      "        [ 0.5599],\n",
      "        [-0.2275],\n",
      "        [ 0.9358],\n",
      "        [-0.2275],\n",
      "        [ 0.5599],\n",
      "        [-0.6045],\n",
      "        [-0.3099],\n",
      "        [ 0.8783],\n",
      "        [ 0.7565],\n",
      "        [ 0.7878],\n",
      "        [ 1.2053],\n",
      "        [ 1.2053],\n",
      "        [ 1.0683],\n",
      "        [-0.3099],\n",
      "        [-1.2212],\n",
      "        [ 1.0683],\n",
      "        [-1.4546],\n",
      "        [ 0.9636],\n",
      "        [-1.3348],\n",
      "        [ 0.5599],\n",
      "        [-0.2275],\n",
      "        [ 0.7565],\n",
      "        [ 0.5260],\n",
      "        [ 1.2053],\n",
      "        [ 0.7565],\n",
      "        [-0.6800],\n",
      "        [-0.1402],\n",
      "        [-1.0545],\n",
      "        [-1.1384],\n",
      "        [ 0.9636],\n",
      "        [-0.8610],\n",
      "        [ 0.6269],\n",
      "        [ 1.2053],\n",
      "        [-1.5768],\n",
      "        [ 0.0482],\n",
      "        [-0.4126],\n",
      "        [-1.3348],\n",
      "        [ 1.0173],\n",
      "        [-0.4126],\n",
      "        [-0.5565],\n",
      "        [-1.5359],\n",
      "        [ 0.6269],\n",
      "        [-1.4546],\n",
      "        [ 0.4230],\n",
      "        [-0.4371],\n",
      "        [ 0.4230],\n",
      "        [ 1.2053],\n",
      "        [ 1.1684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 210/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0261,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1799],\n",
      "        [-1.1799],\n",
      "        [ 0.6598],\n",
      "        [ 0.5935],\n",
      "        [-0.0480],\n",
      "        [ 0.4917],\n",
      "        [ 0.9072],\n",
      "        [ 0.9635],\n",
      "        [ 0.9072],\n",
      "        [ 0.8184],\n",
      "        [-1.5649],\n",
      "        [-0.8609],\n",
      "        [ 0.5598],\n",
      "        [-0.2274],\n",
      "        [ 0.9357],\n",
      "        [-0.2274],\n",
      "        [ 0.5598],\n",
      "        [-0.6045],\n",
      "        [-0.3097],\n",
      "        [ 0.8782],\n",
      "        [ 0.7564],\n",
      "        [ 0.7876],\n",
      "        [ 1.2053],\n",
      "        [ 1.2053],\n",
      "        [ 1.0682],\n",
      "        [-0.3097],\n",
      "        [-1.2208],\n",
      "        [ 1.0682],\n",
      "        [-1.4545],\n",
      "        [ 0.9635],\n",
      "        [-1.3345],\n",
      "        [ 0.5598],\n",
      "        [-0.2274],\n",
      "        [ 0.7564],\n",
      "        [ 0.5259],\n",
      "        [ 1.2053],\n",
      "        [ 0.7564],\n",
      "        [-0.6800],\n",
      "        [-0.1400],\n",
      "        [-1.0542],\n",
      "        [-1.1381],\n",
      "        [ 0.9635],\n",
      "        [-0.8609],\n",
      "        [ 0.6268],\n",
      "        [ 1.2053],\n",
      "        [-1.5771],\n",
      "        [ 0.0484],\n",
      "        [-0.4124],\n",
      "        [-1.3345],\n",
      "        [ 1.0172],\n",
      "        [-0.4124],\n",
      "        [-0.5565],\n",
      "        [-1.5360],\n",
      "        [ 0.6268],\n",
      "        [-1.4545],\n",
      "        [ 0.4230],\n",
      "        [-0.4370],\n",
      "        [ 0.4230],\n",
      "        [ 1.2053],\n",
      "        [ 1.1683]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 211/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0260,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1799],\n",
      "        [-1.1799],\n",
      "        [ 0.6598],\n",
      "        [ 0.5934],\n",
      "        [-0.0478],\n",
      "        [ 0.4917],\n",
      "        [ 0.9072],\n",
      "        [ 0.9634],\n",
      "        [ 0.9072],\n",
      "        [ 0.8183],\n",
      "        [-1.5656],\n",
      "        [-0.8611],\n",
      "        [ 0.5598],\n",
      "        [-0.2273],\n",
      "        [ 0.9356],\n",
      "        [-0.2273],\n",
      "        [ 0.5598],\n",
      "        [-0.6046],\n",
      "        [-0.3097],\n",
      "        [ 0.8781],\n",
      "        [ 0.7563],\n",
      "        [ 0.7876],\n",
      "        [ 1.2054],\n",
      "        [ 1.2054],\n",
      "        [ 1.0682],\n",
      "        [-0.3097],\n",
      "        [-1.2209],\n",
      "        [ 1.0682],\n",
      "        [-1.4548],\n",
      "        [ 0.9634],\n",
      "        [-1.3346],\n",
      "        [ 0.5598],\n",
      "        [-0.2273],\n",
      "        [ 0.7563],\n",
      "        [ 0.5259],\n",
      "        [ 1.2054],\n",
      "        [ 0.7563],\n",
      "        [-0.6802],\n",
      "        [-0.1399],\n",
      "        [-1.0543],\n",
      "        [-1.1382],\n",
      "        [ 0.9634],\n",
      "        [-0.8611],\n",
      "        [ 0.6268],\n",
      "        [ 1.2054],\n",
      "        [-1.5778],\n",
      "        [ 0.0485],\n",
      "        [-0.4124],\n",
      "        [-1.3346],\n",
      "        [ 1.0172],\n",
      "        [-0.4124],\n",
      "        [-0.5566],\n",
      "        [-1.5366],\n",
      "        [ 0.6268],\n",
      "        [-1.4548],\n",
      "        [ 0.4230],\n",
      "        [-0.4370],\n",
      "        [ 0.4230],\n",
      "        [ 1.2054],\n",
      "        [ 1.1684]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 212/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0260,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1802],\n",
      "        [-1.1802],\n",
      "        [ 0.6598],\n",
      "        [ 0.5935],\n",
      "        [-0.0477],\n",
      "        [ 0.4918],\n",
      "        [ 0.9073],\n",
      "        [ 0.9635],\n",
      "        [ 0.9073],\n",
      "        [ 0.8184],\n",
      "        [-1.5665],\n",
      "        [-0.8614],\n",
      "        [ 0.5598],\n",
      "        [-0.2272],\n",
      "        [ 0.9357],\n",
      "        [-0.2272],\n",
      "        [ 0.5598],\n",
      "        [-0.6049],\n",
      "        [-0.3096],\n",
      "        [ 0.8782],\n",
      "        [ 0.7564],\n",
      "        [ 0.7876],\n",
      "        [ 1.2057],\n",
      "        [ 1.2057],\n",
      "        [ 1.0684],\n",
      "        [-0.3096],\n",
      "        [-1.2211],\n",
      "        [ 1.0684],\n",
      "        [-1.4554],\n",
      "        [ 0.9635],\n",
      "        [-1.3350],\n",
      "        [ 0.5598],\n",
      "        [-0.2272],\n",
      "        [ 0.7564],\n",
      "        [ 0.5259],\n",
      "        [ 1.2057],\n",
      "        [ 0.7564],\n",
      "        [-0.6805],\n",
      "        [-0.1398],\n",
      "        [-1.0546],\n",
      "        [-1.1384],\n",
      "        [ 0.9635],\n",
      "        [-0.8614],\n",
      "        [ 0.6268],\n",
      "        [ 1.2057],\n",
      "        [-1.5787],\n",
      "        [ 0.0486],\n",
      "        [-0.4125],\n",
      "        [-1.3350],\n",
      "        [ 1.0173],\n",
      "        [-0.4125],\n",
      "        [-0.5568],\n",
      "        [-1.5374],\n",
      "        [ 0.6268],\n",
      "        [-1.4554],\n",
      "        [ 0.4231],\n",
      "        [-0.4371],\n",
      "        [ 0.4231],\n",
      "        [ 1.2057],\n",
      "        [ 1.1687]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 213/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0259,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1803],\n",
      "        [-1.1803],\n",
      "        [ 0.6599],\n",
      "        [ 0.5936],\n",
      "        [-0.0475],\n",
      "        [ 0.4919],\n",
      "        [ 0.9074],\n",
      "        [ 0.9637],\n",
      "        [ 0.9074],\n",
      "        [ 0.8185],\n",
      "        [-1.5673],\n",
      "        [-0.8617],\n",
      "        [ 0.5599],\n",
      "        [-0.2271],\n",
      "        [ 0.9358],\n",
      "        [-0.2271],\n",
      "        [ 0.5599],\n",
      "        [-0.6051],\n",
      "        [-0.3096],\n",
      "        [ 0.8783],\n",
      "        [ 0.7565],\n",
      "        [ 0.7877],\n",
      "        [ 1.2060],\n",
      "        [ 1.2060],\n",
      "        [ 1.0686],\n",
      "        [-0.3096],\n",
      "        [-1.2213],\n",
      "        [ 1.0686],\n",
      "        [-1.4558],\n",
      "        [ 0.9637],\n",
      "        [-1.3353],\n",
      "        [ 0.5599],\n",
      "        [-0.2271],\n",
      "        [ 0.7565],\n",
      "        [ 0.5260],\n",
      "        [ 1.2060],\n",
      "        [ 0.7565],\n",
      "        [-0.6808],\n",
      "        [-0.1397],\n",
      "        [-1.0548],\n",
      "        [-1.1386],\n",
      "        [ 0.9637],\n",
      "        [-0.8617],\n",
      "        [ 0.6269],\n",
      "        [ 1.2060],\n",
      "        [-1.5796],\n",
      "        [ 0.0488],\n",
      "        [-0.4125],\n",
      "        [-1.3353],\n",
      "        [ 1.0174],\n",
      "        [-0.4125],\n",
      "        [-0.5570],\n",
      "        [-1.5381],\n",
      "        [ 0.6269],\n",
      "        [-1.4558],\n",
      "        [ 0.4232],\n",
      "        [-0.4371],\n",
      "        [ 0.4232],\n",
      "        [ 1.2060],\n",
      "        [ 1.1689]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 214/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0258,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1803],\n",
      "        [-1.1803],\n",
      "        [ 0.6599],\n",
      "        [ 0.5936],\n",
      "        [-0.0474],\n",
      "        [ 0.4920],\n",
      "        [ 0.9074],\n",
      "        [ 0.9637],\n",
      "        [ 0.9074],\n",
      "        [ 0.8185],\n",
      "        [-1.5678],\n",
      "        [-0.8618],\n",
      "        [ 0.5600],\n",
      "        [-0.2269],\n",
      "        [ 0.9359],\n",
      "        [-0.2269],\n",
      "        [ 0.5600],\n",
      "        [-0.6052],\n",
      "        [-0.3095],\n",
      "        [ 0.8783],\n",
      "        [ 0.7565],\n",
      "        [ 0.7877],\n",
      "        [ 1.2062],\n",
      "        [ 1.2062],\n",
      "        [ 1.0687],\n",
      "        [-0.3095],\n",
      "        [-1.2213],\n",
      "        [ 1.0687],\n",
      "        [-1.4560],\n",
      "        [ 0.9637],\n",
      "        [-1.3353],\n",
      "        [ 0.5600],\n",
      "        [-0.2269],\n",
      "        [ 0.7565],\n",
      "        [ 0.5261],\n",
      "        [ 1.2062],\n",
      "        [ 0.7565],\n",
      "        [-0.6809],\n",
      "        [-0.1395],\n",
      "        [-1.0548],\n",
      "        [-1.1386],\n",
      "        [ 0.9637],\n",
      "        [-0.8618],\n",
      "        [ 0.6269],\n",
      "        [ 1.2062],\n",
      "        [-1.5802],\n",
      "        [ 0.0490],\n",
      "        [-0.4124],\n",
      "        [-1.3353],\n",
      "        [ 1.0175],\n",
      "        [-0.4124],\n",
      "        [-0.5570],\n",
      "        [-1.5385],\n",
      "        [ 0.6269],\n",
      "        [-1.4560],\n",
      "        [ 0.4233],\n",
      "        [-0.4371],\n",
      "        [ 0.4233],\n",
      "        [ 1.2062],\n",
      "        [ 1.1691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 215/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0257,\n",
      " epoch_time_duration: 0.0106\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1800],\n",
      "        [-1.1800],\n",
      "        [ 0.6598],\n",
      "        [ 0.5935],\n",
      "        [-0.0472],\n",
      "        [ 0.4919],\n",
      "        [ 0.9073],\n",
      "        [ 0.9636],\n",
      "        [ 0.9073],\n",
      "        [ 0.8183],\n",
      "        [-1.5680],\n",
      "        [-0.8618],\n",
      "        [ 0.5599],\n",
      "        [-0.2268],\n",
      "        [ 0.9358],\n",
      "        [-0.2268],\n",
      "        [ 0.5599],\n",
      "        [-0.6052],\n",
      "        [-0.3093],\n",
      "        [ 0.8782],\n",
      "        [ 0.7563],\n",
      "        [ 0.7876],\n",
      "        [ 1.2063],\n",
      "        [ 1.2063],\n",
      "        [ 1.0686],\n",
      "        [-0.3093],\n",
      "        [-1.2210],\n",
      "        [ 1.0686],\n",
      "        [-1.4559],\n",
      "        [ 0.9636],\n",
      "        [-1.3350],\n",
      "        [ 0.5599],\n",
      "        [-0.2268],\n",
      "        [ 0.7563],\n",
      "        [ 0.5260],\n",
      "        [ 1.2063],\n",
      "        [ 0.7563],\n",
      "        [-0.6810],\n",
      "        [-0.1394],\n",
      "        [-1.0546],\n",
      "        [-1.1383],\n",
      "        [ 0.9636],\n",
      "        [-0.8618],\n",
      "        [ 0.6268],\n",
      "        [ 1.2063],\n",
      "        [-1.5804],\n",
      "        [ 0.0491],\n",
      "        [-0.4123],\n",
      "        [-1.3350],\n",
      "        [ 1.0174],\n",
      "        [-0.4123],\n",
      "        [-0.5570],\n",
      "        [-1.5386],\n",
      "        [ 0.6268],\n",
      "        [-1.4559],\n",
      "        [ 0.4232],\n",
      "        [-0.4370],\n",
      "        [ 0.4232],\n",
      "        [ 1.2063],\n",
      "        [ 1.1691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 216/10000,\n",
      " train_loss: 0.0010,\n",
      " train_mae: 0.0256,\n",
      " epoch_time_duration: 0.0160\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1795],\n",
      "        [-1.1795],\n",
      "        [ 0.6596],\n",
      "        [ 0.5933],\n",
      "        [-0.0471],\n",
      "        [ 0.4917],\n",
      "        [ 0.9071],\n",
      "        [ 0.9634],\n",
      "        [ 0.9071],\n",
      "        [ 0.8181],\n",
      "        [-1.5680],\n",
      "        [-0.8617],\n",
      "        [ 0.5597],\n",
      "        [-0.2266],\n",
      "        [ 0.9355],\n",
      "        [-0.2266],\n",
      "        [ 0.5597],\n",
      "        [-0.6052],\n",
      "        [-0.3092],\n",
      "        [ 0.8780],\n",
      "        [ 0.7561],\n",
      "        [ 0.7874],\n",
      "        [ 1.2063],\n",
      "        [ 1.2063],\n",
      "        [ 1.0685],\n",
      "        [-0.3092],\n",
      "        [-1.2205],\n",
      "        [ 1.0685],\n",
      "        [-1.4556],\n",
      "        [ 0.9634],\n",
      "        [-1.3345],\n",
      "        [ 0.5597],\n",
      "        [-0.2266],\n",
      "        [ 0.7561],\n",
      "        [ 0.5258],\n",
      "        [ 1.2063],\n",
      "        [ 0.7561],\n",
      "        [-0.6810],\n",
      "        [-0.1392],\n",
      "        [-1.0542],\n",
      "        [-1.1379],\n",
      "        [ 0.9634],\n",
      "        [-0.8617],\n",
      "        [ 0.6266],\n",
      "        [ 1.2063],\n",
      "        [-1.5804],\n",
      "        [ 0.0491],\n",
      "        [-0.4122],\n",
      "        [-1.3345],\n",
      "        [ 1.0172],\n",
      "        [-0.4122],\n",
      "        [-0.5570],\n",
      "        [-1.5384],\n",
      "        [ 0.6266],\n",
      "        [-1.4556],\n",
      "        [ 0.4231],\n",
      "        [-0.4369],\n",
      "        [ 0.4231],\n",
      "        [ 1.2063],\n",
      "        [ 1.1691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 217/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0255,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1791],\n",
      "        [-1.1791],\n",
      "        [ 0.6594],\n",
      "        [ 0.5932],\n",
      "        [-0.0471],\n",
      "        [ 0.4916],\n",
      "        [ 0.9069],\n",
      "        [ 0.9633],\n",
      "        [ 0.9069],\n",
      "        [ 0.8179],\n",
      "        [-1.5679],\n",
      "        [-0.8616],\n",
      "        [ 0.5596],\n",
      "        [-0.2265],\n",
      "        [ 0.9354],\n",
      "        [-0.2265],\n",
      "        [ 0.5596],\n",
      "        [-0.6052],\n",
      "        [-0.3091],\n",
      "        [ 0.8778],\n",
      "        [ 0.7559],\n",
      "        [ 0.7872],\n",
      "        [ 1.2063],\n",
      "        [ 1.2063],\n",
      "        [ 1.0684],\n",
      "        [-0.3091],\n",
      "        [-1.2200],\n",
      "        [ 1.0684],\n",
      "        [-1.4552],\n",
      "        [ 0.9633],\n",
      "        [-1.3340],\n",
      "        [ 0.5596],\n",
      "        [-0.2265],\n",
      "        [ 0.7559],\n",
      "        [ 0.5257],\n",
      "        [ 1.2063],\n",
      "        [ 0.7559],\n",
      "        [-0.6810],\n",
      "        [-0.1391],\n",
      "        [-1.0539],\n",
      "        [-1.1374],\n",
      "        [ 0.9633],\n",
      "        [-0.8616],\n",
      "        [ 0.6265],\n",
      "        [ 1.2063],\n",
      "        [-1.5804],\n",
      "        [ 0.0492],\n",
      "        [-0.4122],\n",
      "        [-1.3340],\n",
      "        [ 1.0171],\n",
      "        [-0.4122],\n",
      "        [-0.5570],\n",
      "        [-1.5383],\n",
      "        [ 0.6265],\n",
      "        [-1.4552],\n",
      "        [ 0.4230],\n",
      "        [-0.4369],\n",
      "        [ 0.4230],\n",
      "        [ 1.2063],\n",
      "        [ 1.1691]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 218/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0255,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1788],\n",
      "        [-1.1788],\n",
      "        [ 0.6594],\n",
      "        [ 0.5931],\n",
      "        [-0.0470],\n",
      "        [ 0.4916],\n",
      "        [ 0.9069],\n",
      "        [ 0.9633],\n",
      "        [ 0.9069],\n",
      "        [ 0.8179],\n",
      "        [-1.5680],\n",
      "        [-0.8617],\n",
      "        [ 0.5595],\n",
      "        [-0.2265],\n",
      "        [ 0.9354],\n",
      "        [-0.2265],\n",
      "        [ 0.5595],\n",
      "        [-0.6053],\n",
      "        [-0.3091],\n",
      "        [ 0.8778],\n",
      "        [ 0.7559],\n",
      "        [ 0.7871],\n",
      "        [ 1.2065],\n",
      "        [ 1.2065],\n",
      "        [ 1.0684],\n",
      "        [-0.3091],\n",
      "        [-1.2197],\n",
      "        [ 1.0684],\n",
      "        [-1.4550],\n",
      "        [ 0.9633],\n",
      "        [-1.3337],\n",
      "        [ 0.5595],\n",
      "        [-0.2265],\n",
      "        [ 0.7559],\n",
      "        [ 0.5256],\n",
      "        [ 1.2065],\n",
      "        [ 0.7559],\n",
      "        [-0.6811],\n",
      "        [-0.1391],\n",
      "        [-1.0537],\n",
      "        [-1.1372],\n",
      "        [ 0.9633],\n",
      "        [-0.8617],\n",
      "        [ 0.6264],\n",
      "        [ 1.2065],\n",
      "        [-1.5805],\n",
      "        [ 0.0492],\n",
      "        [-0.4122],\n",
      "        [-1.3337],\n",
      "        [ 1.0171],\n",
      "        [-0.4122],\n",
      "        [-0.5571],\n",
      "        [-1.5383],\n",
      "        [ 0.6264],\n",
      "        [-1.4550],\n",
      "        [ 0.4230],\n",
      "        [-0.4369],\n",
      "        [ 0.4230],\n",
      "        [ 1.2065],\n",
      "        [ 1.1692]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 219/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0254,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1788],\n",
      "        [-1.1788],\n",
      "        [ 0.6594],\n",
      "        [ 0.5931],\n",
      "        [-0.0470],\n",
      "        [ 0.4916],\n",
      "        [ 0.9069],\n",
      "        [ 0.9634],\n",
      "        [ 0.9069],\n",
      "        [ 0.8179],\n",
      "        [-1.5683],\n",
      "        [-0.8619],\n",
      "        [ 0.5595],\n",
      "        [-0.2265],\n",
      "        [ 0.9354],\n",
      "        [-0.2265],\n",
      "        [ 0.5595],\n",
      "        [-0.6056],\n",
      "        [-0.3091],\n",
      "        [ 0.8778],\n",
      "        [ 0.7559],\n",
      "        [ 0.7871],\n",
      "        [ 1.2068],\n",
      "        [ 1.2068],\n",
      "        [ 1.0686],\n",
      "        [-0.3091],\n",
      "        [-1.2196],\n",
      "        [ 1.0686],\n",
      "        [-1.4551],\n",
      "        [ 0.9634],\n",
      "        [-1.3336],\n",
      "        [ 0.5595],\n",
      "        [-0.2265],\n",
      "        [ 0.7559],\n",
      "        [ 0.5257],\n",
      "        [ 1.2068],\n",
      "        [ 0.7559],\n",
      "        [-0.6814],\n",
      "        [-0.1390],\n",
      "        [-1.0538],\n",
      "        [-1.1372],\n",
      "        [ 0.9634],\n",
      "        [-0.8619],\n",
      "        [ 0.6264],\n",
      "        [ 1.2068],\n",
      "        [-1.5808],\n",
      "        [ 0.0493],\n",
      "        [-0.4123],\n",
      "        [-1.3336],\n",
      "        [ 1.0173],\n",
      "        [-0.4123],\n",
      "        [-0.5573],\n",
      "        [-1.5385],\n",
      "        [ 0.6264],\n",
      "        [-1.4551],\n",
      "        [ 0.4230],\n",
      "        [-0.4370],\n",
      "        [ 0.4230],\n",
      "        [ 1.2068],\n",
      "        [ 1.1695]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 220/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0254,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1789],\n",
      "        [-1.1789],\n",
      "        [ 0.6594],\n",
      "        [ 0.5931],\n",
      "        [-0.0470],\n",
      "        [ 0.4916],\n",
      "        [ 0.9070],\n",
      "        [ 0.9635],\n",
      "        [ 0.9070],\n",
      "        [ 0.8180],\n",
      "        [-1.5687],\n",
      "        [-0.8623],\n",
      "        [ 0.5595],\n",
      "        [-0.2266],\n",
      "        [ 0.9356],\n",
      "        [-0.2266],\n",
      "        [ 0.5595],\n",
      "        [-0.6059],\n",
      "        [-0.3092],\n",
      "        [ 0.8779],\n",
      "        [ 0.7559],\n",
      "        [ 0.7872],\n",
      "        [ 1.2071],\n",
      "        [ 1.2071],\n",
      "        [ 1.0688],\n",
      "        [-0.3092],\n",
      "        [-1.2198],\n",
      "        [ 1.0688],\n",
      "        [-1.4553],\n",
      "        [ 0.9635],\n",
      "        [-1.3338],\n",
      "        [ 0.5595],\n",
      "        [-0.2266],\n",
      "        [ 0.7559],\n",
      "        [ 0.5257],\n",
      "        [ 1.2071],\n",
      "        [ 0.7559],\n",
      "        [-0.6818],\n",
      "        [-0.1391],\n",
      "        [-1.0540],\n",
      "        [-1.1374],\n",
      "        [ 0.9635],\n",
      "        [-0.8623],\n",
      "        [ 0.6264],\n",
      "        [ 1.2071],\n",
      "        [-1.5813],\n",
      "        [ 0.0492],\n",
      "        [-0.4125],\n",
      "        [-1.3338],\n",
      "        [ 1.0174],\n",
      "        [-0.4125],\n",
      "        [-0.5576],\n",
      "        [-1.5388],\n",
      "        [ 0.6264],\n",
      "        [-1.4553],\n",
      "        [ 0.4230],\n",
      "        [-0.4372],\n",
      "        [ 0.4230],\n",
      "        [ 1.2071],\n",
      "        [ 1.1698]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 221/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0253,\n",
      " epoch_time_duration: 0.0087\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1790],\n",
      "        [-1.1790],\n",
      "        [ 0.6594],\n",
      "        [ 0.5931],\n",
      "        [-0.0470],\n",
      "        [ 0.4916],\n",
      "        [ 0.9071],\n",
      "        [ 0.9636],\n",
      "        [ 0.9071],\n",
      "        [ 0.8180],\n",
      "        [-1.5691],\n",
      "        [-0.8626],\n",
      "        [ 0.5595],\n",
      "        [-0.2267],\n",
      "        [ 0.9356],\n",
      "        [-0.2267],\n",
      "        [ 0.5595],\n",
      "        [-0.6062],\n",
      "        [-0.3094],\n",
      "        [ 0.8780],\n",
      "        [ 0.7559],\n",
      "        [ 0.7872],\n",
      "        [ 1.2074],\n",
      "        [ 1.2074],\n",
      "        [ 1.0689],\n",
      "        [-0.3094],\n",
      "        [-1.2199],\n",
      "        [ 1.0689],\n",
      "        [-1.4554],\n",
      "        [ 0.9636],\n",
      "        [-1.3339],\n",
      "        [ 0.5595],\n",
      "        [-0.2267],\n",
      "        [ 0.7559],\n",
      "        [ 0.5256],\n",
      "        [ 1.2074],\n",
      "        [ 0.7559],\n",
      "        [-0.6822],\n",
      "        [-0.1392],\n",
      "        [-1.0542],\n",
      "        [-1.1375],\n",
      "        [ 0.9636],\n",
      "        [-0.8626],\n",
      "        [ 0.6264],\n",
      "        [ 1.2074],\n",
      "        [-1.5817],\n",
      "        [ 0.0492],\n",
      "        [-0.4127],\n",
      "        [-1.3339],\n",
      "        [ 1.0175],\n",
      "        [-0.4127],\n",
      "        [-0.5579],\n",
      "        [-1.5391],\n",
      "        [ 0.6264],\n",
      "        [-1.4554],\n",
      "        [ 0.4230],\n",
      "        [-0.4374],\n",
      "        [ 0.4230],\n",
      "        [ 1.2074],\n",
      "        [ 1.1700]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 222/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0253,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1790],\n",
      "        [-1.1790],\n",
      "        [ 0.6593],\n",
      "        [ 0.5931],\n",
      "        [-0.0470],\n",
      "        [ 0.4915],\n",
      "        [ 0.9071],\n",
      "        [ 0.9636],\n",
      "        [ 0.9071],\n",
      "        [ 0.8180],\n",
      "        [-1.5693],\n",
      "        [-0.8628],\n",
      "        [ 0.5594],\n",
      "        [-0.2267],\n",
      "        [ 0.9356],\n",
      "        [-0.2267],\n",
      "        [ 0.5594],\n",
      "        [-0.6065],\n",
      "        [-0.3094],\n",
      "        [ 0.8779],\n",
      "        [ 0.7559],\n",
      "        [ 0.7872],\n",
      "        [ 1.2076],\n",
      "        [ 1.2076],\n",
      "        [ 1.0690],\n",
      "        [-0.3094],\n",
      "        [-1.2198],\n",
      "        [ 1.0690],\n",
      "        [-1.4554],\n",
      "        [ 0.9636],\n",
      "        [-1.3338],\n",
      "        [ 0.5594],\n",
      "        [-0.2267],\n",
      "        [ 0.7559],\n",
      "        [ 0.5256],\n",
      "        [ 1.2076],\n",
      "        [ 0.7559],\n",
      "        [-0.6824],\n",
      "        [-0.1392],\n",
      "        [-1.0543],\n",
      "        [-1.1375],\n",
      "        [ 0.9636],\n",
      "        [-0.8628],\n",
      "        [ 0.6264],\n",
      "        [ 1.2076],\n",
      "        [-1.5819],\n",
      "        [ 0.0492],\n",
      "        [-0.4128],\n",
      "        [-1.3338],\n",
      "        [ 1.0176],\n",
      "        [-0.4128],\n",
      "        [-0.5581],\n",
      "        [-1.5393],\n",
      "        [ 0.6264],\n",
      "        [-1.4554],\n",
      "        [ 0.4229],\n",
      "        [-0.4376],\n",
      "        [ 0.4229],\n",
      "        [ 1.2076],\n",
      "        [ 1.1702]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 223/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0252,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1788],\n",
      "        [-1.1788],\n",
      "        [ 0.6593],\n",
      "        [ 0.5930],\n",
      "        [-0.0469],\n",
      "        [ 0.4915],\n",
      "        [ 0.9070],\n",
      "        [ 0.9636],\n",
      "        [ 0.9070],\n",
      "        [ 0.8179],\n",
      "        [-1.5693],\n",
      "        [-0.8629],\n",
      "        [ 0.5594],\n",
      "        [-0.2266],\n",
      "        [ 0.9356],\n",
      "        [-0.2266],\n",
      "        [ 0.5594],\n",
      "        [-0.6066],\n",
      "        [-0.3094],\n",
      "        [ 0.8779],\n",
      "        [ 0.7558],\n",
      "        [ 0.7871],\n",
      "        [ 1.2078],\n",
      "        [ 1.2078],\n",
      "        [ 1.0691],\n",
      "        [-0.3094],\n",
      "        [-1.2195],\n",
      "        [ 1.0691],\n",
      "        [-1.4552],\n",
      "        [ 0.9636],\n",
      "        [-1.3335],\n",
      "        [ 0.5594],\n",
      "        [-0.2266],\n",
      "        [ 0.7558],\n",
      "        [ 0.5255],\n",
      "        [ 1.2078],\n",
      "        [ 0.7558],\n",
      "        [-0.6825],\n",
      "        [-0.1391],\n",
      "        [-1.0542],\n",
      "        [-1.1373],\n",
      "        [ 0.9636],\n",
      "        [-0.8629],\n",
      "        [ 0.6263],\n",
      "        [ 1.2078],\n",
      "        [-1.5819],\n",
      "        [ 0.0493],\n",
      "        [-0.4127],\n",
      "        [-1.3335],\n",
      "        [ 1.0176],\n",
      "        [-0.4127],\n",
      "        [-0.5582],\n",
      "        [-1.5391],\n",
      "        [ 0.6263],\n",
      "        [-1.4552],\n",
      "        [ 0.4229],\n",
      "        [-0.4375],\n",
      "        [ 0.4229],\n",
      "        [ 1.2078],\n",
      "        [ 1.1703]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 224/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0251,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6591],\n",
      "        [ 0.5929],\n",
      "        [-0.0468],\n",
      "        [ 0.4914],\n",
      "        [ 0.9069],\n",
      "        [ 0.9635],\n",
      "        [ 0.9069],\n",
      "        [ 0.8178],\n",
      "        [-1.5691],\n",
      "        [-0.8629],\n",
      "        [ 0.5593],\n",
      "        [-0.2265],\n",
      "        [ 0.9355],\n",
      "        [-0.2265],\n",
      "        [ 0.5593],\n",
      "        [-0.6066],\n",
      "        [-0.3092],\n",
      "        [ 0.8778],\n",
      "        [ 0.7557],\n",
      "        [ 0.7870],\n",
      "        [ 1.2079],\n",
      "        [ 1.2079],\n",
      "        [ 1.0690],\n",
      "        [-0.3092],\n",
      "        [-1.2192],\n",
      "        [ 1.0690],\n",
      "        [-1.4548],\n",
      "        [ 0.9635],\n",
      "        [-1.3331],\n",
      "        [ 0.5593],\n",
      "        [-0.2265],\n",
      "        [ 0.7557],\n",
      "        [ 0.5255],\n",
      "        [ 1.2079],\n",
      "        [ 0.7557],\n",
      "        [-0.6826],\n",
      "        [-0.1389],\n",
      "        [-1.0540],\n",
      "        [-1.1370],\n",
      "        [ 0.9635],\n",
      "        [-0.8629],\n",
      "        [ 0.6262],\n",
      "        [ 1.2079],\n",
      "        [-1.5818],\n",
      "        [ 0.0494],\n",
      "        [-0.4127],\n",
      "        [-1.3331],\n",
      "        [ 1.0175],\n",
      "        [-0.4127],\n",
      "        [-0.5582],\n",
      "        [-1.5389],\n",
      "        [ 0.6262],\n",
      "        [-1.4548],\n",
      "        [ 0.4228],\n",
      "        [-0.4375],\n",
      "        [ 0.4228],\n",
      "        [ 1.2079],\n",
      "        [ 1.1704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 225/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0250,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1782],\n",
      "        [-1.1782],\n",
      "        [ 0.6590],\n",
      "        [ 0.5928],\n",
      "        [-0.0467],\n",
      "        [ 0.4913],\n",
      "        [ 0.9068],\n",
      "        [ 0.9634],\n",
      "        [ 0.9068],\n",
      "        [ 0.8176],\n",
      "        [-1.5690],\n",
      "        [-0.8629],\n",
      "        [ 0.5592],\n",
      "        [-0.2264],\n",
      "        [ 0.9354],\n",
      "        [-0.2264],\n",
      "        [ 0.5592],\n",
      "        [-0.6066],\n",
      "        [-0.3091],\n",
      "        [ 0.8776],\n",
      "        [ 0.7555],\n",
      "        [ 0.7868],\n",
      "        [ 1.2079],\n",
      "        [ 1.2079],\n",
      "        [ 1.0690],\n",
      "        [-0.3091],\n",
      "        [-1.2189],\n",
      "        [ 1.0690],\n",
      "        [-1.4546],\n",
      "        [ 0.9634],\n",
      "        [-1.3327],\n",
      "        [ 0.5592],\n",
      "        [-0.2264],\n",
      "        [ 0.7555],\n",
      "        [ 0.5254],\n",
      "        [ 1.2079],\n",
      "        [ 0.7555],\n",
      "        [-0.6827],\n",
      "        [-0.1388],\n",
      "        [-1.0538],\n",
      "        [-1.1368],\n",
      "        [ 0.9634],\n",
      "        [-0.8629],\n",
      "        [ 0.6261],\n",
      "        [ 1.2079],\n",
      "        [-1.5818],\n",
      "        [ 0.0495],\n",
      "        [-0.4126],\n",
      "        [-1.3327],\n",
      "        [ 1.0174],\n",
      "        [-0.4126],\n",
      "        [-0.5582],\n",
      "        [-1.5388],\n",
      "        [ 0.6261],\n",
      "        [-1.4546],\n",
      "        [ 0.4228],\n",
      "        [-0.4374],\n",
      "        [ 0.4228],\n",
      "        [ 1.2079],\n",
      "        [ 1.1704]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 226/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0249,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6589],\n",
      "        [ 0.5927],\n",
      "        [-0.0466],\n",
      "        [ 0.4913],\n",
      "        [ 0.9067],\n",
      "        [ 0.9633],\n",
      "        [ 0.9067],\n",
      "        [ 0.8175],\n",
      "        [-1.5691],\n",
      "        [-0.8631],\n",
      "        [ 0.5591],\n",
      "        [-0.2263],\n",
      "        [ 0.9353],\n",
      "        [-0.2263],\n",
      "        [ 0.5591],\n",
      "        [-0.6067],\n",
      "        [-0.3090],\n",
      "        [ 0.8775],\n",
      "        [ 0.7554],\n",
      "        [ 0.7867],\n",
      "        [ 1.2081],\n",
      "        [ 1.2081],\n",
      "        [ 1.0690],\n",
      "        [-0.3090],\n",
      "        [-1.2188],\n",
      "        [ 1.0690],\n",
      "        [-1.4545],\n",
      "        [ 0.9633],\n",
      "        [-1.3326],\n",
      "        [ 0.5591],\n",
      "        [-0.2263],\n",
      "        [ 0.7554],\n",
      "        [ 0.5253],\n",
      "        [ 1.2081],\n",
      "        [ 0.7554],\n",
      "        [-0.6828],\n",
      "        [-0.1387],\n",
      "        [-1.0539],\n",
      "        [-1.1368],\n",
      "        [ 0.9633],\n",
      "        [-0.8631],\n",
      "        [ 0.6260],\n",
      "        [ 1.2081],\n",
      "        [-1.5819],\n",
      "        [ 0.0495],\n",
      "        [-0.4126],\n",
      "        [-1.3326],\n",
      "        [ 1.0174],\n",
      "        [-0.4126],\n",
      "        [-0.5582],\n",
      "        [-1.5388],\n",
      "        [ 0.6260],\n",
      "        [-1.4545],\n",
      "        [ 0.4227],\n",
      "        [-0.4374],\n",
      "        [ 0.4227],\n",
      "        [ 1.2081],\n",
      "        [ 1.1705]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 227/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0249,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1782],\n",
      "        [-1.1782],\n",
      "        [ 0.6589],\n",
      "        [ 0.5927],\n",
      "        [-0.0465],\n",
      "        [ 0.4913],\n",
      "        [ 0.9067],\n",
      "        [ 0.9633],\n",
      "        [ 0.9067],\n",
      "        [ 0.8175],\n",
      "        [-1.5694],\n",
      "        [-0.8633],\n",
      "        [ 0.5591],\n",
      "        [-0.2262],\n",
      "        [ 0.9353],\n",
      "        [-0.2262],\n",
      "        [ 0.5591],\n",
      "        [-0.6069],\n",
      "        [-0.3090],\n",
      "        [ 0.8775],\n",
      "        [ 0.7554],\n",
      "        [ 0.7867],\n",
      "        [ 1.2082],\n",
      "        [ 1.2082],\n",
      "        [ 1.0690],\n",
      "        [-0.3090],\n",
      "        [-1.2189],\n",
      "        [ 1.0690],\n",
      "        [-1.4546],\n",
      "        [ 0.9633],\n",
      "        [-1.3327],\n",
      "        [ 0.5591],\n",
      "        [-0.2262],\n",
      "        [ 0.7554],\n",
      "        [ 0.5253],\n",
      "        [ 1.2082],\n",
      "        [ 0.7554],\n",
      "        [-0.6830],\n",
      "        [-0.1386],\n",
      "        [-1.0540],\n",
      "        [-1.1369],\n",
      "        [ 0.9633],\n",
      "        [-0.8633],\n",
      "        [ 0.6259],\n",
      "        [ 1.2082],\n",
      "        [-1.5822],\n",
      "        [ 0.0496],\n",
      "        [-0.4125],\n",
      "        [-1.3327],\n",
      "        [ 1.0174],\n",
      "        [-0.4125],\n",
      "        [-0.5583],\n",
      "        [-1.5390],\n",
      "        [ 0.6259],\n",
      "        [-1.4546],\n",
      "        [ 0.4228],\n",
      "        [-0.4374],\n",
      "        [ 0.4228],\n",
      "        [ 1.2082],\n",
      "        [ 1.1706]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 228/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0248,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6589],\n",
      "        [ 0.5927],\n",
      "        [-0.0464],\n",
      "        [ 0.4913],\n",
      "        [ 0.9068],\n",
      "        [ 0.9634],\n",
      "        [ 0.9068],\n",
      "        [ 0.8175],\n",
      "        [-1.5698],\n",
      "        [-0.8636],\n",
      "        [ 0.5591],\n",
      "        [-0.2260],\n",
      "        [ 0.9354],\n",
      "        [-0.2260],\n",
      "        [ 0.5591],\n",
      "        [-0.6070],\n",
      "        [-0.3089],\n",
      "        [ 0.8776],\n",
      "        [ 0.7554],\n",
      "        [ 0.7867],\n",
      "        [ 1.2085],\n",
      "        [ 1.2085],\n",
      "        [ 1.0691],\n",
      "        [-0.3089],\n",
      "        [-1.2191],\n",
      "        [ 1.0691],\n",
      "        [-1.4548],\n",
      "        [ 0.9634],\n",
      "        [-1.3328],\n",
      "        [ 0.5591],\n",
      "        [-0.2260],\n",
      "        [ 0.7554],\n",
      "        [ 0.5253],\n",
      "        [ 1.2085],\n",
      "        [ 0.7554],\n",
      "        [-0.6832],\n",
      "        [-0.1385],\n",
      "        [-1.0543],\n",
      "        [-1.1371],\n",
      "        [ 0.9634],\n",
      "        [-0.8636],\n",
      "        [ 0.6260],\n",
      "        [ 1.2085],\n",
      "        [-1.5826],\n",
      "        [ 0.0498],\n",
      "        [-0.4125],\n",
      "        [-1.3328],\n",
      "        [ 1.0175],\n",
      "        [-0.4125],\n",
      "        [-0.5584],\n",
      "        [-1.5393],\n",
      "        [ 0.6260],\n",
      "        [-1.4548],\n",
      "        [ 0.4228],\n",
      "        [-0.4374],\n",
      "        [ 0.4228],\n",
      "        [ 1.2085],\n",
      "        [ 1.1708]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 229/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0248,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1785],\n",
      "        [-1.1785],\n",
      "        [ 0.6589],\n",
      "        [ 0.5927],\n",
      "        [-0.0462],\n",
      "        [ 0.4913],\n",
      "        [ 0.9068],\n",
      "        [ 0.9634],\n",
      "        [ 0.9068],\n",
      "        [ 0.8175],\n",
      "        [-1.5700],\n",
      "        [-0.8639],\n",
      "        [ 0.5592],\n",
      "        [-0.2259],\n",
      "        [ 0.9354],\n",
      "        [-0.2259],\n",
      "        [ 0.5592],\n",
      "        [-0.6071],\n",
      "        [-0.3088],\n",
      "        [ 0.8776],\n",
      "        [ 0.7554],\n",
      "        [ 0.7867],\n",
      "        [ 1.2086],\n",
      "        [ 1.2086],\n",
      "        [ 1.0692],\n",
      "        [-0.3088],\n",
      "        [-1.2192],\n",
      "        [ 1.0692],\n",
      "        [-1.4549],\n",
      "        [ 0.9634],\n",
      "        [-1.3329],\n",
      "        [ 0.5592],\n",
      "        [-0.2259],\n",
      "        [ 0.7554],\n",
      "        [ 0.5254],\n",
      "        [ 1.2086],\n",
      "        [ 0.7554],\n",
      "        [-0.6834],\n",
      "        [-0.1383],\n",
      "        [-1.0544],\n",
      "        [-1.1372],\n",
      "        [ 0.9634],\n",
      "        [-0.8639],\n",
      "        [ 0.6260],\n",
      "        [ 1.2086],\n",
      "        [-1.5829],\n",
      "        [ 0.0499],\n",
      "        [-0.4125],\n",
      "        [-1.3329],\n",
      "        [ 1.0176],\n",
      "        [-0.4125],\n",
      "        [-0.5585],\n",
      "        [-1.5396],\n",
      "        [ 0.6260],\n",
      "        [-1.4549],\n",
      "        [ 0.4229],\n",
      "        [-0.4374],\n",
      "        [ 0.4229],\n",
      "        [ 1.2086],\n",
      "        [ 1.1709]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 230/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0247,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1785],\n",
      "        [-1.1785],\n",
      "        [ 0.6589],\n",
      "        [ 0.5927],\n",
      "        [-0.0461],\n",
      "        [ 0.4913],\n",
      "        [ 0.9067],\n",
      "        [ 0.9633],\n",
      "        [ 0.9067],\n",
      "        [ 0.8175],\n",
      "        [-1.5702],\n",
      "        [-0.8640],\n",
      "        [ 0.5591],\n",
      "        [-0.2258],\n",
      "        [ 0.9353],\n",
      "        [-0.2258],\n",
      "        [ 0.5591],\n",
      "        [-0.6072],\n",
      "        [-0.3087],\n",
      "        [ 0.8775],\n",
      "        [ 0.7554],\n",
      "        [ 0.7867],\n",
      "        [ 1.2088],\n",
      "        [ 1.2088],\n",
      "        [ 1.0692],\n",
      "        [-0.3087],\n",
      "        [-1.2192],\n",
      "        [ 1.0692],\n",
      "        [-1.4549],\n",
      "        [ 0.9633],\n",
      "        [-1.3329],\n",
      "        [ 0.5591],\n",
      "        [-0.2258],\n",
      "        [ 0.7554],\n",
      "        [ 0.5253],\n",
      "        [ 1.2088],\n",
      "        [ 0.7554],\n",
      "        [-0.6835],\n",
      "        [-0.1382],\n",
      "        [-1.0545],\n",
      "        [-1.1372],\n",
      "        [ 0.9633],\n",
      "        [-0.8640],\n",
      "        [ 0.6259],\n",
      "        [ 1.2088],\n",
      "        [-1.5831],\n",
      "        [ 0.0500],\n",
      "        [-0.4124],\n",
      "        [-1.3329],\n",
      "        [ 1.0175],\n",
      "        [-0.4124],\n",
      "        [-0.5586],\n",
      "        [-1.5396],\n",
      "        [ 0.6259],\n",
      "        [-1.4549],\n",
      "        [ 0.4229],\n",
      "        [-0.4373],\n",
      "        [ 0.4229],\n",
      "        [ 1.2088],\n",
      "        [ 1.1710]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 231/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0246,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6587],\n",
      "        [ 0.5926],\n",
      "        [-0.0460],\n",
      "        [ 0.4913],\n",
      "        [ 0.9066],\n",
      "        [ 0.9632],\n",
      "        [ 0.9066],\n",
      "        [ 0.8173],\n",
      "        [-1.5702],\n",
      "        [-0.8641],\n",
      "        [ 0.5590],\n",
      "        [-0.2256],\n",
      "        [ 0.9352],\n",
      "        [-0.2256],\n",
      "        [ 0.5590],\n",
      "        [-0.6073],\n",
      "        [-0.3086],\n",
      "        [ 0.8774],\n",
      "        [ 0.7552],\n",
      "        [ 0.7865],\n",
      "        [ 1.2088],\n",
      "        [ 1.2088],\n",
      "        [ 1.0692],\n",
      "        [-0.3086],\n",
      "        [-1.2190],\n",
      "        [ 1.0692],\n",
      "        [-1.4548],\n",
      "        [ 0.9632],\n",
      "        [-1.3327],\n",
      "        [ 0.5590],\n",
      "        [-0.2256],\n",
      "        [ 0.7552],\n",
      "        [ 0.5252],\n",
      "        [ 1.2088],\n",
      "        [ 0.7552],\n",
      "        [-0.6836],\n",
      "        [-0.1381],\n",
      "        [-1.0545],\n",
      "        [-1.1372],\n",
      "        [ 0.9632],\n",
      "        [-0.8641],\n",
      "        [ 0.6258],\n",
      "        [ 1.2088],\n",
      "        [-1.5831],\n",
      "        [ 0.0501],\n",
      "        [-0.4123],\n",
      "        [-1.3327],\n",
      "        [ 1.0175],\n",
      "        [-0.4123],\n",
      "        [-0.5586],\n",
      "        [-1.5396],\n",
      "        [ 0.6258],\n",
      "        [-1.4548],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2088],\n",
      "        [ 1.1710]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 232/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0245,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6586],\n",
      "        [ 0.5925],\n",
      "        [-0.0458],\n",
      "        [ 0.4912],\n",
      "        [ 0.9065],\n",
      "        [ 0.9631],\n",
      "        [ 0.9065],\n",
      "        [ 0.8172],\n",
      "        [-1.5701],\n",
      "        [-0.8642],\n",
      "        [ 0.5590],\n",
      "        [-0.2255],\n",
      "        [ 0.9351],\n",
      "        [-0.2255],\n",
      "        [ 0.5590],\n",
      "        [-0.6073],\n",
      "        [-0.3084],\n",
      "        [ 0.8773],\n",
      "        [ 0.7551],\n",
      "        [ 0.7864],\n",
      "        [ 1.2089],\n",
      "        [ 1.2089],\n",
      "        [ 1.0691],\n",
      "        [-0.3084],\n",
      "        [-1.2188],\n",
      "        [ 1.0691],\n",
      "        [-1.4545],\n",
      "        [ 0.9631],\n",
      "        [-1.3324],\n",
      "        [ 0.5590],\n",
      "        [-0.2255],\n",
      "        [ 0.7551],\n",
      "        [ 0.5252],\n",
      "        [ 1.2089],\n",
      "        [ 0.7551],\n",
      "        [-0.6837],\n",
      "        [-0.1379],\n",
      "        [-1.0545],\n",
      "        [-1.1370],\n",
      "        [ 0.9631],\n",
      "        [-0.8642],\n",
      "        [ 0.6257],\n",
      "        [ 1.2089],\n",
      "        [-1.5830],\n",
      "        [ 0.0503],\n",
      "        [-0.4122],\n",
      "        [-1.3324],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5585],\n",
      "        [-1.5394],\n",
      "        [ 0.6257],\n",
      "        [-1.4545],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2089],\n",
      "        [ 1.1711]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 233/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0245,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6586],\n",
      "        [ 0.5924],\n",
      "        [-0.0457],\n",
      "        [ 0.4912],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8171],\n",
      "        [-1.5700],\n",
      "        [-0.8643],\n",
      "        [ 0.5589],\n",
      "        [-0.2253],\n",
      "        [ 0.9350],\n",
      "        [-0.2253],\n",
      "        [ 0.5589],\n",
      "        [-0.6073],\n",
      "        [-0.3083],\n",
      "        [ 0.8772],\n",
      "        [ 0.7550],\n",
      "        [ 0.7863],\n",
      "        [ 1.2090],\n",
      "        [ 1.2090],\n",
      "        [ 1.0691],\n",
      "        [-0.3083],\n",
      "        [-1.2187],\n",
      "        [ 1.0691],\n",
      "        [-1.4543],\n",
      "        [ 0.9631],\n",
      "        [-1.3322],\n",
      "        [ 0.5589],\n",
      "        [-0.2253],\n",
      "        [ 0.7550],\n",
      "        [ 0.5251],\n",
      "        [ 1.2090],\n",
      "        [ 0.7550],\n",
      "        [-0.6838],\n",
      "        [-0.1378],\n",
      "        [-1.0544],\n",
      "        [-1.1370],\n",
      "        [ 0.9631],\n",
      "        [-0.8643],\n",
      "        [ 0.6257],\n",
      "        [ 1.2090],\n",
      "        [-1.5830],\n",
      "        [ 0.0504],\n",
      "        [-0.4121],\n",
      "        [-1.3322],\n",
      "        [ 1.0174],\n",
      "        [-0.4121],\n",
      "        [-0.5586],\n",
      "        [-1.5393],\n",
      "        [ 0.6257],\n",
      "        [-1.4543],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2090],\n",
      "        [ 1.1711]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 234/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0244,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6585],\n",
      "        [ 0.5924],\n",
      "        [-0.0456],\n",
      "        [ 0.4912],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8171],\n",
      "        [-1.5701],\n",
      "        [-0.8645],\n",
      "        [ 0.5589],\n",
      "        [-0.2253],\n",
      "        [ 0.9350],\n",
      "        [-0.2253],\n",
      "        [ 0.5589],\n",
      "        [-0.6074],\n",
      "        [-0.3082],\n",
      "        [ 0.8772],\n",
      "        [ 0.7550],\n",
      "        [ 0.7863],\n",
      "        [ 1.2091],\n",
      "        [ 1.2091],\n",
      "        [ 1.0691],\n",
      "        [-0.3082],\n",
      "        [-1.2187],\n",
      "        [ 1.0691],\n",
      "        [-1.4543],\n",
      "        [ 0.9631],\n",
      "        [-1.3322],\n",
      "        [ 0.5589],\n",
      "        [-0.2253],\n",
      "        [ 0.7550],\n",
      "        [ 0.5251],\n",
      "        [ 1.2091],\n",
      "        [ 0.7550],\n",
      "        [-0.6839],\n",
      "        [-0.1377],\n",
      "        [-1.0545],\n",
      "        [-1.1370],\n",
      "        [ 0.9631],\n",
      "        [-0.8645],\n",
      "        [ 0.6256],\n",
      "        [ 1.2091],\n",
      "        [-1.5830],\n",
      "        [ 0.0505],\n",
      "        [-0.4121],\n",
      "        [-1.3322],\n",
      "        [ 1.0174],\n",
      "        [-0.4121],\n",
      "        [-0.5587],\n",
      "        [-1.5393],\n",
      "        [ 0.6256],\n",
      "        [-1.4543],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2091],\n",
      "        [ 1.1712]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 235/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0243,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6585],\n",
      "        [ 0.5924],\n",
      "        [-0.0455],\n",
      "        [ 0.4912],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8171],\n",
      "        [-1.5702],\n",
      "        [-0.8648],\n",
      "        [ 0.5589],\n",
      "        [-0.2252],\n",
      "        [ 0.9350],\n",
      "        [-0.2252],\n",
      "        [ 0.5589],\n",
      "        [-0.6076],\n",
      "        [-0.3082],\n",
      "        [ 0.8772],\n",
      "        [ 0.7550],\n",
      "        [ 0.7863],\n",
      "        [ 1.2093],\n",
      "        [ 1.2093],\n",
      "        [ 1.0692],\n",
      "        [-0.3082],\n",
      "        [-1.2187],\n",
      "        [ 1.0692],\n",
      "        [-1.4543],\n",
      "        [ 0.9631],\n",
      "        [-1.3322],\n",
      "        [ 0.5589],\n",
      "        [-0.2252],\n",
      "        [ 0.7550],\n",
      "        [ 0.5251],\n",
      "        [ 1.2093],\n",
      "        [ 0.7550],\n",
      "        [-0.6842],\n",
      "        [-0.1376],\n",
      "        [-1.0547],\n",
      "        [-1.1371],\n",
      "        [ 0.9631],\n",
      "        [-0.8648],\n",
      "        [ 0.6256],\n",
      "        [ 1.2093],\n",
      "        [-1.5832],\n",
      "        [ 0.0505],\n",
      "        [-0.4122],\n",
      "        [-1.3322],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5588],\n",
      "        [-1.5394],\n",
      "        [ 0.6256],\n",
      "        [-1.4543],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2093],\n",
      "        [ 1.1714]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 236/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0243,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6585],\n",
      "        [ 0.5924],\n",
      "        [-0.0455],\n",
      "        [ 0.4911],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8171],\n",
      "        [-1.5704],\n",
      "        [-0.8651],\n",
      "        [ 0.5588],\n",
      "        [-0.2252],\n",
      "        [ 0.9350],\n",
      "        [-0.2252],\n",
      "        [ 0.5588],\n",
      "        [-0.6079],\n",
      "        [-0.3082],\n",
      "        [ 0.8772],\n",
      "        [ 0.7550],\n",
      "        [ 0.7862],\n",
      "        [ 1.2095],\n",
      "        [ 1.2095],\n",
      "        [ 1.0693],\n",
      "        [-0.3082],\n",
      "        [-1.2188],\n",
      "        [ 1.0693],\n",
      "        [-1.4543],\n",
      "        [ 0.9631],\n",
      "        [-1.3322],\n",
      "        [ 0.5588],\n",
      "        [-0.2252],\n",
      "        [ 0.7550],\n",
      "        [ 0.5251],\n",
      "        [ 1.2095],\n",
      "        [ 0.7550],\n",
      "        [-0.6845],\n",
      "        [-0.1376],\n",
      "        [-1.0549],\n",
      "        [-1.1373],\n",
      "        [ 0.9631],\n",
      "        [-0.8651],\n",
      "        [ 0.6256],\n",
      "        [ 1.2095],\n",
      "        [-1.5834],\n",
      "        [ 0.0506],\n",
      "        [-0.4122],\n",
      "        [-1.3322],\n",
      "        [ 1.0175],\n",
      "        [-0.4122],\n",
      "        [-0.5590],\n",
      "        [-1.5395],\n",
      "        [ 0.6256],\n",
      "        [-1.4543],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2095],\n",
      "        [ 1.1715]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 237/10000,\n",
      " train_loss: 0.0009,\n",
      " train_mae: 0.0242,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6585],\n",
      "        [ 0.5923],\n",
      "        [-0.0454],\n",
      "        [ 0.4911],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8170],\n",
      "        [-1.5705],\n",
      "        [-0.8653],\n",
      "        [ 0.5588],\n",
      "        [-0.2251],\n",
      "        [ 0.9351],\n",
      "        [-0.2251],\n",
      "        [ 0.5588],\n",
      "        [-0.6080],\n",
      "        [-0.3082],\n",
      "        [ 0.8772],\n",
      "        [ 0.7549],\n",
      "        [ 0.7862],\n",
      "        [ 1.2097],\n",
      "        [ 1.2097],\n",
      "        [ 1.0694],\n",
      "        [-0.3082],\n",
      "        [-1.2189],\n",
      "        [ 1.0694],\n",
      "        [-1.4543],\n",
      "        [ 0.9631],\n",
      "        [-1.3322],\n",
      "        [ 0.5588],\n",
      "        [-0.2251],\n",
      "        [ 0.7549],\n",
      "        [ 0.5251],\n",
      "        [ 1.2097],\n",
      "        [ 0.7549],\n",
      "        [-0.6847],\n",
      "        [-0.1375],\n",
      "        [-1.0551],\n",
      "        [-1.1374],\n",
      "        [ 0.9631],\n",
      "        [-0.8653],\n",
      "        [ 0.6256],\n",
      "        [ 1.2097],\n",
      "        [-1.5835],\n",
      "        [ 0.0506],\n",
      "        [-0.4123],\n",
      "        [-1.3322],\n",
      "        [ 1.0175],\n",
      "        [-0.4123],\n",
      "        [-0.5591],\n",
      "        [-1.5396],\n",
      "        [ 0.6256],\n",
      "        [-1.4543],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2097],\n",
      "        [ 1.1717]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 238/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0242,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1784],\n",
      "        [-1.1784],\n",
      "        [ 0.6584],\n",
      "        [ 0.5923],\n",
      "        [-0.0453],\n",
      "        [ 0.4911],\n",
      "        [ 0.9064],\n",
      "        [ 0.9631],\n",
      "        [ 0.9064],\n",
      "        [ 0.8170],\n",
      "        [-1.5704],\n",
      "        [-0.8655],\n",
      "        [ 0.5588],\n",
      "        [-0.2251],\n",
      "        [ 0.9350],\n",
      "        [-0.2251],\n",
      "        [ 0.5588],\n",
      "        [-0.6082],\n",
      "        [-0.3081],\n",
      "        [ 0.8771],\n",
      "        [ 0.7549],\n",
      "        [ 0.7862],\n",
      "        [ 1.2098],\n",
      "        [ 1.2098],\n",
      "        [ 1.0694],\n",
      "        [-0.3081],\n",
      "        [-1.2188],\n",
      "        [ 1.0694],\n",
      "        [-1.4542],\n",
      "        [ 0.9631],\n",
      "        [-1.3320],\n",
      "        [ 0.5588],\n",
      "        [-0.2251],\n",
      "        [ 0.7549],\n",
      "        [ 0.5251],\n",
      "        [ 1.2098],\n",
      "        [ 0.7549],\n",
      "        [-0.6849],\n",
      "        [-0.1374],\n",
      "        [-1.0551],\n",
      "        [-1.1373],\n",
      "        [ 0.9631],\n",
      "        [-0.8655],\n",
      "        [ 0.6255],\n",
      "        [ 1.2098],\n",
      "        [-1.5835],\n",
      "        [ 0.0507],\n",
      "        [-0.4123],\n",
      "        [-1.3320],\n",
      "        [ 1.0175],\n",
      "        [-0.4123],\n",
      "        [-0.5592],\n",
      "        [-1.5395],\n",
      "        [ 0.6255],\n",
      "        [-1.4542],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2098],\n",
      "        [ 1.1718]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 239/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0241,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6583],\n",
      "        [ 0.5922],\n",
      "        [-0.0452],\n",
      "        [ 0.4911],\n",
      "        [ 0.9063],\n",
      "        [ 0.9631],\n",
      "        [ 0.9063],\n",
      "        [ 0.8169],\n",
      "        [-1.5703],\n",
      "        [-0.8656],\n",
      "        [ 0.5587],\n",
      "        [-0.2250],\n",
      "        [ 0.9350],\n",
      "        [-0.2250],\n",
      "        [ 0.5587],\n",
      "        [-0.6083],\n",
      "        [-0.3081],\n",
      "        [ 0.8770],\n",
      "        [ 0.7548],\n",
      "        [ 0.7861],\n",
      "        [ 1.2099],\n",
      "        [ 1.2099],\n",
      "        [ 1.0694],\n",
      "        [-0.3081],\n",
      "        [-1.2186],\n",
      "        [ 1.0694],\n",
      "        [-1.4540],\n",
      "        [ 0.9631],\n",
      "        [-1.3318],\n",
      "        [ 0.5587],\n",
      "        [-0.2250],\n",
      "        [ 0.7548],\n",
      "        [ 0.5250],\n",
      "        [ 1.2099],\n",
      "        [ 0.7548],\n",
      "        [-0.6850],\n",
      "        [-0.1373],\n",
      "        [-1.0551],\n",
      "        [-1.1373],\n",
      "        [ 0.9631],\n",
      "        [-0.8656],\n",
      "        [ 0.6254],\n",
      "        [ 1.2099],\n",
      "        [-1.5834],\n",
      "        [ 0.0508],\n",
      "        [-0.4122],\n",
      "        [-1.3318],\n",
      "        [ 1.0175],\n",
      "        [-0.4122],\n",
      "        [-0.5593],\n",
      "        [-1.5394],\n",
      "        [ 0.6254],\n",
      "        [-1.4540],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2099],\n",
      "        [ 1.1719]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 240/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0240,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6582],\n",
      "        [ 0.5921],\n",
      "        [-0.0451],\n",
      "        [ 0.4910],\n",
      "        [ 0.9062],\n",
      "        [ 0.9630],\n",
      "        [ 0.9062],\n",
      "        [ 0.8168],\n",
      "        [-1.5703],\n",
      "        [-0.8658],\n",
      "        [ 0.5587],\n",
      "        [-0.2249],\n",
      "        [ 0.9349],\n",
      "        [-0.2249],\n",
      "        [ 0.5587],\n",
      "        [-0.6083],\n",
      "        [-0.3080],\n",
      "        [ 0.8769],\n",
      "        [ 0.7547],\n",
      "        [ 0.7860],\n",
      "        [ 1.2100],\n",
      "        [ 1.2100],\n",
      "        [ 1.0694],\n",
      "        [-0.3080],\n",
      "        [-1.2185],\n",
      "        [ 1.0694],\n",
      "        [-1.4538],\n",
      "        [ 0.9630],\n",
      "        [-1.3316],\n",
      "        [ 0.5587],\n",
      "        [-0.2249],\n",
      "        [ 0.7547],\n",
      "        [ 0.5249],\n",
      "        [ 1.2100],\n",
      "        [ 0.7547],\n",
      "        [-0.6851],\n",
      "        [-0.1372],\n",
      "        [-1.0551],\n",
      "        [-1.1372],\n",
      "        [ 0.9630],\n",
      "        [-0.8658],\n",
      "        [ 0.6254],\n",
      "        [ 1.2100],\n",
      "        [-1.5834],\n",
      "        [ 0.0509],\n",
      "        [-0.4122],\n",
      "        [-1.3316],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5593],\n",
      "        [-1.5393],\n",
      "        [ 0.6254],\n",
      "        [-1.4538],\n",
      "        [ 0.4227],\n",
      "        [-0.4372],\n",
      "        [ 0.4227],\n",
      "        [ 1.2100],\n",
      "        [ 1.1719]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 241/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0240,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6582],\n",
      "        [ 0.5921],\n",
      "        [-0.0450],\n",
      "        [ 0.4910],\n",
      "        [ 0.9061],\n",
      "        [ 0.9630],\n",
      "        [ 0.9061],\n",
      "        [ 0.8167],\n",
      "        [-1.5703],\n",
      "        [-0.8659],\n",
      "        [ 0.5586],\n",
      "        [-0.2248],\n",
      "        [ 0.9348],\n",
      "        [-0.2248],\n",
      "        [ 0.5586],\n",
      "        [-0.6085],\n",
      "        [-0.3079],\n",
      "        [ 0.8769],\n",
      "        [ 0.7546],\n",
      "        [ 0.7859],\n",
      "        [ 1.2101],\n",
      "        [ 1.2101],\n",
      "        [ 1.0694],\n",
      "        [-0.3079],\n",
      "        [-1.2184],\n",
      "        [ 1.0694],\n",
      "        [-1.4536],\n",
      "        [ 0.9630],\n",
      "        [-1.3315],\n",
      "        [ 0.5586],\n",
      "        [-0.2248],\n",
      "        [ 0.7546],\n",
      "        [ 0.5249],\n",
      "        [ 1.2101],\n",
      "        [ 0.7546],\n",
      "        [-0.6853],\n",
      "        [-0.1371],\n",
      "        [-1.0552],\n",
      "        [-1.1372],\n",
      "        [ 0.9630],\n",
      "        [-0.8659],\n",
      "        [ 0.6253],\n",
      "        [ 1.2101],\n",
      "        [-1.5834],\n",
      "        [ 0.0509],\n",
      "        [-0.4122],\n",
      "        [-1.3315],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5594],\n",
      "        [-1.5392],\n",
      "        [ 0.6253],\n",
      "        [-1.4536],\n",
      "        [ 0.4227],\n",
      "        [-0.4372],\n",
      "        [ 0.4227],\n",
      "        [ 1.2101],\n",
      "        [ 1.1720]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 242/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0239,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6582],\n",
      "        [ 0.5921],\n",
      "        [-0.0449],\n",
      "        [ 0.4910],\n",
      "        [ 0.9061],\n",
      "        [ 0.9630],\n",
      "        [ 0.9061],\n",
      "        [ 0.8167],\n",
      "        [-1.5704],\n",
      "        [-0.8662],\n",
      "        [ 0.5586],\n",
      "        [-0.2247],\n",
      "        [ 0.9348],\n",
      "        [-0.2247],\n",
      "        [ 0.5586],\n",
      "        [-0.6086],\n",
      "        [-0.3079],\n",
      "        [ 0.8769],\n",
      "        [ 0.7546],\n",
      "        [ 0.7859],\n",
      "        [ 1.2103],\n",
      "        [ 1.2103],\n",
      "        [ 1.0694],\n",
      "        [-0.3079],\n",
      "        [-1.2184],\n",
      "        [ 1.0694],\n",
      "        [-1.4536],\n",
      "        [ 0.9630],\n",
      "        [-1.3315],\n",
      "        [ 0.5586],\n",
      "        [-0.2247],\n",
      "        [ 0.7546],\n",
      "        [ 0.5249],\n",
      "        [ 1.2103],\n",
      "        [ 0.7546],\n",
      "        [-0.6855],\n",
      "        [-0.1370],\n",
      "        [-1.0553],\n",
      "        [-1.1372],\n",
      "        [ 0.9630],\n",
      "        [-0.8662],\n",
      "        [ 0.6253],\n",
      "        [ 1.2103],\n",
      "        [-1.5836],\n",
      "        [ 0.0510],\n",
      "        [-0.4122],\n",
      "        [-1.3315],\n",
      "        [ 1.0174],\n",
      "        [-0.4122],\n",
      "        [-0.5595],\n",
      "        [-1.5393],\n",
      "        [ 0.6253],\n",
      "        [-1.4536],\n",
      "        [ 0.4227],\n",
      "        [-0.4372],\n",
      "        [ 0.4227],\n",
      "        [ 1.2103],\n",
      "        [ 1.1721]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 243/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0239,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1782],\n",
      "        [-1.1782],\n",
      "        [ 0.6581],\n",
      "        [ 0.5921],\n",
      "        [-0.0448],\n",
      "        [ 0.4910],\n",
      "        [ 0.9061],\n",
      "        [ 0.9630],\n",
      "        [ 0.9061],\n",
      "        [ 0.8167],\n",
      "        [-1.5706],\n",
      "        [-0.8664],\n",
      "        [ 0.5586],\n",
      "        [-0.2246],\n",
      "        [ 0.9348],\n",
      "        [-0.2246],\n",
      "        [ 0.5586],\n",
      "        [-0.6087],\n",
      "        [-0.3078],\n",
      "        [ 0.8769],\n",
      "        [ 0.7546],\n",
      "        [ 0.7859],\n",
      "        [ 1.2104],\n",
      "        [ 1.2104],\n",
      "        [ 1.0695],\n",
      "        [-0.3078],\n",
      "        [-1.2185],\n",
      "        [ 1.0695],\n",
      "        [-1.4536],\n",
      "        [ 0.9630],\n",
      "        [-1.3315],\n",
      "        [ 0.5586],\n",
      "        [-0.2246],\n",
      "        [ 0.7546],\n",
      "        [ 0.5249],\n",
      "        [ 1.2104],\n",
      "        [ 0.7546],\n",
      "        [-0.6857],\n",
      "        [-0.1369],\n",
      "        [-1.0554],\n",
      "        [-1.1373],\n",
      "        [ 0.9630],\n",
      "        [-0.8664],\n",
      "        [ 0.6253],\n",
      "        [ 1.2104],\n",
      "        [-1.5838],\n",
      "        [ 0.0511],\n",
      "        [-0.4122],\n",
      "        [-1.3315],\n",
      "        [ 1.0175],\n",
      "        [-0.4122],\n",
      "        [-0.5596],\n",
      "        [-1.5394],\n",
      "        [ 0.6253],\n",
      "        [-1.4536],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2104],\n",
      "        [ 1.1722]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 244/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0238,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6581],\n",
      "        [ 0.5921],\n",
      "        [-0.0447],\n",
      "        [ 0.4910],\n",
      "        [ 0.9061],\n",
      "        [ 0.9630],\n",
      "        [ 0.9061],\n",
      "        [ 0.8167],\n",
      "        [-1.5707],\n",
      "        [-0.8666],\n",
      "        [ 0.5586],\n",
      "        [-0.2245],\n",
      "        [ 0.9348],\n",
      "        [-0.2245],\n",
      "        [ 0.5586],\n",
      "        [-0.6089],\n",
      "        [-0.3078],\n",
      "        [ 0.8768],\n",
      "        [ 0.7545],\n",
      "        [ 0.7858],\n",
      "        [ 1.2106],\n",
      "        [ 1.2106],\n",
      "        [ 1.0695],\n",
      "        [-0.3078],\n",
      "        [-1.2185],\n",
      "        [ 1.0695],\n",
      "        [-1.4537],\n",
      "        [ 0.9630],\n",
      "        [-1.3315],\n",
      "        [ 0.5586],\n",
      "        [-0.2245],\n",
      "        [ 0.7545],\n",
      "        [ 0.5249],\n",
      "        [ 1.2106],\n",
      "        [ 0.7545],\n",
      "        [-0.6858],\n",
      "        [-0.1368],\n",
      "        [-1.0556],\n",
      "        [-1.1374],\n",
      "        [ 0.9630],\n",
      "        [-0.8666],\n",
      "        [ 0.6252],\n",
      "        [ 1.2106],\n",
      "        [-1.5839],\n",
      "        [ 0.0512],\n",
      "        [-0.4121],\n",
      "        [-1.3315],\n",
      "        [ 1.0175],\n",
      "        [-0.4121],\n",
      "        [-0.5597],\n",
      "        [-1.5395],\n",
      "        [ 0.6252],\n",
      "        [-1.4537],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2106],\n",
      "        [ 1.1724]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 245/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0238,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1783],\n",
      "        [-1.1783],\n",
      "        [ 0.6581],\n",
      "        [ 0.5920],\n",
      "        [-0.0446],\n",
      "        [ 0.4910],\n",
      "        [ 0.9061],\n",
      "        [ 0.9629],\n",
      "        [ 0.9061],\n",
      "        [ 0.8166],\n",
      "        [-1.5708],\n",
      "        [-0.8668],\n",
      "        [ 0.5586],\n",
      "        [-0.2244],\n",
      "        [ 0.9348],\n",
      "        [-0.2244],\n",
      "        [ 0.5586],\n",
      "        [-0.6090],\n",
      "        [-0.3077],\n",
      "        [ 0.8768],\n",
      "        [ 0.7545],\n",
      "        [ 0.7858],\n",
      "        [ 1.2107],\n",
      "        [ 1.2107],\n",
      "        [ 1.0695],\n",
      "        [-0.3077],\n",
      "        [-1.2185],\n",
      "        [ 1.0695],\n",
      "        [-1.4536],\n",
      "        [ 0.9629],\n",
      "        [-1.3314],\n",
      "        [ 0.5586],\n",
      "        [-0.2244],\n",
      "        [ 0.7545],\n",
      "        [ 0.5249],\n",
      "        [ 1.2107],\n",
      "        [ 0.7545],\n",
      "        [-0.6860],\n",
      "        [-0.1367],\n",
      "        [-1.0557],\n",
      "        [-1.1374],\n",
      "        [ 0.9629],\n",
      "        [-0.8668],\n",
      "        [ 0.6252],\n",
      "        [ 1.2107],\n",
      "        [-1.5841],\n",
      "        [ 0.0513],\n",
      "        [-0.4121],\n",
      "        [-1.3314],\n",
      "        [ 1.0175],\n",
      "        [-0.4121],\n",
      "        [-0.5598],\n",
      "        [-1.5396],\n",
      "        [ 0.6252],\n",
      "        [-1.4536],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2107],\n",
      "        [ 1.1724]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 246/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0237,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1782],\n",
      "        [-1.1782],\n",
      "        [ 0.6580],\n",
      "        [ 0.5920],\n",
      "        [-0.0445],\n",
      "        [ 0.4910],\n",
      "        [ 0.9060],\n",
      "        [ 0.9629],\n",
      "        [ 0.9060],\n",
      "        [ 0.8165],\n",
      "        [-1.5709],\n",
      "        [-0.8669],\n",
      "        [ 0.5585],\n",
      "        [-0.2243],\n",
      "        [ 0.9347],\n",
      "        [-0.2243],\n",
      "        [ 0.5585],\n",
      "        [-0.6090],\n",
      "        [-0.3076],\n",
      "        [ 0.8767],\n",
      "        [ 0.7544],\n",
      "        [ 0.7857],\n",
      "        [ 1.2108],\n",
      "        [ 1.2108],\n",
      "        [ 1.0695],\n",
      "        [-0.3076],\n",
      "        [-1.2184],\n",
      "        [ 1.0695],\n",
      "        [-1.4535],\n",
      "        [ 0.9629],\n",
      "        [-1.3313],\n",
      "        [ 0.5585],\n",
      "        [-0.2243],\n",
      "        [ 0.7544],\n",
      "        [ 0.5248],\n",
      "        [ 1.2108],\n",
      "        [ 0.7544],\n",
      "        [-0.6861],\n",
      "        [-0.1366],\n",
      "        [-1.0557],\n",
      "        [-1.1374],\n",
      "        [ 0.9629],\n",
      "        [-0.8669],\n",
      "        [ 0.6251],\n",
      "        [ 1.2108],\n",
      "        [-1.5842],\n",
      "        [ 0.0514],\n",
      "        [-0.4121],\n",
      "        [-1.3313],\n",
      "        [ 1.0174],\n",
      "        [-0.4121],\n",
      "        [-0.5598],\n",
      "        [-1.5396],\n",
      "        [ 0.6251],\n",
      "        [-1.4535],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2108],\n",
      "        [ 1.1725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 247/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0236,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1781],\n",
      "        [-1.1781],\n",
      "        [ 0.6579],\n",
      "        [ 0.5919],\n",
      "        [-0.0444],\n",
      "        [ 0.4909],\n",
      "        [ 0.9059],\n",
      "        [ 0.9628],\n",
      "        [ 0.9059],\n",
      "        [ 0.8165],\n",
      "        [-1.5709],\n",
      "        [-0.8670],\n",
      "        [ 0.5585],\n",
      "        [-0.2242],\n",
      "        [ 0.9347],\n",
      "        [-0.2242],\n",
      "        [ 0.5585],\n",
      "        [-0.6091],\n",
      "        [-0.3075],\n",
      "        [ 0.8766],\n",
      "        [ 0.7543],\n",
      "        [ 0.7856],\n",
      "        [ 1.2109],\n",
      "        [ 1.2109],\n",
      "        [ 1.0695],\n",
      "        [-0.3075],\n",
      "        [-1.2183],\n",
      "        [ 1.0695],\n",
      "        [-1.4534],\n",
      "        [ 0.9628],\n",
      "        [-1.3311],\n",
      "        [ 0.5585],\n",
      "        [-0.2242],\n",
      "        [ 0.7543],\n",
      "        [ 0.5248],\n",
      "        [ 1.2109],\n",
      "        [ 0.7543],\n",
      "        [-0.6862],\n",
      "        [-0.1365],\n",
      "        [-1.0557],\n",
      "        [-1.1373],\n",
      "        [ 0.9628],\n",
      "        [-0.8670],\n",
      "        [ 0.6251],\n",
      "        [ 1.2109],\n",
      "        [-1.5842],\n",
      "        [ 0.0515],\n",
      "        [-0.4120],\n",
      "        [-1.3311],\n",
      "        [ 1.0174],\n",
      "        [-0.4120],\n",
      "        [-0.5598],\n",
      "        [-1.5395],\n",
      "        [ 0.6251],\n",
      "        [-1.4534],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2109],\n",
      "        [ 1.1725]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 248/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0236,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6579],\n",
      "        [ 0.5919],\n",
      "        [-0.0443],\n",
      "        [ 0.4909],\n",
      "        [ 0.9059],\n",
      "        [ 0.9628],\n",
      "        [ 0.9059],\n",
      "        [ 0.8164],\n",
      "        [-1.5709],\n",
      "        [-0.8671],\n",
      "        [ 0.5584],\n",
      "        [-0.2241],\n",
      "        [ 0.9346],\n",
      "        [-0.2241],\n",
      "        [ 0.5584],\n",
      "        [-0.6092],\n",
      "        [-0.3074],\n",
      "        [ 0.8766],\n",
      "        [ 0.7543],\n",
      "        [ 0.7856],\n",
      "        [ 1.2110],\n",
      "        [ 1.2110],\n",
      "        [ 1.0695],\n",
      "        [-0.3074],\n",
      "        [-1.2182],\n",
      "        [ 1.0695],\n",
      "        [-1.4533],\n",
      "        [ 0.9628],\n",
      "        [-1.3310],\n",
      "        [ 0.5584],\n",
      "        [-0.2241],\n",
      "        [ 0.7543],\n",
      "        [ 0.5248],\n",
      "        [ 1.2110],\n",
      "        [ 0.7543],\n",
      "        [-0.6863],\n",
      "        [-0.1363],\n",
      "        [-1.0557],\n",
      "        [-1.1373],\n",
      "        [ 0.9628],\n",
      "        [-0.8671],\n",
      "        [ 0.6250],\n",
      "        [ 1.2110],\n",
      "        [-1.5843],\n",
      "        [ 0.0516],\n",
      "        [-0.4119],\n",
      "        [-1.3310],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5599],\n",
      "        [-1.5395],\n",
      "        [ 0.6250],\n",
      "        [-1.4533],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2110],\n",
      "        [ 1.1726]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 249/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0235,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6578],\n",
      "        [ 0.5918],\n",
      "        [-0.0442],\n",
      "        [ 0.4909],\n",
      "        [ 0.9058],\n",
      "        [ 0.9628],\n",
      "        [ 0.9058],\n",
      "        [ 0.8164],\n",
      "        [-1.5710],\n",
      "        [-0.8673],\n",
      "        [ 0.5584],\n",
      "        [-0.2240],\n",
      "        [ 0.9346],\n",
      "        [-0.2240],\n",
      "        [ 0.5584],\n",
      "        [-0.6093],\n",
      "        [-0.3073],\n",
      "        [ 0.8765],\n",
      "        [ 0.7542],\n",
      "        [ 0.7855],\n",
      "        [ 1.2111],\n",
      "        [ 1.2111],\n",
      "        [ 1.0695],\n",
      "        [-0.3073],\n",
      "        [-1.2181],\n",
      "        [ 1.0695],\n",
      "        [-1.4533],\n",
      "        [ 0.9628],\n",
      "        [-1.3309],\n",
      "        [ 0.5584],\n",
      "        [-0.2240],\n",
      "        [ 0.7542],\n",
      "        [ 0.5247],\n",
      "        [ 1.2111],\n",
      "        [ 0.7542],\n",
      "        [-0.6865],\n",
      "        [-0.1362],\n",
      "        [-1.0557],\n",
      "        [-1.1373],\n",
      "        [ 0.9628],\n",
      "        [-0.8673],\n",
      "        [ 0.6250],\n",
      "        [ 1.2111],\n",
      "        [-1.5844],\n",
      "        [ 0.0517],\n",
      "        [-0.4119],\n",
      "        [-1.3309],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5599],\n",
      "        [-1.5395],\n",
      "        [ 0.6250],\n",
      "        [-1.4533],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2111],\n",
      "        [ 1.1727]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 250/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0234,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6578],\n",
      "        [ 0.5918],\n",
      "        [-0.0441],\n",
      "        [ 0.4909],\n",
      "        [ 0.9058],\n",
      "        [ 0.9628],\n",
      "        [ 0.9058],\n",
      "        [ 0.8163],\n",
      "        [-1.5712],\n",
      "        [-0.8675],\n",
      "        [ 0.5584],\n",
      "        [-0.2239],\n",
      "        [ 0.9346],\n",
      "        [-0.2239],\n",
      "        [ 0.5584],\n",
      "        [-0.6094],\n",
      "        [-0.3073],\n",
      "        [ 0.8765],\n",
      "        [ 0.7542],\n",
      "        [ 0.7855],\n",
      "        [ 1.2112],\n",
      "        [ 1.2112],\n",
      "        [ 1.0696],\n",
      "        [-0.3073],\n",
      "        [-1.2181],\n",
      "        [ 1.0696],\n",
      "        [-1.4533],\n",
      "        [ 0.9628],\n",
      "        [-1.3309],\n",
      "        [ 0.5584],\n",
      "        [-0.2239],\n",
      "        [ 0.7542],\n",
      "        [ 0.5247],\n",
      "        [ 1.2112],\n",
      "        [ 0.7542],\n",
      "        [-0.6867],\n",
      "        [-0.1362],\n",
      "        [-1.0558],\n",
      "        [-1.1373],\n",
      "        [ 0.9628],\n",
      "        [-0.8675],\n",
      "        [ 0.6250],\n",
      "        [ 1.2112],\n",
      "        [-1.5846],\n",
      "        [ 0.0518],\n",
      "        [-0.4119],\n",
      "        [-1.3309],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5601],\n",
      "        [-1.5396],\n",
      "        [ 0.6250],\n",
      "        [-1.4533],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2112],\n",
      "        [ 1.1728]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 251/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0234,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6578],\n",
      "        [ 0.5918],\n",
      "        [-0.0440],\n",
      "        [ 0.4909],\n",
      "        [ 0.9058],\n",
      "        [ 0.9628],\n",
      "        [ 0.9058],\n",
      "        [ 0.8163],\n",
      "        [-1.5713],\n",
      "        [-0.8677],\n",
      "        [ 0.5584],\n",
      "        [-0.2239],\n",
      "        [ 0.9346],\n",
      "        [-0.2239],\n",
      "        [ 0.5584],\n",
      "        [-0.6096],\n",
      "        [-0.3072],\n",
      "        [ 0.8765],\n",
      "        [ 0.7542],\n",
      "        [ 0.7855],\n",
      "        [ 1.2114],\n",
      "        [ 1.2114],\n",
      "        [ 1.0696],\n",
      "        [-0.3072],\n",
      "        [-1.2181],\n",
      "        [ 1.0696],\n",
      "        [-1.4533],\n",
      "        [ 0.9628],\n",
      "        [-1.3308],\n",
      "        [ 0.5584],\n",
      "        [-0.2239],\n",
      "        [ 0.7542],\n",
      "        [ 0.5247],\n",
      "        [ 1.2114],\n",
      "        [ 0.7542],\n",
      "        [-0.6869],\n",
      "        [-0.1361],\n",
      "        [-1.0559],\n",
      "        [-1.1374],\n",
      "        [ 0.9628],\n",
      "        [-0.8677],\n",
      "        [ 0.6249],\n",
      "        [ 1.2114],\n",
      "        [-1.5848],\n",
      "        [ 0.0519],\n",
      "        [-0.4119],\n",
      "        [-1.3308],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5602],\n",
      "        [-1.5397],\n",
      "        [ 0.6249],\n",
      "        [-1.4533],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2114],\n",
      "        [ 1.1729]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 252/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0233,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6578],\n",
      "        [ 0.5918],\n",
      "        [-0.0439],\n",
      "        [ 0.4909],\n",
      "        [ 0.9058],\n",
      "        [ 0.9628],\n",
      "        [ 0.9058],\n",
      "        [ 0.8163],\n",
      "        [-1.5715],\n",
      "        [-0.8679],\n",
      "        [ 0.5584],\n",
      "        [-0.2238],\n",
      "        [ 0.9346],\n",
      "        [-0.2238],\n",
      "        [ 0.5584],\n",
      "        [-0.6097],\n",
      "        [-0.3072],\n",
      "        [ 0.8765],\n",
      "        [ 0.7541],\n",
      "        [ 0.7854],\n",
      "        [ 1.2115],\n",
      "        [ 1.2115],\n",
      "        [ 1.0697],\n",
      "        [-0.3072],\n",
      "        [-1.2181],\n",
      "        [ 1.0697],\n",
      "        [-1.4532],\n",
      "        [ 0.9628],\n",
      "        [-1.3307],\n",
      "        [ 0.5584],\n",
      "        [-0.2238],\n",
      "        [ 0.7541],\n",
      "        [ 0.5247],\n",
      "        [ 1.2115],\n",
      "        [ 0.7541],\n",
      "        [-0.6870],\n",
      "        [-0.1360],\n",
      "        [-1.0560],\n",
      "        [-1.1374],\n",
      "        [ 0.9628],\n",
      "        [-0.8679],\n",
      "        [ 0.6249],\n",
      "        [ 1.2115],\n",
      "        [-1.5849],\n",
      "        [ 0.0519],\n",
      "        [-0.4120],\n",
      "        [-1.3307],\n",
      "        [ 1.0174],\n",
      "        [-0.4120],\n",
      "        [-0.5603],\n",
      "        [-1.5398],\n",
      "        [ 0.6249],\n",
      "        [-1.4532],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2115],\n",
      "        [ 1.1730]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 253/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0233,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1780],\n",
      "        [-1.1780],\n",
      "        [ 0.6577],\n",
      "        [ 0.5917],\n",
      "        [-0.0439],\n",
      "        [ 0.4909],\n",
      "        [ 0.9057],\n",
      "        [ 0.9627],\n",
      "        [ 0.9057],\n",
      "        [ 0.8162],\n",
      "        [-1.5715],\n",
      "        [-0.8680],\n",
      "        [ 0.5583],\n",
      "        [-0.2237],\n",
      "        [ 0.9345],\n",
      "        [-0.2237],\n",
      "        [ 0.5583],\n",
      "        [-0.6098],\n",
      "        [-0.3071],\n",
      "        [ 0.8764],\n",
      "        [ 0.7541],\n",
      "        [ 0.7854],\n",
      "        [ 1.2116],\n",
      "        [ 1.2116],\n",
      "        [ 1.0697],\n",
      "        [-0.3071],\n",
      "        [-1.2180],\n",
      "        [ 1.0697],\n",
      "        [-1.4531],\n",
      "        [ 0.9627],\n",
      "        [-1.3306],\n",
      "        [ 0.5583],\n",
      "        [-0.2237],\n",
      "        [ 0.7541],\n",
      "        [ 0.5247],\n",
      "        [ 1.2116],\n",
      "        [ 0.7541],\n",
      "        [-0.6872],\n",
      "        [-0.1359],\n",
      "        [-1.0560],\n",
      "        [-1.1373],\n",
      "        [ 0.9627],\n",
      "        [-0.8680],\n",
      "        [ 0.6249],\n",
      "        [ 1.2116],\n",
      "        [-1.5850],\n",
      "        [ 0.0520],\n",
      "        [-0.4119],\n",
      "        [-1.3306],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5604],\n",
      "        [-1.5398],\n",
      "        [ 0.6249],\n",
      "        [-1.4531],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2116],\n",
      "        [ 1.1731]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 254/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0232,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1779],\n",
      "        [-1.1779],\n",
      "        [ 0.6576],\n",
      "        [ 0.5917],\n",
      "        [-0.0438],\n",
      "        [ 0.4908],\n",
      "        [ 0.9057],\n",
      "        [ 0.9627],\n",
      "        [ 0.9057],\n",
      "        [ 0.8161],\n",
      "        [-1.5716],\n",
      "        [-0.8682],\n",
      "        [ 0.5583],\n",
      "        [-0.2237],\n",
      "        [ 0.9345],\n",
      "        [-0.2237],\n",
      "        [ 0.5583],\n",
      "        [-0.6099],\n",
      "        [-0.3071],\n",
      "        [ 0.8764],\n",
      "        [ 0.7540],\n",
      "        [ 0.7853],\n",
      "        [ 1.2117],\n",
      "        [ 1.2117],\n",
      "        [ 1.0697],\n",
      "        [-0.3071],\n",
      "        [-1.2179],\n",
      "        [ 1.0697],\n",
      "        [-1.4530],\n",
      "        [ 0.9627],\n",
      "        [-1.3305],\n",
      "        [ 0.5583],\n",
      "        [-0.2237],\n",
      "        [ 0.7540],\n",
      "        [ 0.5246],\n",
      "        [ 1.2117],\n",
      "        [ 0.7540],\n",
      "        [-0.6873],\n",
      "        [-0.1359],\n",
      "        [-1.0560],\n",
      "        [-1.1373],\n",
      "        [ 0.9627],\n",
      "        [-0.8682],\n",
      "        [ 0.6248],\n",
      "        [ 1.2117],\n",
      "        [-1.5851],\n",
      "        [ 0.0521],\n",
      "        [-0.4119],\n",
      "        [-1.3305],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5604],\n",
      "        [-1.5398],\n",
      "        [ 0.6248],\n",
      "        [-1.4530],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2117],\n",
      "        [ 1.1732]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 255/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0232,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1778],\n",
      "        [-1.1778],\n",
      "        [ 0.6576],\n",
      "        [ 0.5916],\n",
      "        [-0.0437],\n",
      "        [ 0.4908],\n",
      "        [ 0.9056],\n",
      "        [ 0.9627],\n",
      "        [ 0.9056],\n",
      "        [ 0.8161],\n",
      "        [-1.5716],\n",
      "        [-0.8683],\n",
      "        [ 0.5582],\n",
      "        [-0.2236],\n",
      "        [ 0.9344],\n",
      "        [-0.2236],\n",
      "        [ 0.5582],\n",
      "        [-0.6100],\n",
      "        [-0.3070],\n",
      "        [ 0.8763],\n",
      "        [ 0.7539],\n",
      "        [ 0.7852],\n",
      "        [ 1.2118],\n",
      "        [ 1.2118],\n",
      "        [ 1.0697],\n",
      "        [-0.3070],\n",
      "        [-1.2178],\n",
      "        [ 1.0697],\n",
      "        [-1.4529],\n",
      "        [ 0.9627],\n",
      "        [-1.3303],\n",
      "        [ 0.5582],\n",
      "        [-0.2236],\n",
      "        [ 0.7539],\n",
      "        [ 0.5246],\n",
      "        [ 1.2118],\n",
      "        [ 0.7539],\n",
      "        [-0.6875],\n",
      "        [-0.1358],\n",
      "        [-1.0560],\n",
      "        [-1.1372],\n",
      "        [ 0.9627],\n",
      "        [-0.8683],\n",
      "        [ 0.6248],\n",
      "        [ 1.2118],\n",
      "        [-1.5851],\n",
      "        [ 0.0521],\n",
      "        [-0.4119],\n",
      "        [-1.3303],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5605],\n",
      "        [-1.5398],\n",
      "        [ 0.6248],\n",
      "        [-1.4529],\n",
      "        [ 0.4227],\n",
      "        [-0.4372],\n",
      "        [ 0.4227],\n",
      "        [ 1.2118],\n",
      "        [ 1.1732]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 256/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0231,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1777],\n",
      "        [-1.1777],\n",
      "        [ 0.6575],\n",
      "        [ 0.5916],\n",
      "        [-0.0436],\n",
      "        [ 0.4908],\n",
      "        [ 0.9056],\n",
      "        [ 0.9626],\n",
      "        [ 0.9056],\n",
      "        [ 0.8160],\n",
      "        [-1.5717],\n",
      "        [-0.8684],\n",
      "        [ 0.5582],\n",
      "        [-0.2235],\n",
      "        [ 0.9344],\n",
      "        [-0.2235],\n",
      "        [ 0.5582],\n",
      "        [-0.6101],\n",
      "        [-0.3070],\n",
      "        [ 0.8763],\n",
      "        [ 0.7539],\n",
      "        [ 0.7852],\n",
      "        [ 1.2119],\n",
      "        [ 1.2119],\n",
      "        [ 1.0697],\n",
      "        [-0.3070],\n",
      "        [-1.2177],\n",
      "        [ 1.0697],\n",
      "        [-1.4528],\n",
      "        [ 0.9626],\n",
      "        [-1.3302],\n",
      "        [ 0.5582],\n",
      "        [-0.2235],\n",
      "        [ 0.7539],\n",
      "        [ 0.5246],\n",
      "        [ 1.2119],\n",
      "        [ 0.7539],\n",
      "        [-0.6876],\n",
      "        [-0.1357],\n",
      "        [-1.0561],\n",
      "        [-1.1372],\n",
      "        [ 0.9626],\n",
      "        [-0.8684],\n",
      "        [ 0.6247],\n",
      "        [ 1.2119],\n",
      "        [-1.5853],\n",
      "        [ 0.0522],\n",
      "        [-0.4119],\n",
      "        [-1.3302],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5606],\n",
      "        [-1.5398],\n",
      "        [ 0.6247],\n",
      "        [-1.4528],\n",
      "        [ 0.4227],\n",
      "        [-0.4372],\n",
      "        [ 0.4227],\n",
      "        [ 1.2119],\n",
      "        [ 1.1733]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 257/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0230,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1777],\n",
      "        [-1.1777],\n",
      "        [ 0.6575],\n",
      "        [ 0.5916],\n",
      "        [-0.0435],\n",
      "        [ 0.4908],\n",
      "        [ 0.9056],\n",
      "        [ 0.9626],\n",
      "        [ 0.9056],\n",
      "        [ 0.8160],\n",
      "        [-1.5718],\n",
      "        [-0.8686],\n",
      "        [ 0.5582],\n",
      "        [-0.2235],\n",
      "        [ 0.9344],\n",
      "        [-0.2235],\n",
      "        [ 0.5582],\n",
      "        [-0.6103],\n",
      "        [-0.3069],\n",
      "        [ 0.8762],\n",
      "        [ 0.7539],\n",
      "        [ 0.7852],\n",
      "        [ 1.2121],\n",
      "        [ 1.2121],\n",
      "        [ 1.0697],\n",
      "        [-0.3069],\n",
      "        [-1.2176],\n",
      "        [ 1.0697],\n",
      "        [-1.4528],\n",
      "        [ 0.9626],\n",
      "        [-1.3301],\n",
      "        [ 0.5582],\n",
      "        [-0.2235],\n",
      "        [ 0.7539],\n",
      "        [ 0.5246],\n",
      "        [ 1.2121],\n",
      "        [ 0.7539],\n",
      "        [-0.6878],\n",
      "        [-0.1356],\n",
      "        [-1.0561],\n",
      "        [-1.1372],\n",
      "        [ 0.9626],\n",
      "        [-0.8686],\n",
      "        [ 0.6247],\n",
      "        [ 1.2121],\n",
      "        [-1.5854],\n",
      "        [ 0.0523],\n",
      "        [-0.4119],\n",
      "        [-1.3301],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5607],\n",
      "        [-1.5399],\n",
      "        [ 0.6247],\n",
      "        [-1.4528],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2121],\n",
      "        [ 1.1734]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 258/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0230,\n",
      " epoch_time_duration: 0.0129\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1777],\n",
      "        [-1.1777],\n",
      "        [ 0.6575],\n",
      "        [ 0.5915],\n",
      "        [-0.0435],\n",
      "        [ 0.4908],\n",
      "        [ 0.9056],\n",
      "        [ 0.9626],\n",
      "        [ 0.9056],\n",
      "        [ 0.8160],\n",
      "        [-1.5720],\n",
      "        [-0.8688],\n",
      "        [ 0.5582],\n",
      "        [-0.2234],\n",
      "        [ 0.9344],\n",
      "        [-0.2234],\n",
      "        [ 0.5582],\n",
      "        [-0.6104],\n",
      "        [-0.3069],\n",
      "        [ 0.8762],\n",
      "        [ 0.7538],\n",
      "        [ 0.7851],\n",
      "        [ 1.2122],\n",
      "        [ 1.2122],\n",
      "        [ 1.0698],\n",
      "        [-0.3069],\n",
      "        [-1.2176],\n",
      "        [ 1.0698],\n",
      "        [-1.4527],\n",
      "        [ 0.9626],\n",
      "        [-1.3300],\n",
      "        [ 0.5582],\n",
      "        [-0.2234],\n",
      "        [ 0.7538],\n",
      "        [ 0.5245],\n",
      "        [ 1.2122],\n",
      "        [ 0.7538],\n",
      "        [-0.6880],\n",
      "        [-0.1355],\n",
      "        [-1.0562],\n",
      "        [-1.1372],\n",
      "        [ 0.9626],\n",
      "        [-0.8688],\n",
      "        [ 0.6247],\n",
      "        [ 1.2122],\n",
      "        [-1.5856],\n",
      "        [ 0.0523],\n",
      "        [-0.4119],\n",
      "        [-1.3300],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5608],\n",
      "        [-1.5400],\n",
      "        [ 0.6247],\n",
      "        [-1.4527],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2122],\n",
      "        [ 1.1735]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 259/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0229,\n",
      " epoch_time_duration: 0.0130\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1777],\n",
      "        [-1.1777],\n",
      "        [ 0.6574],\n",
      "        [ 0.5915],\n",
      "        [-0.0434],\n",
      "        [ 0.4907],\n",
      "        [ 0.9055],\n",
      "        [ 0.9626],\n",
      "        [ 0.9055],\n",
      "        [ 0.8159],\n",
      "        [-1.5721],\n",
      "        [-0.8690],\n",
      "        [ 0.5581],\n",
      "        [-0.2233],\n",
      "        [ 0.9344],\n",
      "        [-0.2233],\n",
      "        [ 0.5581],\n",
      "        [-0.6105],\n",
      "        [-0.3069],\n",
      "        [ 0.8762],\n",
      "        [ 0.7538],\n",
      "        [ 0.7851],\n",
      "        [ 1.2123],\n",
      "        [ 1.2123],\n",
      "        [ 1.0698],\n",
      "        [-0.3069],\n",
      "        [-1.2176],\n",
      "        [ 1.0698],\n",
      "        [-1.4527],\n",
      "        [ 0.9626],\n",
      "        [-1.3300],\n",
      "        [ 0.5581],\n",
      "        [-0.2233],\n",
      "        [ 0.7538],\n",
      "        [ 0.5245],\n",
      "        [ 1.2123],\n",
      "        [ 0.7538],\n",
      "        [-0.6881],\n",
      "        [-0.1355],\n",
      "        [-1.0563],\n",
      "        [-1.1372],\n",
      "        [ 0.9626],\n",
      "        [-0.8690],\n",
      "        [ 0.6246],\n",
      "        [ 1.2123],\n",
      "        [-1.5858],\n",
      "        [ 0.0524],\n",
      "        [-0.4119],\n",
      "        [-1.3300],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5609],\n",
      "        [-1.5400],\n",
      "        [ 0.6246],\n",
      "        [-1.4527],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2123],\n",
      "        [ 1.1736]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 260/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0229,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1776],\n",
      "        [-1.1776],\n",
      "        [ 0.6574],\n",
      "        [ 0.5915],\n",
      "        [-0.0433],\n",
      "        [ 0.4907],\n",
      "        [ 0.9055],\n",
      "        [ 0.9626],\n",
      "        [ 0.9055],\n",
      "        [ 0.8159],\n",
      "        [-1.5722],\n",
      "        [-0.8691],\n",
      "        [ 0.5581],\n",
      "        [-0.2233],\n",
      "        [ 0.9343],\n",
      "        [-0.2233],\n",
      "        [ 0.5581],\n",
      "        [-0.6106],\n",
      "        [-0.3068],\n",
      "        [ 0.8761],\n",
      "        [ 0.7537],\n",
      "        [ 0.7850],\n",
      "        [ 1.2124],\n",
      "        [ 1.2124],\n",
      "        [ 1.0698],\n",
      "        [-0.3068],\n",
      "        [-1.2175],\n",
      "        [ 1.0698],\n",
      "        [-1.4527],\n",
      "        [ 0.9626],\n",
      "        [-1.3299],\n",
      "        [ 0.5581],\n",
      "        [-0.2233],\n",
      "        [ 0.7537],\n",
      "        [ 0.5245],\n",
      "        [ 1.2124],\n",
      "        [ 0.7537],\n",
      "        [-0.6883],\n",
      "        [-0.1354],\n",
      "        [-1.0563],\n",
      "        [-1.1372],\n",
      "        [ 0.9626],\n",
      "        [-0.8691],\n",
      "        [ 0.6246],\n",
      "        [ 1.2124],\n",
      "        [-1.5859],\n",
      "        [ 0.0525],\n",
      "        [-0.4119],\n",
      "        [-1.3299],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5610],\n",
      "        [-1.5401],\n",
      "        [ 0.6246],\n",
      "        [-1.4527],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2124],\n",
      "        [ 1.1737]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 261/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0228,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1775],\n",
      "        [-1.1775],\n",
      "        [ 0.6574],\n",
      "        [ 0.5914],\n",
      "        [-0.0432],\n",
      "        [ 0.4907],\n",
      "        [ 0.9055],\n",
      "        [ 0.9626],\n",
      "        [ 0.9055],\n",
      "        [ 0.8158],\n",
      "        [-1.5723],\n",
      "        [-0.8692],\n",
      "        [ 0.5581],\n",
      "        [-0.2232],\n",
      "        [ 0.9343],\n",
      "        [-0.2232],\n",
      "        [ 0.5581],\n",
      "        [-0.6107],\n",
      "        [-0.3067],\n",
      "        [ 0.8761],\n",
      "        [ 0.7537],\n",
      "        [ 0.7850],\n",
      "        [ 1.2125],\n",
      "        [ 1.2125],\n",
      "        [ 1.0698],\n",
      "        [-0.3067],\n",
      "        [-1.2174],\n",
      "        [ 1.0698],\n",
      "        [-1.4526],\n",
      "        [ 0.9626],\n",
      "        [-1.3297],\n",
      "        [ 0.5581],\n",
      "        [-0.2232],\n",
      "        [ 0.7537],\n",
      "        [ 0.5245],\n",
      "        [ 1.2125],\n",
      "        [ 0.7537],\n",
      "        [-0.6884],\n",
      "        [-0.1353],\n",
      "        [-1.0563],\n",
      "        [-1.1371],\n",
      "        [ 0.9626],\n",
      "        [-0.8692],\n",
      "        [ 0.6245],\n",
      "        [ 1.2125],\n",
      "        [-1.5860],\n",
      "        [ 0.0526],\n",
      "        [-0.4119],\n",
      "        [-1.3297],\n",
      "        [ 1.0174],\n",
      "        [-0.4119],\n",
      "        [-0.5610],\n",
      "        [-1.5401],\n",
      "        [ 0.6245],\n",
      "        [-1.4526],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2125],\n",
      "        [ 1.1738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 262/10000,\n",
      " train_loss: 0.0008,\n",
      " train_mae: 0.0228,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1775],\n",
      "        [-1.1775],\n",
      "        [ 0.6573],\n",
      "        [ 0.5914],\n",
      "        [-0.0431],\n",
      "        [ 0.4907],\n",
      "        [ 0.9054],\n",
      "        [ 0.9625],\n",
      "        [ 0.9054],\n",
      "        [ 0.8158],\n",
      "        [-1.5724],\n",
      "        [-0.8693],\n",
      "        [ 0.5580],\n",
      "        [-0.2231],\n",
      "        [ 0.9342],\n",
      "        [-0.2231],\n",
      "        [ 0.5580],\n",
      "        [-0.6108],\n",
      "        [-0.3067],\n",
      "        [ 0.8760],\n",
      "        [ 0.7536],\n",
      "        [ 0.7849],\n",
      "        [ 1.2126],\n",
      "        [ 1.2126],\n",
      "        [ 1.0698],\n",
      "        [-0.3067],\n",
      "        [-1.2173],\n",
      "        [ 1.0698],\n",
      "        [-1.4525],\n",
      "        [ 0.9625],\n",
      "        [-1.3296],\n",
      "        [ 0.5580],\n",
      "        [-0.2231],\n",
      "        [ 0.7536],\n",
      "        [ 0.5245],\n",
      "        [ 1.2126],\n",
      "        [ 0.7536],\n",
      "        [-0.6885],\n",
      "        [-0.1352],\n",
      "        [-1.0563],\n",
      "        [-1.1371],\n",
      "        [ 0.9625],\n",
      "        [-0.8693],\n",
      "        [ 0.6245],\n",
      "        [ 1.2126],\n",
      "        [-1.5861],\n",
      "        [ 0.0527],\n",
      "        [-0.4118],\n",
      "        [-1.3296],\n",
      "        [ 1.0174],\n",
      "        [-0.4118],\n",
      "        [-0.5611],\n",
      "        [-1.5401],\n",
      "        [ 0.6245],\n",
      "        [-1.4525],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2126],\n",
      "        [ 1.1738]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 263/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0227,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1774],\n",
      "        [-1.1774],\n",
      "        [ 0.6573],\n",
      "        [ 0.5914],\n",
      "        [-0.0430],\n",
      "        [ 0.4907],\n",
      "        [ 0.9054],\n",
      "        [ 0.9625],\n",
      "        [ 0.9054],\n",
      "        [ 0.8157],\n",
      "        [-1.5725],\n",
      "        [-0.8695],\n",
      "        [ 0.5580],\n",
      "        [-0.2230],\n",
      "        [ 0.9342],\n",
      "        [-0.2230],\n",
      "        [ 0.5580],\n",
      "        [-0.6109],\n",
      "        [-0.3066],\n",
      "        [ 0.8760],\n",
      "        [ 0.7536],\n",
      "        [ 0.7849],\n",
      "        [ 1.2127],\n",
      "        [ 1.2127],\n",
      "        [ 1.0698],\n",
      "        [-0.3066],\n",
      "        [-1.2172],\n",
      "        [ 1.0698],\n",
      "        [-1.4524],\n",
      "        [ 0.9625],\n",
      "        [-1.3295],\n",
      "        [ 0.5580],\n",
      "        [-0.2230],\n",
      "        [ 0.7536],\n",
      "        [ 0.5244],\n",
      "        [ 1.2127],\n",
      "        [ 0.7536],\n",
      "        [-0.6886],\n",
      "        [-0.1351],\n",
      "        [-1.0563],\n",
      "        [-1.1370],\n",
      "        [ 0.9625],\n",
      "        [-0.8695],\n",
      "        [ 0.6245],\n",
      "        [ 1.2127],\n",
      "        [-1.5863],\n",
      "        [ 0.0528],\n",
      "        [-0.4118],\n",
      "        [-1.3295],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5611],\n",
      "        [-1.5402],\n",
      "        [ 0.6245],\n",
      "        [-1.4524],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2127],\n",
      "        [ 1.1739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 264/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0226,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1774],\n",
      "        [-1.1774],\n",
      "        [ 0.6572],\n",
      "        [ 0.5913],\n",
      "        [-0.0429],\n",
      "        [ 0.4907],\n",
      "        [ 0.9053],\n",
      "        [ 0.9625],\n",
      "        [ 0.9053],\n",
      "        [ 0.8157],\n",
      "        [-1.5726],\n",
      "        [-0.8696],\n",
      "        [ 0.5580],\n",
      "        [-0.2229],\n",
      "        [ 0.9342],\n",
      "        [-0.2229],\n",
      "        [ 0.5580],\n",
      "        [-0.6110],\n",
      "        [-0.3065],\n",
      "        [ 0.8760],\n",
      "        [ 0.7535],\n",
      "        [ 0.7848],\n",
      "        [ 1.2128],\n",
      "        [ 1.2128],\n",
      "        [ 1.0698],\n",
      "        [-0.3065],\n",
      "        [-1.2172],\n",
      "        [ 1.0698],\n",
      "        [-1.4524],\n",
      "        [ 0.9625],\n",
      "        [-1.3294],\n",
      "        [ 0.5580],\n",
      "        [-0.2229],\n",
      "        [ 0.7535],\n",
      "        [ 0.5244],\n",
      "        [ 1.2128],\n",
      "        [ 0.7535],\n",
      "        [-0.6888],\n",
      "        [-0.1350],\n",
      "        [-1.0564],\n",
      "        [-1.1370],\n",
      "        [ 0.9625],\n",
      "        [-0.8696],\n",
      "        [ 0.6244],\n",
      "        [ 1.2128],\n",
      "        [-1.5864],\n",
      "        [ 0.0528],\n",
      "        [-0.4118],\n",
      "        [-1.3294],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5612],\n",
      "        [-1.5402],\n",
      "        [ 0.6244],\n",
      "        [-1.4524],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2128],\n",
      "        [ 1.1740]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 265/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0226,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1774],\n",
      "        [-1.1774],\n",
      "        [ 0.6572],\n",
      "        [ 0.5913],\n",
      "        [-0.0428],\n",
      "        [ 0.4907],\n",
      "        [ 0.9053],\n",
      "        [ 0.9625],\n",
      "        [ 0.9053],\n",
      "        [ 0.8156],\n",
      "        [-1.5728],\n",
      "        [-0.8698],\n",
      "        [ 0.5580],\n",
      "        [-0.2228],\n",
      "        [ 0.9342],\n",
      "        [-0.2228],\n",
      "        [ 0.5580],\n",
      "        [-0.6111],\n",
      "        [-0.3065],\n",
      "        [ 0.8759],\n",
      "        [ 0.7535],\n",
      "        [ 0.7848],\n",
      "        [ 1.2129],\n",
      "        [ 1.2129],\n",
      "        [ 1.0699],\n",
      "        [-0.3065],\n",
      "        [-1.2171],\n",
      "        [ 1.0699],\n",
      "        [-1.4524],\n",
      "        [ 0.9625],\n",
      "        [-1.3294],\n",
      "        [ 0.5580],\n",
      "        [-0.2228],\n",
      "        [ 0.7535],\n",
      "        [ 0.5244],\n",
      "        [ 1.2129],\n",
      "        [ 0.7535],\n",
      "        [-0.6889],\n",
      "        [-0.1349],\n",
      "        [-1.0564],\n",
      "        [-1.1371],\n",
      "        [ 0.9625],\n",
      "        [-0.8698],\n",
      "        [ 0.6244],\n",
      "        [ 1.2129],\n",
      "        [-1.5866],\n",
      "        [ 0.0529],\n",
      "        [-0.4118],\n",
      "        [-1.3294],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5613],\n",
      "        [-1.5403],\n",
      "        [ 0.6244],\n",
      "        [-1.4524],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2129],\n",
      "        [ 1.1741]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 266/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0225,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1773],\n",
      "        [-1.1773],\n",
      "        [ 0.6572],\n",
      "        [ 0.5913],\n",
      "        [-0.0428],\n",
      "        [ 0.4906],\n",
      "        [ 0.9053],\n",
      "        [ 0.9624],\n",
      "        [ 0.9053],\n",
      "        [ 0.8156],\n",
      "        [-1.5729],\n",
      "        [-0.8699],\n",
      "        [ 0.5580],\n",
      "        [-0.2228],\n",
      "        [ 0.9341],\n",
      "        [-0.2228],\n",
      "        [ 0.5580],\n",
      "        [-0.6112],\n",
      "        [-0.3064],\n",
      "        [ 0.8759],\n",
      "        [ 0.7535],\n",
      "        [ 0.7848],\n",
      "        [ 1.2131],\n",
      "        [ 1.2131],\n",
      "        [ 1.0699],\n",
      "        [-0.3064],\n",
      "        [-1.2171],\n",
      "        [ 1.0699],\n",
      "        [-1.4523],\n",
      "        [ 0.9624],\n",
      "        [-1.3293],\n",
      "        [ 0.5580],\n",
      "        [-0.2228],\n",
      "        [ 0.7535],\n",
      "        [ 0.5244],\n",
      "        [ 1.2131],\n",
      "        [ 0.7535],\n",
      "        [-0.6891],\n",
      "        [-0.1348],\n",
      "        [-1.0565],\n",
      "        [-1.1371],\n",
      "        [ 0.9624],\n",
      "        [-0.8699],\n",
      "        [ 0.6244],\n",
      "        [ 1.2131],\n",
      "        [-1.5868],\n",
      "        [ 0.0530],\n",
      "        [-0.4118],\n",
      "        [-1.3293],\n",
      "        [ 1.0174],\n",
      "        [-0.4118],\n",
      "        [-0.5614],\n",
      "        [-1.5404],\n",
      "        [ 0.6244],\n",
      "        [-1.4523],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2131],\n",
      "        [ 1.1742]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 267/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0225,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1773],\n",
      "        [-1.1773],\n",
      "        [ 0.6571],\n",
      "        [ 0.5913],\n",
      "        [-0.0427],\n",
      "        [ 0.4906],\n",
      "        [ 0.9053],\n",
      "        [ 0.9624],\n",
      "        [ 0.9053],\n",
      "        [ 0.8156],\n",
      "        [-1.5730],\n",
      "        [-0.8701],\n",
      "        [ 0.5579],\n",
      "        [-0.2227],\n",
      "        [ 0.9341],\n",
      "        [-0.2227],\n",
      "        [ 0.5579],\n",
      "        [-0.6113],\n",
      "        [-0.3064],\n",
      "        [ 0.8759],\n",
      "        [ 0.7534],\n",
      "        [ 0.7847],\n",
      "        [ 1.2132],\n",
      "        [ 1.2132],\n",
      "        [ 1.0699],\n",
      "        [-0.3064],\n",
      "        [-1.2170],\n",
      "        [ 1.0699],\n",
      "        [-1.4523],\n",
      "        [ 0.9624],\n",
      "        [-1.3292],\n",
      "        [ 0.5579],\n",
      "        [-0.2227],\n",
      "        [ 0.7534],\n",
      "        [ 0.5244],\n",
      "        [ 1.2132],\n",
      "        [ 0.7534],\n",
      "        [-0.6892],\n",
      "        [-0.1348],\n",
      "        [-1.0565],\n",
      "        [-1.1370],\n",
      "        [ 0.9624],\n",
      "        [-0.8701],\n",
      "        [ 0.6243],\n",
      "        [ 1.2132],\n",
      "        [-1.5869],\n",
      "        [ 0.0530],\n",
      "        [-0.4118],\n",
      "        [-1.3292],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5615],\n",
      "        [-1.5404],\n",
      "        [ 0.6243],\n",
      "        [-1.4523],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2132],\n",
      "        [ 1.1742]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 268/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0224,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1772],\n",
      "        [-1.1772],\n",
      "        [ 0.6571],\n",
      "        [ 0.5912],\n",
      "        [-0.0426],\n",
      "        [ 0.4906],\n",
      "        [ 0.9052],\n",
      "        [ 0.9624],\n",
      "        [ 0.9052],\n",
      "        [ 0.8155],\n",
      "        [-1.5731],\n",
      "        [-0.8702],\n",
      "        [ 0.5579],\n",
      "        [-0.2226],\n",
      "        [ 0.9341],\n",
      "        [-0.2226],\n",
      "        [ 0.5579],\n",
      "        [-0.6114],\n",
      "        [-0.3063],\n",
      "        [ 0.8758],\n",
      "        [ 0.7534],\n",
      "        [ 0.7847],\n",
      "        [ 1.2133],\n",
      "        [ 1.2133],\n",
      "        [ 1.0699],\n",
      "        [-0.3063],\n",
      "        [-1.2169],\n",
      "        [ 1.0699],\n",
      "        [-1.4522],\n",
      "        [ 0.9624],\n",
      "        [-1.3291],\n",
      "        [ 0.5579],\n",
      "        [-0.2226],\n",
      "        [ 0.7534],\n",
      "        [ 0.5243],\n",
      "        [ 1.2133],\n",
      "        [ 0.7534],\n",
      "        [-0.6894],\n",
      "        [-0.1347],\n",
      "        [-1.0565],\n",
      "        [-1.1370],\n",
      "        [ 0.9624],\n",
      "        [-0.8702],\n",
      "        [ 0.6243],\n",
      "        [ 1.2133],\n",
      "        [-1.5870],\n",
      "        [ 0.0531],\n",
      "        [-0.4118],\n",
      "        [-1.3291],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5615],\n",
      "        [-1.5405],\n",
      "        [ 0.6243],\n",
      "        [-1.4522],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2133],\n",
      "        [ 1.1743]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 269/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0224,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1772],\n",
      "        [-1.1772],\n",
      "        [ 0.6570],\n",
      "        [ 0.5912],\n",
      "        [-0.0425],\n",
      "        [ 0.4906],\n",
      "        [ 0.9052],\n",
      "        [ 0.9624],\n",
      "        [ 0.9052],\n",
      "        [ 0.8155],\n",
      "        [-1.5731],\n",
      "        [-0.8704],\n",
      "        [ 0.5579],\n",
      "        [-0.2226],\n",
      "        [ 0.9340],\n",
      "        [-0.2226],\n",
      "        [ 0.5579],\n",
      "        [-0.6115],\n",
      "        [-0.3063],\n",
      "        [ 0.8758],\n",
      "        [ 0.7533],\n",
      "        [ 0.7846],\n",
      "        [ 1.2134],\n",
      "        [ 1.2134],\n",
      "        [ 1.0699],\n",
      "        [-0.3063],\n",
      "        [-1.2168],\n",
      "        [ 1.0699],\n",
      "        [-1.4521],\n",
      "        [ 0.9624],\n",
      "        [-1.3290],\n",
      "        [ 0.5579],\n",
      "        [-0.2226],\n",
      "        [ 0.7533],\n",
      "        [ 0.5243],\n",
      "        [ 1.2134],\n",
      "        [ 0.7533],\n",
      "        [-0.6895],\n",
      "        [-0.1346],\n",
      "        [-1.0566],\n",
      "        [-1.1370],\n",
      "        [ 0.9624],\n",
      "        [-0.8704],\n",
      "        [ 0.6243],\n",
      "        [ 1.2134],\n",
      "        [-1.5871],\n",
      "        [ 0.0532],\n",
      "        [-0.4118],\n",
      "        [-1.3290],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5616],\n",
      "        [-1.5405],\n",
      "        [ 0.6243],\n",
      "        [-1.4521],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2134],\n",
      "        [ 1.1744]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 270/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0223,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1771],\n",
      "        [-1.1771],\n",
      "        [ 0.6570],\n",
      "        [ 0.5912],\n",
      "        [-0.0424],\n",
      "        [ 0.4906],\n",
      "        [ 0.9051],\n",
      "        [ 0.9623],\n",
      "        [ 0.9051],\n",
      "        [ 0.8154],\n",
      "        [-1.5732],\n",
      "        [-0.8705],\n",
      "        [ 0.5578],\n",
      "        [-0.2225],\n",
      "        [ 0.9340],\n",
      "        [-0.2225],\n",
      "        [ 0.5578],\n",
      "        [-0.6116],\n",
      "        [-0.3062],\n",
      "        [ 0.8757],\n",
      "        [ 0.7533],\n",
      "        [ 0.7846],\n",
      "        [ 1.2135],\n",
      "        [ 1.2135],\n",
      "        [ 1.0700],\n",
      "        [-0.3062],\n",
      "        [-1.2168],\n",
      "        [ 1.0700],\n",
      "        [-1.4520],\n",
      "        [ 0.9623],\n",
      "        [-1.3288],\n",
      "        [ 0.5578],\n",
      "        [-0.2225],\n",
      "        [ 0.7533],\n",
      "        [ 0.5243],\n",
      "        [ 1.2135],\n",
      "        [ 0.7533],\n",
      "        [-0.6897],\n",
      "        [-0.1345],\n",
      "        [-1.0566],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8705],\n",
      "        [ 0.6242],\n",
      "        [ 1.2135],\n",
      "        [-1.5872],\n",
      "        [ 0.0533],\n",
      "        [-0.4118],\n",
      "        [-1.3288],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5617],\n",
      "        [-1.5405],\n",
      "        [ 0.6242],\n",
      "        [-1.4520],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2135],\n",
      "        [ 1.1744]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 271/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0223,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1771],\n",
      "        [-1.1771],\n",
      "        [ 0.6570],\n",
      "        [ 0.5911],\n",
      "        [-0.0424],\n",
      "        [ 0.4906],\n",
      "        [ 0.9051],\n",
      "        [ 0.9623],\n",
      "        [ 0.9051],\n",
      "        [ 0.8154],\n",
      "        [-1.5733],\n",
      "        [-0.8706],\n",
      "        [ 0.5578],\n",
      "        [-0.2224],\n",
      "        [ 0.9340],\n",
      "        [-0.2224],\n",
      "        [ 0.5578],\n",
      "        [-0.6118],\n",
      "        [-0.3062],\n",
      "        [ 0.8757],\n",
      "        [ 0.7532],\n",
      "        [ 0.7845],\n",
      "        [ 1.2136],\n",
      "        [ 1.2136],\n",
      "        [ 1.0700],\n",
      "        [-0.3062],\n",
      "        [-1.2167],\n",
      "        [ 1.0700],\n",
      "        [-1.4520],\n",
      "        [ 0.9623],\n",
      "        [-1.3287],\n",
      "        [ 0.5578],\n",
      "        [-0.2224],\n",
      "        [ 0.7532],\n",
      "        [ 0.5243],\n",
      "        [ 1.2136],\n",
      "        [ 0.7532],\n",
      "        [-0.6898],\n",
      "        [-0.1344],\n",
      "        [-1.0566],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8706],\n",
      "        [ 0.6242],\n",
      "        [ 1.2136],\n",
      "        [-1.5873],\n",
      "        [ 0.0533],\n",
      "        [-0.4118],\n",
      "        [-1.3287],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5618],\n",
      "        [-1.5405],\n",
      "        [ 0.6242],\n",
      "        [-1.4520],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2136],\n",
      "        [ 1.1745]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 272/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0222,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1771],\n",
      "        [-1.1771],\n",
      "        [ 0.6569],\n",
      "        [ 0.5911],\n",
      "        [-0.0423],\n",
      "        [ 0.4906],\n",
      "        [ 0.9051],\n",
      "        [ 0.9623],\n",
      "        [ 0.9051],\n",
      "        [ 0.8153],\n",
      "        [-1.5734],\n",
      "        [-0.8708],\n",
      "        [ 0.5578],\n",
      "        [-0.2224],\n",
      "        [ 0.9340],\n",
      "        [-0.2224],\n",
      "        [ 0.5578],\n",
      "        [-0.6119],\n",
      "        [-0.3062],\n",
      "        [ 0.8757],\n",
      "        [ 0.7532],\n",
      "        [ 0.7845],\n",
      "        [ 1.2137],\n",
      "        [ 1.2137],\n",
      "        [ 1.0700],\n",
      "        [-0.3062],\n",
      "        [-1.2167],\n",
      "        [ 1.0700],\n",
      "        [-1.4519],\n",
      "        [ 0.9623],\n",
      "        [-1.3287],\n",
      "        [ 0.5578],\n",
      "        [-0.2224],\n",
      "        [ 0.7532],\n",
      "        [ 0.5243],\n",
      "        [ 1.2137],\n",
      "        [ 0.7532],\n",
      "        [-0.6900],\n",
      "        [-0.1344],\n",
      "        [-1.0567],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8708],\n",
      "        [ 0.6242],\n",
      "        [ 1.2137],\n",
      "        [-1.5875],\n",
      "        [ 0.0534],\n",
      "        [-0.4118],\n",
      "        [-1.3287],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5619],\n",
      "        [-1.5406],\n",
      "        [ 0.6242],\n",
      "        [-1.4519],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2137],\n",
      "        [ 1.1746]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 273/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0222,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1770],\n",
      "        [-1.1770],\n",
      "        [ 0.6569],\n",
      "        [ 0.5911],\n",
      "        [-0.0422],\n",
      "        [ 0.4905],\n",
      "        [ 0.9051],\n",
      "        [ 0.9623],\n",
      "        [ 0.9051],\n",
      "        [ 0.8153],\n",
      "        [-1.5735],\n",
      "        [-0.8710],\n",
      "        [ 0.5578],\n",
      "        [-0.2223],\n",
      "        [ 0.9339],\n",
      "        [-0.2223],\n",
      "        [ 0.5578],\n",
      "        [-0.6120],\n",
      "        [-0.3061],\n",
      "        [ 0.8756],\n",
      "        [ 0.7531],\n",
      "        [ 0.7844],\n",
      "        [ 1.2138],\n",
      "        [ 1.2138],\n",
      "        [ 1.0700],\n",
      "        [-0.3061],\n",
      "        [-1.2166],\n",
      "        [ 1.0700],\n",
      "        [-1.4519],\n",
      "        [ 0.9623],\n",
      "        [-1.3286],\n",
      "        [ 0.5578],\n",
      "        [-0.2223],\n",
      "        [ 0.7531],\n",
      "        [ 0.5242],\n",
      "        [ 1.2138],\n",
      "        [ 0.7531],\n",
      "        [-0.6901],\n",
      "        [-0.1343],\n",
      "        [-1.0567],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8710],\n",
      "        [ 0.6241],\n",
      "        [ 1.2138],\n",
      "        [-1.5876],\n",
      "        [ 0.0535],\n",
      "        [-0.4118],\n",
      "        [-1.3286],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5619],\n",
      "        [-1.5406],\n",
      "        [ 0.6241],\n",
      "        [-1.4519],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2138],\n",
      "        [ 1.1747]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 274/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0221,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1770],\n",
      "        [-1.1770],\n",
      "        [ 0.6569],\n",
      "        [ 0.5910],\n",
      "        [-0.0421],\n",
      "        [ 0.4905],\n",
      "        [ 0.9050],\n",
      "        [ 0.9623],\n",
      "        [ 0.9050],\n",
      "        [ 0.8153],\n",
      "        [-1.5736],\n",
      "        [-0.8711],\n",
      "        [ 0.5577],\n",
      "        [-0.2222],\n",
      "        [ 0.9339],\n",
      "        [-0.2222],\n",
      "        [ 0.5577],\n",
      "        [-0.6121],\n",
      "        [-0.3061],\n",
      "        [ 0.8756],\n",
      "        [ 0.7531],\n",
      "        [ 0.7844],\n",
      "        [ 1.2139],\n",
      "        [ 1.2139],\n",
      "        [ 1.0700],\n",
      "        [-0.3061],\n",
      "        [-1.2166],\n",
      "        [ 1.0700],\n",
      "        [-1.4518],\n",
      "        [ 0.9623],\n",
      "        [-1.3285],\n",
      "        [ 0.5577],\n",
      "        [-0.2222],\n",
      "        [ 0.7531],\n",
      "        [ 0.5242],\n",
      "        [ 1.2139],\n",
      "        [ 0.7531],\n",
      "        [-0.6903],\n",
      "        [-0.1342],\n",
      "        [-1.0568],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8711],\n",
      "        [ 0.6241],\n",
      "        [ 1.2139],\n",
      "        [-1.5877],\n",
      "        [ 0.0535],\n",
      "        [-0.4118],\n",
      "        [-1.3285],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5620],\n",
      "        [-1.5407],\n",
      "        [ 0.6241],\n",
      "        [-1.4518],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2139],\n",
      "        [ 1.1748]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 275/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0221,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1769],\n",
      "        [-1.1769],\n",
      "        [ 0.6568],\n",
      "        [ 0.5910],\n",
      "        [-0.0421],\n",
      "        [ 0.4905],\n",
      "        [ 0.9050],\n",
      "        [ 0.9623],\n",
      "        [ 0.9050],\n",
      "        [ 0.8152],\n",
      "        [-1.5737],\n",
      "        [-0.8712],\n",
      "        [ 0.5577],\n",
      "        [-0.2222],\n",
      "        [ 0.9339],\n",
      "        [-0.2222],\n",
      "        [ 0.5577],\n",
      "        [-0.6122],\n",
      "        [-0.3060],\n",
      "        [ 0.8756],\n",
      "        [ 0.7531],\n",
      "        [ 0.7844],\n",
      "        [ 1.2140],\n",
      "        [ 1.2140],\n",
      "        [ 1.0701],\n",
      "        [-0.3060],\n",
      "        [-1.2165],\n",
      "        [ 1.0701],\n",
      "        [-1.4518],\n",
      "        [ 0.9623],\n",
      "        [-1.3284],\n",
      "        [ 0.5577],\n",
      "        [-0.2222],\n",
      "        [ 0.7531],\n",
      "        [ 0.5242],\n",
      "        [ 1.2140],\n",
      "        [ 0.7531],\n",
      "        [-0.6904],\n",
      "        [-0.1341],\n",
      "        [-1.0568],\n",
      "        [-1.1369],\n",
      "        [ 0.9623],\n",
      "        [-0.8712],\n",
      "        [ 0.6241],\n",
      "        [ 1.2140],\n",
      "        [-1.5878],\n",
      "        [ 0.0536],\n",
      "        [-0.4118],\n",
      "        [-1.3284],\n",
      "        [ 1.0173],\n",
      "        [-0.4118],\n",
      "        [-0.5621],\n",
      "        [-1.5407],\n",
      "        [ 0.6241],\n",
      "        [-1.4518],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2140],\n",
      "        [ 1.1748]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 276/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0220,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1769],\n",
      "        [-1.1769],\n",
      "        [ 0.6568],\n",
      "        [ 0.5910],\n",
      "        [-0.0420],\n",
      "        [ 0.4905],\n",
      "        [ 0.9049],\n",
      "        [ 0.9622],\n",
      "        [ 0.9049],\n",
      "        [ 0.8152],\n",
      "        [-1.5738],\n",
      "        [-0.8714],\n",
      "        [ 0.5577],\n",
      "        [-0.2221],\n",
      "        [ 0.9339],\n",
      "        [-0.2221],\n",
      "        [ 0.5577],\n",
      "        [-0.6123],\n",
      "        [-0.3060],\n",
      "        [ 0.8755],\n",
      "        [ 0.7530],\n",
      "        [ 0.7843],\n",
      "        [ 1.2141],\n",
      "        [ 1.2141],\n",
      "        [ 1.0701],\n",
      "        [-0.3060],\n",
      "        [-1.2164],\n",
      "        [ 1.0701],\n",
      "        [-1.4517],\n",
      "        [ 0.9622],\n",
      "        [-1.3283],\n",
      "        [ 0.5577],\n",
      "        [-0.2221],\n",
      "        [ 0.7530],\n",
      "        [ 0.5242],\n",
      "        [ 1.2141],\n",
      "        [ 0.7530],\n",
      "        [-0.6905],\n",
      "        [-0.1340],\n",
      "        [-1.0568],\n",
      "        [-1.1369],\n",
      "        [ 0.9622],\n",
      "        [-0.8714],\n",
      "        [ 0.6240],\n",
      "        [ 1.2141],\n",
      "        [-1.5879],\n",
      "        [ 0.0537],\n",
      "        [-0.4117],\n",
      "        [-1.3283],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5621],\n",
      "        [-1.5407],\n",
      "        [ 0.6240],\n",
      "        [-1.4517],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2141],\n",
      "        [ 1.1749]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 277/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0220,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1769],\n",
      "        [-1.1769],\n",
      "        [ 0.6567],\n",
      "        [ 0.5909],\n",
      "        [-0.0419],\n",
      "        [ 0.4905],\n",
      "        [ 0.9049],\n",
      "        [ 0.9622],\n",
      "        [ 0.9049],\n",
      "        [ 0.8151],\n",
      "        [-1.5739],\n",
      "        [-0.8715],\n",
      "        [ 0.5577],\n",
      "        [-0.2220],\n",
      "        [ 0.9338],\n",
      "        [-0.2220],\n",
      "        [ 0.5577],\n",
      "        [-0.6124],\n",
      "        [-0.3059],\n",
      "        [ 0.8755],\n",
      "        [ 0.7530],\n",
      "        [ 0.7843],\n",
      "        [ 1.2142],\n",
      "        [ 1.2142],\n",
      "        [ 1.0701],\n",
      "        [-0.3059],\n",
      "        [-1.2164],\n",
      "        [ 1.0701],\n",
      "        [-1.4516],\n",
      "        [ 0.9622],\n",
      "        [-1.3282],\n",
      "        [ 0.5577],\n",
      "        [-0.2220],\n",
      "        [ 0.7530],\n",
      "        [ 0.5242],\n",
      "        [ 1.2142],\n",
      "        [ 0.7530],\n",
      "        [-0.6906],\n",
      "        [-0.1340],\n",
      "        [-1.0569],\n",
      "        [-1.1368],\n",
      "        [ 0.9622],\n",
      "        [-0.8715],\n",
      "        [ 0.6240],\n",
      "        [ 1.2142],\n",
      "        [-1.5881],\n",
      "        [ 0.0538],\n",
      "        [-0.4117],\n",
      "        [-1.3282],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5622],\n",
      "        [-1.5408],\n",
      "        [ 0.6240],\n",
      "        [-1.4516],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2142],\n",
      "        [ 1.1749]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 278/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0219,\n",
      " epoch_time_duration: 0.0165\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1768],\n",
      "        [-1.1768],\n",
      "        [ 0.6567],\n",
      "        [ 0.5909],\n",
      "        [-0.0418],\n",
      "        [ 0.4905],\n",
      "        [ 0.9049],\n",
      "        [ 0.9622],\n",
      "        [ 0.9049],\n",
      "        [ 0.8151],\n",
      "        [-1.5740],\n",
      "        [-0.8717],\n",
      "        [ 0.5576],\n",
      "        [-0.2219],\n",
      "        [ 0.9338],\n",
      "        [-0.2219],\n",
      "        [ 0.5576],\n",
      "        [-0.6125],\n",
      "        [-0.3058],\n",
      "        [ 0.8754],\n",
      "        [ 0.7529],\n",
      "        [ 0.7842],\n",
      "        [ 1.2143],\n",
      "        [ 1.2143],\n",
      "        [ 1.0701],\n",
      "        [-0.3058],\n",
      "        [-1.2163],\n",
      "        [ 1.0701],\n",
      "        [-1.4516],\n",
      "        [ 0.9622],\n",
      "        [-1.3281],\n",
      "        [ 0.5576],\n",
      "        [-0.2219],\n",
      "        [ 0.7529],\n",
      "        [ 0.5242],\n",
      "        [ 1.2143],\n",
      "        [ 0.7529],\n",
      "        [-0.6908],\n",
      "        [-0.1339],\n",
      "        [-1.0569],\n",
      "        [-1.1368],\n",
      "        [ 0.9622],\n",
      "        [-0.8717],\n",
      "        [ 0.6240],\n",
      "        [ 1.2143],\n",
      "        [-1.5882],\n",
      "        [ 0.0538],\n",
      "        [-0.4117],\n",
      "        [-1.3281],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5623],\n",
      "        [-1.5408],\n",
      "        [ 0.6240],\n",
      "        [-1.4516],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2143],\n",
      "        [ 1.1750]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 279/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0219,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1768],\n",
      "        [-1.1768],\n",
      "        [ 0.6567],\n",
      "        [ 0.5909],\n",
      "        [-0.0417],\n",
      "        [ 0.4905],\n",
      "        [ 0.9048],\n",
      "        [ 0.9622],\n",
      "        [ 0.9048],\n",
      "        [ 0.8151],\n",
      "        [-1.5741],\n",
      "        [-0.8718],\n",
      "        [ 0.5576],\n",
      "        [-0.2219],\n",
      "        [ 0.9338],\n",
      "        [-0.2219],\n",
      "        [ 0.5576],\n",
      "        [-0.6126],\n",
      "        [-0.3058],\n",
      "        [ 0.8754],\n",
      "        [ 0.7529],\n",
      "        [ 0.7842],\n",
      "        [ 1.2144],\n",
      "        [ 1.2144],\n",
      "        [ 1.0701],\n",
      "        [-0.3058],\n",
      "        [-1.2163],\n",
      "        [ 1.0701],\n",
      "        [-1.4515],\n",
      "        [ 0.9622],\n",
      "        [-1.3280],\n",
      "        [ 0.5576],\n",
      "        [-0.2219],\n",
      "        [ 0.7529],\n",
      "        [ 0.5241],\n",
      "        [ 1.2144],\n",
      "        [ 0.7529],\n",
      "        [-0.6909],\n",
      "        [-0.1338],\n",
      "        [-1.0570],\n",
      "        [-1.1368],\n",
      "        [ 0.9622],\n",
      "        [-0.8718],\n",
      "        [ 0.6239],\n",
      "        [ 1.2144],\n",
      "        [-1.5883],\n",
      "        [ 0.0539],\n",
      "        [-0.4117],\n",
      "        [-1.3280],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5624],\n",
      "        [-1.5408],\n",
      "        [ 0.6239],\n",
      "        [-1.4515],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2144],\n",
      "        [ 1.1751]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 280/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0218,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1768],\n",
      "        [-1.1768],\n",
      "        [ 0.6566],\n",
      "        [ 0.5909],\n",
      "        [-0.0416],\n",
      "        [ 0.4905],\n",
      "        [ 0.9048],\n",
      "        [ 0.9621],\n",
      "        [ 0.9048],\n",
      "        [ 0.8150],\n",
      "        [-1.5742],\n",
      "        [-0.8720],\n",
      "        [ 0.5576],\n",
      "        [-0.2218],\n",
      "        [ 0.9337],\n",
      "        [-0.2218],\n",
      "        [ 0.5576],\n",
      "        [-0.6127],\n",
      "        [-0.3057],\n",
      "        [ 0.8754],\n",
      "        [ 0.7528],\n",
      "        [ 0.7841],\n",
      "        [ 1.2145],\n",
      "        [ 1.2145],\n",
      "        [ 1.0701],\n",
      "        [-0.3057],\n",
      "        [-1.2162],\n",
      "        [ 1.0701],\n",
      "        [-1.4515],\n",
      "        [ 0.9621],\n",
      "        [-1.3280],\n",
      "        [ 0.5576],\n",
      "        [-0.2218],\n",
      "        [ 0.7528],\n",
      "        [ 0.5241],\n",
      "        [ 1.2145],\n",
      "        [ 0.7528],\n",
      "        [-0.6911],\n",
      "        [-0.1337],\n",
      "        [-1.0570],\n",
      "        [-1.1369],\n",
      "        [ 0.9621],\n",
      "        [-0.8720],\n",
      "        [ 0.6239],\n",
      "        [ 1.2145],\n",
      "        [-1.5884],\n",
      "        [ 0.0540],\n",
      "        [-0.4117],\n",
      "        [-1.3280],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5624],\n",
      "        [-1.5409],\n",
      "        [ 0.6239],\n",
      "        [-1.4515],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2145],\n",
      "        [ 1.1752]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 281/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0218,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1768],\n",
      "        [-1.1768],\n",
      "        [ 0.6566],\n",
      "        [ 0.5908],\n",
      "        [-0.0416],\n",
      "        [ 0.4905],\n",
      "        [ 0.9048],\n",
      "        [ 0.9621],\n",
      "        [ 0.9048],\n",
      "        [ 0.8150],\n",
      "        [-1.5743],\n",
      "        [-0.8721],\n",
      "        [ 0.5576],\n",
      "        [-0.2217],\n",
      "        [ 0.9337],\n",
      "        [-0.2217],\n",
      "        [ 0.5576],\n",
      "        [-0.6128],\n",
      "        [-0.3057],\n",
      "        [ 0.8753],\n",
      "        [ 0.7528],\n",
      "        [ 0.7841],\n",
      "        [ 1.2146],\n",
      "        [ 1.2146],\n",
      "        [ 1.0701],\n",
      "        [-0.3057],\n",
      "        [-1.2162],\n",
      "        [ 1.0701],\n",
      "        [-1.4514],\n",
      "        [ 0.9621],\n",
      "        [-1.3279],\n",
      "        [ 0.5576],\n",
      "        [-0.2217],\n",
      "        [ 0.7528],\n",
      "        [ 0.5241],\n",
      "        [ 1.2146],\n",
      "        [ 0.7528],\n",
      "        [-0.6912],\n",
      "        [-0.1336],\n",
      "        [-1.0571],\n",
      "        [-1.1369],\n",
      "        [ 0.9621],\n",
      "        [-0.8721],\n",
      "        [ 0.6239],\n",
      "        [ 1.2146],\n",
      "        [-1.5886],\n",
      "        [ 0.0541],\n",
      "        [-0.4117],\n",
      "        [-1.3279],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5625],\n",
      "        [-1.5409],\n",
      "        [ 0.6239],\n",
      "        [-1.4514],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2146],\n",
      "        [ 1.1752]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 282/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0217,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1767],\n",
      "        [-1.1767],\n",
      "        [ 0.6566],\n",
      "        [ 0.5908],\n",
      "        [-0.0415],\n",
      "        [ 0.4904],\n",
      "        [ 0.9048],\n",
      "        [ 0.9621],\n",
      "        [ 0.9048],\n",
      "        [ 0.8149],\n",
      "        [-1.5743],\n",
      "        [-0.8722],\n",
      "        [ 0.5576],\n",
      "        [-0.2217],\n",
      "        [ 0.9337],\n",
      "        [-0.2217],\n",
      "        [ 0.5576],\n",
      "        [-0.6129],\n",
      "        [-0.3056],\n",
      "        [ 0.8753],\n",
      "        [ 0.7528],\n",
      "        [ 0.7841],\n",
      "        [ 1.2147],\n",
      "        [ 1.2147],\n",
      "        [ 1.0701],\n",
      "        [-0.3056],\n",
      "        [-1.2161],\n",
      "        [ 1.0701],\n",
      "        [-1.4514],\n",
      "        [ 0.9621],\n",
      "        [-1.3278],\n",
      "        [ 0.5576],\n",
      "        [-0.2217],\n",
      "        [ 0.7528],\n",
      "        [ 0.5241],\n",
      "        [ 1.2147],\n",
      "        [ 0.7528],\n",
      "        [-0.6913],\n",
      "        [-0.1336],\n",
      "        [-1.0571],\n",
      "        [-1.1368],\n",
      "        [ 0.9621],\n",
      "        [-0.8722],\n",
      "        [ 0.6238],\n",
      "        [ 1.2147],\n",
      "        [-1.5887],\n",
      "        [ 0.0541],\n",
      "        [-0.4117],\n",
      "        [-1.3278],\n",
      "        [ 1.0173],\n",
      "        [-0.4117],\n",
      "        [-0.5626],\n",
      "        [-1.5410],\n",
      "        [ 0.6238],\n",
      "        [-1.4514],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2147],\n",
      "        [ 1.1753]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 283/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0217,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1767],\n",
      "        [-1.1767],\n",
      "        [ 0.6565],\n",
      "        [ 0.5908],\n",
      "        [-0.0414],\n",
      "        [ 0.4904],\n",
      "        [ 0.9047],\n",
      "        [ 0.9621],\n",
      "        [ 0.9047],\n",
      "        [ 0.8149],\n",
      "        [-1.5744],\n",
      "        [-0.8724],\n",
      "        [ 0.5575],\n",
      "        [-0.2216],\n",
      "        [ 0.9337],\n",
      "        [-0.2216],\n",
      "        [ 0.5575],\n",
      "        [-0.6130],\n",
      "        [-0.3056],\n",
      "        [ 0.8753],\n",
      "        [ 0.7527],\n",
      "        [ 0.7840],\n",
      "        [ 1.2148],\n",
      "        [ 1.2148],\n",
      "        [ 1.0702],\n",
      "        [-0.3056],\n",
      "        [-1.2161],\n",
      "        [ 1.0702],\n",
      "        [-1.4513],\n",
      "        [ 0.9621],\n",
      "        [-1.3277],\n",
      "        [ 0.5575],\n",
      "        [-0.2216],\n",
      "        [ 0.7527],\n",
      "        [ 0.5241],\n",
      "        [ 1.2148],\n",
      "        [ 0.7527],\n",
      "        [-0.6915],\n",
      "        [-0.1335],\n",
      "        [-1.0572],\n",
      "        [-1.1368],\n",
      "        [ 0.9621],\n",
      "        [-0.8724],\n",
      "        [ 0.6238],\n",
      "        [ 1.2148],\n",
      "        [-1.5888],\n",
      "        [ 0.0542],\n",
      "        [-0.4116],\n",
      "        [-1.3277],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5626],\n",
      "        [-1.5410],\n",
      "        [ 0.6238],\n",
      "        [-1.4513],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2148],\n",
      "        [ 1.1754]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 284/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0216,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6565],\n",
      "        [ 0.5908],\n",
      "        [-0.0413],\n",
      "        [ 0.4904],\n",
      "        [ 0.9047],\n",
      "        [ 0.9620],\n",
      "        [ 0.9047],\n",
      "        [ 0.8148],\n",
      "        [-1.5745],\n",
      "        [-0.8725],\n",
      "        [ 0.5575],\n",
      "        [-0.2215],\n",
      "        [ 0.9336],\n",
      "        [-0.2215],\n",
      "        [ 0.5575],\n",
      "        [-0.6131],\n",
      "        [-0.3055],\n",
      "        [ 0.8752],\n",
      "        [ 0.7527],\n",
      "        [ 0.7840],\n",
      "        [ 1.2148],\n",
      "        [ 1.2148],\n",
      "        [ 1.0702],\n",
      "        [-0.3055],\n",
      "        [-1.2160],\n",
      "        [ 1.0702],\n",
      "        [-1.4512],\n",
      "        [ 0.9620],\n",
      "        [-1.3276],\n",
      "        [ 0.5575],\n",
      "        [-0.2215],\n",
      "        [ 0.7527],\n",
      "        [ 0.5241],\n",
      "        [ 1.2148],\n",
      "        [ 0.7527],\n",
      "        [-0.6916],\n",
      "        [-0.1334],\n",
      "        [-1.0572],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8725],\n",
      "        [ 0.6238],\n",
      "        [ 1.2148],\n",
      "        [-1.5889],\n",
      "        [ 0.0543],\n",
      "        [-0.4116],\n",
      "        [-1.3276],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5627],\n",
      "        [-1.5410],\n",
      "        [ 0.6238],\n",
      "        [-1.4512],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2148],\n",
      "        [ 1.1754]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 285/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0216,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6564],\n",
      "        [ 0.5907],\n",
      "        [-0.0413],\n",
      "        [ 0.4904],\n",
      "        [ 0.9047],\n",
      "        [ 0.9620],\n",
      "        [ 0.9047],\n",
      "        [ 0.8148],\n",
      "        [-1.5746],\n",
      "        [-0.8727],\n",
      "        [ 0.5575],\n",
      "        [-0.2214],\n",
      "        [ 0.9336],\n",
      "        [-0.2214],\n",
      "        [ 0.5575],\n",
      "        [-0.6132],\n",
      "        [-0.3055],\n",
      "        [ 0.8752],\n",
      "        [ 0.7526],\n",
      "        [ 0.7839],\n",
      "        [ 1.2149],\n",
      "        [ 1.2149],\n",
      "        [ 1.0702],\n",
      "        [-0.3055],\n",
      "        [-1.2160],\n",
      "        [ 1.0702],\n",
      "        [-1.4512],\n",
      "        [ 0.9620],\n",
      "        [-1.3275],\n",
      "        [ 0.5575],\n",
      "        [-0.2214],\n",
      "        [ 0.7526],\n",
      "        [ 0.5240],\n",
      "        [ 1.2149],\n",
      "        [ 0.7526],\n",
      "        [-0.6917],\n",
      "        [-0.1333],\n",
      "        [-1.0573],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8727],\n",
      "        [ 0.6237],\n",
      "        [ 1.2149],\n",
      "        [-1.5890],\n",
      "        [ 0.0543],\n",
      "        [-0.4116],\n",
      "        [-1.3275],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5628],\n",
      "        [-1.5410],\n",
      "        [ 0.6237],\n",
      "        [-1.4512],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2149],\n",
      "        [ 1.1755]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 286/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0215,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6564],\n",
      "        [ 0.5907],\n",
      "        [-0.0412],\n",
      "        [ 0.4904],\n",
      "        [ 0.9046],\n",
      "        [ 0.9620],\n",
      "        [ 0.9046],\n",
      "        [ 0.8148],\n",
      "        [-1.5747],\n",
      "        [-0.8728],\n",
      "        [ 0.5575],\n",
      "        [-0.2214],\n",
      "        [ 0.9336],\n",
      "        [-0.2214],\n",
      "        [ 0.5575],\n",
      "        [-0.6133],\n",
      "        [-0.3054],\n",
      "        [ 0.8752],\n",
      "        [ 0.7526],\n",
      "        [ 0.7839],\n",
      "        [ 1.2150],\n",
      "        [ 1.2150],\n",
      "        [ 1.0702],\n",
      "        [-0.3054],\n",
      "        [-1.2159],\n",
      "        [ 1.0702],\n",
      "        [-1.4511],\n",
      "        [ 0.9620],\n",
      "        [-1.3274],\n",
      "        [ 0.5575],\n",
      "        [-0.2214],\n",
      "        [ 0.7526],\n",
      "        [ 0.5240],\n",
      "        [ 1.2150],\n",
      "        [ 0.7526],\n",
      "        [-0.6919],\n",
      "        [-0.1333],\n",
      "        [-1.0573],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8728],\n",
      "        [ 0.6237],\n",
      "        [ 1.2150],\n",
      "        [-1.5891],\n",
      "        [ 0.0544],\n",
      "        [-0.4116],\n",
      "        [-1.3274],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5628],\n",
      "        [-1.5411],\n",
      "        [ 0.6237],\n",
      "        [-1.4511],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2150],\n",
      "        [ 1.1756]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 287/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0215,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6564],\n",
      "        [ 0.5907],\n",
      "        [-0.0411],\n",
      "        [ 0.4904],\n",
      "        [ 0.9046],\n",
      "        [ 0.9620],\n",
      "        [ 0.9046],\n",
      "        [ 0.8147],\n",
      "        [-1.5747],\n",
      "        [-0.8729],\n",
      "        [ 0.5574],\n",
      "        [-0.2213],\n",
      "        [ 0.9336],\n",
      "        [-0.2213],\n",
      "        [ 0.5574],\n",
      "        [-0.6134],\n",
      "        [-0.3054],\n",
      "        [ 0.8751],\n",
      "        [ 0.7526],\n",
      "        [ 0.7839],\n",
      "        [ 1.2151],\n",
      "        [ 1.2151],\n",
      "        [ 1.0702],\n",
      "        [-0.3054],\n",
      "        [-1.2159],\n",
      "        [ 1.0702],\n",
      "        [-1.4511],\n",
      "        [ 0.9620],\n",
      "        [-1.3274],\n",
      "        [ 0.5574],\n",
      "        [-0.2213],\n",
      "        [ 0.7526],\n",
      "        [ 0.5240],\n",
      "        [ 1.2151],\n",
      "        [ 0.7526],\n",
      "        [-0.6920],\n",
      "        [-0.1332],\n",
      "        [-1.0574],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8729],\n",
      "        [ 0.6237],\n",
      "        [ 1.2151],\n",
      "        [-1.5892],\n",
      "        [ 0.0545],\n",
      "        [-0.4116],\n",
      "        [-1.3274],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5629],\n",
      "        [-1.5411],\n",
      "        [ 0.6237],\n",
      "        [-1.4511],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2151],\n",
      "        [ 1.1756]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 288/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0214,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1766],\n",
      "        [-1.1766],\n",
      "        [ 0.6563],\n",
      "        [ 0.5907],\n",
      "        [-0.0410],\n",
      "        [ 0.4904],\n",
      "        [ 0.9046],\n",
      "        [ 0.9620],\n",
      "        [ 0.9046],\n",
      "        [ 0.8147],\n",
      "        [-1.5748],\n",
      "        [-0.8731],\n",
      "        [ 0.5574],\n",
      "        [-0.2213],\n",
      "        [ 0.9335],\n",
      "        [-0.2213],\n",
      "        [ 0.5574],\n",
      "        [-0.6135],\n",
      "        [-0.3053],\n",
      "        [ 0.8751],\n",
      "        [ 0.7525],\n",
      "        [ 0.7838],\n",
      "        [ 1.2152],\n",
      "        [ 1.2152],\n",
      "        [ 1.0702],\n",
      "        [-0.3053],\n",
      "        [-1.2158],\n",
      "        [ 1.0702],\n",
      "        [-1.4510],\n",
      "        [ 0.9620],\n",
      "        [-1.3273],\n",
      "        [ 0.5574],\n",
      "        [-0.2213],\n",
      "        [ 0.7525],\n",
      "        [ 0.5240],\n",
      "        [ 1.2152],\n",
      "        [ 0.7525],\n",
      "        [-0.6921],\n",
      "        [-0.1331],\n",
      "        [-1.0574],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8731],\n",
      "        [ 0.6236],\n",
      "        [ 1.2152],\n",
      "        [-1.5893],\n",
      "        [ 0.0545],\n",
      "        [-0.4116],\n",
      "        [-1.3273],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5630],\n",
      "        [-1.5411],\n",
      "        [ 0.6236],\n",
      "        [-1.4510],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2152],\n",
      "        [ 1.1757]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 289/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0214,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1765],\n",
      "        [-1.1765],\n",
      "        [ 0.6563],\n",
      "        [ 0.5906],\n",
      "        [-0.0410],\n",
      "        [ 0.4904],\n",
      "        [ 0.9045],\n",
      "        [ 0.9620],\n",
      "        [ 0.9045],\n",
      "        [ 0.8147],\n",
      "        [-1.5749],\n",
      "        [-0.8732],\n",
      "        [ 0.5574],\n",
      "        [-0.2212],\n",
      "        [ 0.9335],\n",
      "        [-0.2212],\n",
      "        [ 0.5574],\n",
      "        [-0.6136],\n",
      "        [-0.3053],\n",
      "        [ 0.8751],\n",
      "        [ 0.7525],\n",
      "        [ 0.7838],\n",
      "        [ 1.2153],\n",
      "        [ 1.2153],\n",
      "        [ 1.0702],\n",
      "        [-0.3053],\n",
      "        [-1.2158],\n",
      "        [ 1.0702],\n",
      "        [-1.4509],\n",
      "        [ 0.9620],\n",
      "        [-1.3272],\n",
      "        [ 0.5574],\n",
      "        [-0.2212],\n",
      "        [ 0.7525],\n",
      "        [ 0.5240],\n",
      "        [ 1.2153],\n",
      "        [ 0.7525],\n",
      "        [-0.6923],\n",
      "        [-0.1330],\n",
      "        [-1.0575],\n",
      "        [-1.1368],\n",
      "        [ 0.9620],\n",
      "        [-0.8732],\n",
      "        [ 0.6236],\n",
      "        [ 1.2153],\n",
      "        [-1.5894],\n",
      "        [ 0.0546],\n",
      "        [-0.4116],\n",
      "        [-1.3272],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5631],\n",
      "        [-1.5411],\n",
      "        [ 0.6236],\n",
      "        [-1.4509],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2153],\n",
      "        [ 1.1758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 290/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0213,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1765],\n",
      "        [-1.1765],\n",
      "        [ 0.6563],\n",
      "        [ 0.5906],\n",
      "        [-0.0409],\n",
      "        [ 0.4903],\n",
      "        [ 0.9045],\n",
      "        [ 0.9619],\n",
      "        [ 0.9045],\n",
      "        [ 0.8146],\n",
      "        [-1.5750],\n",
      "        [-0.8733],\n",
      "        [ 0.5574],\n",
      "        [-0.2211],\n",
      "        [ 0.9335],\n",
      "        [-0.2211],\n",
      "        [ 0.5574],\n",
      "        [-0.6137],\n",
      "        [-0.3052],\n",
      "        [ 0.8750],\n",
      "        [ 0.7524],\n",
      "        [ 0.7837],\n",
      "        [ 1.2154],\n",
      "        [ 1.2154],\n",
      "        [ 1.0702],\n",
      "        [-0.3052],\n",
      "        [-1.2157],\n",
      "        [ 1.0702],\n",
      "        [-1.4509],\n",
      "        [ 0.9619],\n",
      "        [-1.3271],\n",
      "        [ 0.5574],\n",
      "        [-0.2211],\n",
      "        [ 0.7524],\n",
      "        [ 0.5239],\n",
      "        [ 1.2154],\n",
      "        [ 0.7524],\n",
      "        [-0.6924],\n",
      "        [-0.1329],\n",
      "        [-1.0575],\n",
      "        [-1.1368],\n",
      "        [ 0.9619],\n",
      "        [-0.8733],\n",
      "        [ 0.6236],\n",
      "        [ 1.2154],\n",
      "        [-1.5895],\n",
      "        [ 0.0547],\n",
      "        [-0.4116],\n",
      "        [-1.3271],\n",
      "        [ 1.0172],\n",
      "        [-0.4116],\n",
      "        [-0.5631],\n",
      "        [-1.5412],\n",
      "        [ 0.6236],\n",
      "        [-1.4509],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2154],\n",
      "        [ 1.1758]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 291/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0213,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1765],\n",
      "        [-1.1765],\n",
      "        [ 0.6562],\n",
      "        [ 0.5906],\n",
      "        [-0.0408],\n",
      "        [ 0.4903],\n",
      "        [ 0.9045],\n",
      "        [ 0.9619],\n",
      "        [ 0.9045],\n",
      "        [ 0.8146],\n",
      "        [-1.5750],\n",
      "        [-0.8735],\n",
      "        [ 0.5573],\n",
      "        [-0.2210],\n",
      "        [ 0.9334],\n",
      "        [-0.2210],\n",
      "        [ 0.5573],\n",
      "        [-0.6138],\n",
      "        [-0.3052],\n",
      "        [ 0.8750],\n",
      "        [ 0.7524],\n",
      "        [ 0.7837],\n",
      "        [ 1.2155],\n",
      "        [ 1.2155],\n",
      "        [ 1.0703],\n",
      "        [-0.3052],\n",
      "        [-1.2157],\n",
      "        [ 1.0703],\n",
      "        [-1.4508],\n",
      "        [ 0.9619],\n",
      "        [-1.3270],\n",
      "        [ 0.5573],\n",
      "        [-0.2210],\n",
      "        [ 0.7524],\n",
      "        [ 0.5239],\n",
      "        [ 1.2155],\n",
      "        [ 0.7524],\n",
      "        [-0.6925],\n",
      "        [-0.1329],\n",
      "        [-1.0575],\n",
      "        [-1.1368],\n",
      "        [ 0.9619],\n",
      "        [-0.8735],\n",
      "        [ 0.6235],\n",
      "        [ 1.2155],\n",
      "        [-1.5896],\n",
      "        [ 0.0547],\n",
      "        [-0.4115],\n",
      "        [-1.3270],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5632],\n",
      "        [-1.5412],\n",
      "        [ 0.6235],\n",
      "        [-1.4508],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2155],\n",
      "        [ 1.1759]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 292/10000,\n",
      " train_loss: 0.0007,\n",
      " train_mae: 0.0212,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1764],\n",
      "        [-1.1764],\n",
      "        [ 0.6562],\n",
      "        [ 0.5905],\n",
      "        [-0.0407],\n",
      "        [ 0.4903],\n",
      "        [ 0.9044],\n",
      "        [ 0.9619],\n",
      "        [ 0.9044],\n",
      "        [ 0.8145],\n",
      "        [-1.5751],\n",
      "        [-0.8736],\n",
      "        [ 0.5573],\n",
      "        [-0.2210],\n",
      "        [ 0.9334],\n",
      "        [-0.2210],\n",
      "        [ 0.5573],\n",
      "        [-0.6138],\n",
      "        [-0.3051],\n",
      "        [ 0.8749],\n",
      "        [ 0.7523],\n",
      "        [ 0.7836],\n",
      "        [ 1.2156],\n",
      "        [ 1.2156],\n",
      "        [ 1.0703],\n",
      "        [-0.3051],\n",
      "        [-1.2156],\n",
      "        [ 1.0703],\n",
      "        [-1.4508],\n",
      "        [ 0.9619],\n",
      "        [-1.3269],\n",
      "        [ 0.5573],\n",
      "        [-0.2210],\n",
      "        [ 0.7523],\n",
      "        [ 0.5239],\n",
      "        [ 1.2156],\n",
      "        [ 0.7523],\n",
      "        [-0.6926],\n",
      "        [-0.1328],\n",
      "        [-1.0576],\n",
      "        [-1.1368],\n",
      "        [ 0.9619],\n",
      "        [-0.8736],\n",
      "        [ 0.6235],\n",
      "        [ 1.2156],\n",
      "        [-1.5897],\n",
      "        [ 0.0548],\n",
      "        [-0.4115],\n",
      "        [-1.3269],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5632],\n",
      "        [-1.5412],\n",
      "        [ 0.6235],\n",
      "        [-1.4508],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2156],\n",
      "        [ 1.1760]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 293/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0212,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1764],\n",
      "        [-1.1764],\n",
      "        [ 0.6562],\n",
      "        [ 0.5905],\n",
      "        [-0.0407],\n",
      "        [ 0.4903],\n",
      "        [ 0.9044],\n",
      "        [ 0.9619],\n",
      "        [ 0.9044],\n",
      "        [ 0.8145],\n",
      "        [-1.5752],\n",
      "        [-0.8738],\n",
      "        [ 0.5573],\n",
      "        [-0.2209],\n",
      "        [ 0.9334],\n",
      "        [-0.2209],\n",
      "        [ 0.5573],\n",
      "        [-0.6139],\n",
      "        [-0.3051],\n",
      "        [ 0.8749],\n",
      "        [ 0.7523],\n",
      "        [ 0.7836],\n",
      "        [ 1.2157],\n",
      "        [ 1.2157],\n",
      "        [ 1.0703],\n",
      "        [-0.3051],\n",
      "        [-1.2156],\n",
      "        [ 1.0703],\n",
      "        [-1.4507],\n",
      "        [ 0.9619],\n",
      "        [-1.3268],\n",
      "        [ 0.5573],\n",
      "        [-0.2209],\n",
      "        [ 0.7523],\n",
      "        [ 0.5239],\n",
      "        [ 1.2157],\n",
      "        [ 0.7523],\n",
      "        [-0.6928],\n",
      "        [-0.1327],\n",
      "        [-1.0576],\n",
      "        [-1.1368],\n",
      "        [ 0.9619],\n",
      "        [-0.8738],\n",
      "        [ 0.6235],\n",
      "        [ 1.2157],\n",
      "        [-1.5898],\n",
      "        [ 0.0549],\n",
      "        [-0.4115],\n",
      "        [-1.3268],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5633],\n",
      "        [-1.5412],\n",
      "        [ 0.6235],\n",
      "        [-1.4507],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2157],\n",
      "        [ 1.1760]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 294/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0211,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1764],\n",
      "        [-1.1764],\n",
      "        [ 0.6561],\n",
      "        [ 0.5905],\n",
      "        [-0.0406],\n",
      "        [ 0.4903],\n",
      "        [ 0.9044],\n",
      "        [ 0.9618],\n",
      "        [ 0.9044],\n",
      "        [ 0.8145],\n",
      "        [-1.5753],\n",
      "        [-0.8739],\n",
      "        [ 0.5573],\n",
      "        [-0.2208],\n",
      "        [ 0.9334],\n",
      "        [-0.2208],\n",
      "        [ 0.5573],\n",
      "        [-0.6140],\n",
      "        [-0.3050],\n",
      "        [ 0.8749],\n",
      "        [ 0.7523],\n",
      "        [ 0.7836],\n",
      "        [ 1.2158],\n",
      "        [ 1.2158],\n",
      "        [ 1.0703],\n",
      "        [-0.3050],\n",
      "        [-1.2155],\n",
      "        [ 1.0703],\n",
      "        [-1.4507],\n",
      "        [ 0.9618],\n",
      "        [-1.3268],\n",
      "        [ 0.5573],\n",
      "        [-0.2208],\n",
      "        [ 0.7523],\n",
      "        [ 0.5239],\n",
      "        [ 1.2158],\n",
      "        [ 0.7523],\n",
      "        [-0.6929],\n",
      "        [-0.1326],\n",
      "        [-1.0577],\n",
      "        [-1.1368],\n",
      "        [ 0.9618],\n",
      "        [-0.8739],\n",
      "        [ 0.6234],\n",
      "        [ 1.2158],\n",
      "        [-1.5899],\n",
      "        [ 0.0549],\n",
      "        [-0.4115],\n",
      "        [-1.3268],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5634],\n",
      "        [-1.5413],\n",
      "        [ 0.6234],\n",
      "        [-1.4507],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2158],\n",
      "        [ 1.1761]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 295/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0211,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1764],\n",
      "        [-1.1764],\n",
      "        [ 0.6561],\n",
      "        [ 0.5905],\n",
      "        [-0.0405],\n",
      "        [ 0.4903],\n",
      "        [ 0.9043],\n",
      "        [ 0.9618],\n",
      "        [ 0.9043],\n",
      "        [ 0.8144],\n",
      "        [-1.5754],\n",
      "        [-0.8740],\n",
      "        [ 0.5573],\n",
      "        [-0.2208],\n",
      "        [ 0.9333],\n",
      "        [-0.2208],\n",
      "        [ 0.5573],\n",
      "        [-0.6141],\n",
      "        [-0.3050],\n",
      "        [ 0.8748],\n",
      "        [ 0.7522],\n",
      "        [ 0.7835],\n",
      "        [ 1.2159],\n",
      "        [ 1.2159],\n",
      "        [ 1.0703],\n",
      "        [-0.3050],\n",
      "        [-1.2155],\n",
      "        [ 1.0703],\n",
      "        [-1.4506],\n",
      "        [ 0.9618],\n",
      "        [-1.3267],\n",
      "        [ 0.5573],\n",
      "        [-0.2208],\n",
      "        [ 0.7522],\n",
      "        [ 0.5239],\n",
      "        [ 1.2159],\n",
      "        [ 0.7522],\n",
      "        [-0.6930],\n",
      "        [-0.1326],\n",
      "        [-1.0577],\n",
      "        [-1.1368],\n",
      "        [ 0.9618],\n",
      "        [-0.8740],\n",
      "        [ 0.6234],\n",
      "        [ 1.2159],\n",
      "        [-1.5900],\n",
      "        [ 0.0550],\n",
      "        [-0.4115],\n",
      "        [-1.3267],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5634],\n",
      "        [-1.5413],\n",
      "        [ 0.6234],\n",
      "        [-1.4506],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2159],\n",
      "        [ 1.1762]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 296/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0210,\n",
      " epoch_time_duration: 0.0131\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1763],\n",
      "        [-1.1763],\n",
      "        [ 0.6561],\n",
      "        [ 0.5904],\n",
      "        [-0.0404],\n",
      "        [ 0.4903],\n",
      "        [ 0.9043],\n",
      "        [ 0.9618],\n",
      "        [ 0.9043],\n",
      "        [ 0.8144],\n",
      "        [-1.5755],\n",
      "        [-0.8742],\n",
      "        [ 0.5572],\n",
      "        [-0.2207],\n",
      "        [ 0.9333],\n",
      "        [-0.2207],\n",
      "        [ 0.5572],\n",
      "        [-0.6142],\n",
      "        [-0.3049],\n",
      "        [ 0.8748],\n",
      "        [ 0.7522],\n",
      "        [ 0.7835],\n",
      "        [ 1.2160],\n",
      "        [ 1.2160],\n",
      "        [ 1.0703],\n",
      "        [-0.3049],\n",
      "        [-1.2154],\n",
      "        [ 1.0703],\n",
      "        [-1.4506],\n",
      "        [ 0.9618],\n",
      "        [-1.3266],\n",
      "        [ 0.5572],\n",
      "        [-0.2207],\n",
      "        [ 0.7522],\n",
      "        [ 0.5238],\n",
      "        [ 1.2160],\n",
      "        [ 0.7522],\n",
      "        [-0.6931],\n",
      "        [-0.1325],\n",
      "        [-1.0578],\n",
      "        [-1.1368],\n",
      "        [ 0.9618],\n",
      "        [-0.8742],\n",
      "        [ 0.6234],\n",
      "        [ 1.2160],\n",
      "        [-1.5901],\n",
      "        [ 0.0551],\n",
      "        [-0.4115],\n",
      "        [-1.3266],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5635],\n",
      "        [-1.5413],\n",
      "        [ 0.6234],\n",
      "        [-1.4506],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2160],\n",
      "        [ 1.1762]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 297/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0210,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1763],\n",
      "        [-1.1763],\n",
      "        [ 0.6560],\n",
      "        [ 0.5904],\n",
      "        [-0.0404],\n",
      "        [ 0.4903],\n",
      "        [ 0.9043],\n",
      "        [ 0.9618],\n",
      "        [ 0.9043],\n",
      "        [ 0.8143],\n",
      "        [-1.5755],\n",
      "        [-0.8743],\n",
      "        [ 0.5572],\n",
      "        [-0.2206],\n",
      "        [ 0.9333],\n",
      "        [-0.2206],\n",
      "        [ 0.5572],\n",
      "        [-0.6143],\n",
      "        [-0.3049],\n",
      "        [ 0.8748],\n",
      "        [ 0.7521],\n",
      "        [ 0.7834],\n",
      "        [ 1.2160],\n",
      "        [ 1.2160],\n",
      "        [ 1.0703],\n",
      "        [-0.3049],\n",
      "        [-1.2154],\n",
      "        [ 1.0703],\n",
      "        [-1.4505],\n",
      "        [ 0.9618],\n",
      "        [-1.3265],\n",
      "        [ 0.5572],\n",
      "        [-0.2206],\n",
      "        [ 0.7521],\n",
      "        [ 0.5238],\n",
      "        [ 1.2160],\n",
      "        [ 0.7521],\n",
      "        [-0.6933],\n",
      "        [-0.1324],\n",
      "        [-1.0578],\n",
      "        [-1.1368],\n",
      "        [ 0.9618],\n",
      "        [-0.8743],\n",
      "        [ 0.6234],\n",
      "        [ 1.2160],\n",
      "        [-1.5902],\n",
      "        [ 0.0551],\n",
      "        [-0.4115],\n",
      "        [-1.3265],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5636],\n",
      "        [-1.5414],\n",
      "        [ 0.6234],\n",
      "        [-1.4505],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2160],\n",
      "        [ 1.1763]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 298/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0209,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1763],\n",
      "        [-1.1763],\n",
      "        [ 0.6560],\n",
      "        [ 0.5904],\n",
      "        [-0.0403],\n",
      "        [ 0.4903],\n",
      "        [ 0.9042],\n",
      "        [ 0.9618],\n",
      "        [ 0.9042],\n",
      "        [ 0.8143],\n",
      "        [-1.5756],\n",
      "        [-0.8744],\n",
      "        [ 0.5572],\n",
      "        [-0.2206],\n",
      "        [ 0.9333],\n",
      "        [-0.2206],\n",
      "        [ 0.5572],\n",
      "        [-0.6144],\n",
      "        [-0.3048],\n",
      "        [ 0.8747],\n",
      "        [ 0.7521],\n",
      "        [ 0.7834],\n",
      "        [ 1.2161],\n",
      "        [ 1.2161],\n",
      "        [ 1.0703],\n",
      "        [-0.3048],\n",
      "        [-1.2154],\n",
      "        [ 1.0703],\n",
      "        [-1.4504],\n",
      "        [ 0.9618],\n",
      "        [-1.3264],\n",
      "        [ 0.5572],\n",
      "        [-0.2206],\n",
      "        [ 0.7521],\n",
      "        [ 0.5238],\n",
      "        [ 1.2161],\n",
      "        [ 0.7521],\n",
      "        [-0.6934],\n",
      "        [-0.1323],\n",
      "        [-1.0578],\n",
      "        [-1.1368],\n",
      "        [ 0.9618],\n",
      "        [-0.8744],\n",
      "        [ 0.6233],\n",
      "        [ 1.2161],\n",
      "        [-1.5903],\n",
      "        [ 0.0552],\n",
      "        [-0.4115],\n",
      "        [-1.3264],\n",
      "        [ 1.0172],\n",
      "        [-0.4115],\n",
      "        [-0.5636],\n",
      "        [-1.5414],\n",
      "        [ 0.6233],\n",
      "        [-1.4504],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2161],\n",
      "        [ 1.1764]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 299/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0209,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1762],\n",
      "        [-1.1762],\n",
      "        [ 0.6560],\n",
      "        [ 0.5903],\n",
      "        [-0.0402],\n",
      "        [ 0.4902],\n",
      "        [ 0.9042],\n",
      "        [ 0.9617],\n",
      "        [ 0.9042],\n",
      "        [ 0.8143],\n",
      "        [-1.5757],\n",
      "        [-0.8746],\n",
      "        [ 0.5572],\n",
      "        [-0.2205],\n",
      "        [ 0.9332],\n",
      "        [-0.2205],\n",
      "        [ 0.5572],\n",
      "        [-0.6145],\n",
      "        [-0.3048],\n",
      "        [ 0.8747],\n",
      "        [ 0.7521],\n",
      "        [ 0.7834],\n",
      "        [ 1.2162],\n",
      "        [ 1.2162],\n",
      "        [ 1.0704],\n",
      "        [-0.3048],\n",
      "        [-1.2153],\n",
      "        [ 1.0704],\n",
      "        [-1.4504],\n",
      "        [ 0.9617],\n",
      "        [-1.3264],\n",
      "        [ 0.5572],\n",
      "        [-0.2205],\n",
      "        [ 0.7521],\n",
      "        [ 0.5238],\n",
      "        [ 1.2162],\n",
      "        [ 0.7521],\n",
      "        [-0.6935],\n",
      "        [-0.1323],\n",
      "        [-1.0579],\n",
      "        [-1.1368],\n",
      "        [ 0.9617],\n",
      "        [-0.8746],\n",
      "        [ 0.6233],\n",
      "        [ 1.2162],\n",
      "        [-1.5904],\n",
      "        [ 0.0553],\n",
      "        [-0.4114],\n",
      "        [-1.3264],\n",
      "        [ 1.0172],\n",
      "        [-0.4114],\n",
      "        [-0.5637],\n",
      "        [-1.5414],\n",
      "        [ 0.6233],\n",
      "        [-1.4504],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2162],\n",
      "        [ 1.1764]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 300/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0208,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1762],\n",
      "        [-1.1762],\n",
      "        [ 0.6559],\n",
      "        [ 0.5903],\n",
      "        [-0.0401],\n",
      "        [ 0.4902],\n",
      "        [ 0.9042],\n",
      "        [ 0.9617],\n",
      "        [ 0.9042],\n",
      "        [ 0.8142],\n",
      "        [-1.5758],\n",
      "        [-0.8747],\n",
      "        [ 0.5572],\n",
      "        [-0.2204],\n",
      "        [ 0.9332],\n",
      "        [-0.2204],\n",
      "        [ 0.5572],\n",
      "        [-0.6146],\n",
      "        [-0.3047],\n",
      "        [ 0.8747],\n",
      "        [ 0.7520],\n",
      "        [ 0.7833],\n",
      "        [ 1.2163],\n",
      "        [ 1.2163],\n",
      "        [ 1.0704],\n",
      "        [-0.3047],\n",
      "        [-1.2153],\n",
      "        [ 1.0704],\n",
      "        [-1.4503],\n",
      "        [ 0.9617],\n",
      "        [-1.3263],\n",
      "        [ 0.5572],\n",
      "        [-0.2204],\n",
      "        [ 0.7520],\n",
      "        [ 0.5238],\n",
      "        [ 1.2163],\n",
      "        [ 0.7520],\n",
      "        [-0.6936],\n",
      "        [-0.1322],\n",
      "        [-1.0579],\n",
      "        [-1.1368],\n",
      "        [ 0.9617],\n",
      "        [-0.8747],\n",
      "        [ 0.6233],\n",
      "        [ 1.2163],\n",
      "        [-1.5906],\n",
      "        [ 0.0553],\n",
      "        [-0.4114],\n",
      "        [-1.3263],\n",
      "        [ 1.0172],\n",
      "        [-0.4114],\n",
      "        [-0.5637],\n",
      "        [-1.5414],\n",
      "        [ 0.6233],\n",
      "        [-1.4503],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2163],\n",
      "        [ 1.1765]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 301/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0208,\n",
      " epoch_time_duration: 0.0112\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1762],\n",
      "        [-1.1762],\n",
      "        [ 0.6559],\n",
      "        [ 0.5903],\n",
      "        [-0.0401],\n",
      "        [ 0.4902],\n",
      "        [ 0.9042],\n",
      "        [ 0.9617],\n",
      "        [ 0.9042],\n",
      "        [ 0.8142],\n",
      "        [-1.5758],\n",
      "        [-0.8748],\n",
      "        [ 0.5571],\n",
      "        [-0.2204],\n",
      "        [ 0.9332],\n",
      "        [-0.2204],\n",
      "        [ 0.5571],\n",
      "        [-0.6147],\n",
      "        [-0.3047],\n",
      "        [ 0.8746],\n",
      "        [ 0.7520],\n",
      "        [ 0.7833],\n",
      "        [ 1.2164],\n",
      "        [ 1.2164],\n",
      "        [ 1.0704],\n",
      "        [-0.3047],\n",
      "        [-1.2152],\n",
      "        [ 1.0704],\n",
      "        [-1.4503],\n",
      "        [ 0.9617],\n",
      "        [-1.3262],\n",
      "        [ 0.5571],\n",
      "        [-0.2204],\n",
      "        [ 0.7520],\n",
      "        [ 0.5238],\n",
      "        [ 1.2164],\n",
      "        [ 0.7520],\n",
      "        [-0.6938],\n",
      "        [-0.1321],\n",
      "        [-1.0580],\n",
      "        [-1.1368],\n",
      "        [ 0.9617],\n",
      "        [-0.8748],\n",
      "        [ 0.6232],\n",
      "        [ 1.2164],\n",
      "        [-1.5907],\n",
      "        [ 0.0554],\n",
      "        [-0.4114],\n",
      "        [-1.3262],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5638],\n",
      "        [-1.5415],\n",
      "        [ 0.6232],\n",
      "        [-1.4503],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2164],\n",
      "        [ 1.1766]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 302/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0208,\n",
      " epoch_time_duration: 0.0106\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1762],\n",
      "        [-1.1762],\n",
      "        [ 0.6559],\n",
      "        [ 0.5903],\n",
      "        [-0.0400],\n",
      "        [ 0.4902],\n",
      "        [ 0.9041],\n",
      "        [ 0.9617],\n",
      "        [ 0.9041],\n",
      "        [ 0.8141],\n",
      "        [-1.5759],\n",
      "        [-0.8749],\n",
      "        [ 0.5571],\n",
      "        [-0.2203],\n",
      "        [ 0.9332],\n",
      "        [-0.2203],\n",
      "        [ 0.5571],\n",
      "        [-0.6147],\n",
      "        [-0.3046],\n",
      "        [ 0.8746],\n",
      "        [ 0.7520],\n",
      "        [ 0.7833],\n",
      "        [ 1.2165],\n",
      "        [ 1.2165],\n",
      "        [ 1.0704],\n",
      "        [-0.3046],\n",
      "        [-1.2152],\n",
      "        [ 1.0704],\n",
      "        [-1.4502],\n",
      "        [ 0.9617],\n",
      "        [-1.3261],\n",
      "        [ 0.5571],\n",
      "        [-0.2203],\n",
      "        [ 0.7520],\n",
      "        [ 0.5237],\n",
      "        [ 1.2165],\n",
      "        [ 0.7520],\n",
      "        [-0.6939],\n",
      "        [-0.1321],\n",
      "        [-1.0580],\n",
      "        [-1.1367],\n",
      "        [ 0.9617],\n",
      "        [-0.8749],\n",
      "        [ 0.6232],\n",
      "        [ 1.2165],\n",
      "        [-1.5908],\n",
      "        [ 0.0554],\n",
      "        [-0.4114],\n",
      "        [-1.3261],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5639],\n",
      "        [-1.5415],\n",
      "        [ 0.6232],\n",
      "        [-1.4502],\n",
      "        [ 0.4228],\n",
      "        [-0.4373],\n",
      "        [ 0.4228],\n",
      "        [ 1.2165],\n",
      "        [ 1.1766]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 303/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0207,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1761],\n",
      "        [-1.1761],\n",
      "        [ 0.6558],\n",
      "        [ 0.5902],\n",
      "        [-0.0399],\n",
      "        [ 0.4902],\n",
      "        [ 0.9041],\n",
      "        [ 0.9617],\n",
      "        [ 0.9041],\n",
      "        [ 0.8141],\n",
      "        [-1.5760],\n",
      "        [-0.8751],\n",
      "        [ 0.5571],\n",
      "        [-0.2203],\n",
      "        [ 0.9331],\n",
      "        [-0.2203],\n",
      "        [ 0.5571],\n",
      "        [-0.6148],\n",
      "        [-0.3046],\n",
      "        [ 0.8746],\n",
      "        [ 0.7519],\n",
      "        [ 0.7832],\n",
      "        [ 1.2166],\n",
      "        [ 1.2166],\n",
      "        [ 1.0704],\n",
      "        [-0.3046],\n",
      "        [-1.2151],\n",
      "        [ 1.0704],\n",
      "        [-1.4501],\n",
      "        [ 0.9617],\n",
      "        [-1.3260],\n",
      "        [ 0.5571],\n",
      "        [-0.2203],\n",
      "        [ 0.7519],\n",
      "        [ 0.5237],\n",
      "        [ 1.2166],\n",
      "        [ 0.7519],\n",
      "        [-0.6940],\n",
      "        [-0.1320],\n",
      "        [-1.0581],\n",
      "        [-1.1367],\n",
      "        [ 0.9617],\n",
      "        [-0.8751],\n",
      "        [ 0.6232],\n",
      "        [ 1.2166],\n",
      "        [-1.5909],\n",
      "        [ 0.0555],\n",
      "        [-0.4114],\n",
      "        [-1.3260],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5639],\n",
      "        [-1.5415],\n",
      "        [ 0.6232],\n",
      "        [-1.4501],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2166],\n",
      "        [ 1.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 304/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0207,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1761],\n",
      "        [-1.1761],\n",
      "        [ 0.6558],\n",
      "        [ 0.5902],\n",
      "        [-0.0399],\n",
      "        [ 0.4902],\n",
      "        [ 0.9041],\n",
      "        [ 0.9616],\n",
      "        [ 0.9041],\n",
      "        [ 0.8141],\n",
      "        [-1.5761],\n",
      "        [-0.8752],\n",
      "        [ 0.5571],\n",
      "        [-0.2202],\n",
      "        [ 0.9331],\n",
      "        [-0.2202],\n",
      "        [ 0.5571],\n",
      "        [-0.6149],\n",
      "        [-0.3046],\n",
      "        [ 0.8745],\n",
      "        [ 0.7519],\n",
      "        [ 0.7832],\n",
      "        [ 1.2167],\n",
      "        [ 1.2167],\n",
      "        [ 1.0704],\n",
      "        [-0.3046],\n",
      "        [-1.2151],\n",
      "        [ 1.0704],\n",
      "        [-1.4501],\n",
      "        [ 0.9616],\n",
      "        [-1.3260],\n",
      "        [ 0.5571],\n",
      "        [-0.2202],\n",
      "        [ 0.7519],\n",
      "        [ 0.5237],\n",
      "        [ 1.2167],\n",
      "        [ 0.7519],\n",
      "        [-0.6941],\n",
      "        [-0.1319],\n",
      "        [-1.0581],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8752],\n",
      "        [ 0.6231],\n",
      "        [ 1.2167],\n",
      "        [-1.5910],\n",
      "        [ 0.0556],\n",
      "        [-0.4114],\n",
      "        [-1.3260],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5640],\n",
      "        [-1.5415],\n",
      "        [ 0.6231],\n",
      "        [-1.4501],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2167],\n",
      "        [ 1.1767]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 305/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0206,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1761],\n",
      "        [-1.1761],\n",
      "        [ 0.6558],\n",
      "        [ 0.5902],\n",
      "        [-0.0398],\n",
      "        [ 0.4902],\n",
      "        [ 0.9040],\n",
      "        [ 0.9616],\n",
      "        [ 0.9040],\n",
      "        [ 0.8140],\n",
      "        [-1.5761],\n",
      "        [-0.8753],\n",
      "        [ 0.5570],\n",
      "        [-0.2201],\n",
      "        [ 0.9331],\n",
      "        [-0.2201],\n",
      "        [ 0.5570],\n",
      "        [-0.6150],\n",
      "        [-0.3045],\n",
      "        [ 0.8745],\n",
      "        [ 0.7518],\n",
      "        [ 0.7831],\n",
      "        [ 1.2168],\n",
      "        [ 1.2168],\n",
      "        [ 1.0704],\n",
      "        [-0.3045],\n",
      "        [-1.2150],\n",
      "        [ 1.0704],\n",
      "        [-1.4500],\n",
      "        [ 0.9616],\n",
      "        [-1.3259],\n",
      "        [ 0.5570],\n",
      "        [-0.2201],\n",
      "        [ 0.7518],\n",
      "        [ 0.5237],\n",
      "        [ 1.2168],\n",
      "        [ 0.7518],\n",
      "        [-0.6942],\n",
      "        [-0.1319],\n",
      "        [-1.0581],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8753],\n",
      "        [ 0.6231],\n",
      "        [ 1.2168],\n",
      "        [-1.5911],\n",
      "        [ 0.0556],\n",
      "        [-0.4114],\n",
      "        [-1.3259],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5640],\n",
      "        [-1.5416],\n",
      "        [ 0.6231],\n",
      "        [-1.4500],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2168],\n",
      "        [ 1.1768]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 306/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0206,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1761],\n",
      "        [-1.1761],\n",
      "        [ 0.6557],\n",
      "        [ 0.5902],\n",
      "        [-0.0397],\n",
      "        [ 0.4902],\n",
      "        [ 0.9040],\n",
      "        [ 0.9616],\n",
      "        [ 0.9040],\n",
      "        [ 0.8140],\n",
      "        [-1.5762],\n",
      "        [-0.8754],\n",
      "        [ 0.5570],\n",
      "        [-0.2201],\n",
      "        [ 0.9331],\n",
      "        [-0.2201],\n",
      "        [ 0.5570],\n",
      "        [-0.6151],\n",
      "        [-0.3045],\n",
      "        [ 0.8745],\n",
      "        [ 0.7518],\n",
      "        [ 0.7831],\n",
      "        [ 1.2168],\n",
      "        [ 1.2168],\n",
      "        [ 1.0705],\n",
      "        [-0.3045],\n",
      "        [-1.2150],\n",
      "        [ 1.0705],\n",
      "        [-1.4500],\n",
      "        [ 0.9616],\n",
      "        [-1.3258],\n",
      "        [ 0.5570],\n",
      "        [-0.2201],\n",
      "        [ 0.7518],\n",
      "        [ 0.5237],\n",
      "        [ 1.2168],\n",
      "        [ 0.7518],\n",
      "        [-0.6944],\n",
      "        [-0.1318],\n",
      "        [-1.0582],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8754],\n",
      "        [ 0.6231],\n",
      "        [ 1.2168],\n",
      "        [-1.5912],\n",
      "        [ 0.0557],\n",
      "        [-0.4114],\n",
      "        [-1.3258],\n",
      "        [ 1.0171],\n",
      "        [-0.4114],\n",
      "        [-0.5641],\n",
      "        [-1.5416],\n",
      "        [ 0.6231],\n",
      "        [-1.4500],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2168],\n",
      "        [ 1.1769]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 307/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0205,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1760],\n",
      "        [-1.1760],\n",
      "        [ 0.6557],\n",
      "        [ 0.5901],\n",
      "        [-0.0397],\n",
      "        [ 0.4901],\n",
      "        [ 0.9040],\n",
      "        [ 0.9616],\n",
      "        [ 0.9040],\n",
      "        [ 0.8140],\n",
      "        [-1.5763],\n",
      "        [-0.8756],\n",
      "        [ 0.5570],\n",
      "        [-0.2200],\n",
      "        [ 0.9330],\n",
      "        [-0.2200],\n",
      "        [ 0.5570],\n",
      "        [-0.6152],\n",
      "        [-0.3044],\n",
      "        [ 0.8744],\n",
      "        [ 0.7518],\n",
      "        [ 0.7831],\n",
      "        [ 1.2169],\n",
      "        [ 1.2169],\n",
      "        [ 1.0705],\n",
      "        [-0.3044],\n",
      "        [-1.2149],\n",
      "        [ 1.0705],\n",
      "        [-1.4499],\n",
      "        [ 0.9616],\n",
      "        [-1.3257],\n",
      "        [ 0.5570],\n",
      "        [-0.2200],\n",
      "        [ 0.7518],\n",
      "        [ 0.5237],\n",
      "        [ 1.2169],\n",
      "        [ 0.7518],\n",
      "        [-0.6945],\n",
      "        [-0.1317],\n",
      "        [-1.0582],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8756],\n",
      "        [ 0.6230],\n",
      "        [ 1.2169],\n",
      "        [-1.5913],\n",
      "        [ 0.0558],\n",
      "        [-0.4113],\n",
      "        [-1.3257],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5642],\n",
      "        [-1.5416],\n",
      "        [ 0.6230],\n",
      "        [-1.4499],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2169],\n",
      "        [ 1.1769]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 308/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0205,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1760],\n",
      "        [-1.1760],\n",
      "        [ 0.6557],\n",
      "        [ 0.5901],\n",
      "        [-0.0396],\n",
      "        [ 0.4901],\n",
      "        [ 0.9040],\n",
      "        [ 0.9616],\n",
      "        [ 0.9040],\n",
      "        [ 0.8139],\n",
      "        [-1.5764],\n",
      "        [-0.8757],\n",
      "        [ 0.5570],\n",
      "        [-0.2199],\n",
      "        [ 0.9330],\n",
      "        [-0.2199],\n",
      "        [ 0.5570],\n",
      "        [-0.6152],\n",
      "        [-0.3044],\n",
      "        [ 0.8744],\n",
      "        [ 0.7517],\n",
      "        [ 0.7830],\n",
      "        [ 1.2170],\n",
      "        [ 1.2170],\n",
      "        [ 1.0705],\n",
      "        [-0.3044],\n",
      "        [-1.2149],\n",
      "        [ 1.0705],\n",
      "        [-1.4499],\n",
      "        [ 0.9616],\n",
      "        [-1.3256],\n",
      "        [ 0.5570],\n",
      "        [-0.2199],\n",
      "        [ 0.7517],\n",
      "        [ 0.5236],\n",
      "        [ 1.2170],\n",
      "        [ 0.7517],\n",
      "        [-0.6946],\n",
      "        [-0.1316],\n",
      "        [-1.0583],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8757],\n",
      "        [ 0.6230],\n",
      "        [ 1.2170],\n",
      "        [-1.5914],\n",
      "        [ 0.0558],\n",
      "        [-0.4113],\n",
      "        [-1.3256],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5642],\n",
      "        [-1.5416],\n",
      "        [ 0.6230],\n",
      "        [-1.4499],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2170],\n",
      "        [ 1.1770]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 309/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0204,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1760],\n",
      "        [-1.1760],\n",
      "        [ 0.6556],\n",
      "        [ 0.5901],\n",
      "        [-0.0395],\n",
      "        [ 0.4901],\n",
      "        [ 0.9039],\n",
      "        [ 0.9616],\n",
      "        [ 0.9039],\n",
      "        [ 0.8139],\n",
      "        [-1.5765],\n",
      "        [-0.8758],\n",
      "        [ 0.5569],\n",
      "        [-0.2199],\n",
      "        [ 0.9330],\n",
      "        [-0.2199],\n",
      "        [ 0.5569],\n",
      "        [-0.6153],\n",
      "        [-0.3043],\n",
      "        [ 0.8744],\n",
      "        [ 0.7517],\n",
      "        [ 0.7830],\n",
      "        [ 1.2171],\n",
      "        [ 1.2171],\n",
      "        [ 1.0705],\n",
      "        [-0.3043],\n",
      "        [-1.2149],\n",
      "        [ 1.0705],\n",
      "        [-1.4498],\n",
      "        [ 0.9616],\n",
      "        [-1.3256],\n",
      "        [ 0.5569],\n",
      "        [-0.2199],\n",
      "        [ 0.7517],\n",
      "        [ 0.5236],\n",
      "        [ 1.2171],\n",
      "        [ 0.7517],\n",
      "        [-0.6947],\n",
      "        [-0.1316],\n",
      "        [-1.0583],\n",
      "        [-1.1367],\n",
      "        [ 0.9616],\n",
      "        [-0.8758],\n",
      "        [ 0.6230],\n",
      "        [ 1.2171],\n",
      "        [-1.5915],\n",
      "        [ 0.0559],\n",
      "        [-0.4113],\n",
      "        [-1.3256],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5643],\n",
      "        [-1.5417],\n",
      "        [ 0.6230],\n",
      "        [-1.4498],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2171],\n",
      "        [ 1.1771]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 310/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0204,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1760],\n",
      "        [-1.1760],\n",
      "        [ 0.6556],\n",
      "        [ 0.5901],\n",
      "        [-0.0395],\n",
      "        [ 0.4901],\n",
      "        [ 0.9039],\n",
      "        [ 0.9615],\n",
      "        [ 0.9039],\n",
      "        [ 0.8138],\n",
      "        [-1.5765],\n",
      "        [-0.8759],\n",
      "        [ 0.5569],\n",
      "        [-0.2198],\n",
      "        [ 0.9330],\n",
      "        [-0.2198],\n",
      "        [ 0.5569],\n",
      "        [-0.6154],\n",
      "        [-0.3043],\n",
      "        [ 0.8743],\n",
      "        [ 0.7516],\n",
      "        [ 0.7829],\n",
      "        [ 1.2172],\n",
      "        [ 1.2172],\n",
      "        [ 1.0705],\n",
      "        [-0.3043],\n",
      "        [-1.2148],\n",
      "        [ 1.0705],\n",
      "        [-1.4498],\n",
      "        [ 0.9615],\n",
      "        [-1.3255],\n",
      "        [ 0.5569],\n",
      "        [-0.2198],\n",
      "        [ 0.7516],\n",
      "        [ 0.5236],\n",
      "        [ 1.2172],\n",
      "        [ 0.7516],\n",
      "        [-0.6948],\n",
      "        [-0.1315],\n",
      "        [-1.0584],\n",
      "        [-1.1367],\n",
      "        [ 0.9615],\n",
      "        [-0.8759],\n",
      "        [ 0.6230],\n",
      "        [ 1.2172],\n",
      "        [-1.5916],\n",
      "        [ 0.0559],\n",
      "        [-0.4113],\n",
      "        [-1.3255],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5643],\n",
      "        [-1.5417],\n",
      "        [ 0.6230],\n",
      "        [-1.4498],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2172],\n",
      "        [ 1.1771]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 311/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0204,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1759],\n",
      "        [-1.1759],\n",
      "        [ 0.6556],\n",
      "        [ 0.5900],\n",
      "        [-0.0394],\n",
      "        [ 0.4901],\n",
      "        [ 0.9039],\n",
      "        [ 0.9615],\n",
      "        [ 0.9039],\n",
      "        [ 0.8138],\n",
      "        [-1.5766],\n",
      "        [-0.8761],\n",
      "        [ 0.5569],\n",
      "        [-0.2198],\n",
      "        [ 0.9329],\n",
      "        [-0.2198],\n",
      "        [ 0.5569],\n",
      "        [-0.6155],\n",
      "        [-0.3042],\n",
      "        [ 0.8743],\n",
      "        [ 0.7516],\n",
      "        [ 0.7829],\n",
      "        [ 1.2173],\n",
      "        [ 1.2173],\n",
      "        [ 1.0705],\n",
      "        [-0.3042],\n",
      "        [-1.2148],\n",
      "        [ 1.0705],\n",
      "        [-1.4497],\n",
      "        [ 0.9615],\n",
      "        [-1.3254],\n",
      "        [ 0.5569],\n",
      "        [-0.2198],\n",
      "        [ 0.7516],\n",
      "        [ 0.5236],\n",
      "        [ 1.2173],\n",
      "        [ 0.7516],\n",
      "        [-0.6949],\n",
      "        [-0.1314],\n",
      "        [-1.0584],\n",
      "        [-1.1367],\n",
      "        [ 0.9615],\n",
      "        [-0.8761],\n",
      "        [ 0.6229],\n",
      "        [ 1.2173],\n",
      "        [-1.5917],\n",
      "        [ 0.0560],\n",
      "        [-0.4113],\n",
      "        [-1.3254],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5644],\n",
      "        [-1.5417],\n",
      "        [ 0.6229],\n",
      "        [-1.4497],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2173],\n",
      "        [ 1.1772]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 312/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0203,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1759],\n",
      "        [-1.1759],\n",
      "        [ 0.6555],\n",
      "        [ 0.5900],\n",
      "        [-0.0393],\n",
      "        [ 0.4901],\n",
      "        [ 0.9038],\n",
      "        [ 0.9615],\n",
      "        [ 0.9038],\n",
      "        [ 0.8138],\n",
      "        [-1.5767],\n",
      "        [-0.8762],\n",
      "        [ 0.5569],\n",
      "        [-0.2197],\n",
      "        [ 0.9329],\n",
      "        [-0.2197],\n",
      "        [ 0.5569],\n",
      "        [-0.6156],\n",
      "        [-0.3042],\n",
      "        [ 0.8743],\n",
      "        [ 0.7516],\n",
      "        [ 0.7829],\n",
      "        [ 1.2174],\n",
      "        [ 1.2174],\n",
      "        [ 1.0705],\n",
      "        [-0.3042],\n",
      "        [-1.2147],\n",
      "        [ 1.0705],\n",
      "        [-1.4497],\n",
      "        [ 0.9615],\n",
      "        [-1.3253],\n",
      "        [ 0.5569],\n",
      "        [-0.2197],\n",
      "        [ 0.7516],\n",
      "        [ 0.5236],\n",
      "        [ 1.2174],\n",
      "        [ 0.7516],\n",
      "        [-0.6950],\n",
      "        [-0.1314],\n",
      "        [-1.0584],\n",
      "        [-1.1367],\n",
      "        [ 0.9615],\n",
      "        [-0.8762],\n",
      "        [ 0.6229],\n",
      "        [ 1.2174],\n",
      "        [-1.5918],\n",
      "        [ 0.0561],\n",
      "        [-0.4113],\n",
      "        [-1.3253],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5644],\n",
      "        [-1.5417],\n",
      "        [ 0.6229],\n",
      "        [-1.4497],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2174],\n",
      "        [ 1.1772]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 313/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0203,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1759],\n",
      "        [-1.1759],\n",
      "        [ 0.6555],\n",
      "        [ 0.5900],\n",
      "        [-0.0393],\n",
      "        [ 0.4901],\n",
      "        [ 0.9038],\n",
      "        [ 0.9615],\n",
      "        [ 0.9038],\n",
      "        [ 0.8137],\n",
      "        [-1.5768],\n",
      "        [-0.8763],\n",
      "        [ 0.5569],\n",
      "        [-0.2196],\n",
      "        [ 0.9329],\n",
      "        [-0.2196],\n",
      "        [ 0.5569],\n",
      "        [-0.6157],\n",
      "        [-0.3041],\n",
      "        [ 0.8742],\n",
      "        [ 0.7515],\n",
      "        [ 0.7828],\n",
      "        [ 1.2174],\n",
      "        [ 1.2174],\n",
      "        [ 1.0705],\n",
      "        [-0.3041],\n",
      "        [-1.2147],\n",
      "        [ 1.0705],\n",
      "        [-1.4496],\n",
      "        [ 0.9615],\n",
      "        [-1.3253],\n",
      "        [ 0.5569],\n",
      "        [-0.2196],\n",
      "        [ 0.7515],\n",
      "        [ 0.5235],\n",
      "        [ 1.2174],\n",
      "        [ 0.7515],\n",
      "        [-0.6952],\n",
      "        [-0.1313],\n",
      "        [-1.0585],\n",
      "        [-1.1367],\n",
      "        [ 0.9615],\n",
      "        [-0.8763],\n",
      "        [ 0.6229],\n",
      "        [ 1.2174],\n",
      "        [-1.5919],\n",
      "        [ 0.0561],\n",
      "        [-0.4113],\n",
      "        [-1.3253],\n",
      "        [ 1.0171],\n",
      "        [-0.4113],\n",
      "        [-0.5645],\n",
      "        [-1.5418],\n",
      "        [ 0.6229],\n",
      "        [-1.4496],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2174],\n",
      "        [ 1.1773]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 314/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0202,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1759],\n",
      "        [-1.1759],\n",
      "        [ 0.6555],\n",
      "        [ 0.5900],\n",
      "        [-0.0392],\n",
      "        [ 0.4901],\n",
      "        [ 0.9038],\n",
      "        [ 0.9615],\n",
      "        [ 0.9038],\n",
      "        [ 0.8137],\n",
      "        [-1.5768],\n",
      "        [-0.8764],\n",
      "        [ 0.5568],\n",
      "        [-0.2196],\n",
      "        [ 0.9329],\n",
      "        [-0.2196],\n",
      "        [ 0.5568],\n",
      "        [-0.6157],\n",
      "        [-0.3041],\n",
      "        [ 0.8742],\n",
      "        [ 0.7515],\n",
      "        [ 0.7828],\n",
      "        [ 1.2175],\n",
      "        [ 1.2175],\n",
      "        [ 1.0705],\n",
      "        [-0.3041],\n",
      "        [-1.2146],\n",
      "        [ 1.0705],\n",
      "        [-1.4496],\n",
      "        [ 0.9615],\n",
      "        [-1.3252],\n",
      "        [ 0.5568],\n",
      "        [-0.2196],\n",
      "        [ 0.7515],\n",
      "        [ 0.5235],\n",
      "        [ 1.2175],\n",
      "        [ 0.7515],\n",
      "        [-0.6953],\n",
      "        [-0.1312],\n",
      "        [-1.0585],\n",
      "        [-1.1367],\n",
      "        [ 0.9615],\n",
      "        [-0.8764],\n",
      "        [ 0.6228],\n",
      "        [ 1.2175],\n",
      "        [-1.5920],\n",
      "        [ 0.0562],\n",
      "        [-0.4112],\n",
      "        [-1.3252],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5646],\n",
      "        [-1.5418],\n",
      "        [ 0.6228],\n",
      "        [-1.4496],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2175],\n",
      "        [ 1.1774]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 315/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0202,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1758],\n",
      "        [-1.1758],\n",
      "        [ 0.6554],\n",
      "        [ 0.5899],\n",
      "        [-0.0391],\n",
      "        [ 0.4900],\n",
      "        [ 0.9038],\n",
      "        [ 0.9614],\n",
      "        [ 0.9038],\n",
      "        [ 0.8137],\n",
      "        [-1.5769],\n",
      "        [-0.8766],\n",
      "        [ 0.5568],\n",
      "        [-0.2195],\n",
      "        [ 0.9328],\n",
      "        [-0.2195],\n",
      "        [ 0.5568],\n",
      "        [-0.6158],\n",
      "        [-0.3040],\n",
      "        [ 0.8742],\n",
      "        [ 0.7515],\n",
      "        [ 0.7828],\n",
      "        [ 1.2176],\n",
      "        [ 1.2176],\n",
      "        [ 1.0706],\n",
      "        [-0.3040],\n",
      "        [-1.2146],\n",
      "        [ 1.0706],\n",
      "        [-1.4495],\n",
      "        [ 0.9614],\n",
      "        [-1.3251],\n",
      "        [ 0.5568],\n",
      "        [-0.2195],\n",
      "        [ 0.7515],\n",
      "        [ 0.5235],\n",
      "        [ 1.2176],\n",
      "        [ 0.7515],\n",
      "        [-0.6954],\n",
      "        [-0.1312],\n",
      "        [-1.0586],\n",
      "        [-1.1367],\n",
      "        [ 0.9614],\n",
      "        [-0.8766],\n",
      "        [ 0.6228],\n",
      "        [ 1.2176],\n",
      "        [-1.5921],\n",
      "        [ 0.0562],\n",
      "        [-0.4112],\n",
      "        [-1.3251],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5646],\n",
      "        [-1.5418],\n",
      "        [ 0.6228],\n",
      "        [-1.4495],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2176],\n",
      "        [ 1.1774]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 316/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0201,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1758],\n",
      "        [-1.1758],\n",
      "        [ 0.6554],\n",
      "        [ 0.5899],\n",
      "        [-0.0391],\n",
      "        [ 0.4900],\n",
      "        [ 0.9037],\n",
      "        [ 0.9614],\n",
      "        [ 0.9037],\n",
      "        [ 0.8136],\n",
      "        [-1.5770],\n",
      "        [-0.8767],\n",
      "        [ 0.5568],\n",
      "        [-0.2194],\n",
      "        [ 0.9328],\n",
      "        [-0.2194],\n",
      "        [ 0.5568],\n",
      "        [-0.6159],\n",
      "        [-0.3040],\n",
      "        [ 0.8741],\n",
      "        [ 0.7514],\n",
      "        [ 0.7827],\n",
      "        [ 1.2177],\n",
      "        [ 1.2177],\n",
      "        [ 1.0706],\n",
      "        [-0.3040],\n",
      "        [-1.2146],\n",
      "        [ 1.0706],\n",
      "        [-1.4494],\n",
      "        [ 0.9614],\n",
      "        [-1.3250],\n",
      "        [ 0.5568],\n",
      "        [-0.2194],\n",
      "        [ 0.7514],\n",
      "        [ 0.5235],\n",
      "        [ 1.2177],\n",
      "        [ 0.7514],\n",
      "        [-0.6955],\n",
      "        [-0.1311],\n",
      "        [-1.0586],\n",
      "        [-1.1367],\n",
      "        [ 0.9614],\n",
      "        [-0.8767],\n",
      "        [ 0.6228],\n",
      "        [ 1.2177],\n",
      "        [-1.5922],\n",
      "        [ 0.0563],\n",
      "        [-0.4112],\n",
      "        [-1.3250],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5647],\n",
      "        [-1.5418],\n",
      "        [ 0.6228],\n",
      "        [-1.4494],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2177],\n",
      "        [ 1.1775]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 317/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0201,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1758],\n",
      "        [-1.1758],\n",
      "        [ 0.6554],\n",
      "        [ 0.5899],\n",
      "        [-0.0390],\n",
      "        [ 0.4900],\n",
      "        [ 0.9037],\n",
      "        [ 0.9614],\n",
      "        [ 0.9037],\n",
      "        [ 0.8136],\n",
      "        [-1.5770],\n",
      "        [-0.8768],\n",
      "        [ 0.5568],\n",
      "        [-0.2194],\n",
      "        [ 0.9328],\n",
      "        [-0.2194],\n",
      "        [ 0.5568],\n",
      "        [-0.6160],\n",
      "        [-0.3039],\n",
      "        [ 0.8741],\n",
      "        [ 0.7514],\n",
      "        [ 0.7827],\n",
      "        [ 1.2178],\n",
      "        [ 1.2178],\n",
      "        [ 1.0706],\n",
      "        [-0.3039],\n",
      "        [-1.2145],\n",
      "        [ 1.0706],\n",
      "        [-1.4494],\n",
      "        [ 0.9614],\n",
      "        [-1.3250],\n",
      "        [ 0.5568],\n",
      "        [-0.2194],\n",
      "        [ 0.7514],\n",
      "        [ 0.5235],\n",
      "        [ 1.2178],\n",
      "        [ 0.7514],\n",
      "        [-0.6956],\n",
      "        [-0.1310],\n",
      "        [-1.0587],\n",
      "        [-1.1367],\n",
      "        [ 0.9614],\n",
      "        [-0.8768],\n",
      "        [ 0.6227],\n",
      "        [ 1.2178],\n",
      "        [-1.5923],\n",
      "        [ 0.0563],\n",
      "        [-0.4112],\n",
      "        [-1.3250],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5647],\n",
      "        [-1.5419],\n",
      "        [ 0.6227],\n",
      "        [-1.4494],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2178],\n",
      "        [ 1.1775]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 318/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0201,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1758],\n",
      "        [-1.1758],\n",
      "        [ 0.6553],\n",
      "        [ 0.5898],\n",
      "        [-0.0389],\n",
      "        [ 0.4900],\n",
      "        [ 0.9037],\n",
      "        [ 0.9614],\n",
      "        [ 0.9037],\n",
      "        [ 0.8136],\n",
      "        [-1.5771],\n",
      "        [-0.8769],\n",
      "        [ 0.5567],\n",
      "        [-0.2193],\n",
      "        [ 0.9328],\n",
      "        [-0.2193],\n",
      "        [ 0.5567],\n",
      "        [-0.6160],\n",
      "        [-0.3039],\n",
      "        [ 0.8741],\n",
      "        [ 0.7513],\n",
      "        [ 0.7826],\n",
      "        [ 1.2179],\n",
      "        [ 1.2179],\n",
      "        [ 1.0706],\n",
      "        [-0.3039],\n",
      "        [-1.2145],\n",
      "        [ 1.0706],\n",
      "        [-1.4493],\n",
      "        [ 0.9614],\n",
      "        [-1.3249],\n",
      "        [ 0.5567],\n",
      "        [-0.2193],\n",
      "        [ 0.7513],\n",
      "        [ 0.5235],\n",
      "        [ 1.2179],\n",
      "        [ 0.7513],\n",
      "        [-0.6957],\n",
      "        [-0.1310],\n",
      "        [-1.0587],\n",
      "        [-1.1367],\n",
      "        [ 0.9614],\n",
      "        [-0.8769],\n",
      "        [ 0.6227],\n",
      "        [ 1.2179],\n",
      "        [-1.5924],\n",
      "        [ 0.0564],\n",
      "        [-0.4112],\n",
      "        [-1.3249],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5648],\n",
      "        [-1.5419],\n",
      "        [ 0.6227],\n",
      "        [-1.4493],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2179],\n",
      "        [ 1.1776]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 319/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0200,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1758],\n",
      "        [-1.1758],\n",
      "        [ 0.6553],\n",
      "        [ 0.5898],\n",
      "        [-0.0389],\n",
      "        [ 0.4900],\n",
      "        [ 0.9036],\n",
      "        [ 0.9614],\n",
      "        [ 0.9036],\n",
      "        [ 0.8135],\n",
      "        [-1.5772],\n",
      "        [-0.8770],\n",
      "        [ 0.5567],\n",
      "        [-0.2193],\n",
      "        [ 0.9327],\n",
      "        [-0.2193],\n",
      "        [ 0.5567],\n",
      "        [-0.6161],\n",
      "        [-0.3038],\n",
      "        [ 0.8741],\n",
      "        [ 0.7513],\n",
      "        [ 0.7826],\n",
      "        [ 1.2180],\n",
      "        [ 1.2180],\n",
      "        [ 1.0706],\n",
      "        [-0.3038],\n",
      "        [-1.2144],\n",
      "        [ 1.0706],\n",
      "        [-1.4493],\n",
      "        [ 0.9614],\n",
      "        [-1.3248],\n",
      "        [ 0.5567],\n",
      "        [-0.2193],\n",
      "        [ 0.7513],\n",
      "        [ 0.5234],\n",
      "        [ 1.2180],\n",
      "        [ 0.7513],\n",
      "        [-0.6958],\n",
      "        [-0.1309],\n",
      "        [-1.0587],\n",
      "        [-1.1367],\n",
      "        [ 0.9614],\n",
      "        [-0.8770],\n",
      "        [ 0.6227],\n",
      "        [ 1.2180],\n",
      "        [-1.5924],\n",
      "        [ 0.0565],\n",
      "        [-0.4112],\n",
      "        [-1.3248],\n",
      "        [ 1.0171],\n",
      "        [-0.4112],\n",
      "        [-0.5648],\n",
      "        [-1.5419],\n",
      "        [ 0.6227],\n",
      "        [-1.4493],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2180],\n",
      "        [ 1.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 320/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0200,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1757],\n",
      "        [-1.1757],\n",
      "        [ 0.6553],\n",
      "        [ 0.5898],\n",
      "        [-0.0388],\n",
      "        [ 0.4900],\n",
      "        [ 0.9036],\n",
      "        [ 0.9613],\n",
      "        [ 0.9036],\n",
      "        [ 0.8135],\n",
      "        [-1.5773],\n",
      "        [-0.8772],\n",
      "        [ 0.5567],\n",
      "        [-0.2192],\n",
      "        [ 0.9327],\n",
      "        [-0.2192],\n",
      "        [ 0.5567],\n",
      "        [-0.6162],\n",
      "        [-0.3038],\n",
      "        [ 0.8740],\n",
      "        [ 0.7513],\n",
      "        [ 0.7826],\n",
      "        [ 1.2180],\n",
      "        [ 1.2180],\n",
      "        [ 1.0706],\n",
      "        [-0.3038],\n",
      "        [-1.2144],\n",
      "        [ 1.0706],\n",
      "        [-1.4492],\n",
      "        [ 0.9613],\n",
      "        [-1.3247],\n",
      "        [ 0.5567],\n",
      "        [-0.2192],\n",
      "        [ 0.7513],\n",
      "        [ 0.5234],\n",
      "        [ 1.2180],\n",
      "        [ 0.7513],\n",
      "        [-0.6959],\n",
      "        [-0.1308],\n",
      "        [-1.0588],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8772],\n",
      "        [ 0.6227],\n",
      "        [ 1.2180],\n",
      "        [-1.5925],\n",
      "        [ 0.0565],\n",
      "        [-0.4112],\n",
      "        [-1.3247],\n",
      "        [ 1.0170],\n",
      "        [-0.4112],\n",
      "        [-0.5649],\n",
      "        [-1.5419],\n",
      "        [ 0.6227],\n",
      "        [-1.4492],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2180],\n",
      "        [ 1.1777]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 321/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0199,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1757],\n",
      "        [-1.1757],\n",
      "        [ 0.6552],\n",
      "        [ 0.5898],\n",
      "        [-0.0387],\n",
      "        [ 0.4900],\n",
      "        [ 0.9036],\n",
      "        [ 0.9613],\n",
      "        [ 0.9036],\n",
      "        [ 0.8134],\n",
      "        [-1.5773],\n",
      "        [-0.8773],\n",
      "        [ 0.5567],\n",
      "        [-0.2191],\n",
      "        [ 0.9327],\n",
      "        [-0.2191],\n",
      "        [ 0.5567],\n",
      "        [-0.6163],\n",
      "        [-0.3038],\n",
      "        [ 0.8740],\n",
      "        [ 0.7512],\n",
      "        [ 0.7825],\n",
      "        [ 1.2181],\n",
      "        [ 1.2181],\n",
      "        [ 1.0706],\n",
      "        [-0.3038],\n",
      "        [-1.2144],\n",
      "        [ 1.0706],\n",
      "        [-1.4492],\n",
      "        [ 0.9613],\n",
      "        [-1.3247],\n",
      "        [ 0.5567],\n",
      "        [-0.2191],\n",
      "        [ 0.7512],\n",
      "        [ 0.5234],\n",
      "        [ 1.2181],\n",
      "        [ 0.7512],\n",
      "        [-0.6961],\n",
      "        [-0.1308],\n",
      "        [-1.0588],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8773],\n",
      "        [ 0.6226],\n",
      "        [ 1.2181],\n",
      "        [-1.5926],\n",
      "        [ 0.0566],\n",
      "        [-0.4111],\n",
      "        [-1.3247],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5649],\n",
      "        [-1.5420],\n",
      "        [ 0.6226],\n",
      "        [-1.4492],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2181],\n",
      "        [ 1.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 322/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0199,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1757],\n",
      "        [-1.1757],\n",
      "        [ 0.6552],\n",
      "        [ 0.5897],\n",
      "        [-0.0387],\n",
      "        [ 0.4900],\n",
      "        [ 0.9036],\n",
      "        [ 0.9613],\n",
      "        [ 0.9036],\n",
      "        [ 0.8134],\n",
      "        [-1.5774],\n",
      "        [-0.8774],\n",
      "        [ 0.5567],\n",
      "        [-0.2191],\n",
      "        [ 0.9327],\n",
      "        [-0.2191],\n",
      "        [ 0.5567],\n",
      "        [-0.6164],\n",
      "        [-0.3037],\n",
      "        [ 0.8740],\n",
      "        [ 0.7512],\n",
      "        [ 0.7825],\n",
      "        [ 1.2182],\n",
      "        [ 1.2182],\n",
      "        [ 1.0706],\n",
      "        [-0.3037],\n",
      "        [-1.2143],\n",
      "        [ 1.0706],\n",
      "        [-1.4491],\n",
      "        [ 0.9613],\n",
      "        [-1.3246],\n",
      "        [ 0.5567],\n",
      "        [-0.2191],\n",
      "        [ 0.7512],\n",
      "        [ 0.5234],\n",
      "        [ 1.2182],\n",
      "        [ 0.7512],\n",
      "        [-0.6962],\n",
      "        [-0.1307],\n",
      "        [-1.0589],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8774],\n",
      "        [ 0.6226],\n",
      "        [ 1.2182],\n",
      "        [-1.5927],\n",
      "        [ 0.0566],\n",
      "        [-0.4111],\n",
      "        [-1.3246],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5650],\n",
      "        [-1.5420],\n",
      "        [ 0.6226],\n",
      "        [-1.4491],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2182],\n",
      "        [ 1.1778]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 323/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0198,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1757],\n",
      "        [-1.1757],\n",
      "        [ 0.6552],\n",
      "        [ 0.5897],\n",
      "        [-0.0386],\n",
      "        [ 0.4899],\n",
      "        [ 0.9035],\n",
      "        [ 0.9613],\n",
      "        [ 0.9035],\n",
      "        [ 0.8134],\n",
      "        [-1.5775],\n",
      "        [-0.8775],\n",
      "        [ 0.5566],\n",
      "        [-0.2190],\n",
      "        [ 0.9327],\n",
      "        [-0.2190],\n",
      "        [ 0.5566],\n",
      "        [-0.6164],\n",
      "        [-0.3037],\n",
      "        [ 0.8739],\n",
      "        [ 0.7512],\n",
      "        [ 0.7825],\n",
      "        [ 1.2183],\n",
      "        [ 1.2183],\n",
      "        [ 1.0707],\n",
      "        [-0.3037],\n",
      "        [-1.2143],\n",
      "        [ 1.0707],\n",
      "        [-1.4491],\n",
      "        [ 0.9613],\n",
      "        [-1.3245],\n",
      "        [ 0.5566],\n",
      "        [-0.2190],\n",
      "        [ 0.7512],\n",
      "        [ 0.5234],\n",
      "        [ 1.2183],\n",
      "        [ 0.7512],\n",
      "        [-0.6963],\n",
      "        [-0.1306],\n",
      "        [-1.0589],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8775],\n",
      "        [ 0.6226],\n",
      "        [ 1.2183],\n",
      "        [-1.5928],\n",
      "        [ 0.0567],\n",
      "        [-0.4111],\n",
      "        [-1.3245],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5650],\n",
      "        [-1.5420],\n",
      "        [ 0.6226],\n",
      "        [-1.4491],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2183],\n",
      "        [ 1.1779]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 324/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0198,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1756],\n",
      "        [-1.1756],\n",
      "        [ 0.6551],\n",
      "        [ 0.5897],\n",
      "        [-0.0385],\n",
      "        [ 0.4899],\n",
      "        [ 0.9035],\n",
      "        [ 0.9613],\n",
      "        [ 0.9035],\n",
      "        [ 0.8133],\n",
      "        [-1.5775],\n",
      "        [-0.8776],\n",
      "        [ 0.5566],\n",
      "        [-0.2190],\n",
      "        [ 0.9326],\n",
      "        [-0.2190],\n",
      "        [ 0.5566],\n",
      "        [-0.6165],\n",
      "        [-0.3036],\n",
      "        [ 0.8739],\n",
      "        [ 0.7511],\n",
      "        [ 0.7824],\n",
      "        [ 1.2184],\n",
      "        [ 1.2184],\n",
      "        [ 1.0707],\n",
      "        [-0.3036],\n",
      "        [-1.2142],\n",
      "        [ 1.0707],\n",
      "        [-1.4490],\n",
      "        [ 0.9613],\n",
      "        [-1.3244],\n",
      "        [ 0.5566],\n",
      "        [-0.2190],\n",
      "        [ 0.7511],\n",
      "        [ 0.5234],\n",
      "        [ 1.2184],\n",
      "        [ 0.7511],\n",
      "        [-0.6964],\n",
      "        [-0.1306],\n",
      "        [-1.0589],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8776],\n",
      "        [ 0.6225],\n",
      "        [ 1.2184],\n",
      "        [-1.5929],\n",
      "        [ 0.0567],\n",
      "        [-0.4111],\n",
      "        [-1.3244],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5651],\n",
      "        [-1.5420],\n",
      "        [ 0.6225],\n",
      "        [-1.4490],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2184],\n",
      "        [ 1.1780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 325/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0198,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1756],\n",
      "        [-1.1756],\n",
      "        [ 0.6551],\n",
      "        [ 0.5897],\n",
      "        [-0.0385],\n",
      "        [ 0.4899],\n",
      "        [ 0.9035],\n",
      "        [ 0.9613],\n",
      "        [ 0.9035],\n",
      "        [ 0.8133],\n",
      "        [-1.5776],\n",
      "        [-0.8777],\n",
      "        [ 0.5566],\n",
      "        [-0.2189],\n",
      "        [ 0.9326],\n",
      "        [-0.2189],\n",
      "        [ 0.5566],\n",
      "        [-0.6166],\n",
      "        [-0.3036],\n",
      "        [ 0.8739],\n",
      "        [ 0.7511],\n",
      "        [ 0.7824],\n",
      "        [ 1.2184],\n",
      "        [ 1.2184],\n",
      "        [ 1.0707],\n",
      "        [-0.3036],\n",
      "        [-1.2142],\n",
      "        [ 1.0707],\n",
      "        [-1.4490],\n",
      "        [ 0.9613],\n",
      "        [-1.3244],\n",
      "        [ 0.5566],\n",
      "        [-0.2189],\n",
      "        [ 0.7511],\n",
      "        [ 0.5233],\n",
      "        [ 1.2184],\n",
      "        [ 0.7511],\n",
      "        [-0.6965],\n",
      "        [-0.1305],\n",
      "        [-1.0590],\n",
      "        [-1.1367],\n",
      "        [ 0.9613],\n",
      "        [-0.8777],\n",
      "        [ 0.6225],\n",
      "        [ 1.2184],\n",
      "        [-1.5930],\n",
      "        [ 0.0568],\n",
      "        [-0.4111],\n",
      "        [-1.3244],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5651],\n",
      "        [-1.5421],\n",
      "        [ 0.6225],\n",
      "        [-1.4490],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2184],\n",
      "        [ 1.1780]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 326/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0197,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1756],\n",
      "        [-1.1756],\n",
      "        [ 0.6551],\n",
      "        [ 0.5896],\n",
      "        [-0.0384],\n",
      "        [ 0.4899],\n",
      "        [ 0.9034],\n",
      "        [ 0.9612],\n",
      "        [ 0.9034],\n",
      "        [ 0.8133],\n",
      "        [-1.5777],\n",
      "        [-0.8779],\n",
      "        [ 0.5566],\n",
      "        [-0.2189],\n",
      "        [ 0.9326],\n",
      "        [-0.2189],\n",
      "        [ 0.5566],\n",
      "        [-0.6167],\n",
      "        [-0.3035],\n",
      "        [ 0.8738],\n",
      "        [ 0.7511],\n",
      "        [ 0.7824],\n",
      "        [ 1.2185],\n",
      "        [ 1.2185],\n",
      "        [ 1.0707],\n",
      "        [-0.3035],\n",
      "        [-1.2142],\n",
      "        [ 1.0707],\n",
      "        [-1.4489],\n",
      "        [ 0.9612],\n",
      "        [-1.3243],\n",
      "        [ 0.5566],\n",
      "        [-0.2189],\n",
      "        [ 0.7511],\n",
      "        [ 0.5233],\n",
      "        [ 1.2185],\n",
      "        [ 0.7511],\n",
      "        [-0.6966],\n",
      "        [-0.1304],\n",
      "        [-1.0590],\n",
      "        [-1.1367],\n",
      "        [ 0.9612],\n",
      "        [-0.8779],\n",
      "        [ 0.6225],\n",
      "        [ 1.2185],\n",
      "        [-1.5931],\n",
      "        [ 0.0568],\n",
      "        [-0.4111],\n",
      "        [-1.3243],\n",
      "        [ 1.0170],\n",
      "        [-0.4111],\n",
      "        [-0.5652],\n",
      "        [-1.5421],\n",
      "        [ 0.6225],\n",
      "        [-1.4489],\n",
      "        [ 0.4228],\n",
      "        [-0.4372],\n",
      "        [ 0.4228],\n",
      "        [ 1.2185],\n",
      "        [ 1.1781]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 327/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0197,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1756],\n",
      "        [-1.1756],\n",
      "        [ 0.6550],\n",
      "        [ 0.5896],\n",
      "        [-0.0383],\n",
      "        [ 0.4899],\n",
      "        [ 0.9034],\n",
      "        [ 0.9612],\n",
      "        [ 0.9034],\n",
      "        [ 0.8132],\n",
      "        [-1.5777],\n",
      "        [-0.8780],\n",
      "        [ 0.5566],\n",
      "        [-0.2188],\n",
      "        [ 0.9326],\n",
      "        [-0.2188],\n",
      "        [ 0.5566],\n",
      "        [-0.6167],\n",
      "        [-0.3035],\n",
      "        [ 0.8738],\n",
      "        [ 0.7510],\n",
      "        [ 0.7823],\n",
      "        [ 1.2186],\n",
      "        [ 1.2186],\n",
      "        [ 1.0707],\n",
      "        [-0.3035],\n",
      "        [-1.2141],\n",
      "        [ 1.0707],\n",
      "        [-1.4489],\n",
      "        [ 0.9612],\n",
      "        [-1.3242],\n",
      "        [ 0.5566],\n",
      "        [-0.2188],\n",
      "        [ 0.7510],\n",
      "        [ 0.5233],\n",
      "        [ 1.2186],\n",
      "        [ 0.7510],\n",
      "        [-0.6967],\n",
      "        [-0.1304],\n",
      "        [-1.0591],\n",
      "        [-1.1367],\n",
      "        [ 0.9612],\n",
      "        [-0.8780],\n",
      "        [ 0.6225],\n",
      "        [ 1.2186],\n",
      "        [-1.5932],\n",
      "        [ 0.0569],\n",
      "        [-0.4110],\n",
      "        [-1.3242],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5652],\n",
      "        [-1.5421],\n",
      "        [ 0.6225],\n",
      "        [-1.4489],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2186],\n",
      "        [ 1.1781]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 328/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0196,\n",
      " epoch_time_duration: 0.0087\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1756],\n",
      "        [-1.1756],\n",
      "        [ 0.6550],\n",
      "        [ 0.5896],\n",
      "        [-0.0383],\n",
      "        [ 0.4899],\n",
      "        [ 0.9034],\n",
      "        [ 0.9612],\n",
      "        [ 0.9034],\n",
      "        [ 0.8132],\n",
      "        [-1.5778],\n",
      "        [-0.8781],\n",
      "        [ 0.5565],\n",
      "        [-0.2187],\n",
      "        [ 0.9325],\n",
      "        [-0.2187],\n",
      "        [ 0.5565],\n",
      "        [-0.6168],\n",
      "        [-0.3034],\n",
      "        [ 0.8738],\n",
      "        [ 0.7510],\n",
      "        [ 0.7823],\n",
      "        [ 1.2187],\n",
      "        [ 1.2187],\n",
      "        [ 1.0707],\n",
      "        [-0.3034],\n",
      "        [-1.2141],\n",
      "        [ 1.0707],\n",
      "        [-1.4488],\n",
      "        [ 0.9612],\n",
      "        [-1.3242],\n",
      "        [ 0.5565],\n",
      "        [-0.2187],\n",
      "        [ 0.7510],\n",
      "        [ 0.5233],\n",
      "        [ 1.2187],\n",
      "        [ 0.7510],\n",
      "        [-0.6968],\n",
      "        [-0.1303],\n",
      "        [-1.0591],\n",
      "        [-1.1367],\n",
      "        [ 0.9612],\n",
      "        [-0.8781],\n",
      "        [ 0.6224],\n",
      "        [ 1.2187],\n",
      "        [-1.5933],\n",
      "        [ 0.0570],\n",
      "        [-0.4110],\n",
      "        [-1.3242],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5653],\n",
      "        [-1.5421],\n",
      "        [ 0.6224],\n",
      "        [-1.4488],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2187],\n",
      "        [ 1.1782]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 329/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0196,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6550],\n",
      "        [ 0.5896],\n",
      "        [-0.0382],\n",
      "        [ 0.4899],\n",
      "        [ 0.9034],\n",
      "        [ 0.9612],\n",
      "        [ 0.9034],\n",
      "        [ 0.8132],\n",
      "        [-1.5779],\n",
      "        [-0.8782],\n",
      "        [ 0.5565],\n",
      "        [-0.2187],\n",
      "        [ 0.9325],\n",
      "        [-0.2187],\n",
      "        [ 0.5565],\n",
      "        [-0.6169],\n",
      "        [-0.3034],\n",
      "        [ 0.8737],\n",
      "        [ 0.7509],\n",
      "        [ 0.7822],\n",
      "        [ 1.2188],\n",
      "        [ 1.2188],\n",
      "        [ 1.0707],\n",
      "        [-0.3034],\n",
      "        [-1.2140],\n",
      "        [ 1.0707],\n",
      "        [-1.4487],\n",
      "        [ 0.9612],\n",
      "        [-1.3241],\n",
      "        [ 0.5565],\n",
      "        [-0.2187],\n",
      "        [ 0.7509],\n",
      "        [ 0.5233],\n",
      "        [ 1.2188],\n",
      "        [ 0.7509],\n",
      "        [-0.6969],\n",
      "        [-0.1302],\n",
      "        [-1.0592],\n",
      "        [-1.1367],\n",
      "        [ 0.9612],\n",
      "        [-0.8782],\n",
      "        [ 0.6224],\n",
      "        [ 1.2188],\n",
      "        [-1.5934],\n",
      "        [ 0.0570],\n",
      "        [-0.4110],\n",
      "        [-1.3241],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5653],\n",
      "        [-1.5421],\n",
      "        [ 0.6224],\n",
      "        [-1.4487],\n",
      "        [ 0.4228],\n",
      "        [-0.4371],\n",
      "        [ 0.4228],\n",
      "        [ 1.2188],\n",
      "        [ 1.1782]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 330/10000,\n",
      " train_loss: 0.0006,\n",
      " train_mae: 0.0196,\n",
      " epoch_time_duration: 0.0176\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6550],\n",
      "        [ 0.5895],\n",
      "        [-0.0382],\n",
      "        [ 0.4899],\n",
      "        [ 0.9033],\n",
      "        [ 0.9612],\n",
      "        [ 0.9033],\n",
      "        [ 0.8131],\n",
      "        [-1.5779],\n",
      "        [-0.8783],\n",
      "        [ 0.5565],\n",
      "        [-0.2186],\n",
      "        [ 0.9325],\n",
      "        [-0.2186],\n",
      "        [ 0.5565],\n",
      "        [-0.6170],\n",
      "        [-0.3033],\n",
      "        [ 0.8737],\n",
      "        [ 0.7509],\n",
      "        [ 0.7822],\n",
      "        [ 1.2188],\n",
      "        [ 1.2188],\n",
      "        [ 1.0707],\n",
      "        [-0.3033],\n",
      "        [-1.2140],\n",
      "        [ 1.0707],\n",
      "        [-1.4487],\n",
      "        [ 0.9612],\n",
      "        [-1.3240],\n",
      "        [ 0.5565],\n",
      "        [-0.2186],\n",
      "        [ 0.7509],\n",
      "        [ 0.5232],\n",
      "        [ 1.2188],\n",
      "        [ 0.7509],\n",
      "        [-0.6970],\n",
      "        [-0.1302],\n",
      "        [-1.0592],\n",
      "        [-1.1367],\n",
      "        [ 0.9612],\n",
      "        [-0.8783],\n",
      "        [ 0.6224],\n",
      "        [ 1.2188],\n",
      "        [-1.5935],\n",
      "        [ 0.0571],\n",
      "        [-0.4110],\n",
      "        [-1.3240],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5654],\n",
      "        [-1.5422],\n",
      "        [ 0.6224],\n",
      "        [-1.4487],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2188],\n",
      "        [ 1.1783]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 331/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0195,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6549],\n",
      "        [ 0.5895],\n",
      "        [-0.0381],\n",
      "        [ 0.4898],\n",
      "        [ 0.9033],\n",
      "        [ 0.9611],\n",
      "        [ 0.9033],\n",
      "        [ 0.8131],\n",
      "        [-1.5780],\n",
      "        [-0.8784],\n",
      "        [ 0.5565],\n",
      "        [-0.2186],\n",
      "        [ 0.9325],\n",
      "        [-0.2186],\n",
      "        [ 0.5565],\n",
      "        [-0.6170],\n",
      "        [-0.3033],\n",
      "        [ 0.8737],\n",
      "        [ 0.7509],\n",
      "        [ 0.7822],\n",
      "        [ 1.2189],\n",
      "        [ 1.2189],\n",
      "        [ 1.0707],\n",
      "        [-0.3033],\n",
      "        [-1.2140],\n",
      "        [ 1.0707],\n",
      "        [-1.4486],\n",
      "        [ 0.9611],\n",
      "        [-1.3239],\n",
      "        [ 0.5565],\n",
      "        [-0.2186],\n",
      "        [ 0.7509],\n",
      "        [ 0.5232],\n",
      "        [ 1.2189],\n",
      "        [ 0.7509],\n",
      "        [-0.6971],\n",
      "        [-0.1301],\n",
      "        [-1.0592],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8784],\n",
      "        [ 0.6223],\n",
      "        [ 1.2189],\n",
      "        [-1.5936],\n",
      "        [ 0.0571],\n",
      "        [-0.4110],\n",
      "        [-1.3239],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5654],\n",
      "        [-1.5422],\n",
      "        [ 0.6223],\n",
      "        [-1.4486],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2189],\n",
      "        [ 1.1784]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 332/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0195,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6549],\n",
      "        [ 0.5895],\n",
      "        [-0.0380],\n",
      "        [ 0.4898],\n",
      "        [ 0.9033],\n",
      "        [ 0.9611],\n",
      "        [ 0.9033],\n",
      "        [ 0.8131],\n",
      "        [-1.5781],\n",
      "        [-0.8785],\n",
      "        [ 0.5564],\n",
      "        [-0.2185],\n",
      "        [ 0.9324],\n",
      "        [-0.2185],\n",
      "        [ 0.5564],\n",
      "        [-0.6171],\n",
      "        [-0.3033],\n",
      "        [ 0.8736],\n",
      "        [ 0.7508],\n",
      "        [ 0.7821],\n",
      "        [ 1.2190],\n",
      "        [ 1.2190],\n",
      "        [ 1.0708],\n",
      "        [-0.3033],\n",
      "        [-1.2139],\n",
      "        [ 1.0708],\n",
      "        [-1.4486],\n",
      "        [ 0.9611],\n",
      "        [-1.3239],\n",
      "        [ 0.5564],\n",
      "        [-0.2185],\n",
      "        [ 0.7508],\n",
      "        [ 0.5232],\n",
      "        [ 1.2190],\n",
      "        [ 0.7508],\n",
      "        [-0.6972],\n",
      "        [-0.1301],\n",
      "        [-1.0593],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8785],\n",
      "        [ 0.6223],\n",
      "        [ 1.2190],\n",
      "        [-1.5937],\n",
      "        [ 0.0572],\n",
      "        [-0.4110],\n",
      "        [-1.3239],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5655],\n",
      "        [-1.5422],\n",
      "        [ 0.6223],\n",
      "        [-1.4486],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2190],\n",
      "        [ 1.1784]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 333/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0194,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6549],\n",
      "        [ 0.5895],\n",
      "        [-0.0380],\n",
      "        [ 0.4898],\n",
      "        [ 0.9033],\n",
      "        [ 0.9611],\n",
      "        [ 0.9033],\n",
      "        [ 0.8130],\n",
      "        [-1.5781],\n",
      "        [-0.8787],\n",
      "        [ 0.5564],\n",
      "        [-0.2184],\n",
      "        [ 0.9324],\n",
      "        [-0.2184],\n",
      "        [ 0.5564],\n",
      "        [-0.6172],\n",
      "        [-0.3032],\n",
      "        [ 0.8736],\n",
      "        [ 0.7508],\n",
      "        [ 0.7821],\n",
      "        [ 1.2191],\n",
      "        [ 1.2191],\n",
      "        [ 1.0708],\n",
      "        [-0.3032],\n",
      "        [-1.2139],\n",
      "        [ 1.0708],\n",
      "        [-1.4485],\n",
      "        [ 0.9611],\n",
      "        [-1.3238],\n",
      "        [ 0.5564],\n",
      "        [-0.2184],\n",
      "        [ 0.7508],\n",
      "        [ 0.5232],\n",
      "        [ 1.2191],\n",
      "        [ 0.7508],\n",
      "        [-0.6973],\n",
      "        [-0.1300],\n",
      "        [-1.0593],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8787],\n",
      "        [ 0.6223],\n",
      "        [ 1.2191],\n",
      "        [-1.5937],\n",
      "        [ 0.0572],\n",
      "        [-0.4110],\n",
      "        [-1.3238],\n",
      "        [ 1.0170],\n",
      "        [-0.4110],\n",
      "        [-0.5655],\n",
      "        [-1.5422],\n",
      "        [ 0.6223],\n",
      "        [-1.4485],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2191],\n",
      "        [ 1.1785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 334/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0194,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6548],\n",
      "        [ 0.5894],\n",
      "        [-0.0379],\n",
      "        [ 0.4898],\n",
      "        [ 0.9032],\n",
      "        [ 0.9611],\n",
      "        [ 0.9032],\n",
      "        [ 0.8130],\n",
      "        [-1.5782],\n",
      "        [-0.8788],\n",
      "        [ 0.5564],\n",
      "        [-0.2184],\n",
      "        [ 0.9324],\n",
      "        [-0.2184],\n",
      "        [ 0.5564],\n",
      "        [-0.6172],\n",
      "        [-0.3032],\n",
      "        [ 0.8736],\n",
      "        [ 0.7508],\n",
      "        [ 0.7821],\n",
      "        [ 1.2192],\n",
      "        [ 1.2192],\n",
      "        [ 1.0708],\n",
      "        [-0.3032],\n",
      "        [-1.2139],\n",
      "        [ 1.0708],\n",
      "        [-1.4485],\n",
      "        [ 0.9611],\n",
      "        [-1.3237],\n",
      "        [ 0.5564],\n",
      "        [-0.2184],\n",
      "        [ 0.7508],\n",
      "        [ 0.5232],\n",
      "        [ 1.2192],\n",
      "        [ 0.7508],\n",
      "        [-0.6974],\n",
      "        [-0.1299],\n",
      "        [-1.0594],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8788],\n",
      "        [ 0.6223],\n",
      "        [ 1.2192],\n",
      "        [-1.5938],\n",
      "        [ 0.0573],\n",
      "        [-0.4109],\n",
      "        [-1.3237],\n",
      "        [ 1.0170],\n",
      "        [-0.4109],\n",
      "        [-0.5656],\n",
      "        [-1.5422],\n",
      "        [ 0.6223],\n",
      "        [-1.4485],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2192],\n",
      "        [ 1.1785]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 335/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0194,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1754],\n",
      "        [-1.1754],\n",
      "        [ 0.6548],\n",
      "        [ 0.5894],\n",
      "        [-0.0379],\n",
      "        [ 0.4898],\n",
      "        [ 0.9032],\n",
      "        [ 0.9611],\n",
      "        [ 0.9032],\n",
      "        [ 0.8130],\n",
      "        [-1.5783],\n",
      "        [-0.8789],\n",
      "        [ 0.5564],\n",
      "        [-0.2183],\n",
      "        [ 0.9324],\n",
      "        [-0.2183],\n",
      "        [ 0.5564],\n",
      "        [-0.6173],\n",
      "        [-0.3031],\n",
      "        [ 0.8736],\n",
      "        [ 0.7507],\n",
      "        [ 0.7820],\n",
      "        [ 1.2192],\n",
      "        [ 1.2192],\n",
      "        [ 1.0708],\n",
      "        [-0.3031],\n",
      "        [-1.2138],\n",
      "        [ 1.0708],\n",
      "        [-1.4484],\n",
      "        [ 0.9611],\n",
      "        [-1.3237],\n",
      "        [ 0.5564],\n",
      "        [-0.2183],\n",
      "        [ 0.7507],\n",
      "        [ 0.5232],\n",
      "        [ 1.2192],\n",
      "        [ 0.7507],\n",
      "        [-0.6975],\n",
      "        [-0.1299],\n",
      "        [-1.0594],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8789],\n",
      "        [ 0.6222],\n",
      "        [ 1.2192],\n",
      "        [-1.5939],\n",
      "        [ 0.0573],\n",
      "        [-0.4109],\n",
      "        [-1.3237],\n",
      "        [ 1.0170],\n",
      "        [-0.4109],\n",
      "        [-0.5656],\n",
      "        [-1.5423],\n",
      "        [ 0.6222],\n",
      "        [-1.4484],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2192],\n",
      "        [ 1.1786]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 336/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0193,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1754],\n",
      "        [-1.1754],\n",
      "        [ 0.6548],\n",
      "        [ 0.5894],\n",
      "        [-0.0378],\n",
      "        [ 0.4898],\n",
      "        [ 0.9032],\n",
      "        [ 0.9611],\n",
      "        [ 0.9032],\n",
      "        [ 0.8129],\n",
      "        [-1.5783],\n",
      "        [-0.8790],\n",
      "        [ 0.5564],\n",
      "        [-0.2183],\n",
      "        [ 0.9324],\n",
      "        [-0.2183],\n",
      "        [ 0.5564],\n",
      "        [-0.6174],\n",
      "        [-0.3031],\n",
      "        [ 0.8735],\n",
      "        [ 0.7507],\n",
      "        [ 0.7820],\n",
      "        [ 1.2193],\n",
      "        [ 1.2193],\n",
      "        [ 1.0708],\n",
      "        [-0.3031],\n",
      "        [-1.2138],\n",
      "        [ 1.0708],\n",
      "        [-1.4484],\n",
      "        [ 0.9611],\n",
      "        [-1.3236],\n",
      "        [ 0.5564],\n",
      "        [-0.2183],\n",
      "        [ 0.7507],\n",
      "        [ 0.5231],\n",
      "        [ 1.2193],\n",
      "        [ 0.7507],\n",
      "        [-0.6976],\n",
      "        [-0.1298],\n",
      "        [-1.0594],\n",
      "        [-1.1367],\n",
      "        [ 0.9611],\n",
      "        [-0.8790],\n",
      "        [ 0.6222],\n",
      "        [ 1.2193],\n",
      "        [-1.5940],\n",
      "        [ 0.0574],\n",
      "        [-0.4109],\n",
      "        [-1.3236],\n",
      "        [ 1.0170],\n",
      "        [-0.4109],\n",
      "        [-0.5657],\n",
      "        [-1.5423],\n",
      "        [ 0.6222],\n",
      "        [-1.4484],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2193],\n",
      "        [ 1.1786]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 337/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0193,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1754],\n",
      "        [-1.1754],\n",
      "        [ 0.6547],\n",
      "        [ 0.5894],\n",
      "        [-0.0377],\n",
      "        [ 0.4898],\n",
      "        [ 0.9031],\n",
      "        [ 0.9610],\n",
      "        [ 0.9031],\n",
      "        [ 0.8129],\n",
      "        [-1.5784],\n",
      "        [-0.8791],\n",
      "        [ 0.5563],\n",
      "        [-0.2182],\n",
      "        [ 0.9323],\n",
      "        [-0.2182],\n",
      "        [ 0.5563],\n",
      "        [-0.6175],\n",
      "        [-0.3030],\n",
      "        [ 0.8735],\n",
      "        [ 0.7507],\n",
      "        [ 0.7820],\n",
      "        [ 1.2194],\n",
      "        [ 1.2194],\n",
      "        [ 1.0708],\n",
      "        [-0.3030],\n",
      "        [-1.2138],\n",
      "        [ 1.0708],\n",
      "        [-1.4483],\n",
      "        [ 0.9610],\n",
      "        [-1.3235],\n",
      "        [ 0.5563],\n",
      "        [-0.2182],\n",
      "        [ 0.7507],\n",
      "        [ 0.5231],\n",
      "        [ 1.2194],\n",
      "        [ 0.7507],\n",
      "        [-0.6977],\n",
      "        [-0.1297],\n",
      "        [-1.0595],\n",
      "        [-1.1367],\n",
      "        [ 0.9610],\n",
      "        [-0.8791],\n",
      "        [ 0.6222],\n",
      "        [ 1.2194],\n",
      "        [-1.5941],\n",
      "        [ 0.0574],\n",
      "        [-0.4109],\n",
      "        [-1.3235],\n",
      "        [ 1.0170],\n",
      "        [-0.4109],\n",
      "        [-0.5657],\n",
      "        [-1.5423],\n",
      "        [ 0.6222],\n",
      "        [-1.4483],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2194],\n",
      "        [ 1.1787]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 338/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0192,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1754],\n",
      "        [-1.1754],\n",
      "        [ 0.6547],\n",
      "        [ 0.5893],\n",
      "        [-0.0377],\n",
      "        [ 0.4898],\n",
      "        [ 0.9031],\n",
      "        [ 0.9610],\n",
      "        [ 0.9031],\n",
      "        [ 0.8129],\n",
      "        [-1.5785],\n",
      "        [-0.8792],\n",
      "        [ 0.5563],\n",
      "        [-0.2182],\n",
      "        [ 0.9323],\n",
      "        [-0.2182],\n",
      "        [ 0.5563],\n",
      "        [-0.6175],\n",
      "        [-0.3030],\n",
      "        [ 0.8735],\n",
      "        [ 0.7506],\n",
      "        [ 0.7819],\n",
      "        [ 1.2195],\n",
      "        [ 1.2195],\n",
      "        [ 1.0708],\n",
      "        [-0.3030],\n",
      "        [-1.2137],\n",
      "        [ 1.0708],\n",
      "        [-1.4483],\n",
      "        [ 0.9610],\n",
      "        [-1.3235],\n",
      "        [ 0.5563],\n",
      "        [-0.2182],\n",
      "        [ 0.7506],\n",
      "        [ 0.5231],\n",
      "        [ 1.2195],\n",
      "        [ 0.7506],\n",
      "        [-0.6978],\n",
      "        [-0.1297],\n",
      "        [-1.0595],\n",
      "        [-1.1367],\n",
      "        [ 0.9610],\n",
      "        [-0.8792],\n",
      "        [ 0.6221],\n",
      "        [ 1.2195],\n",
      "        [-1.5942],\n",
      "        [ 0.0575],\n",
      "        [-0.4109],\n",
      "        [-1.3235],\n",
      "        [ 1.0170],\n",
      "        [-0.4109],\n",
      "        [-0.5658],\n",
      "        [-1.5423],\n",
      "        [ 0.6221],\n",
      "        [-1.4483],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2195],\n",
      "        [ 1.1787]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 339/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0192,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1754],\n",
      "        [-1.1754],\n",
      "        [ 0.6547],\n",
      "        [ 0.5893],\n",
      "        [-0.0376],\n",
      "        [ 0.4897],\n",
      "        [ 0.9031],\n",
      "        [ 0.9610],\n",
      "        [ 0.9031],\n",
      "        [ 0.8128],\n",
      "        [-1.5785],\n",
      "        [-0.8793],\n",
      "        [ 0.5563],\n",
      "        [-0.2181],\n",
      "        [ 0.9323],\n",
      "        [-0.2181],\n",
      "        [ 0.5563],\n",
      "        [-0.6176],\n",
      "        [-0.3029],\n",
      "        [ 0.8734],\n",
      "        [ 0.7506],\n",
      "        [ 0.7819],\n",
      "        [ 1.2196],\n",
      "        [ 1.2196],\n",
      "        [ 1.0708],\n",
      "        [-0.3029],\n",
      "        [-1.2137],\n",
      "        [ 1.0708],\n",
      "        [-1.4482],\n",
      "        [ 0.9610],\n",
      "        [-1.3234],\n",
      "        [ 0.5563],\n",
      "        [-0.2181],\n",
      "        [ 0.7506],\n",
      "        [ 0.5231],\n",
      "        [ 1.2196],\n",
      "        [ 0.7506],\n",
      "        [-0.6979],\n",
      "        [-0.1296],\n",
      "        [-1.0596],\n",
      "        [-1.1367],\n",
      "        [ 0.9610],\n",
      "        [-0.8793],\n",
      "        [ 0.6221],\n",
      "        [ 1.2196],\n",
      "        [-1.5943],\n",
      "        [ 0.0575],\n",
      "        [-0.4109],\n",
      "        [-1.3234],\n",
      "        [ 1.0169],\n",
      "        [-0.4109],\n",
      "        [-0.5658],\n",
      "        [-1.5423],\n",
      "        [ 0.6221],\n",
      "        [-1.4482],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2196],\n",
      "        [ 1.1788]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 340/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0192,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6546],\n",
      "        [ 0.5893],\n",
      "        [-0.0376],\n",
      "        [ 0.4897],\n",
      "        [ 0.9031],\n",
      "        [ 0.9610],\n",
      "        [ 0.9031],\n",
      "        [ 0.8128],\n",
      "        [-1.5786],\n",
      "        [-0.8794],\n",
      "        [ 0.5563],\n",
      "        [-0.2180],\n",
      "        [ 0.9323],\n",
      "        [-0.2180],\n",
      "        [ 0.5563],\n",
      "        [-0.6177],\n",
      "        [-0.3029],\n",
      "        [ 0.8734],\n",
      "        [ 0.7506],\n",
      "        [ 0.7819],\n",
      "        [ 1.2196],\n",
      "        [ 1.2196],\n",
      "        [ 1.0708],\n",
      "        [-0.3029],\n",
      "        [-1.2136],\n",
      "        [ 1.0708],\n",
      "        [-1.4482],\n",
      "        [ 0.9610],\n",
      "        [-1.3233],\n",
      "        [ 0.5563],\n",
      "        [-0.2180],\n",
      "        [ 0.7506],\n",
      "        [ 0.5231],\n",
      "        [ 1.2196],\n",
      "        [ 0.7506],\n",
      "        [-0.6980],\n",
      "        [-0.1296],\n",
      "        [-1.0596],\n",
      "        [-1.1367],\n",
      "        [ 0.9610],\n",
      "        [-0.8794],\n",
      "        [ 0.6221],\n",
      "        [ 1.2196],\n",
      "        [-1.5944],\n",
      "        [ 0.0576],\n",
      "        [-0.4108],\n",
      "        [-1.3233],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5659],\n",
      "        [-1.5424],\n",
      "        [ 0.6221],\n",
      "        [-1.4482],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2196],\n",
      "        [ 1.1789]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 341/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0191,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6546],\n",
      "        [ 0.5893],\n",
      "        [-0.0375],\n",
      "        [ 0.4897],\n",
      "        [ 0.9030],\n",
      "        [ 0.9610],\n",
      "        [ 0.9030],\n",
      "        [ 0.8128],\n",
      "        [-1.5787],\n",
      "        [-0.8795],\n",
      "        [ 0.5563],\n",
      "        [-0.2180],\n",
      "        [ 0.9322],\n",
      "        [-0.2180],\n",
      "        [ 0.5563],\n",
      "        [-0.6177],\n",
      "        [-0.3029],\n",
      "        [ 0.8734],\n",
      "        [ 0.7505],\n",
      "        [ 0.7818],\n",
      "        [ 1.2197],\n",
      "        [ 1.2197],\n",
      "        [ 1.0709],\n",
      "        [-0.3029],\n",
      "        [-1.2136],\n",
      "        [ 1.0709],\n",
      "        [-1.4481],\n",
      "        [ 0.9610],\n",
      "        [-1.3233],\n",
      "        [ 0.5563],\n",
      "        [-0.2180],\n",
      "        [ 0.7505],\n",
      "        [ 0.5231],\n",
      "        [ 1.2197],\n",
      "        [ 0.7505],\n",
      "        [-0.6981],\n",
      "        [-0.1295],\n",
      "        [-1.0597],\n",
      "        [-1.1367],\n",
      "        [ 0.9610],\n",
      "        [-0.8795],\n",
      "        [ 0.6221],\n",
      "        [ 1.2197],\n",
      "        [-1.5945],\n",
      "        [ 0.0576],\n",
      "        [-0.4108],\n",
      "        [-1.3233],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5659],\n",
      "        [-1.5424],\n",
      "        [ 0.6221],\n",
      "        [-1.4481],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2197],\n",
      "        [ 1.1789]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 342/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0191,\n",
      " epoch_time_duration: 0.0138\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6546],\n",
      "        [ 0.5892],\n",
      "        [-0.0374],\n",
      "        [ 0.4897],\n",
      "        [ 0.9030],\n",
      "        [ 0.9609],\n",
      "        [ 0.9030],\n",
      "        [ 0.8127],\n",
      "        [-1.5787],\n",
      "        [-0.8797],\n",
      "        [ 0.5562],\n",
      "        [-0.2179],\n",
      "        [ 0.9322],\n",
      "        [-0.2179],\n",
      "        [ 0.5562],\n",
      "        [-0.6178],\n",
      "        [-0.3028],\n",
      "        [ 0.8733],\n",
      "        [ 0.7505],\n",
      "        [ 0.7818],\n",
      "        [ 1.2198],\n",
      "        [ 1.2198],\n",
      "        [ 1.0709],\n",
      "        [-0.3028],\n",
      "        [-1.2136],\n",
      "        [ 1.0709],\n",
      "        [-1.4481],\n",
      "        [ 0.9609],\n",
      "        [-1.3232],\n",
      "        [ 0.5562],\n",
      "        [-0.2179],\n",
      "        [ 0.7505],\n",
      "        [ 0.5230],\n",
      "        [ 1.2198],\n",
      "        [ 0.7505],\n",
      "        [-0.6982],\n",
      "        [-0.1294],\n",
      "        [-1.0597],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8797],\n",
      "        [ 0.6220],\n",
      "        [ 1.2198],\n",
      "        [-1.5945],\n",
      "        [ 0.0577],\n",
      "        [-0.4108],\n",
      "        [-1.3232],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5660],\n",
      "        [-1.5424],\n",
      "        [ 0.6220],\n",
      "        [-1.4481],\n",
      "        [ 0.4227],\n",
      "        [-0.4371],\n",
      "        [ 0.4227],\n",
      "        [ 1.2198],\n",
      "        [ 1.1790]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 343/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0190,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6546],\n",
      "        [ 0.5892],\n",
      "        [-0.0374],\n",
      "        [ 0.4897],\n",
      "        [ 0.9030],\n",
      "        [ 0.9609],\n",
      "        [ 0.9030],\n",
      "        [ 0.8127],\n",
      "        [-1.5788],\n",
      "        [-0.8798],\n",
      "        [ 0.5562],\n",
      "        [-0.2179],\n",
      "        [ 0.9322],\n",
      "        [-0.2179],\n",
      "        [ 0.5562],\n",
      "        [-0.6179],\n",
      "        [-0.3028],\n",
      "        [ 0.8733],\n",
      "        [ 0.7505],\n",
      "        [ 0.7818],\n",
      "        [ 1.2199],\n",
      "        [ 1.2199],\n",
      "        [ 1.0709],\n",
      "        [-0.3028],\n",
      "        [-1.2135],\n",
      "        [ 1.0709],\n",
      "        [-1.4480],\n",
      "        [ 0.9609],\n",
      "        [-1.3231],\n",
      "        [ 0.5562],\n",
      "        [-0.2179],\n",
      "        [ 0.7505],\n",
      "        [ 0.5230],\n",
      "        [ 1.2199],\n",
      "        [ 0.7505],\n",
      "        [-0.6983],\n",
      "        [-0.1294],\n",
      "        [-1.0597],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8798],\n",
      "        [ 0.6220],\n",
      "        [ 1.2199],\n",
      "        [-1.5946],\n",
      "        [ 0.0578],\n",
      "        [-0.4108],\n",
      "        [-1.3231],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5660],\n",
      "        [-1.5424],\n",
      "        [ 0.6220],\n",
      "        [-1.4480],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2199],\n",
      "        [ 1.1790]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 344/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0190,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6545],\n",
      "        [ 0.5892],\n",
      "        [-0.0373],\n",
      "        [ 0.4897],\n",
      "        [ 0.9030],\n",
      "        [ 0.9609],\n",
      "        [ 0.9030],\n",
      "        [ 0.8127],\n",
      "        [-1.5788],\n",
      "        [-0.8799],\n",
      "        [ 0.5562],\n",
      "        [-0.2178],\n",
      "        [ 0.9322],\n",
      "        [-0.2178],\n",
      "        [ 0.5562],\n",
      "        [-0.6179],\n",
      "        [-0.3027],\n",
      "        [ 0.8733],\n",
      "        [ 0.7504],\n",
      "        [ 0.7817],\n",
      "        [ 1.2199],\n",
      "        [ 1.2199],\n",
      "        [ 1.0709],\n",
      "        [-0.3027],\n",
      "        [-1.2135],\n",
      "        [ 1.0709],\n",
      "        [-1.4480],\n",
      "        [ 0.9609],\n",
      "        [-1.3231],\n",
      "        [ 0.5562],\n",
      "        [-0.2178],\n",
      "        [ 0.7504],\n",
      "        [ 0.5230],\n",
      "        [ 1.2199],\n",
      "        [ 0.7504],\n",
      "        [-0.6984],\n",
      "        [-0.1293],\n",
      "        [-1.0598],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8799],\n",
      "        [ 0.6220],\n",
      "        [ 1.2199],\n",
      "        [-1.5947],\n",
      "        [ 0.0578],\n",
      "        [-0.4108],\n",
      "        [-1.3231],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5661],\n",
      "        [-1.5424],\n",
      "        [ 0.6220],\n",
      "        [-1.4480],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2199],\n",
      "        [ 1.1791]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 345/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0190,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1753],\n",
      "        [-1.1753],\n",
      "        [ 0.6545],\n",
      "        [ 0.5892],\n",
      "        [-0.0373],\n",
      "        [ 0.4897],\n",
      "        [ 0.9029],\n",
      "        [ 0.9609],\n",
      "        [ 0.9029],\n",
      "        [ 0.8126],\n",
      "        [-1.5789],\n",
      "        [-0.8800],\n",
      "        [ 0.5562],\n",
      "        [-0.2178],\n",
      "        [ 0.9322],\n",
      "        [-0.2178],\n",
      "        [ 0.5562],\n",
      "        [-0.6180],\n",
      "        [-0.3027],\n",
      "        [ 0.8733],\n",
      "        [ 0.7504],\n",
      "        [ 0.7817],\n",
      "        [ 1.2200],\n",
      "        [ 1.2200],\n",
      "        [ 1.0709],\n",
      "        [-0.3027],\n",
      "        [-1.2135],\n",
      "        [ 1.0709],\n",
      "        [-1.4479],\n",
      "        [ 0.9609],\n",
      "        [-1.3230],\n",
      "        [ 0.5562],\n",
      "        [-0.2178],\n",
      "        [ 0.7504],\n",
      "        [ 0.5230],\n",
      "        [ 1.2200],\n",
      "        [ 0.7504],\n",
      "        [-0.6985],\n",
      "        [-0.1293],\n",
      "        [-1.0598],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8800],\n",
      "        [ 0.6219],\n",
      "        [ 1.2200],\n",
      "        [-1.5948],\n",
      "        [ 0.0579],\n",
      "        [-0.4108],\n",
      "        [-1.3230],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5661],\n",
      "        [-1.5424],\n",
      "        [ 0.6219],\n",
      "        [-1.4479],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2200],\n",
      "        [ 1.1791]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 346/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0189,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6545],\n",
      "        [ 0.5891],\n",
      "        [-0.0372],\n",
      "        [ 0.4897],\n",
      "        [ 0.9029],\n",
      "        [ 0.9609],\n",
      "        [ 0.9029],\n",
      "        [ 0.8126],\n",
      "        [-1.5790],\n",
      "        [-0.8801],\n",
      "        [ 0.5561],\n",
      "        [-0.2177],\n",
      "        [ 0.9321],\n",
      "        [-0.2177],\n",
      "        [ 0.5561],\n",
      "        [-0.6181],\n",
      "        [-0.3026],\n",
      "        [ 0.8732],\n",
      "        [ 0.7504],\n",
      "        [ 0.7817],\n",
      "        [ 1.2201],\n",
      "        [ 1.2201],\n",
      "        [ 1.0709],\n",
      "        [-0.3026],\n",
      "        [-1.2134],\n",
      "        [ 1.0709],\n",
      "        [-1.4479],\n",
      "        [ 0.9609],\n",
      "        [-1.3229],\n",
      "        [ 0.5561],\n",
      "        [-0.2177],\n",
      "        [ 0.7504],\n",
      "        [ 0.5230],\n",
      "        [ 1.2201],\n",
      "        [ 0.7504],\n",
      "        [-0.6986],\n",
      "        [-0.1292],\n",
      "        [-1.0599],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8801],\n",
      "        [ 0.6219],\n",
      "        [ 1.2201],\n",
      "        [-1.5949],\n",
      "        [ 0.0579],\n",
      "        [-0.4108],\n",
      "        [-1.3229],\n",
      "        [ 1.0169],\n",
      "        [-0.4108],\n",
      "        [-0.5662],\n",
      "        [-1.5425],\n",
      "        [ 0.6219],\n",
      "        [-1.4479],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2201],\n",
      "        [ 1.1792]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 347/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0189,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6544],\n",
      "        [ 0.5891],\n",
      "        [-0.0371],\n",
      "        [ 0.4896],\n",
      "        [ 0.9029],\n",
      "        [ 0.9609],\n",
      "        [ 0.9029],\n",
      "        [ 0.8126],\n",
      "        [-1.5790],\n",
      "        [-0.8802],\n",
      "        [ 0.5561],\n",
      "        [-0.2177],\n",
      "        [ 0.9321],\n",
      "        [-0.2177],\n",
      "        [ 0.5561],\n",
      "        [-0.6181],\n",
      "        [-0.3026],\n",
      "        [ 0.8732],\n",
      "        [ 0.7503],\n",
      "        [ 0.7816],\n",
      "        [ 1.2202],\n",
      "        [ 1.2202],\n",
      "        [ 1.0709],\n",
      "        [-0.3026],\n",
      "        [-1.2134],\n",
      "        [ 1.0709],\n",
      "        [-1.4478],\n",
      "        [ 0.9609],\n",
      "        [-1.3229],\n",
      "        [ 0.5561],\n",
      "        [-0.2177],\n",
      "        [ 0.7503],\n",
      "        [ 0.5230],\n",
      "        [ 1.2202],\n",
      "        [ 0.7503],\n",
      "        [-0.6987],\n",
      "        [-0.1291],\n",
      "        [-1.0599],\n",
      "        [-1.1367],\n",
      "        [ 0.9609],\n",
      "        [-0.8802],\n",
      "        [ 0.6219],\n",
      "        [ 1.2202],\n",
      "        [-1.5950],\n",
      "        [ 0.0580],\n",
      "        [-0.4107],\n",
      "        [-1.3229],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5662],\n",
      "        [-1.5425],\n",
      "        [ 0.6219],\n",
      "        [-1.4478],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2202],\n",
      "        [ 1.1792]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 348/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0189,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6544],\n",
      "        [ 0.5891],\n",
      "        [-0.0371],\n",
      "        [ 0.4896],\n",
      "        [ 0.9029],\n",
      "        [ 0.9608],\n",
      "        [ 0.9029],\n",
      "        [ 0.8125],\n",
      "        [-1.5791],\n",
      "        [-0.8803],\n",
      "        [ 0.5561],\n",
      "        [-0.2176],\n",
      "        [ 0.9321],\n",
      "        [-0.2176],\n",
      "        [ 0.5561],\n",
      "        [-0.6182],\n",
      "        [-0.3026],\n",
      "        [ 0.8732],\n",
      "        [ 0.7503],\n",
      "        [ 0.7816],\n",
      "        [ 1.2202],\n",
      "        [ 1.2202],\n",
      "        [ 1.0709],\n",
      "        [-0.3026],\n",
      "        [-1.2134],\n",
      "        [ 1.0709],\n",
      "        [-1.4478],\n",
      "        [ 0.9608],\n",
      "        [-1.3228],\n",
      "        [ 0.5561],\n",
      "        [-0.2176],\n",
      "        [ 0.7503],\n",
      "        [ 0.5229],\n",
      "        [ 1.2202],\n",
      "        [ 0.7503],\n",
      "        [-0.6988],\n",
      "        [-0.1291],\n",
      "        [-1.0599],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8803],\n",
      "        [ 0.6219],\n",
      "        [ 1.2202],\n",
      "        [-1.5950],\n",
      "        [ 0.0580],\n",
      "        [-0.4107],\n",
      "        [-1.3228],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5662],\n",
      "        [-1.5425],\n",
      "        [ 0.6219],\n",
      "        [-1.4478],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2202],\n",
      "        [ 1.1793]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 349/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0188,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6544],\n",
      "        [ 0.5891],\n",
      "        [-0.0370],\n",
      "        [ 0.4896],\n",
      "        [ 0.9028],\n",
      "        [ 0.9608],\n",
      "        [ 0.9028],\n",
      "        [ 0.8125],\n",
      "        [-1.5792],\n",
      "        [-0.8804],\n",
      "        [ 0.5561],\n",
      "        [-0.2175],\n",
      "        [ 0.9321],\n",
      "        [-0.2175],\n",
      "        [ 0.5561],\n",
      "        [-0.6183],\n",
      "        [-0.3025],\n",
      "        [ 0.8731],\n",
      "        [ 0.7503],\n",
      "        [ 0.7816],\n",
      "        [ 1.2203],\n",
      "        [ 1.2203],\n",
      "        [ 1.0709],\n",
      "        [-0.3025],\n",
      "        [-1.2133],\n",
      "        [ 1.0709],\n",
      "        [-1.4477],\n",
      "        [ 0.9608],\n",
      "        [-1.3227],\n",
      "        [ 0.5561],\n",
      "        [-0.2175],\n",
      "        [ 0.7503],\n",
      "        [ 0.5229],\n",
      "        [ 1.2203],\n",
      "        [ 0.7503],\n",
      "        [-0.6989],\n",
      "        [-0.1290],\n",
      "        [-1.0600],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8804],\n",
      "        [ 0.6218],\n",
      "        [ 1.2203],\n",
      "        [-1.5951],\n",
      "        [ 0.0581],\n",
      "        [-0.4107],\n",
      "        [-1.3227],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5663],\n",
      "        [-1.5425],\n",
      "        [ 0.6218],\n",
      "        [-1.4477],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2203],\n",
      "        [ 1.1793]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 350/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0188,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6543],\n",
      "        [ 0.5890],\n",
      "        [-0.0370],\n",
      "        [ 0.4896],\n",
      "        [ 0.9028],\n",
      "        [ 0.9608],\n",
      "        [ 0.9028],\n",
      "        [ 0.8125],\n",
      "        [-1.5792],\n",
      "        [-0.8805],\n",
      "        [ 0.5561],\n",
      "        [-0.2175],\n",
      "        [ 0.9320],\n",
      "        [-0.2175],\n",
      "        [ 0.5561],\n",
      "        [-0.6183],\n",
      "        [-0.3025],\n",
      "        [ 0.8731],\n",
      "        [ 0.7502],\n",
      "        [ 0.7815],\n",
      "        [ 1.2204],\n",
      "        [ 1.2204],\n",
      "        [ 1.0709],\n",
      "        [-0.3025],\n",
      "        [-1.2133],\n",
      "        [ 1.0709],\n",
      "        [-1.4477],\n",
      "        [ 0.9608],\n",
      "        [-1.3227],\n",
      "        [ 0.5561],\n",
      "        [-0.2175],\n",
      "        [ 0.7502],\n",
      "        [ 0.5229],\n",
      "        [ 1.2204],\n",
      "        [ 0.7502],\n",
      "        [-0.6990],\n",
      "        [-0.1290],\n",
      "        [-1.0600],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8805],\n",
      "        [ 0.6218],\n",
      "        [ 1.2204],\n",
      "        [-1.5952],\n",
      "        [ 0.0581],\n",
      "        [-0.4107],\n",
      "        [-1.3227],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5663],\n",
      "        [-1.5425],\n",
      "        [ 0.6218],\n",
      "        [-1.4477],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2204],\n",
      "        [ 1.1794]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 351/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0187,\n",
      " epoch_time_duration: 0.0122\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1752],\n",
      "        [-1.1752],\n",
      "        [ 0.6543],\n",
      "        [ 0.5890],\n",
      "        [-0.0369],\n",
      "        [ 0.4896],\n",
      "        [ 0.9028],\n",
      "        [ 0.9608],\n",
      "        [ 0.9028],\n",
      "        [ 0.8124],\n",
      "        [-1.5793],\n",
      "        [-0.8806],\n",
      "        [ 0.5560],\n",
      "        [-0.2174],\n",
      "        [ 0.9320],\n",
      "        [-0.2174],\n",
      "        [ 0.5560],\n",
      "        [-0.6184],\n",
      "        [-0.3024],\n",
      "        [ 0.8731],\n",
      "        [ 0.7502],\n",
      "        [ 0.7815],\n",
      "        [ 1.2205],\n",
      "        [ 1.2205],\n",
      "        [ 1.0710],\n",
      "        [-0.3024],\n",
      "        [-1.2133],\n",
      "        [ 1.0710],\n",
      "        [-1.4476],\n",
      "        [ 0.9608],\n",
      "        [-1.3226],\n",
      "        [ 0.5560],\n",
      "        [-0.2174],\n",
      "        [ 0.7502],\n",
      "        [ 0.5229],\n",
      "        [ 1.2205],\n",
      "        [ 0.7502],\n",
      "        [-0.6991],\n",
      "        [-0.1289],\n",
      "        [-1.0601],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8806],\n",
      "        [ 0.6218],\n",
      "        [ 1.2205],\n",
      "        [-1.5953],\n",
      "        [ 0.0582],\n",
      "        [-0.4107],\n",
      "        [-1.3226],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5664],\n",
      "        [-1.5425],\n",
      "        [ 0.6218],\n",
      "        [-1.4476],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2205],\n",
      "        [ 1.1795]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 352/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0187,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6543],\n",
      "        [ 0.5890],\n",
      "        [-0.0369],\n",
      "        [ 0.4896],\n",
      "        [ 0.9028],\n",
      "        [ 0.9608],\n",
      "        [ 0.9028],\n",
      "        [ 0.8124],\n",
      "        [-1.5793],\n",
      "        [-0.8807],\n",
      "        [ 0.5560],\n",
      "        [-0.2174],\n",
      "        [ 0.9320],\n",
      "        [-0.2174],\n",
      "        [ 0.5560],\n",
      "        [-0.6185],\n",
      "        [-0.3024],\n",
      "        [ 0.8731],\n",
      "        [ 0.7502],\n",
      "        [ 0.7815],\n",
      "        [ 1.2205],\n",
      "        [ 1.2205],\n",
      "        [ 1.0710],\n",
      "        [-0.3024],\n",
      "        [-1.2132],\n",
      "        [ 1.0710],\n",
      "        [-1.4476],\n",
      "        [ 0.9608],\n",
      "        [-1.3225],\n",
      "        [ 0.5560],\n",
      "        [-0.2174],\n",
      "        [ 0.7502],\n",
      "        [ 0.5229],\n",
      "        [ 1.2205],\n",
      "        [ 0.7502],\n",
      "        [-0.6992],\n",
      "        [-0.1288],\n",
      "        [-1.0601],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8807],\n",
      "        [ 0.6218],\n",
      "        [ 1.2205],\n",
      "        [-1.5954],\n",
      "        [ 0.0582],\n",
      "        [-0.4107],\n",
      "        [-1.3225],\n",
      "        [ 1.0169],\n",
      "        [-0.4107],\n",
      "        [-0.5664],\n",
      "        [-1.5426],\n",
      "        [ 0.6218],\n",
      "        [-1.4476],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2205],\n",
      "        [ 1.1795]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 353/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0187,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6543],\n",
      "        [ 0.5890],\n",
      "        [-0.0368],\n",
      "        [ 0.4896],\n",
      "        [ 0.9027],\n",
      "        [ 0.9608],\n",
      "        [ 0.9027],\n",
      "        [ 0.8124],\n",
      "        [-1.5794],\n",
      "        [-0.8808],\n",
      "        [ 0.5560],\n",
      "        [-0.2173],\n",
      "        [ 0.9320],\n",
      "        [-0.2173],\n",
      "        [ 0.5560],\n",
      "        [-0.6185],\n",
      "        [-0.3023],\n",
      "        [ 0.8730],\n",
      "        [ 0.7501],\n",
      "        [ 0.7814],\n",
      "        [ 1.2206],\n",
      "        [ 1.2206],\n",
      "        [ 1.0710],\n",
      "        [-0.3023],\n",
      "        [-1.2132],\n",
      "        [ 1.0710],\n",
      "        [-1.4475],\n",
      "        [ 0.9608],\n",
      "        [-1.3225],\n",
      "        [ 0.5560],\n",
      "        [-0.2173],\n",
      "        [ 0.7501],\n",
      "        [ 0.5229],\n",
      "        [ 1.2206],\n",
      "        [ 0.7501],\n",
      "        [-0.6993],\n",
      "        [-0.1288],\n",
      "        [-1.0601],\n",
      "        [-1.1367],\n",
      "        [ 0.9608],\n",
      "        [-0.8808],\n",
      "        [ 0.6217],\n",
      "        [ 1.2206],\n",
      "        [-1.5955],\n",
      "        [ 0.0583],\n",
      "        [-0.4106],\n",
      "        [-1.3225],\n",
      "        [ 1.0169],\n",
      "        [-0.4106],\n",
      "        [-0.5665],\n",
      "        [-1.5426],\n",
      "        [ 0.6217],\n",
      "        [-1.4475],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2206],\n",
      "        [ 1.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 354/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0186,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6542],\n",
      "        [ 0.5889],\n",
      "        [-0.0367],\n",
      "        [ 0.4896],\n",
      "        [ 0.9027],\n",
      "        [ 0.9607],\n",
      "        [ 0.9027],\n",
      "        [ 0.8123],\n",
      "        [-1.5795],\n",
      "        [-0.8809],\n",
      "        [ 0.5560],\n",
      "        [-0.2173],\n",
      "        [ 0.9320],\n",
      "        [-0.2173],\n",
      "        [ 0.5560],\n",
      "        [-0.6186],\n",
      "        [-0.3023],\n",
      "        [ 0.8730],\n",
      "        [ 0.7501],\n",
      "        [ 0.7814],\n",
      "        [ 1.2207],\n",
      "        [ 1.2207],\n",
      "        [ 1.0710],\n",
      "        [-0.3023],\n",
      "        [-1.2132],\n",
      "        [ 1.0710],\n",
      "        [-1.4475],\n",
      "        [ 0.9607],\n",
      "        [-1.3224],\n",
      "        [ 0.5560],\n",
      "        [-0.2173],\n",
      "        [ 0.7501],\n",
      "        [ 0.5228],\n",
      "        [ 1.2207],\n",
      "        [ 0.7501],\n",
      "        [-0.6994],\n",
      "        [-0.1287],\n",
      "        [-1.0602],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8809],\n",
      "        [ 0.6217],\n",
      "        [ 1.2207],\n",
      "        [-1.5955],\n",
      "        [ 0.0583],\n",
      "        [-0.4106],\n",
      "        [-1.3224],\n",
      "        [ 1.0169],\n",
      "        [-0.4106],\n",
      "        [-0.5665],\n",
      "        [-1.5426],\n",
      "        [ 0.6217],\n",
      "        [-1.4475],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2207],\n",
      "        [ 1.1796]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 355/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0186,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6542],\n",
      "        [ 0.5889],\n",
      "        [-0.0367],\n",
      "        [ 0.4895],\n",
      "        [ 0.9027],\n",
      "        [ 0.9607],\n",
      "        [ 0.9027],\n",
      "        [ 0.8123],\n",
      "        [-1.5795],\n",
      "        [-0.8810],\n",
      "        [ 0.5560],\n",
      "        [-0.2172],\n",
      "        [ 0.9319],\n",
      "        [-0.2172],\n",
      "        [ 0.5560],\n",
      "        [-0.6187],\n",
      "        [-0.3023],\n",
      "        [ 0.8730],\n",
      "        [ 0.7501],\n",
      "        [ 0.7814],\n",
      "        [ 1.2208],\n",
      "        [ 1.2208],\n",
      "        [ 1.0710],\n",
      "        [-0.3023],\n",
      "        [-1.2131],\n",
      "        [ 1.0710],\n",
      "        [-1.4474],\n",
      "        [ 0.9607],\n",
      "        [-1.3224],\n",
      "        [ 0.5560],\n",
      "        [-0.2172],\n",
      "        [ 0.7501],\n",
      "        [ 0.5228],\n",
      "        [ 1.2208],\n",
      "        [ 0.7501],\n",
      "        [-0.6994],\n",
      "        [-0.1287],\n",
      "        [-1.0602],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8810],\n",
      "        [ 0.6217],\n",
      "        [ 1.2208],\n",
      "        [-1.5956],\n",
      "        [ 0.0583],\n",
      "        [-0.4106],\n",
      "        [-1.3224],\n",
      "        [ 1.0169],\n",
      "        [-0.4106],\n",
      "        [-0.5665],\n",
      "        [-1.5426],\n",
      "        [ 0.6217],\n",
      "        [-1.4474],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2208],\n",
      "        [ 1.1797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 356/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0186,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6542],\n",
      "        [ 0.5889],\n",
      "        [-0.0366],\n",
      "        [ 0.4895],\n",
      "        [ 0.9027],\n",
      "        [ 0.9607],\n",
      "        [ 0.9027],\n",
      "        [ 0.8123],\n",
      "        [-1.5796],\n",
      "        [-0.8811],\n",
      "        [ 0.5559],\n",
      "        [-0.2172],\n",
      "        [ 0.9319],\n",
      "        [-0.2172],\n",
      "        [ 0.5559],\n",
      "        [-0.6187],\n",
      "        [-0.3022],\n",
      "        [ 0.8729],\n",
      "        [ 0.7500],\n",
      "        [ 0.7813],\n",
      "        [ 1.2208],\n",
      "        [ 1.2208],\n",
      "        [ 1.0710],\n",
      "        [-0.3022],\n",
      "        [-1.2131],\n",
      "        [ 1.0710],\n",
      "        [-1.4474],\n",
      "        [ 0.9607],\n",
      "        [-1.3223],\n",
      "        [ 0.5559],\n",
      "        [-0.2172],\n",
      "        [ 0.7500],\n",
      "        [ 0.5228],\n",
      "        [ 1.2208],\n",
      "        [ 0.7500],\n",
      "        [-0.6995],\n",
      "        [-0.1286],\n",
      "        [-1.0603],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8811],\n",
      "        [ 0.6216],\n",
      "        [ 1.2208],\n",
      "        [-1.5957],\n",
      "        [ 0.0584],\n",
      "        [-0.4106],\n",
      "        [-1.3223],\n",
      "        [ 1.0169],\n",
      "        [-0.4106],\n",
      "        [-0.5666],\n",
      "        [-1.5426],\n",
      "        [ 0.6216],\n",
      "        [-1.4474],\n",
      "        [ 0.4227],\n",
      "        [-0.4370],\n",
      "        [ 0.4227],\n",
      "        [ 1.2208],\n",
      "        [ 1.1797]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 357/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0185,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6541],\n",
      "        [ 0.5889],\n",
      "        [-0.0366],\n",
      "        [ 0.4895],\n",
      "        [ 0.9026],\n",
      "        [ 0.9607],\n",
      "        [ 0.9026],\n",
      "        [ 0.8122],\n",
      "        [-1.5796],\n",
      "        [-0.8812],\n",
      "        [ 0.5559],\n",
      "        [-0.2171],\n",
      "        [ 0.9319],\n",
      "        [-0.2171],\n",
      "        [ 0.5559],\n",
      "        [-0.6188],\n",
      "        [-0.3022],\n",
      "        [ 0.8729],\n",
      "        [ 0.7500],\n",
      "        [ 0.7813],\n",
      "        [ 1.2209],\n",
      "        [ 1.2209],\n",
      "        [ 1.0710],\n",
      "        [-0.3022],\n",
      "        [-1.2131],\n",
      "        [ 1.0710],\n",
      "        [-1.4473],\n",
      "        [ 0.9607],\n",
      "        [-1.3222],\n",
      "        [ 0.5559],\n",
      "        [-0.2171],\n",
      "        [ 0.7500],\n",
      "        [ 0.5228],\n",
      "        [ 1.2209],\n",
      "        [ 0.7500],\n",
      "        [-0.6996],\n",
      "        [-0.1285],\n",
      "        [-1.0603],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8812],\n",
      "        [ 0.6216],\n",
      "        [ 1.2209],\n",
      "        [-1.5958],\n",
      "        [ 0.0584],\n",
      "        [-0.4106],\n",
      "        [-1.3222],\n",
      "        [ 1.0169],\n",
      "        [-0.4106],\n",
      "        [-0.5666],\n",
      "        [-1.5426],\n",
      "        [ 0.6216],\n",
      "        [-1.4473],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2209],\n",
      "        [ 1.1798]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 358/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0185,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1751],\n",
      "        [-1.1751],\n",
      "        [ 0.6541],\n",
      "        [ 0.5888],\n",
      "        [-0.0365],\n",
      "        [ 0.4895],\n",
      "        [ 0.9026],\n",
      "        [ 0.9607],\n",
      "        [ 0.9026],\n",
      "        [ 0.8122],\n",
      "        [-1.5797],\n",
      "        [-0.8813],\n",
      "        [ 0.5559],\n",
      "        [-0.2171],\n",
      "        [ 0.9319],\n",
      "        [-0.2171],\n",
      "        [ 0.5559],\n",
      "        [-0.6189],\n",
      "        [-0.3021],\n",
      "        [ 0.8729],\n",
      "        [ 0.7500],\n",
      "        [ 0.7813],\n",
      "        [ 1.2210],\n",
      "        [ 1.2210],\n",
      "        [ 1.0710],\n",
      "        [-0.3021],\n",
      "        [-1.2131],\n",
      "        [ 1.0710],\n",
      "        [-1.4473],\n",
      "        [ 0.9607],\n",
      "        [-1.3222],\n",
      "        [ 0.5559],\n",
      "        [-0.2171],\n",
      "        [ 0.7500],\n",
      "        [ 0.5228],\n",
      "        [ 1.2210],\n",
      "        [ 0.7500],\n",
      "        [-0.6997],\n",
      "        [-0.1285],\n",
      "        [-1.0603],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8813],\n",
      "        [ 0.6216],\n",
      "        [ 1.2210],\n",
      "        [-1.5959],\n",
      "        [ 0.0585],\n",
      "        [-0.4106],\n",
      "        [-1.3222],\n",
      "        [ 1.0168],\n",
      "        [-0.4106],\n",
      "        [-0.5667],\n",
      "        [-1.5427],\n",
      "        [ 0.6216],\n",
      "        [-1.4473],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2210],\n",
      "        [ 1.1798]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 359/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0184,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6541],\n",
      "        [ 0.5888],\n",
      "        [-0.0365],\n",
      "        [ 0.4895],\n",
      "        [ 0.9026],\n",
      "        [ 0.9607],\n",
      "        [ 0.9026],\n",
      "        [ 0.8122],\n",
      "        [-1.5798],\n",
      "        [-0.8814],\n",
      "        [ 0.5559],\n",
      "        [-0.2170],\n",
      "        [ 0.9318],\n",
      "        [-0.2170],\n",
      "        [ 0.5559],\n",
      "        [-0.6189],\n",
      "        [-0.3021],\n",
      "        [ 0.8729],\n",
      "        [ 0.7499],\n",
      "        [ 0.7812],\n",
      "        [ 1.2210],\n",
      "        [ 1.2210],\n",
      "        [ 1.0710],\n",
      "        [-0.3021],\n",
      "        [-1.2130],\n",
      "        [ 1.0710],\n",
      "        [-1.4472],\n",
      "        [ 0.9607],\n",
      "        [-1.3221],\n",
      "        [ 0.5559],\n",
      "        [-0.2170],\n",
      "        [ 0.7499],\n",
      "        [ 0.5228],\n",
      "        [ 1.2210],\n",
      "        [ 0.7499],\n",
      "        [-0.6998],\n",
      "        [-0.1284],\n",
      "        [-1.0604],\n",
      "        [-1.1367],\n",
      "        [ 0.9607],\n",
      "        [-0.8814],\n",
      "        [ 0.6216],\n",
      "        [ 1.2210],\n",
      "        [-1.5960],\n",
      "        [ 0.0585],\n",
      "        [-0.4105],\n",
      "        [-1.3221],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5667],\n",
      "        [-1.5427],\n",
      "        [ 0.6216],\n",
      "        [-1.4472],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2210],\n",
      "        [ 1.1799]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 360/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0184,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6540],\n",
      "        [ 0.5888],\n",
      "        [-0.0364],\n",
      "        [ 0.4895],\n",
      "        [ 0.9026],\n",
      "        [ 0.9606],\n",
      "        [ 0.9026],\n",
      "        [ 0.8121],\n",
      "        [-1.5798],\n",
      "        [-0.8815],\n",
      "        [ 0.5559],\n",
      "        [-0.2170],\n",
      "        [ 0.9318],\n",
      "        [-0.2170],\n",
      "        [ 0.5559],\n",
      "        [-0.6190],\n",
      "        [-0.3020],\n",
      "        [ 0.8728],\n",
      "        [ 0.7499],\n",
      "        [ 0.7812],\n",
      "        [ 1.2211],\n",
      "        [ 1.2211],\n",
      "        [ 1.0710],\n",
      "        [-0.3020],\n",
      "        [-1.2130],\n",
      "        [ 1.0710],\n",
      "        [-1.4472],\n",
      "        [ 0.9606],\n",
      "        [-1.3220],\n",
      "        [ 0.5559],\n",
      "        [-0.2170],\n",
      "        [ 0.7499],\n",
      "        [ 0.5227],\n",
      "        [ 1.2211],\n",
      "        [ 0.7499],\n",
      "        [-0.6999],\n",
      "        [-0.1284],\n",
      "        [-1.0604],\n",
      "        [-1.1367],\n",
      "        [ 0.9606],\n",
      "        [-0.8815],\n",
      "        [ 0.6215],\n",
      "        [ 1.2211],\n",
      "        [-1.5960],\n",
      "        [ 0.0586],\n",
      "        [-0.4105],\n",
      "        [-1.3220],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5668],\n",
      "        [-1.5427],\n",
      "        [ 0.6215],\n",
      "        [-1.4472],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2211],\n",
      "        [ 1.1799]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 361/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0184,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6540],\n",
      "        [ 0.5888],\n",
      "        [-0.0364],\n",
      "        [ 0.4895],\n",
      "        [ 0.9025],\n",
      "        [ 0.9606],\n",
      "        [ 0.9025],\n",
      "        [ 0.8121],\n",
      "        [-1.5799],\n",
      "        [-0.8817],\n",
      "        [ 0.5558],\n",
      "        [-0.2169],\n",
      "        [ 0.9318],\n",
      "        [-0.2169],\n",
      "        [ 0.5558],\n",
      "        [-0.6190],\n",
      "        [-0.3020],\n",
      "        [ 0.8728],\n",
      "        [ 0.7499],\n",
      "        [ 0.7812],\n",
      "        [ 1.2212],\n",
      "        [ 1.2212],\n",
      "        [ 1.0711],\n",
      "        [-0.3020],\n",
      "        [-1.2130],\n",
      "        [ 1.0711],\n",
      "        [-1.4471],\n",
      "        [ 0.9606],\n",
      "        [-1.3220],\n",
      "        [ 0.5558],\n",
      "        [-0.2169],\n",
      "        [ 0.7499],\n",
      "        [ 0.5227],\n",
      "        [ 1.2212],\n",
      "        [ 0.7499],\n",
      "        [-0.7000],\n",
      "        [-0.1283],\n",
      "        [-1.0605],\n",
      "        [-1.1367],\n",
      "        [ 0.9606],\n",
      "        [-0.8817],\n",
      "        [ 0.6215],\n",
      "        [ 1.2212],\n",
      "        [-1.5961],\n",
      "        [ 0.0586],\n",
      "        [-0.4105],\n",
      "        [-1.3220],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5668],\n",
      "        [-1.5427],\n",
      "        [ 0.6215],\n",
      "        [-1.4471],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2212],\n",
      "        [ 1.1800]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 362/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0183,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6540],\n",
      "        [ 0.5888],\n",
      "        [-0.0363],\n",
      "        [ 0.4895],\n",
      "        [ 0.9025],\n",
      "        [ 0.9606],\n",
      "        [ 0.9025],\n",
      "        [ 0.8121],\n",
      "        [-1.5799],\n",
      "        [-0.8818],\n",
      "        [ 0.5558],\n",
      "        [-0.2168],\n",
      "        [ 0.9318],\n",
      "        [-0.2168],\n",
      "        [ 0.5558],\n",
      "        [-0.6191],\n",
      "        [-0.3020],\n",
      "        [ 0.8728],\n",
      "        [ 0.7498],\n",
      "        [ 0.7811],\n",
      "        [ 1.2213],\n",
      "        [ 1.2213],\n",
      "        [ 1.0711],\n",
      "        [-0.3020],\n",
      "        [-1.2129],\n",
      "        [ 1.0711],\n",
      "        [-1.4471],\n",
      "        [ 0.9606],\n",
      "        [-1.3219],\n",
      "        [ 0.5558],\n",
      "        [-0.2168],\n",
      "        [ 0.7498],\n",
      "        [ 0.5227],\n",
      "        [ 1.2213],\n",
      "        [ 0.7498],\n",
      "        [-0.7001],\n",
      "        [-0.1283],\n",
      "        [-1.0605],\n",
      "        [-1.1367],\n",
      "        [ 0.9606],\n",
      "        [-0.8818],\n",
      "        [ 0.6215],\n",
      "        [ 1.2213],\n",
      "        [-1.5962],\n",
      "        [ 0.0587],\n",
      "        [-0.4105],\n",
      "        [-1.3219],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5668],\n",
      "        [-1.5427],\n",
      "        [ 0.6215],\n",
      "        [-1.4471],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2213],\n",
      "        [ 1.1800]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 363/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0183,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6540],\n",
      "        [ 0.5887],\n",
      "        [-0.0362],\n",
      "        [ 0.4894],\n",
      "        [ 0.9025],\n",
      "        [ 0.9606],\n",
      "        [ 0.9025],\n",
      "        [ 0.8120],\n",
      "        [-1.5800],\n",
      "        [-0.8819],\n",
      "        [ 0.5558],\n",
      "        [-0.2168],\n",
      "        [ 0.9318],\n",
      "        [-0.2168],\n",
      "        [ 0.5558],\n",
      "        [-0.6192],\n",
      "        [-0.3019],\n",
      "        [ 0.8727],\n",
      "        [ 0.7498],\n",
      "        [ 0.7811],\n",
      "        [ 1.2213],\n",
      "        [ 1.2213],\n",
      "        [ 1.0711],\n",
      "        [-0.3019],\n",
      "        [-1.2129],\n",
      "        [ 1.0711],\n",
      "        [-1.4470],\n",
      "        [ 0.9606],\n",
      "        [-1.3219],\n",
      "        [ 0.5558],\n",
      "        [-0.2168],\n",
      "        [ 0.7498],\n",
      "        [ 0.5227],\n",
      "        [ 1.2213],\n",
      "        [ 0.7498],\n",
      "        [-0.7002],\n",
      "        [-0.1282],\n",
      "        [-1.0605],\n",
      "        [-1.1367],\n",
      "        [ 0.9606],\n",
      "        [-0.8819],\n",
      "        [ 0.6215],\n",
      "        [ 1.2213],\n",
      "        [-1.5963],\n",
      "        [ 0.0587],\n",
      "        [-0.4105],\n",
      "        [-1.3219],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5669],\n",
      "        [-1.5427],\n",
      "        [ 0.6215],\n",
      "        [-1.4470],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2213],\n",
      "        [ 1.1801]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 364/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0183,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6539],\n",
      "        [ 0.5887],\n",
      "        [-0.0362],\n",
      "        [ 0.4894],\n",
      "        [ 0.9025],\n",
      "        [ 0.9606],\n",
      "        [ 0.9025],\n",
      "        [ 0.8120],\n",
      "        [-1.5801],\n",
      "        [-0.8820],\n",
      "        [ 0.5558],\n",
      "        [-0.2167],\n",
      "        [ 0.9317],\n",
      "        [-0.2167],\n",
      "        [ 0.5558],\n",
      "        [-0.6192],\n",
      "        [-0.3019],\n",
      "        [ 0.8727],\n",
      "        [ 0.7498],\n",
      "        [ 0.7811],\n",
      "        [ 1.2214],\n",
      "        [ 1.2214],\n",
      "        [ 1.0711],\n",
      "        [-0.3019],\n",
      "        [-1.2129],\n",
      "        [ 1.0711],\n",
      "        [-1.4470],\n",
      "        [ 0.9606],\n",
      "        [-1.3218],\n",
      "        [ 0.5558],\n",
      "        [-0.2167],\n",
      "        [ 0.7498],\n",
      "        [ 0.5227],\n",
      "        [ 1.2214],\n",
      "        [ 0.7498],\n",
      "        [-0.7003],\n",
      "        [-0.1281],\n",
      "        [-1.0606],\n",
      "        [-1.1368],\n",
      "        [ 0.9606],\n",
      "        [-0.8820],\n",
      "        [ 0.6214],\n",
      "        [ 1.2214],\n",
      "        [-1.5964],\n",
      "        [ 0.0588],\n",
      "        [-0.4105],\n",
      "        [-1.3218],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5669],\n",
      "        [-1.5428],\n",
      "        [ 0.6214],\n",
      "        [-1.4470],\n",
      "        [ 0.4227],\n",
      "        [-0.4369],\n",
      "        [ 0.4227],\n",
      "        [ 1.2214],\n",
      "        [ 1.1801]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 365/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0182,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1750],\n",
      "        [-1.1750],\n",
      "        [ 0.6539],\n",
      "        [ 0.5887],\n",
      "        [-0.0361],\n",
      "        [ 0.4894],\n",
      "        [ 0.9024],\n",
      "        [ 0.9606],\n",
      "        [ 0.9024],\n",
      "        [ 0.8120],\n",
      "        [-1.5801],\n",
      "        [-0.8821],\n",
      "        [ 0.5558],\n",
      "        [-0.2167],\n",
      "        [ 0.9317],\n",
      "        [-0.2167],\n",
      "        [ 0.5558],\n",
      "        [-0.6193],\n",
      "        [-0.3018],\n",
      "        [ 0.8727],\n",
      "        [ 0.7497],\n",
      "        [ 0.7810],\n",
      "        [ 1.2215],\n",
      "        [ 1.2215],\n",
      "        [ 1.0711],\n",
      "        [-0.3018],\n",
      "        [-1.2128],\n",
      "        [ 1.0711],\n",
      "        [-1.4469],\n",
      "        [ 0.9606],\n",
      "        [-1.3217],\n",
      "        [ 0.5558],\n",
      "        [-0.2167],\n",
      "        [ 0.7497],\n",
      "        [ 0.5227],\n",
      "        [ 1.2215],\n",
      "        [ 0.7497],\n",
      "        [-0.7003],\n",
      "        [-0.1281],\n",
      "        [-1.0606],\n",
      "        [-1.1368],\n",
      "        [ 0.9606],\n",
      "        [-0.8821],\n",
      "        [ 0.6214],\n",
      "        [ 1.2215],\n",
      "        [-1.5964],\n",
      "        [ 0.0588],\n",
      "        [-0.4105],\n",
      "        [-1.3217],\n",
      "        [ 1.0168],\n",
      "        [-0.4105],\n",
      "        [-0.5670],\n",
      "        [-1.5428],\n",
      "        [ 0.6214],\n",
      "        [-1.4469],\n",
      "        [ 0.4226],\n",
      "        [-0.4369],\n",
      "        [ 0.4226],\n",
      "        [ 1.2215],\n",
      "        [ 1.1802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 366/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0182,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6539],\n",
      "        [ 0.5887],\n",
      "        [-0.0361],\n",
      "        [ 0.4894],\n",
      "        [ 0.9024],\n",
      "        [ 0.9605],\n",
      "        [ 0.9024],\n",
      "        [ 0.8119],\n",
      "        [-1.5802],\n",
      "        [-0.8822],\n",
      "        [ 0.5557],\n",
      "        [-0.2166],\n",
      "        [ 0.9317],\n",
      "        [-0.2166],\n",
      "        [ 0.5557],\n",
      "        [-0.6193],\n",
      "        [-0.3018],\n",
      "        [ 0.8727],\n",
      "        [ 0.7497],\n",
      "        [ 0.7810],\n",
      "        [ 1.2215],\n",
      "        [ 1.2215],\n",
      "        [ 1.0711],\n",
      "        [-0.3018],\n",
      "        [-1.2128],\n",
      "        [ 1.0711],\n",
      "        [-1.4469],\n",
      "        [ 0.9605],\n",
      "        [-1.3217],\n",
      "        [ 0.5557],\n",
      "        [-0.2166],\n",
      "        [ 0.7497],\n",
      "        [ 0.5226],\n",
      "        [ 1.2215],\n",
      "        [ 0.7497],\n",
      "        [-0.7004],\n",
      "        [-0.1280],\n",
      "        [-1.0607],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8822],\n",
      "        [ 0.6214],\n",
      "        [ 1.2215],\n",
      "        [-1.5965],\n",
      "        [ 0.0589],\n",
      "        [-0.4104],\n",
      "        [-1.3217],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5670],\n",
      "        [-1.5428],\n",
      "        [ 0.6214],\n",
      "        [-1.4469],\n",
      "        [ 0.4226],\n",
      "        [-0.4369],\n",
      "        [ 0.4226],\n",
      "        [ 1.2215],\n",
      "        [ 1.1802]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 367/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0182,\n",
      " epoch_time_duration: 0.0154\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6538],\n",
      "        [ 0.5886],\n",
      "        [-0.0360],\n",
      "        [ 0.4894],\n",
      "        [ 0.9024],\n",
      "        [ 0.9605],\n",
      "        [ 0.9024],\n",
      "        [ 0.8119],\n",
      "        [-1.5802],\n",
      "        [-0.8823],\n",
      "        [ 0.5557],\n",
      "        [-0.2166],\n",
      "        [ 0.9317],\n",
      "        [-0.2166],\n",
      "        [ 0.5557],\n",
      "        [-0.6194],\n",
      "        [-0.3018],\n",
      "        [ 0.8726],\n",
      "        [ 0.7497],\n",
      "        [ 0.7810],\n",
      "        [ 1.2216],\n",
      "        [ 1.2216],\n",
      "        [ 1.0711],\n",
      "        [-0.3018],\n",
      "        [-1.2128],\n",
      "        [ 1.0711],\n",
      "        [-1.4468],\n",
      "        [ 0.9605],\n",
      "        [-1.3216],\n",
      "        [ 0.5557],\n",
      "        [-0.2166],\n",
      "        [ 0.7497],\n",
      "        [ 0.5226],\n",
      "        [ 1.2216],\n",
      "        [ 0.7497],\n",
      "        [-0.7005],\n",
      "        [-0.1280],\n",
      "        [-1.0607],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8823],\n",
      "        [ 0.6214],\n",
      "        [ 1.2216],\n",
      "        [-1.5966],\n",
      "        [ 0.0589],\n",
      "        [-0.4104],\n",
      "        [-1.3216],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5670],\n",
      "        [-1.5428],\n",
      "        [ 0.6214],\n",
      "        [-1.4468],\n",
      "        [ 0.4226],\n",
      "        [-0.4369],\n",
      "        [ 0.4226],\n",
      "        [ 1.2216],\n",
      "        [ 1.1803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 368/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0181,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6538],\n",
      "        [ 0.5886],\n",
      "        [-0.0360],\n",
      "        [ 0.4894],\n",
      "        [ 0.9024],\n",
      "        [ 0.9605],\n",
      "        [ 0.9024],\n",
      "        [ 0.8119],\n",
      "        [-1.5803],\n",
      "        [-0.8824],\n",
      "        [ 0.5557],\n",
      "        [-0.2165],\n",
      "        [ 0.9317],\n",
      "        [-0.2165],\n",
      "        [ 0.5557],\n",
      "        [-0.6195],\n",
      "        [-0.3017],\n",
      "        [ 0.8726],\n",
      "        [ 0.7496],\n",
      "        [ 0.7809],\n",
      "        [ 1.2217],\n",
      "        [ 1.2217],\n",
      "        [ 1.0711],\n",
      "        [-0.3017],\n",
      "        [-1.2128],\n",
      "        [ 1.0711],\n",
      "        [-1.4468],\n",
      "        [ 0.9605],\n",
      "        [-1.3216],\n",
      "        [ 0.5557],\n",
      "        [-0.2165],\n",
      "        [ 0.7496],\n",
      "        [ 0.5226],\n",
      "        [ 1.2217],\n",
      "        [ 0.7496],\n",
      "        [-0.7006],\n",
      "        [-0.1279],\n",
      "        [-1.0607],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8824],\n",
      "        [ 0.6213],\n",
      "        [ 1.2217],\n",
      "        [-1.5967],\n",
      "        [ 0.0590],\n",
      "        [-0.4104],\n",
      "        [-1.3216],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5671],\n",
      "        [-1.5428],\n",
      "        [ 0.6213],\n",
      "        [-1.4468],\n",
      "        [ 0.4226],\n",
      "        [-0.4369],\n",
      "        [ 0.4226],\n",
      "        [ 1.2217],\n",
      "        [ 1.1803]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 369/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0181,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6538],\n",
      "        [ 0.5886],\n",
      "        [-0.0359],\n",
      "        [ 0.4894],\n",
      "        [ 0.9023],\n",
      "        [ 0.9605],\n",
      "        [ 0.9023],\n",
      "        [ 0.8119],\n",
      "        [-1.5803],\n",
      "        [-0.8825],\n",
      "        [ 0.5557],\n",
      "        [-0.2165],\n",
      "        [ 0.9316],\n",
      "        [-0.2165],\n",
      "        [ 0.5557],\n",
      "        [-0.6195],\n",
      "        [-0.3017],\n",
      "        [ 0.8726],\n",
      "        [ 0.7496],\n",
      "        [ 0.7809],\n",
      "        [ 1.2218],\n",
      "        [ 1.2218],\n",
      "        [ 1.0711],\n",
      "        [-0.3017],\n",
      "        [-1.2127],\n",
      "        [ 1.0711],\n",
      "        [-1.4467],\n",
      "        [ 0.9605],\n",
      "        [-1.3215],\n",
      "        [ 0.5557],\n",
      "        [-0.2165],\n",
      "        [ 0.7496],\n",
      "        [ 0.5226],\n",
      "        [ 1.2218],\n",
      "        [ 0.7496],\n",
      "        [-0.7007],\n",
      "        [-0.1279],\n",
      "        [-1.0608],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8825],\n",
      "        [ 0.6213],\n",
      "        [ 1.2218],\n",
      "        [-1.5968],\n",
      "        [ 0.0590],\n",
      "        [-0.4104],\n",
      "        [-1.3215],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5671],\n",
      "        [-1.5428],\n",
      "        [ 0.6213],\n",
      "        [-1.4467],\n",
      "        [ 0.4226],\n",
      "        [-0.4369],\n",
      "        [ 0.4226],\n",
      "        [ 1.2218],\n",
      "        [ 1.1804]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 370/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0181,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6538],\n",
      "        [ 0.5886],\n",
      "        [-0.0359],\n",
      "        [ 0.4894],\n",
      "        [ 0.9023],\n",
      "        [ 0.9605],\n",
      "        [ 0.9023],\n",
      "        [ 0.8118],\n",
      "        [-1.5804],\n",
      "        [-0.8826],\n",
      "        [ 0.5557],\n",
      "        [-0.2164],\n",
      "        [ 0.9316],\n",
      "        [-0.2164],\n",
      "        [ 0.5557],\n",
      "        [-0.6196],\n",
      "        [-0.3016],\n",
      "        [ 0.8726],\n",
      "        [ 0.7496],\n",
      "        [ 0.7809],\n",
      "        [ 1.2218],\n",
      "        [ 1.2218],\n",
      "        [ 1.0711],\n",
      "        [-0.3016],\n",
      "        [-1.2127],\n",
      "        [ 1.0711],\n",
      "        [-1.4467],\n",
      "        [ 0.9605],\n",
      "        [-1.3214],\n",
      "        [ 0.5557],\n",
      "        [-0.2164],\n",
      "        [ 0.7496],\n",
      "        [ 0.5226],\n",
      "        [ 1.2218],\n",
      "        [ 0.7496],\n",
      "        [-0.7008],\n",
      "        [-0.1278],\n",
      "        [-1.0608],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8826],\n",
      "        [ 0.6213],\n",
      "        [ 1.2218],\n",
      "        [-1.5968],\n",
      "        [ 0.0591],\n",
      "        [-0.4104],\n",
      "        [-1.3214],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5672],\n",
      "        [-1.5429],\n",
      "        [ 0.6213],\n",
      "        [-1.4467],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2218],\n",
      "        [ 1.1804]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 371/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0180,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6537],\n",
      "        [ 0.5885],\n",
      "        [-0.0358],\n",
      "        [ 0.4893],\n",
      "        [ 0.9023],\n",
      "        [ 0.9605],\n",
      "        [ 0.9023],\n",
      "        [ 0.8118],\n",
      "        [-1.5804],\n",
      "        [-0.8826],\n",
      "        [ 0.5556],\n",
      "        [-0.2164],\n",
      "        [ 0.9316],\n",
      "        [-0.2164],\n",
      "        [ 0.5556],\n",
      "        [-0.6196],\n",
      "        [-0.3016],\n",
      "        [ 0.8725],\n",
      "        [ 0.7495],\n",
      "        [ 0.7808],\n",
      "        [ 1.2219],\n",
      "        [ 1.2219],\n",
      "        [ 1.0711],\n",
      "        [-0.3016],\n",
      "        [-1.2127],\n",
      "        [ 1.0711],\n",
      "        [-1.4466],\n",
      "        [ 0.9605],\n",
      "        [-1.3214],\n",
      "        [ 0.5556],\n",
      "        [-0.2164],\n",
      "        [ 0.7495],\n",
      "        [ 0.5226],\n",
      "        [ 1.2219],\n",
      "        [ 0.7495],\n",
      "        [-0.7009],\n",
      "        [-0.1278],\n",
      "        [-1.0608],\n",
      "        [-1.1368],\n",
      "        [ 0.9605],\n",
      "        [-0.8826],\n",
      "        [ 0.6213],\n",
      "        [ 1.2219],\n",
      "        [-1.5969],\n",
      "        [ 0.0591],\n",
      "        [-0.4104],\n",
      "        [-1.3214],\n",
      "        [ 1.0168],\n",
      "        [-0.4104],\n",
      "        [-0.5672],\n",
      "        [-1.5429],\n",
      "        [ 0.6213],\n",
      "        [-1.4466],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2219],\n",
      "        [ 1.1805]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 372/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0180,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1749],\n",
      "        [-1.1749],\n",
      "        [ 0.6537],\n",
      "        [ 0.5885],\n",
      "        [-0.0358],\n",
      "        [ 0.4893],\n",
      "        [ 0.9023],\n",
      "        [ 0.9604],\n",
      "        [ 0.9023],\n",
      "        [ 0.8118],\n",
      "        [-1.5805],\n",
      "        [-0.8827],\n",
      "        [ 0.5556],\n",
      "        [-0.2163],\n",
      "        [ 0.9316],\n",
      "        [-0.2163],\n",
      "        [ 0.5556],\n",
      "        [-0.6197],\n",
      "        [-0.3016],\n",
      "        [ 0.8725],\n",
      "        [ 0.7495],\n",
      "        [ 0.7808],\n",
      "        [ 1.2220],\n",
      "        [ 1.2220],\n",
      "        [ 1.0712],\n",
      "        [-0.3016],\n",
      "        [-1.2126],\n",
      "        [ 1.0712],\n",
      "        [-1.4466],\n",
      "        [ 0.9604],\n",
      "        [-1.3213],\n",
      "        [ 0.5556],\n",
      "        [-0.2163],\n",
      "        [ 0.7495],\n",
      "        [ 0.5225],\n",
      "        [ 1.2220],\n",
      "        [ 0.7495],\n",
      "        [-0.7010],\n",
      "        [-0.1277],\n",
      "        [-1.0609],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8827],\n",
      "        [ 0.6212],\n",
      "        [ 1.2220],\n",
      "        [-1.5970],\n",
      "        [ 0.0591],\n",
      "        [-0.4103],\n",
      "        [-1.3213],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5672],\n",
      "        [-1.5429],\n",
      "        [ 0.6212],\n",
      "        [-1.4466],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2220],\n",
      "        [ 1.1805]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 373/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0179,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6537],\n",
      "        [ 0.5885],\n",
      "        [-0.0357],\n",
      "        [ 0.4893],\n",
      "        [ 0.9022],\n",
      "        [ 0.9604],\n",
      "        [ 0.9022],\n",
      "        [ 0.8117],\n",
      "        [-1.5806],\n",
      "        [-0.8828],\n",
      "        [ 0.5556],\n",
      "        [-0.2163],\n",
      "        [ 0.9316],\n",
      "        [-0.2163],\n",
      "        [ 0.5556],\n",
      "        [-0.6198],\n",
      "        [-0.3015],\n",
      "        [ 0.8725],\n",
      "        [ 0.7495],\n",
      "        [ 0.7808],\n",
      "        [ 1.2220],\n",
      "        [ 1.2220],\n",
      "        [ 1.0712],\n",
      "        [-0.3015],\n",
      "        [-1.2126],\n",
      "        [ 1.0712],\n",
      "        [-1.4465],\n",
      "        [ 0.9604],\n",
      "        [-1.3213],\n",
      "        [ 0.5556],\n",
      "        [-0.2163],\n",
      "        [ 0.7495],\n",
      "        [ 0.5225],\n",
      "        [ 1.2220],\n",
      "        [ 0.7495],\n",
      "        [-0.7010],\n",
      "        [-0.1276],\n",
      "        [-1.0609],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8828],\n",
      "        [ 0.6212],\n",
      "        [ 1.2220],\n",
      "        [-1.5971],\n",
      "        [ 0.0592],\n",
      "        [-0.4103],\n",
      "        [-1.3213],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5673],\n",
      "        [-1.5429],\n",
      "        [ 0.6212],\n",
      "        [-1.4465],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2220],\n",
      "        [ 1.1806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 374/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0179,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6537],\n",
      "        [ 0.5885],\n",
      "        [-0.0357],\n",
      "        [ 0.4893],\n",
      "        [ 0.9022],\n",
      "        [ 0.9604],\n",
      "        [ 0.9022],\n",
      "        [ 0.8117],\n",
      "        [-1.5806],\n",
      "        [-0.8829],\n",
      "        [ 0.5556],\n",
      "        [-0.2162],\n",
      "        [ 0.9315],\n",
      "        [-0.2162],\n",
      "        [ 0.5556],\n",
      "        [-0.6198],\n",
      "        [-0.3015],\n",
      "        [ 0.8724],\n",
      "        [ 0.7494],\n",
      "        [ 0.7807],\n",
      "        [ 1.2221],\n",
      "        [ 1.2221],\n",
      "        [ 1.0712],\n",
      "        [-0.3015],\n",
      "        [-1.2126],\n",
      "        [ 1.0712],\n",
      "        [-1.4465],\n",
      "        [ 0.9604],\n",
      "        [-1.3212],\n",
      "        [ 0.5556],\n",
      "        [-0.2162],\n",
      "        [ 0.7494],\n",
      "        [ 0.5225],\n",
      "        [ 1.2221],\n",
      "        [ 0.7494],\n",
      "        [-0.7011],\n",
      "        [-0.1276],\n",
      "        [-1.0610],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8829],\n",
      "        [ 0.6212],\n",
      "        [ 1.2221],\n",
      "        [-1.5971],\n",
      "        [ 0.0592],\n",
      "        [-0.4103],\n",
      "        [-1.3212],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5673],\n",
      "        [-1.5429],\n",
      "        [ 0.6212],\n",
      "        [-1.4465],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2221],\n",
      "        [ 1.1806]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 375/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0179,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6536],\n",
      "        [ 0.5885],\n",
      "        [-0.0356],\n",
      "        [ 0.4893],\n",
      "        [ 0.9022],\n",
      "        [ 0.9604],\n",
      "        [ 0.9022],\n",
      "        [ 0.8117],\n",
      "        [-1.5807],\n",
      "        [-0.8830],\n",
      "        [ 0.5556],\n",
      "        [-0.2162],\n",
      "        [ 0.9315],\n",
      "        [-0.2162],\n",
      "        [ 0.5556],\n",
      "        [-0.6199],\n",
      "        [-0.3014],\n",
      "        [ 0.8724],\n",
      "        [ 0.7494],\n",
      "        [ 0.7807],\n",
      "        [ 1.2222],\n",
      "        [ 1.2222],\n",
      "        [ 1.0712],\n",
      "        [-0.3014],\n",
      "        [-1.2126],\n",
      "        [ 1.0712],\n",
      "        [-1.4464],\n",
      "        [ 0.9604],\n",
      "        [-1.3211],\n",
      "        [ 0.5556],\n",
      "        [-0.2162],\n",
      "        [ 0.7494],\n",
      "        [ 0.5225],\n",
      "        [ 1.2222],\n",
      "        [ 0.7494],\n",
      "        [-0.7012],\n",
      "        [-0.1275],\n",
      "        [-1.0610],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8830],\n",
      "        [ 0.6211],\n",
      "        [ 1.2222],\n",
      "        [-1.5972],\n",
      "        [ 0.0593],\n",
      "        [-0.4103],\n",
      "        [-1.3211],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5674],\n",
      "        [-1.5429],\n",
      "        [ 0.6211],\n",
      "        [-1.4464],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2222],\n",
      "        [ 1.1807]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 376/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0178,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6536],\n",
      "        [ 0.5884],\n",
      "        [-0.0356],\n",
      "        [ 0.4893],\n",
      "        [ 0.9022],\n",
      "        [ 0.9604],\n",
      "        [ 0.9022],\n",
      "        [ 0.8116],\n",
      "        [-1.5807],\n",
      "        [-0.8831],\n",
      "        [ 0.5555],\n",
      "        [-0.2161],\n",
      "        [ 0.9315],\n",
      "        [-0.2161],\n",
      "        [ 0.5555],\n",
      "        [-0.6199],\n",
      "        [-0.3014],\n",
      "        [ 0.8724],\n",
      "        [ 0.7494],\n",
      "        [ 0.7807],\n",
      "        [ 1.2222],\n",
      "        [ 1.2222],\n",
      "        [ 1.0712],\n",
      "        [-0.3014],\n",
      "        [-1.2125],\n",
      "        [ 1.0712],\n",
      "        [-1.4464],\n",
      "        [ 0.9604],\n",
      "        [-1.3211],\n",
      "        [ 0.5555],\n",
      "        [-0.2161],\n",
      "        [ 0.7494],\n",
      "        [ 0.5225],\n",
      "        [ 1.2222],\n",
      "        [ 0.7494],\n",
      "        [-0.7013],\n",
      "        [-0.1275],\n",
      "        [-1.0610],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8831],\n",
      "        [ 0.6211],\n",
      "        [ 1.2222],\n",
      "        [-1.5973],\n",
      "        [ 0.0593],\n",
      "        [-0.4103],\n",
      "        [-1.3211],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5674],\n",
      "        [-1.5429],\n",
      "        [ 0.6211],\n",
      "        [-1.4464],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2222],\n",
      "        [ 1.1807]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 377/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0178,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6536],\n",
      "        [ 0.5884],\n",
      "        [-0.0355],\n",
      "        [ 0.4893],\n",
      "        [ 0.9021],\n",
      "        [ 0.9604],\n",
      "        [ 0.9021],\n",
      "        [ 0.8116],\n",
      "        [-1.5808],\n",
      "        [-0.8832],\n",
      "        [ 0.5555],\n",
      "        [-0.2161],\n",
      "        [ 0.9315],\n",
      "        [-0.2161],\n",
      "        [ 0.5555],\n",
      "        [-0.6200],\n",
      "        [-0.3013],\n",
      "        [ 0.8724],\n",
      "        [ 0.7494],\n",
      "        [ 0.7807],\n",
      "        [ 1.2223],\n",
      "        [ 1.2223],\n",
      "        [ 1.0712],\n",
      "        [-0.3013],\n",
      "        [-1.2125],\n",
      "        [ 1.0712],\n",
      "        [-1.4463],\n",
      "        [ 0.9604],\n",
      "        [-1.3210],\n",
      "        [ 0.5555],\n",
      "        [-0.2161],\n",
      "        [ 0.7494],\n",
      "        [ 0.5225],\n",
      "        [ 1.2223],\n",
      "        [ 0.7494],\n",
      "        [-0.7014],\n",
      "        [-0.1274],\n",
      "        [-1.0611],\n",
      "        [-1.1368],\n",
      "        [ 0.9604],\n",
      "        [-0.8832],\n",
      "        [ 0.6211],\n",
      "        [ 1.2223],\n",
      "        [-1.5974],\n",
      "        [ 0.0594],\n",
      "        [-0.4103],\n",
      "        [-1.3210],\n",
      "        [ 1.0168],\n",
      "        [-0.4103],\n",
      "        [-0.5674],\n",
      "        [-1.5429],\n",
      "        [ 0.6211],\n",
      "        [-1.4463],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2223],\n",
      "        [ 1.1808]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 378/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0178,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6535],\n",
      "        [ 0.5884],\n",
      "        [-0.0354],\n",
      "        [ 0.4893],\n",
      "        [ 0.9021],\n",
      "        [ 0.9603],\n",
      "        [ 0.9021],\n",
      "        [ 0.8116],\n",
      "        [-1.5808],\n",
      "        [-0.8833],\n",
      "        [ 0.5555],\n",
      "        [-0.2160],\n",
      "        [ 0.9315],\n",
      "        [-0.2160],\n",
      "        [ 0.5555],\n",
      "        [-0.6201],\n",
      "        [-0.3013],\n",
      "        [ 0.8723],\n",
      "        [ 0.7493],\n",
      "        [ 0.7806],\n",
      "        [ 1.2224],\n",
      "        [ 1.2224],\n",
      "        [ 1.0712],\n",
      "        [-0.3013],\n",
      "        [-1.2125],\n",
      "        [ 1.0712],\n",
      "        [-1.4463],\n",
      "        [ 0.9603],\n",
      "        [-1.3210],\n",
      "        [ 0.5555],\n",
      "        [-0.2160],\n",
      "        [ 0.7493],\n",
      "        [ 0.5224],\n",
      "        [ 1.2224],\n",
      "        [ 0.7493],\n",
      "        [-0.7015],\n",
      "        [-0.1274],\n",
      "        [-1.0611],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8833],\n",
      "        [ 0.6211],\n",
      "        [ 1.2224],\n",
      "        [-1.5974],\n",
      "        [ 0.0594],\n",
      "        [-0.4102],\n",
      "        [-1.3210],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5675],\n",
      "        [-1.5430],\n",
      "        [ 0.6211],\n",
      "        [-1.4463],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2224],\n",
      "        [ 1.1808]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 379/10000,\n",
      " train_loss: 0.0005,\n",
      " train_mae: 0.0177,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6535],\n",
      "        [ 0.5884],\n",
      "        [-0.0354],\n",
      "        [ 0.4892],\n",
      "        [ 0.9021],\n",
      "        [ 0.9603],\n",
      "        [ 0.9021],\n",
      "        [ 0.8115],\n",
      "        [-1.5809],\n",
      "        [-0.8834],\n",
      "        [ 0.5555],\n",
      "        [-0.2160],\n",
      "        [ 0.9314],\n",
      "        [-0.2160],\n",
      "        [ 0.5555],\n",
      "        [-0.6201],\n",
      "        [-0.3013],\n",
      "        [ 0.8723],\n",
      "        [ 0.7493],\n",
      "        [ 0.7806],\n",
      "        [ 1.2224],\n",
      "        [ 1.2224],\n",
      "        [ 1.0712],\n",
      "        [-0.3013],\n",
      "        [-1.2124],\n",
      "        [ 1.0712],\n",
      "        [-1.4462],\n",
      "        [ 0.9603],\n",
      "        [-1.3209],\n",
      "        [ 0.5555],\n",
      "        [-0.2160],\n",
      "        [ 0.7493],\n",
      "        [ 0.5224],\n",
      "        [ 1.2224],\n",
      "        [ 0.7493],\n",
      "        [-0.7015],\n",
      "        [-0.1273],\n",
      "        [-1.0612],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8834],\n",
      "        [ 0.6210],\n",
      "        [ 1.2224],\n",
      "        [-1.5975],\n",
      "        [ 0.0595],\n",
      "        [-0.4102],\n",
      "        [-1.3209],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5675],\n",
      "        [-1.5430],\n",
      "        [ 0.6210],\n",
      "        [-1.4462],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2224],\n",
      "        [ 1.1809]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 380/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0177,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1748],\n",
      "        [-1.1748],\n",
      "        [ 0.6535],\n",
      "        [ 0.5883],\n",
      "        [-0.0353],\n",
      "        [ 0.4892],\n",
      "        [ 0.9021],\n",
      "        [ 0.9603],\n",
      "        [ 0.9021],\n",
      "        [ 0.8115],\n",
      "        [-1.5809],\n",
      "        [-0.8835],\n",
      "        [ 0.5555],\n",
      "        [-0.2159],\n",
      "        [ 0.9314],\n",
      "        [-0.2159],\n",
      "        [ 0.5555],\n",
      "        [-0.6202],\n",
      "        [-0.3012],\n",
      "        [ 0.8723],\n",
      "        [ 0.7493],\n",
      "        [ 0.7806],\n",
      "        [ 1.2225],\n",
      "        [ 1.2225],\n",
      "        [ 1.0712],\n",
      "        [-0.3012],\n",
      "        [-1.2124],\n",
      "        [ 1.0712],\n",
      "        [-1.4462],\n",
      "        [ 0.9603],\n",
      "        [-1.3208],\n",
      "        [ 0.5555],\n",
      "        [-0.2159],\n",
      "        [ 0.7493],\n",
      "        [ 0.5224],\n",
      "        [ 1.2225],\n",
      "        [ 0.7493],\n",
      "        [-0.7016],\n",
      "        [-0.1273],\n",
      "        [-1.0612],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8835],\n",
      "        [ 0.6210],\n",
      "        [ 1.2225],\n",
      "        [-1.5976],\n",
      "        [ 0.0595],\n",
      "        [-0.4102],\n",
      "        [-1.3208],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5675],\n",
      "        [-1.5430],\n",
      "        [ 0.6210],\n",
      "        [-1.4462],\n",
      "        [ 0.4226],\n",
      "        [-0.4368],\n",
      "        [ 0.4226],\n",
      "        [ 1.2225],\n",
      "        [ 1.1809]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 381/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0177,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6535],\n",
      "        [ 0.5883],\n",
      "        [-0.0353],\n",
      "        [ 0.4892],\n",
      "        [ 0.9020],\n",
      "        [ 0.9603],\n",
      "        [ 0.9020],\n",
      "        [ 0.8115],\n",
      "        [-1.5810],\n",
      "        [-0.8836],\n",
      "        [ 0.5554],\n",
      "        [-0.2159],\n",
      "        [ 0.9314],\n",
      "        [-0.2159],\n",
      "        [ 0.5554],\n",
      "        [-0.6202],\n",
      "        [-0.3012],\n",
      "        [ 0.8723],\n",
      "        [ 0.7492],\n",
      "        [ 0.7805],\n",
      "        [ 1.2226],\n",
      "        [ 1.2226],\n",
      "        [ 1.0712],\n",
      "        [-0.3012],\n",
      "        [-1.2124],\n",
      "        [ 1.0712],\n",
      "        [-1.4462],\n",
      "        [ 0.9603],\n",
      "        [-1.3208],\n",
      "        [ 0.5554],\n",
      "        [-0.2159],\n",
      "        [ 0.7492],\n",
      "        [ 0.5224],\n",
      "        [ 1.2226],\n",
      "        [ 0.7492],\n",
      "        [-0.7017],\n",
      "        [-0.1272],\n",
      "        [-1.0612],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8836],\n",
      "        [ 0.6210],\n",
      "        [ 1.2226],\n",
      "        [-1.5977],\n",
      "        [ 0.0596],\n",
      "        [-0.4102],\n",
      "        [-1.3208],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5676],\n",
      "        [-1.5430],\n",
      "        [ 0.6210],\n",
      "        [-1.4462],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2226],\n",
      "        [ 1.1810]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 382/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0176,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6534],\n",
      "        [ 0.5883],\n",
      "        [-0.0352],\n",
      "        [ 0.4892],\n",
      "        [ 0.9020],\n",
      "        [ 0.9603],\n",
      "        [ 0.9020],\n",
      "        [ 0.8115],\n",
      "        [-1.5810],\n",
      "        [-0.8837],\n",
      "        [ 0.5554],\n",
      "        [-0.2158],\n",
      "        [ 0.9314],\n",
      "        [-0.2158],\n",
      "        [ 0.5554],\n",
      "        [-0.6203],\n",
      "        [-0.3011],\n",
      "        [ 0.8722],\n",
      "        [ 0.7492],\n",
      "        [ 0.7805],\n",
      "        [ 1.2226],\n",
      "        [ 1.2226],\n",
      "        [ 1.0712],\n",
      "        [-0.3011],\n",
      "        [-1.2124],\n",
      "        [ 1.0712],\n",
      "        [-1.4461],\n",
      "        [ 0.9603],\n",
      "        [-1.3207],\n",
      "        [ 0.5554],\n",
      "        [-0.2158],\n",
      "        [ 0.7492],\n",
      "        [ 0.5224],\n",
      "        [ 1.2226],\n",
      "        [ 0.7492],\n",
      "        [-0.7018],\n",
      "        [-0.1272],\n",
      "        [-1.0613],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8837],\n",
      "        [ 0.6210],\n",
      "        [ 1.2226],\n",
      "        [-1.5977],\n",
      "        [ 0.0596],\n",
      "        [-0.4102],\n",
      "        [-1.3207],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5676],\n",
      "        [-1.5430],\n",
      "        [ 0.6210],\n",
      "        [-1.4461],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2226],\n",
      "        [ 1.1810]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 383/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0176,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6534],\n",
      "        [ 0.5883],\n",
      "        [-0.0352],\n",
      "        [ 0.4892],\n",
      "        [ 0.9020],\n",
      "        [ 0.9603],\n",
      "        [ 0.9020],\n",
      "        [ 0.8114],\n",
      "        [-1.5811],\n",
      "        [-0.8838],\n",
      "        [ 0.5554],\n",
      "        [-0.2158],\n",
      "        [ 0.9314],\n",
      "        [-0.2158],\n",
      "        [ 0.5554],\n",
      "        [-0.6203],\n",
      "        [-0.3011],\n",
      "        [ 0.8722],\n",
      "        [ 0.7492],\n",
      "        [ 0.7805],\n",
      "        [ 1.2227],\n",
      "        [ 1.2227],\n",
      "        [ 1.0712],\n",
      "        [-0.3011],\n",
      "        [-1.2123],\n",
      "        [ 1.0712],\n",
      "        [-1.4461],\n",
      "        [ 0.9603],\n",
      "        [-1.3207],\n",
      "        [ 0.5554],\n",
      "        [-0.2158],\n",
      "        [ 0.7492],\n",
      "        [ 0.5224],\n",
      "        [ 1.2227],\n",
      "        [ 0.7492],\n",
      "        [-0.7019],\n",
      "        [-0.1271],\n",
      "        [-1.0613],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8838],\n",
      "        [ 0.6209],\n",
      "        [ 1.2227],\n",
      "        [-1.5978],\n",
      "        [ 0.0596],\n",
      "        [-0.4102],\n",
      "        [-1.3207],\n",
      "        [ 1.0167],\n",
      "        [-0.4102],\n",
      "        [-0.5676],\n",
      "        [-1.5430],\n",
      "        [ 0.6209],\n",
      "        [-1.4461],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2227],\n",
      "        [ 1.1811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 384/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0176,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6534],\n",
      "        [ 0.5882],\n",
      "        [-0.0351],\n",
      "        [ 0.4892],\n",
      "        [ 0.9020],\n",
      "        [ 0.9603],\n",
      "        [ 0.9020],\n",
      "        [ 0.8114],\n",
      "        [-1.5812],\n",
      "        [-0.8839],\n",
      "        [ 0.5554],\n",
      "        [-0.2157],\n",
      "        [ 0.9313],\n",
      "        [-0.2157],\n",
      "        [ 0.5554],\n",
      "        [-0.6204],\n",
      "        [-0.3011],\n",
      "        [ 0.8722],\n",
      "        [ 0.7491],\n",
      "        [ 0.7804],\n",
      "        [ 1.2228],\n",
      "        [ 1.2228],\n",
      "        [ 1.0713],\n",
      "        [-0.3011],\n",
      "        [-1.2123],\n",
      "        [ 1.0713],\n",
      "        [-1.4460],\n",
      "        [ 0.9603],\n",
      "        [-1.3206],\n",
      "        [ 0.5554],\n",
      "        [-0.2157],\n",
      "        [ 0.7491],\n",
      "        [ 0.5224],\n",
      "        [ 1.2228],\n",
      "        [ 0.7491],\n",
      "        [-0.7020],\n",
      "        [-0.1271],\n",
      "        [-1.0613],\n",
      "        [-1.1368],\n",
      "        [ 0.9603],\n",
      "        [-0.8839],\n",
      "        [ 0.6209],\n",
      "        [ 1.2228],\n",
      "        [-1.5979],\n",
      "        [ 0.0597],\n",
      "        [-0.4101],\n",
      "        [-1.3206],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5677],\n",
      "        [-1.5430],\n",
      "        [ 0.6209],\n",
      "        [-1.4460],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2228],\n",
      "        [ 1.1811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 385/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0175,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6533],\n",
      "        [ 0.5882],\n",
      "        [-0.0351],\n",
      "        [ 0.4892],\n",
      "        [ 0.9019],\n",
      "        [ 0.9602],\n",
      "        [ 0.9019],\n",
      "        [ 0.8114],\n",
      "        [-1.5812],\n",
      "        [-0.8840],\n",
      "        [ 0.5554],\n",
      "        [-0.2157],\n",
      "        [ 0.9313],\n",
      "        [-0.2157],\n",
      "        [ 0.5554],\n",
      "        [-0.6205],\n",
      "        [-0.3010],\n",
      "        [ 0.8722],\n",
      "        [ 0.7491],\n",
      "        [ 0.7804],\n",
      "        [ 1.2228],\n",
      "        [ 1.2228],\n",
      "        [ 1.0713],\n",
      "        [-0.3010],\n",
      "        [-1.2123],\n",
      "        [ 1.0713],\n",
      "        [-1.4460],\n",
      "        [ 0.9602],\n",
      "        [-1.3206],\n",
      "        [ 0.5554],\n",
      "        [-0.2157],\n",
      "        [ 0.7491],\n",
      "        [ 0.5223],\n",
      "        [ 1.2228],\n",
      "        [ 0.7491],\n",
      "        [-0.7020],\n",
      "        [-0.1270],\n",
      "        [-1.0614],\n",
      "        [-1.1368],\n",
      "        [ 0.9602],\n",
      "        [-0.8840],\n",
      "        [ 0.6209],\n",
      "        [ 1.2228],\n",
      "        [-1.5980],\n",
      "        [ 0.0597],\n",
      "        [-0.4101],\n",
      "        [-1.3206],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5677],\n",
      "        [-1.5431],\n",
      "        [ 0.6209],\n",
      "        [-1.4460],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2228],\n",
      "        [ 1.1811]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 386/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0175,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6533],\n",
      "        [ 0.5882],\n",
      "        [-0.0350],\n",
      "        [ 0.4892],\n",
      "        [ 0.9019],\n",
      "        [ 0.9602],\n",
      "        [ 0.9019],\n",
      "        [ 0.8113],\n",
      "        [-1.5813],\n",
      "        [-0.8841],\n",
      "        [ 0.5553],\n",
      "        [-0.2156],\n",
      "        [ 0.9313],\n",
      "        [-0.2156],\n",
      "        [ 0.5553],\n",
      "        [-0.6205],\n",
      "        [-0.3010],\n",
      "        [ 0.8721],\n",
      "        [ 0.7491],\n",
      "        [ 0.7804],\n",
      "        [ 1.2229],\n",
      "        [ 1.2229],\n",
      "        [ 1.0713],\n",
      "        [-0.3010],\n",
      "        [-1.2123],\n",
      "        [ 1.0713],\n",
      "        [-1.4459],\n",
      "        [ 0.9602],\n",
      "        [-1.3205],\n",
      "        [ 0.5553],\n",
      "        [-0.2156],\n",
      "        [ 0.7491],\n",
      "        [ 0.5223],\n",
      "        [ 1.2229],\n",
      "        [ 0.7491],\n",
      "        [-0.7021],\n",
      "        [-0.1269],\n",
      "        [-1.0614],\n",
      "        [-1.1368],\n",
      "        [ 0.9602],\n",
      "        [-0.8841],\n",
      "        [ 0.6209],\n",
      "        [ 1.2229],\n",
      "        [-1.5980],\n",
      "        [ 0.0598],\n",
      "        [-0.4101],\n",
      "        [-1.3205],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5678],\n",
      "        [-1.5431],\n",
      "        [ 0.6209],\n",
      "        [-1.4459],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2229],\n",
      "        [ 1.1812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 387/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0175,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6533],\n",
      "        [ 0.5882],\n",
      "        [-0.0350],\n",
      "        [ 0.4892],\n",
      "        [ 0.9019],\n",
      "        [ 0.9602],\n",
      "        [ 0.9019],\n",
      "        [ 0.8113],\n",
      "        [-1.5813],\n",
      "        [-0.8842],\n",
      "        [ 0.5553],\n",
      "        [-0.2156],\n",
      "        [ 0.9313],\n",
      "        [-0.2156],\n",
      "        [ 0.5553],\n",
      "        [-0.6206],\n",
      "        [-0.3009],\n",
      "        [ 0.8721],\n",
      "        [ 0.7490],\n",
      "        [ 0.7804],\n",
      "        [ 1.2230],\n",
      "        [ 1.2230],\n",
      "        [ 1.0713],\n",
      "        [-0.3009],\n",
      "        [-1.2122],\n",
      "        [ 1.0713],\n",
      "        [-1.4459],\n",
      "        [ 0.9602],\n",
      "        [-1.3205],\n",
      "        [ 0.5553],\n",
      "        [-0.2156],\n",
      "        [ 0.7490],\n",
      "        [ 0.5223],\n",
      "        [ 1.2230],\n",
      "        [ 0.7490],\n",
      "        [-0.7022],\n",
      "        [-0.1269],\n",
      "        [-1.0615],\n",
      "        [-1.1368],\n",
      "        [ 0.9602],\n",
      "        [-0.8842],\n",
      "        [ 0.6208],\n",
      "        [ 1.2230],\n",
      "        [-1.5981],\n",
      "        [ 0.0598],\n",
      "        [-0.4101],\n",
      "        [-1.3205],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5678],\n",
      "        [-1.5431],\n",
      "        [ 0.6208],\n",
      "        [-1.4459],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2230],\n",
      "        [ 1.1812]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 388/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0174,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6533],\n",
      "        [ 0.5882],\n",
      "        [-0.0349],\n",
      "        [ 0.4891],\n",
      "        [ 0.9019],\n",
      "        [ 0.9602],\n",
      "        [ 0.9019],\n",
      "        [ 0.8113],\n",
      "        [-1.5814],\n",
      "        [-0.8843],\n",
      "        [ 0.5553],\n",
      "        [-0.2155],\n",
      "        [ 0.9313],\n",
      "        [-0.2155],\n",
      "        [ 0.5553],\n",
      "        [-0.6206],\n",
      "        [-0.3009],\n",
      "        [ 0.8721],\n",
      "        [ 0.7490],\n",
      "        [ 0.7803],\n",
      "        [ 1.2230],\n",
      "        [ 1.2230],\n",
      "        [ 1.0713],\n",
      "        [-0.3009],\n",
      "        [-1.2122],\n",
      "        [ 1.0713],\n",
      "        [-1.4458],\n",
      "        [ 0.9602],\n",
      "        [-1.3204],\n",
      "        [ 0.5553],\n",
      "        [-0.2155],\n",
      "        [ 0.7490],\n",
      "        [ 0.5223],\n",
      "        [ 1.2230],\n",
      "        [ 0.7490],\n",
      "        [-0.7023],\n",
      "        [-0.1268],\n",
      "        [-1.0615],\n",
      "        [-1.1369],\n",
      "        [ 0.9602],\n",
      "        [-0.8843],\n",
      "        [ 0.6208],\n",
      "        [ 1.2230],\n",
      "        [-1.5982],\n",
      "        [ 0.0599],\n",
      "        [-0.4101],\n",
      "        [-1.3204],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5678],\n",
      "        [-1.5431],\n",
      "        [ 0.6208],\n",
      "        [-1.4458],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2230],\n",
      "        [ 1.1813]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 389/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0174,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1747],\n",
      "        [-1.1747],\n",
      "        [ 0.6532],\n",
      "        [ 0.5881],\n",
      "        [-0.0349],\n",
      "        [ 0.4891],\n",
      "        [ 0.9019],\n",
      "        [ 0.9602],\n",
      "        [ 0.9019],\n",
      "        [ 0.8112],\n",
      "        [-1.5814],\n",
      "        [-0.8844],\n",
      "        [ 0.5553],\n",
      "        [-0.2155],\n",
      "        [ 0.9312],\n",
      "        [-0.2155],\n",
      "        [ 0.5553],\n",
      "        [-0.6207],\n",
      "        [-0.3009],\n",
      "        [ 0.8721],\n",
      "        [ 0.7490],\n",
      "        [ 0.7803],\n",
      "        [ 1.2231],\n",
      "        [ 1.2231],\n",
      "        [ 1.0713],\n",
      "        [-0.3009],\n",
      "        [-1.2122],\n",
      "        [ 1.0713],\n",
      "        [-1.4458],\n",
      "        [ 0.9602],\n",
      "        [-1.3203],\n",
      "        [ 0.5553],\n",
      "        [-0.2155],\n",
      "        [ 0.7490],\n",
      "        [ 0.5223],\n",
      "        [ 1.2231],\n",
      "        [ 0.7490],\n",
      "        [-0.7024],\n",
      "        [-0.1268],\n",
      "        [-1.0615],\n",
      "        [-1.1369],\n",
      "        [ 0.9602],\n",
      "        [-0.8844],\n",
      "        [ 0.6208],\n",
      "        [ 1.2231],\n",
      "        [-1.5983],\n",
      "        [ 0.0599],\n",
      "        [-0.4101],\n",
      "        [-1.3203],\n",
      "        [ 1.0167],\n",
      "        [-0.4101],\n",
      "        [-0.5679],\n",
      "        [-1.5431],\n",
      "        [ 0.6208],\n",
      "        [-1.4458],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2231],\n",
      "        [ 1.1813]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 390/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0174,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6532],\n",
      "        [ 0.5881],\n",
      "        [-0.0348],\n",
      "        [ 0.4891],\n",
      "        [ 0.9018],\n",
      "        [ 0.9602],\n",
      "        [ 0.9018],\n",
      "        [ 0.8112],\n",
      "        [-1.5815],\n",
      "        [-0.8845],\n",
      "        [ 0.5553],\n",
      "        [-0.2154],\n",
      "        [ 0.9312],\n",
      "        [-0.2154],\n",
      "        [ 0.5553],\n",
      "        [-0.6207],\n",
      "        [-0.3008],\n",
      "        [ 0.8720],\n",
      "        [ 0.7490],\n",
      "        [ 0.7803],\n",
      "        [ 1.2232],\n",
      "        [ 1.2232],\n",
      "        [ 1.0713],\n",
      "        [-0.3008],\n",
      "        [-1.2121],\n",
      "        [ 1.0713],\n",
      "        [-1.4457],\n",
      "        [ 0.9602],\n",
      "        [-1.3203],\n",
      "        [ 0.5553],\n",
      "        [-0.2154],\n",
      "        [ 0.7490],\n",
      "        [ 0.5223],\n",
      "        [ 1.2232],\n",
      "        [ 0.7490],\n",
      "        [-0.7024],\n",
      "        [-0.1267],\n",
      "        [-1.0616],\n",
      "        [-1.1369],\n",
      "        [ 0.9602],\n",
      "        [-0.8845],\n",
      "        [ 0.6208],\n",
      "        [ 1.2232],\n",
      "        [-1.5983],\n",
      "        [ 0.0599],\n",
      "        [-0.4100],\n",
      "        [-1.3203],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5679],\n",
      "        [-1.5431],\n",
      "        [ 0.6208],\n",
      "        [-1.4457],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2232],\n",
      "        [ 1.1814]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 391/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0173,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6532],\n",
      "        [ 0.5881],\n",
      "        [-0.0348],\n",
      "        [ 0.4891],\n",
      "        [ 0.9018],\n",
      "        [ 0.9601],\n",
      "        [ 0.9018],\n",
      "        [ 0.8112],\n",
      "        [-1.5815],\n",
      "        [-0.8845],\n",
      "        [ 0.5552],\n",
      "        [-0.2154],\n",
      "        [ 0.9312],\n",
      "        [-0.2154],\n",
      "        [ 0.5552],\n",
      "        [-0.6208],\n",
      "        [-0.3008],\n",
      "        [ 0.8720],\n",
      "        [ 0.7489],\n",
      "        [ 0.7802],\n",
      "        [ 1.2232],\n",
      "        [ 1.2232],\n",
      "        [ 1.0713],\n",
      "        [-0.3008],\n",
      "        [-1.2121],\n",
      "        [ 1.0713],\n",
      "        [-1.4457],\n",
      "        [ 0.9601],\n",
      "        [-1.3202],\n",
      "        [ 0.5552],\n",
      "        [-0.2154],\n",
      "        [ 0.7489],\n",
      "        [ 0.5222],\n",
      "        [ 1.2232],\n",
      "        [ 0.7489],\n",
      "        [-0.7025],\n",
      "        [-0.1267],\n",
      "        [-1.0616],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8845],\n",
      "        [ 0.6207],\n",
      "        [ 1.2232],\n",
      "        [-1.5984],\n",
      "        [ 0.0600],\n",
      "        [-0.4100],\n",
      "        [-1.3202],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5679],\n",
      "        [-1.5431],\n",
      "        [ 0.6207],\n",
      "        [-1.4457],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2232],\n",
      "        [ 1.1814]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 392/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0173,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6532],\n",
      "        [ 0.5881],\n",
      "        [-0.0347],\n",
      "        [ 0.4891],\n",
      "        [ 0.9018],\n",
      "        [ 0.9601],\n",
      "        [ 0.9018],\n",
      "        [ 0.8112],\n",
      "        [-1.5816],\n",
      "        [-0.8846],\n",
      "        [ 0.5552],\n",
      "        [-0.2153],\n",
      "        [ 0.9312],\n",
      "        [-0.2153],\n",
      "        [ 0.5552],\n",
      "        [-0.6208],\n",
      "        [-0.3008],\n",
      "        [ 0.8720],\n",
      "        [ 0.7489],\n",
      "        [ 0.7802],\n",
      "        [ 1.2233],\n",
      "        [ 1.2233],\n",
      "        [ 1.0713],\n",
      "        [-0.3008],\n",
      "        [-1.2121],\n",
      "        [ 1.0713],\n",
      "        [-1.4456],\n",
      "        [ 0.9601],\n",
      "        [-1.3202],\n",
      "        [ 0.5552],\n",
      "        [-0.2153],\n",
      "        [ 0.7489],\n",
      "        [ 0.5222],\n",
      "        [ 1.2233],\n",
      "        [ 0.7489],\n",
      "        [-0.7026],\n",
      "        [-0.1266],\n",
      "        [-1.0617],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8846],\n",
      "        [ 0.6207],\n",
      "        [ 1.2233],\n",
      "        [-1.5985],\n",
      "        [ 0.0600],\n",
      "        [-0.4100],\n",
      "        [-1.3202],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5680],\n",
      "        [-1.5431],\n",
      "        [ 0.6207],\n",
      "        [-1.4456],\n",
      "        [ 0.4226],\n",
      "        [-0.4367],\n",
      "        [ 0.4226],\n",
      "        [ 1.2233],\n",
      "        [ 1.1815]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 393/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0173,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6531],\n",
      "        [ 0.5880],\n",
      "        [-0.0347],\n",
      "        [ 0.4891],\n",
      "        [ 0.9018],\n",
      "        [ 0.9601],\n",
      "        [ 0.9018],\n",
      "        [ 0.8111],\n",
      "        [-1.5816],\n",
      "        [-0.8847],\n",
      "        [ 0.5552],\n",
      "        [-0.2153],\n",
      "        [ 0.9312],\n",
      "        [-0.2153],\n",
      "        [ 0.5552],\n",
      "        [-0.6209],\n",
      "        [-0.3007],\n",
      "        [ 0.8719],\n",
      "        [ 0.7489],\n",
      "        [ 0.7802],\n",
      "        [ 1.2234],\n",
      "        [ 1.2234],\n",
      "        [ 1.0713],\n",
      "        [-0.3007],\n",
      "        [-1.2121],\n",
      "        [ 1.0713],\n",
      "        [-1.4456],\n",
      "        [ 0.9601],\n",
      "        [-1.3201],\n",
      "        [ 0.5552],\n",
      "        [-0.2153],\n",
      "        [ 0.7489],\n",
      "        [ 0.5222],\n",
      "        [ 1.2234],\n",
      "        [ 0.7489],\n",
      "        [-0.7027],\n",
      "        [-0.1266],\n",
      "        [-1.0617],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8847],\n",
      "        [ 0.6207],\n",
      "        [ 1.2234],\n",
      "        [-1.5986],\n",
      "        [ 0.0601],\n",
      "        [-0.4100],\n",
      "        [-1.3201],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5680],\n",
      "        [-1.5432],\n",
      "        [ 0.6207],\n",
      "        [-1.4456],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2234],\n",
      "        [ 1.1815]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 394/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0172,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6531],\n",
      "        [ 0.5880],\n",
      "        [-0.0346],\n",
      "        [ 0.4891],\n",
      "        [ 0.9017],\n",
      "        [ 0.9601],\n",
      "        [ 0.9017],\n",
      "        [ 0.8111],\n",
      "        [-1.5817],\n",
      "        [-0.8848],\n",
      "        [ 0.5552],\n",
      "        [-0.2152],\n",
      "        [ 0.9311],\n",
      "        [-0.2152],\n",
      "        [ 0.5552],\n",
      "        [-0.6209],\n",
      "        [-0.3007],\n",
      "        [ 0.8719],\n",
      "        [ 0.7488],\n",
      "        [ 0.7801],\n",
      "        [ 1.2234],\n",
      "        [ 1.2234],\n",
      "        [ 1.0713],\n",
      "        [-0.3007],\n",
      "        [-1.2120],\n",
      "        [ 1.0713],\n",
      "        [-1.4455],\n",
      "        [ 0.9601],\n",
      "        [-1.3201],\n",
      "        [ 0.5552],\n",
      "        [-0.2152],\n",
      "        [ 0.7488],\n",
      "        [ 0.5222],\n",
      "        [ 1.2234],\n",
      "        [ 0.7488],\n",
      "        [-0.7028],\n",
      "        [-0.1265],\n",
      "        [-1.0617],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8848],\n",
      "        [ 0.6207],\n",
      "        [ 1.2234],\n",
      "        [-1.5986],\n",
      "        [ 0.0601],\n",
      "        [-0.4100],\n",
      "        [-1.3201],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5680],\n",
      "        [-1.5432],\n",
      "        [ 0.6207],\n",
      "        [-1.4455],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2234],\n",
      "        [ 1.1816]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 395/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0172,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6531],\n",
      "        [ 0.5880],\n",
      "        [-0.0346],\n",
      "        [ 0.4891],\n",
      "        [ 0.9017],\n",
      "        [ 0.9601],\n",
      "        [ 0.9017],\n",
      "        [ 0.8111],\n",
      "        [-1.5817],\n",
      "        [-0.8849],\n",
      "        [ 0.5552],\n",
      "        [-0.2152],\n",
      "        [ 0.9311],\n",
      "        [-0.2152],\n",
      "        [ 0.5552],\n",
      "        [-0.6210],\n",
      "        [-0.3006],\n",
      "        [ 0.8719],\n",
      "        [ 0.7488],\n",
      "        [ 0.7801],\n",
      "        [ 1.2235],\n",
      "        [ 1.2235],\n",
      "        [ 1.0713],\n",
      "        [-0.3006],\n",
      "        [-1.2120],\n",
      "        [ 1.0713],\n",
      "        [-1.4455],\n",
      "        [ 0.9601],\n",
      "        [-1.3200],\n",
      "        [ 0.5552],\n",
      "        [-0.2152],\n",
      "        [ 0.7488],\n",
      "        [ 0.5222],\n",
      "        [ 1.2235],\n",
      "        [ 0.7488],\n",
      "        [-0.7028],\n",
      "        [-0.1265],\n",
      "        [-1.0618],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8849],\n",
      "        [ 0.6207],\n",
      "        [ 1.2235],\n",
      "        [-1.5987],\n",
      "        [ 0.0602],\n",
      "        [-0.4100],\n",
      "        [-1.3200],\n",
      "        [ 1.0167],\n",
      "        [-0.4100],\n",
      "        [-0.5681],\n",
      "        [-1.5432],\n",
      "        [ 0.6207],\n",
      "        [-1.4455],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2235],\n",
      "        [ 1.1816]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 396/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0172,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6531],\n",
      "        [ 0.5880],\n",
      "        [-0.0345],\n",
      "        [ 0.4890],\n",
      "        [ 0.9017],\n",
      "        [ 0.9601],\n",
      "        [ 0.9017],\n",
      "        [ 0.8110],\n",
      "        [-1.5818],\n",
      "        [-0.8850],\n",
      "        [ 0.5552],\n",
      "        [-0.2151],\n",
      "        [ 0.9311],\n",
      "        [-0.2151],\n",
      "        [ 0.5552],\n",
      "        [-0.6210],\n",
      "        [-0.3006],\n",
      "        [ 0.8719],\n",
      "        [ 0.7488],\n",
      "        [ 0.7801],\n",
      "        [ 1.2236],\n",
      "        [ 1.2236],\n",
      "        [ 1.0714],\n",
      "        [-0.3006],\n",
      "        [-1.2120],\n",
      "        [ 1.0714],\n",
      "        [-1.4455],\n",
      "        [ 0.9601],\n",
      "        [-1.3200],\n",
      "        [ 0.5552],\n",
      "        [-0.2151],\n",
      "        [ 0.7488],\n",
      "        [ 0.5222],\n",
      "        [ 1.2236],\n",
      "        [ 0.7488],\n",
      "        [-0.7029],\n",
      "        [-0.1264],\n",
      "        [-1.0618],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8850],\n",
      "        [ 0.6206],\n",
      "        [ 1.2236],\n",
      "        [-1.5988],\n",
      "        [ 0.0602],\n",
      "        [-0.4099],\n",
      "        [-1.3200],\n",
      "        [ 1.0167],\n",
      "        [-0.4099],\n",
      "        [-0.5681],\n",
      "        [-1.5432],\n",
      "        [ 0.6206],\n",
      "        [-1.4455],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2236],\n",
      "        [ 1.1817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 397/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0171,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6530],\n",
      "        [ 0.5880],\n",
      "        [-0.0345],\n",
      "        [ 0.4890],\n",
      "        [ 0.9017],\n",
      "        [ 0.9601],\n",
      "        [ 0.9017],\n",
      "        [ 0.8110],\n",
      "        [-1.5818],\n",
      "        [-0.8851],\n",
      "        [ 0.5551],\n",
      "        [-0.2151],\n",
      "        [ 0.9311],\n",
      "        [-0.2151],\n",
      "        [ 0.5551],\n",
      "        [-0.6211],\n",
      "        [-0.3006],\n",
      "        [ 0.8718],\n",
      "        [ 0.7487],\n",
      "        [ 0.7801],\n",
      "        [ 1.2236],\n",
      "        [ 1.2236],\n",
      "        [ 1.0714],\n",
      "        [-0.3006],\n",
      "        [-1.2120],\n",
      "        [ 1.0714],\n",
      "        [-1.4454],\n",
      "        [ 0.9601],\n",
      "        [-1.3199],\n",
      "        [ 0.5551],\n",
      "        [-0.2151],\n",
      "        [ 0.7487],\n",
      "        [ 0.5221],\n",
      "        [ 1.2236],\n",
      "        [ 0.7487],\n",
      "        [-0.7030],\n",
      "        [-0.1264],\n",
      "        [-1.0618],\n",
      "        [-1.1369],\n",
      "        [ 0.9601],\n",
      "        [-0.8851],\n",
      "        [ 0.6206],\n",
      "        [ 1.2236],\n",
      "        [-1.5988],\n",
      "        [ 0.0602],\n",
      "        [-0.4099],\n",
      "        [-1.3199],\n",
      "        [ 1.0166],\n",
      "        [-0.4099],\n",
      "        [-0.5681],\n",
      "        [-1.5432],\n",
      "        [ 0.6206],\n",
      "        [-1.4454],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2236],\n",
      "        [ 1.1817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 398/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0171,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1746],\n",
      "        [-1.1746],\n",
      "        [ 0.6530],\n",
      "        [ 0.5879],\n",
      "        [-0.0344],\n",
      "        [ 0.4890],\n",
      "        [ 0.9016],\n",
      "        [ 0.9600],\n",
      "        [ 0.9016],\n",
      "        [ 0.8110],\n",
      "        [-1.5819],\n",
      "        [-0.8852],\n",
      "        [ 0.5551],\n",
      "        [-0.2150],\n",
      "        [ 0.9311],\n",
      "        [-0.2150],\n",
      "        [ 0.5551],\n",
      "        [-0.6212],\n",
      "        [-0.3005],\n",
      "        [ 0.8718],\n",
      "        [ 0.7487],\n",
      "        [ 0.7800],\n",
      "        [ 1.2237],\n",
      "        [ 1.2237],\n",
      "        [ 1.0714],\n",
      "        [-0.3005],\n",
      "        [-1.2119],\n",
      "        [ 1.0714],\n",
      "        [-1.4454],\n",
      "        [ 0.9600],\n",
      "        [-1.3198],\n",
      "        [ 0.5551],\n",
      "        [-0.2150],\n",
      "        [ 0.7487],\n",
      "        [ 0.5221],\n",
      "        [ 1.2237],\n",
      "        [ 0.7487],\n",
      "        [-0.7031],\n",
      "        [-0.1263],\n",
      "        [-1.0619],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8852],\n",
      "        [ 0.6206],\n",
      "        [ 1.2237],\n",
      "        [-1.5989],\n",
      "        [ 0.0603],\n",
      "        [-0.4099],\n",
      "        [-1.3198],\n",
      "        [ 1.0166],\n",
      "        [-0.4099],\n",
      "        [-0.5682],\n",
      "        [-1.5432],\n",
      "        [ 0.6206],\n",
      "        [-1.4454],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2237],\n",
      "        [ 1.1817]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 399/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0171,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6530],\n",
      "        [ 0.5879],\n",
      "        [-0.0344],\n",
      "        [ 0.4890],\n",
      "        [ 0.9016],\n",
      "        [ 0.9600],\n",
      "        [ 0.9016],\n",
      "        [ 0.8110],\n",
      "        [-1.5819],\n",
      "        [-0.8853],\n",
      "        [ 0.5551],\n",
      "        [-0.2150],\n",
      "        [ 0.9310],\n",
      "        [-0.2150],\n",
      "        [ 0.5551],\n",
      "        [-0.6212],\n",
      "        [-0.3005],\n",
      "        [ 0.8718],\n",
      "        [ 0.7487],\n",
      "        [ 0.7800],\n",
      "        [ 1.2238],\n",
      "        [ 1.2238],\n",
      "        [ 1.0714],\n",
      "        [-0.3005],\n",
      "        [-1.2119],\n",
      "        [ 1.0714],\n",
      "        [-1.4453],\n",
      "        [ 0.9600],\n",
      "        [-1.3198],\n",
      "        [ 0.5551],\n",
      "        [-0.2150],\n",
      "        [ 0.7487],\n",
      "        [ 0.5221],\n",
      "        [ 1.2238],\n",
      "        [ 0.7487],\n",
      "        [-0.7032],\n",
      "        [-0.1263],\n",
      "        [-1.0619],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8853],\n",
      "        [ 0.6206],\n",
      "        [ 1.2238],\n",
      "        [-1.5990],\n",
      "        [ 0.0603],\n",
      "        [-0.4099],\n",
      "        [-1.3198],\n",
      "        [ 1.0166],\n",
      "        [-0.4099],\n",
      "        [-0.5682],\n",
      "        [-1.5432],\n",
      "        [ 0.6206],\n",
      "        [-1.4453],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2238],\n",
      "        [ 1.1818]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 400/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0170,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6529],\n",
      "        [ 0.5879],\n",
      "        [-0.0344],\n",
      "        [ 0.4890],\n",
      "        [ 0.9016],\n",
      "        [ 0.9600],\n",
      "        [ 0.9016],\n",
      "        [ 0.8109],\n",
      "        [-1.5820],\n",
      "        [-0.8854],\n",
      "        [ 0.5551],\n",
      "        [-0.2149],\n",
      "        [ 0.9310],\n",
      "        [-0.2149],\n",
      "        [ 0.5551],\n",
      "        [-0.6213],\n",
      "        [-0.3004],\n",
      "        [ 0.8718],\n",
      "        [ 0.7487],\n",
      "        [ 0.7800],\n",
      "        [ 1.2238],\n",
      "        [ 1.2238],\n",
      "        [ 1.0714],\n",
      "        [-0.3004],\n",
      "        [-1.2119],\n",
      "        [ 1.0714],\n",
      "        [-1.4453],\n",
      "        [ 0.9600],\n",
      "        [-1.3197],\n",
      "        [ 0.5551],\n",
      "        [-0.2149],\n",
      "        [ 0.7487],\n",
      "        [ 0.5221],\n",
      "        [ 1.2238],\n",
      "        [ 0.7487],\n",
      "        [-0.7032],\n",
      "        [-0.1262],\n",
      "        [-1.0619],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8854],\n",
      "        [ 0.6205],\n",
      "        [ 1.2238],\n",
      "        [-1.5990],\n",
      "        [ 0.0604],\n",
      "        [-0.4099],\n",
      "        [-1.3197],\n",
      "        [ 1.0166],\n",
      "        [-0.4099],\n",
      "        [-0.5682],\n",
      "        [-1.5432],\n",
      "        [ 0.6205],\n",
      "        [-1.4453],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2238],\n",
      "        [ 1.1818]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 401/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0170,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6529],\n",
      "        [ 0.5879],\n",
      "        [-0.0343],\n",
      "        [ 0.4890],\n",
      "        [ 0.9016],\n",
      "        [ 0.9600],\n",
      "        [ 0.9016],\n",
      "        [ 0.8109],\n",
      "        [-1.5820],\n",
      "        [-0.8854],\n",
      "        [ 0.5551],\n",
      "        [-0.2149],\n",
      "        [ 0.9310],\n",
      "        [-0.2149],\n",
      "        [ 0.5551],\n",
      "        [-0.6213],\n",
      "        [-0.3004],\n",
      "        [ 0.8717],\n",
      "        [ 0.7486],\n",
      "        [ 0.7799],\n",
      "        [ 1.2239],\n",
      "        [ 1.2239],\n",
      "        [ 1.0714],\n",
      "        [-0.3004],\n",
      "        [-1.2119],\n",
      "        [ 1.0714],\n",
      "        [-1.4452],\n",
      "        [ 0.9600],\n",
      "        [-1.3197],\n",
      "        [ 0.5551],\n",
      "        [-0.2149],\n",
      "        [ 0.7486],\n",
      "        [ 0.5221],\n",
      "        [ 1.2239],\n",
      "        [ 0.7486],\n",
      "        [-0.7033],\n",
      "        [-0.1262],\n",
      "        [-1.0620],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8854],\n",
      "        [ 0.6205],\n",
      "        [ 1.2239],\n",
      "        [-1.5991],\n",
      "        [ 0.0604],\n",
      "        [-0.4099],\n",
      "        [-1.3197],\n",
      "        [ 1.0166],\n",
      "        [-0.4099],\n",
      "        [-0.5683],\n",
      "        [-1.5432],\n",
      "        [ 0.6205],\n",
      "        [-1.4452],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2239],\n",
      "        [ 1.1819]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 402/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0170,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6529],\n",
      "        [ 0.5879],\n",
      "        [-0.0343],\n",
      "        [ 0.4890],\n",
      "        [ 0.9016],\n",
      "        [ 0.9600],\n",
      "        [ 0.9016],\n",
      "        [ 0.8109],\n",
      "        [-1.5821],\n",
      "        [-0.8855],\n",
      "        [ 0.5550],\n",
      "        [-0.2149],\n",
      "        [ 0.9310],\n",
      "        [-0.2149],\n",
      "        [ 0.5550],\n",
      "        [-0.6214],\n",
      "        [-0.3004],\n",
      "        [ 0.8717],\n",
      "        [ 0.7486],\n",
      "        [ 0.7799],\n",
      "        [ 1.2239],\n",
      "        [ 1.2239],\n",
      "        [ 1.0714],\n",
      "        [-0.3004],\n",
      "        [-1.2118],\n",
      "        [ 1.0714],\n",
      "        [-1.4452],\n",
      "        [ 0.9600],\n",
      "        [-1.3196],\n",
      "        [ 0.5550],\n",
      "        [-0.2149],\n",
      "        [ 0.7486],\n",
      "        [ 0.5221],\n",
      "        [ 1.2239],\n",
      "        [ 0.7486],\n",
      "        [-0.7034],\n",
      "        [-0.1261],\n",
      "        [-1.0620],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8855],\n",
      "        [ 0.6205],\n",
      "        [ 1.2239],\n",
      "        [-1.5992],\n",
      "        [ 0.0604],\n",
      "        [-0.4098],\n",
      "        [-1.3196],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5683],\n",
      "        [-1.5433],\n",
      "        [ 0.6205],\n",
      "        [-1.4452],\n",
      "        [ 0.4225],\n",
      "        [-0.4366],\n",
      "        [ 0.4225],\n",
      "        [ 1.2239],\n",
      "        [ 1.1819]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 403/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0169,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6529],\n",
      "        [ 0.5878],\n",
      "        [-0.0342],\n",
      "        [ 0.4890],\n",
      "        [ 0.9015],\n",
      "        [ 0.9600],\n",
      "        [ 0.9015],\n",
      "        [ 0.8108],\n",
      "        [-1.5821],\n",
      "        [-0.8856],\n",
      "        [ 0.5550],\n",
      "        [-0.2148],\n",
      "        [ 0.9310],\n",
      "        [-0.2148],\n",
      "        [ 0.5550],\n",
      "        [-0.6214],\n",
      "        [-0.3003],\n",
      "        [ 0.8717],\n",
      "        [ 0.7486],\n",
      "        [ 0.7799],\n",
      "        [ 1.2240],\n",
      "        [ 1.2240],\n",
      "        [ 1.0714],\n",
      "        [-0.3003],\n",
      "        [-1.2118],\n",
      "        [ 1.0714],\n",
      "        [-1.4451],\n",
      "        [ 0.9600],\n",
      "        [-1.3196],\n",
      "        [ 0.5550],\n",
      "        [-0.2148],\n",
      "        [ 0.7486],\n",
      "        [ 0.5221],\n",
      "        [ 1.2240],\n",
      "        [ 0.7486],\n",
      "        [-0.7035],\n",
      "        [-0.1261],\n",
      "        [-1.0621],\n",
      "        [-1.1369],\n",
      "        [ 0.9600],\n",
      "        [-0.8856],\n",
      "        [ 0.6205],\n",
      "        [ 1.2240],\n",
      "        [-1.5993],\n",
      "        [ 0.0605],\n",
      "        [-0.4098],\n",
      "        [-1.3196],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5683],\n",
      "        [-1.5433],\n",
      "        [ 0.6205],\n",
      "        [-1.4451],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2240],\n",
      "        [ 1.1820]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 404/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0169,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6528],\n",
      "        [ 0.5878],\n",
      "        [-0.0342],\n",
      "        [ 0.4890],\n",
      "        [ 0.9015],\n",
      "        [ 0.9599],\n",
      "        [ 0.9015],\n",
      "        [ 0.8108],\n",
      "        [-1.5822],\n",
      "        [-0.8857],\n",
      "        [ 0.5550],\n",
      "        [-0.2148],\n",
      "        [ 0.9309],\n",
      "        [-0.2148],\n",
      "        [ 0.5550],\n",
      "        [-0.6215],\n",
      "        [-0.3003],\n",
      "        [ 0.8717],\n",
      "        [ 0.7485],\n",
      "        [ 0.7798],\n",
      "        [ 1.2241],\n",
      "        [ 1.2241],\n",
      "        [ 1.0714],\n",
      "        [-0.3003],\n",
      "        [-1.2118],\n",
      "        [ 1.0714],\n",
      "        [-1.4451],\n",
      "        [ 0.9599],\n",
      "        [-1.3195],\n",
      "        [ 0.5550],\n",
      "        [-0.2148],\n",
      "        [ 0.7485],\n",
      "        [ 0.5220],\n",
      "        [ 1.2241],\n",
      "        [ 0.7485],\n",
      "        [-0.7035],\n",
      "        [-0.1260],\n",
      "        [-1.0621],\n",
      "        [-1.1369],\n",
      "        [ 0.9599],\n",
      "        [-0.8857],\n",
      "        [ 0.6204],\n",
      "        [ 1.2241],\n",
      "        [-1.5993],\n",
      "        [ 0.0605],\n",
      "        [-0.4098],\n",
      "        [-1.3195],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5684],\n",
      "        [-1.5433],\n",
      "        [ 0.6204],\n",
      "        [-1.4451],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2241],\n",
      "        [ 1.1820]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 405/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0169,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6528],\n",
      "        [ 0.5878],\n",
      "        [-0.0341],\n",
      "        [ 0.4889],\n",
      "        [ 0.9015],\n",
      "        [ 0.9599],\n",
      "        [ 0.9015],\n",
      "        [ 0.8108],\n",
      "        [-1.5822],\n",
      "        [-0.8858],\n",
      "        [ 0.5550],\n",
      "        [-0.2147],\n",
      "        [ 0.9309],\n",
      "        [-0.2147],\n",
      "        [ 0.5550],\n",
      "        [-0.6215],\n",
      "        [-0.3003],\n",
      "        [ 0.8716],\n",
      "        [ 0.7485],\n",
      "        [ 0.7798],\n",
      "        [ 1.2241],\n",
      "        [ 1.2241],\n",
      "        [ 1.0714],\n",
      "        [-0.3003],\n",
      "        [-1.2118],\n",
      "        [ 1.0714],\n",
      "        [-1.4450],\n",
      "        [ 0.9599],\n",
      "        [-1.3195],\n",
      "        [ 0.5550],\n",
      "        [-0.2147],\n",
      "        [ 0.7485],\n",
      "        [ 0.5220],\n",
      "        [ 1.2241],\n",
      "        [ 0.7485],\n",
      "        [-0.7036],\n",
      "        [-0.1260],\n",
      "        [-1.0621],\n",
      "        [-1.1369],\n",
      "        [ 0.9599],\n",
      "        [-0.8858],\n",
      "        [ 0.6204],\n",
      "        [ 1.2241],\n",
      "        [-1.5994],\n",
      "        [ 0.0606],\n",
      "        [-0.4098],\n",
      "        [-1.3195],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5684],\n",
      "        [-1.5433],\n",
      "        [ 0.6204],\n",
      "        [-1.4450],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2241],\n",
      "        [ 1.1821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 406/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0168,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6528],\n",
      "        [ 0.5878],\n",
      "        [-0.0341],\n",
      "        [ 0.4889],\n",
      "        [ 0.9015],\n",
      "        [ 0.9599],\n",
      "        [ 0.9015],\n",
      "        [ 0.8108],\n",
      "        [-1.5823],\n",
      "        [-0.8859],\n",
      "        [ 0.5550],\n",
      "        [-0.2147],\n",
      "        [ 0.9309],\n",
      "        [-0.2147],\n",
      "        [ 0.5550],\n",
      "        [-0.6216],\n",
      "        [-0.3002],\n",
      "        [ 0.8716],\n",
      "        [ 0.7485],\n",
      "        [ 0.7798],\n",
      "        [ 1.2242],\n",
      "        [ 1.2242],\n",
      "        [ 1.0714],\n",
      "        [-0.3002],\n",
      "        [-1.2118],\n",
      "        [ 1.0714],\n",
      "        [-1.4450],\n",
      "        [ 0.9599],\n",
      "        [-1.3194],\n",
      "        [ 0.5550],\n",
      "        [-0.2147],\n",
      "        [ 0.7485],\n",
      "        [ 0.5220],\n",
      "        [ 1.2242],\n",
      "        [ 0.7485],\n",
      "        [-0.7037],\n",
      "        [-0.1259],\n",
      "        [-1.0622],\n",
      "        [-1.1370],\n",
      "        [ 0.9599],\n",
      "        [-0.8859],\n",
      "        [ 0.6204],\n",
      "        [ 1.2242],\n",
      "        [-1.5995],\n",
      "        [ 0.0606],\n",
      "        [-0.4098],\n",
      "        [-1.3194],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5684],\n",
      "        [-1.5433],\n",
      "        [ 0.6204],\n",
      "        [-1.4450],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2242],\n",
      "        [ 1.1821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 407/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0168,\n",
      " epoch_time_duration: 0.0135\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6528],\n",
      "        [ 0.5877],\n",
      "        [-0.0340],\n",
      "        [ 0.4889],\n",
      "        [ 0.9014],\n",
      "        [ 0.9599],\n",
      "        [ 0.9014],\n",
      "        [ 0.8107],\n",
      "        [-1.5823],\n",
      "        [-0.8860],\n",
      "        [ 0.5550],\n",
      "        [-0.2146],\n",
      "        [ 0.9309],\n",
      "        [-0.2146],\n",
      "        [ 0.5550],\n",
      "        [-0.6216],\n",
      "        [-0.3002],\n",
      "        [ 0.8716],\n",
      "        [ 0.7485],\n",
      "        [ 0.7798],\n",
      "        [ 1.2243],\n",
      "        [ 1.2243],\n",
      "        [ 1.0714],\n",
      "        [-0.3002],\n",
      "        [-1.2117],\n",
      "        [ 1.0714],\n",
      "        [-1.4450],\n",
      "        [ 0.9599],\n",
      "        [-1.3194],\n",
      "        [ 0.5550],\n",
      "        [-0.2146],\n",
      "        [ 0.7485],\n",
      "        [ 0.5220],\n",
      "        [ 1.2243],\n",
      "        [ 0.7485],\n",
      "        [-0.7038],\n",
      "        [-0.1259],\n",
      "        [-1.0622],\n",
      "        [-1.1370],\n",
      "        [ 0.9599],\n",
      "        [-0.8860],\n",
      "        [ 0.6204],\n",
      "        [ 1.2243],\n",
      "        [-1.5995],\n",
      "        [ 0.0606],\n",
      "        [-0.4098],\n",
      "        [-1.3194],\n",
      "        [ 1.0166],\n",
      "        [-0.4098],\n",
      "        [-0.5685],\n",
      "        [-1.5433],\n",
      "        [ 0.6204],\n",
      "        [-1.4450],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2243],\n",
      "        [ 1.1821]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 408/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0168,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1745],\n",
      "        [-1.1745],\n",
      "        [ 0.6527],\n",
      "        [ 0.5877],\n",
      "        [-0.0340],\n",
      "        [ 0.4889],\n",
      "        [ 0.9014],\n",
      "        [ 0.9599],\n",
      "        [ 0.9014],\n",
      "        [ 0.8107],\n",
      "        [-1.5824],\n",
      "        [-0.8861],\n",
      "        [ 0.5549],\n",
      "        [-0.2146],\n",
      "        [ 0.9309],\n",
      "        [-0.2146],\n",
      "        [ 0.5549],\n",
      "        [-0.6217],\n",
      "        [-0.3001],\n",
      "        [ 0.8716],\n",
      "        [ 0.7484],\n",
      "        [ 0.7797],\n",
      "        [ 1.2243],\n",
      "        [ 1.2243],\n",
      "        [ 1.0714],\n",
      "        [-0.3001],\n",
      "        [-1.2117],\n",
      "        [ 1.0714],\n",
      "        [-1.4449],\n",
      "        [ 0.9599],\n",
      "        [-1.3193],\n",
      "        [ 0.5549],\n",
      "        [-0.2146],\n",
      "        [ 0.7484],\n",
      "        [ 0.5220],\n",
      "        [ 1.2243],\n",
      "        [ 0.7484],\n",
      "        [-0.7038],\n",
      "        [-0.1258],\n",
      "        [-1.0622],\n",
      "        [-1.1370],\n",
      "        [ 0.9599],\n",
      "        [-0.8861],\n",
      "        [ 0.6203],\n",
      "        [ 1.2243],\n",
      "        [-1.5996],\n",
      "        [ 0.0607],\n",
      "        [-0.4097],\n",
      "        [-1.3193],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5685],\n",
      "        [-1.5433],\n",
      "        [ 0.6203],\n",
      "        [-1.4449],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2243],\n",
      "        [ 1.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 409/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0168,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6527],\n",
      "        [ 0.5877],\n",
      "        [-0.0339],\n",
      "        [ 0.4889],\n",
      "        [ 0.9014],\n",
      "        [ 0.9599],\n",
      "        [ 0.9014],\n",
      "        [ 0.8107],\n",
      "        [-1.5824],\n",
      "        [-0.8862],\n",
      "        [ 0.5549],\n",
      "        [-0.2145],\n",
      "        [ 0.9308],\n",
      "        [-0.2145],\n",
      "        [ 0.5549],\n",
      "        [-0.6217],\n",
      "        [-0.3001],\n",
      "        [ 0.8715],\n",
      "        [ 0.7484],\n",
      "        [ 0.7797],\n",
      "        [ 1.2244],\n",
      "        [ 1.2244],\n",
      "        [ 1.0715],\n",
      "        [-0.3001],\n",
      "        [-1.2117],\n",
      "        [ 1.0715],\n",
      "        [-1.4449],\n",
      "        [ 0.9599],\n",
      "        [-1.3193],\n",
      "        [ 0.5549],\n",
      "        [-0.2145],\n",
      "        [ 0.7484],\n",
      "        [ 0.5220],\n",
      "        [ 1.2244],\n",
      "        [ 0.7484],\n",
      "        [-0.7039],\n",
      "        [-0.1258],\n",
      "        [-1.0623],\n",
      "        [-1.1370],\n",
      "        [ 0.9599],\n",
      "        [-0.8862],\n",
      "        [ 0.6203],\n",
      "        [ 1.2244],\n",
      "        [-1.5997],\n",
      "        [ 0.0607],\n",
      "        [-0.4097],\n",
      "        [-1.3193],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5685],\n",
      "        [-1.5433],\n",
      "        [ 0.6203],\n",
      "        [-1.4449],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2244],\n",
      "        [ 1.1822]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 410/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0167,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6527],\n",
      "        [ 0.5877],\n",
      "        [-0.0339],\n",
      "        [ 0.4889],\n",
      "        [ 0.9014],\n",
      "        [ 0.9599],\n",
      "        [ 0.9014],\n",
      "        [ 0.8106],\n",
      "        [-1.5825],\n",
      "        [-0.8862],\n",
      "        [ 0.5549],\n",
      "        [-0.2145],\n",
      "        [ 0.9308],\n",
      "        [-0.2145],\n",
      "        [ 0.5549],\n",
      "        [-0.6218],\n",
      "        [-0.3001],\n",
      "        [ 0.8715],\n",
      "        [ 0.7484],\n",
      "        [ 0.7797],\n",
      "        [ 1.2244],\n",
      "        [ 1.2244],\n",
      "        [ 1.0715],\n",
      "        [-0.3001],\n",
      "        [-1.2117],\n",
      "        [ 1.0715],\n",
      "        [-1.4448],\n",
      "        [ 0.9599],\n",
      "        [-1.3192],\n",
      "        [ 0.5549],\n",
      "        [-0.2145],\n",
      "        [ 0.7484],\n",
      "        [ 0.5220],\n",
      "        [ 1.2244],\n",
      "        [ 0.7484],\n",
      "        [-0.7040],\n",
      "        [-0.1257],\n",
      "        [-1.0623],\n",
      "        [-1.1370],\n",
      "        [ 0.9599],\n",
      "        [-0.8862],\n",
      "        [ 0.6203],\n",
      "        [ 1.2244],\n",
      "        [-1.5997],\n",
      "        [ 0.0608],\n",
      "        [-0.4097],\n",
      "        [-1.3192],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5686],\n",
      "        [-1.5433],\n",
      "        [ 0.6203],\n",
      "        [-1.4448],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2244],\n",
      "        [ 1.1823]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 411/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0167,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6527],\n",
      "        [ 0.5877],\n",
      "        [-0.0338],\n",
      "        [ 0.4889],\n",
      "        [ 0.9014],\n",
      "        [ 0.9598],\n",
      "        [ 0.9014],\n",
      "        [ 0.8106],\n",
      "        [-1.5825],\n",
      "        [-0.8863],\n",
      "        [ 0.5549],\n",
      "        [-0.2144],\n",
      "        [ 0.9308],\n",
      "        [-0.2144],\n",
      "        [ 0.5549],\n",
      "        [-0.6218],\n",
      "        [-0.3000],\n",
      "        [ 0.8715],\n",
      "        [ 0.7483],\n",
      "        [ 0.7796],\n",
      "        [ 1.2245],\n",
      "        [ 1.2245],\n",
      "        [ 1.0715],\n",
      "        [-0.3000],\n",
      "        [-1.2116],\n",
      "        [ 1.0715],\n",
      "        [-1.4448],\n",
      "        [ 0.9598],\n",
      "        [-1.3192],\n",
      "        [ 0.5549],\n",
      "        [-0.2144],\n",
      "        [ 0.7483],\n",
      "        [ 0.5219],\n",
      "        [ 1.2245],\n",
      "        [ 0.7483],\n",
      "        [-0.7041],\n",
      "        [-0.1257],\n",
      "        [-1.0624],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8863],\n",
      "        [ 0.6203],\n",
      "        [ 1.2245],\n",
      "        [-1.5998],\n",
      "        [ 0.0608],\n",
      "        [-0.4097],\n",
      "        [-1.3192],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5686],\n",
      "        [-1.5433],\n",
      "        [ 0.6203],\n",
      "        [-1.4448],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2245],\n",
      "        [ 1.1823]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 412/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0167,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6526],\n",
      "        [ 0.5876],\n",
      "        [-0.0338],\n",
      "        [ 0.4889],\n",
      "        [ 0.9013],\n",
      "        [ 0.9598],\n",
      "        [ 0.9013],\n",
      "        [ 0.8106],\n",
      "        [-1.5826],\n",
      "        [-0.8864],\n",
      "        [ 0.5549],\n",
      "        [-0.2144],\n",
      "        [ 0.9308],\n",
      "        [-0.2144],\n",
      "        [ 0.5549],\n",
      "        [-0.6219],\n",
      "        [-0.3000],\n",
      "        [ 0.8715],\n",
      "        [ 0.7483],\n",
      "        [ 0.7796],\n",
      "        [ 1.2246],\n",
      "        [ 1.2246],\n",
      "        [ 1.0715],\n",
      "        [-0.3000],\n",
      "        [-1.2116],\n",
      "        [ 1.0715],\n",
      "        [-1.4447],\n",
      "        [ 0.9598],\n",
      "        [-1.3191],\n",
      "        [ 0.5549],\n",
      "        [-0.2144],\n",
      "        [ 0.7483],\n",
      "        [ 0.5219],\n",
      "        [ 1.2246],\n",
      "        [ 0.7483],\n",
      "        [-0.7041],\n",
      "        [-0.1256],\n",
      "        [-1.0624],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8864],\n",
      "        [ 0.6202],\n",
      "        [ 1.2246],\n",
      "        [-1.5999],\n",
      "        [ 0.0608],\n",
      "        [-0.4097],\n",
      "        [-1.3191],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5686],\n",
      "        [-1.5434],\n",
      "        [ 0.6202],\n",
      "        [-1.4447],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2246],\n",
      "        [ 1.1824]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 413/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0166,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6526],\n",
      "        [ 0.5876],\n",
      "        [-0.0337],\n",
      "        [ 0.4888],\n",
      "        [ 0.9013],\n",
      "        [ 0.9598],\n",
      "        [ 0.9013],\n",
      "        [ 0.8106],\n",
      "        [-1.5826],\n",
      "        [-0.8865],\n",
      "        [ 0.5548],\n",
      "        [-0.2143],\n",
      "        [ 0.9308],\n",
      "        [-0.2143],\n",
      "        [ 0.5548],\n",
      "        [-0.6219],\n",
      "        [-0.3000],\n",
      "        [ 0.8714],\n",
      "        [ 0.7483],\n",
      "        [ 0.7796],\n",
      "        [ 1.2246],\n",
      "        [ 1.2246],\n",
      "        [ 1.0715],\n",
      "        [-0.3000],\n",
      "        [-1.2116],\n",
      "        [ 1.0715],\n",
      "        [-1.4447],\n",
      "        [ 0.9598],\n",
      "        [-1.3191],\n",
      "        [ 0.5548],\n",
      "        [-0.2143],\n",
      "        [ 0.7483],\n",
      "        [ 0.5219],\n",
      "        [ 1.2246],\n",
      "        [ 0.7483],\n",
      "        [-0.7042],\n",
      "        [-0.1256],\n",
      "        [-1.0624],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8865],\n",
      "        [ 0.6202],\n",
      "        [ 1.2246],\n",
      "        [-1.5999],\n",
      "        [ 0.0609],\n",
      "        [-0.4097],\n",
      "        [-1.3191],\n",
      "        [ 1.0166],\n",
      "        [-0.4097],\n",
      "        [-0.5687],\n",
      "        [-1.5434],\n",
      "        [ 0.6202],\n",
      "        [-1.4447],\n",
      "        [ 0.4225],\n",
      "        [-0.4365],\n",
      "        [ 0.4225],\n",
      "        [ 1.2246],\n",
      "        [ 1.1824]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 414/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0166,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6526],\n",
      "        [ 0.5876],\n",
      "        [-0.0337],\n",
      "        [ 0.4888],\n",
      "        [ 0.9013],\n",
      "        [ 0.9598],\n",
      "        [ 0.9013],\n",
      "        [ 0.8105],\n",
      "        [-1.5827],\n",
      "        [-0.8866],\n",
      "        [ 0.5548],\n",
      "        [-0.2143],\n",
      "        [ 0.9308],\n",
      "        [-0.2143],\n",
      "        [ 0.5548],\n",
      "        [-0.6220],\n",
      "        [-0.2999],\n",
      "        [ 0.8714],\n",
      "        [ 0.7483],\n",
      "        [ 0.7796],\n",
      "        [ 1.2247],\n",
      "        [ 1.2247],\n",
      "        [ 1.0715],\n",
      "        [-0.2999],\n",
      "        [-1.2116],\n",
      "        [ 1.0715],\n",
      "        [-1.4446],\n",
      "        [ 0.9598],\n",
      "        [-1.3190],\n",
      "        [ 0.5548],\n",
      "        [-0.2143],\n",
      "        [ 0.7483],\n",
      "        [ 0.5219],\n",
      "        [ 1.2247],\n",
      "        [ 0.7483],\n",
      "        [-0.7043],\n",
      "        [-0.1255],\n",
      "        [-1.0625],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8866],\n",
      "        [ 0.6202],\n",
      "        [ 1.2247],\n",
      "        [-1.6000],\n",
      "        [ 0.0609],\n",
      "        [-0.4096],\n",
      "        [-1.3190],\n",
      "        [ 1.0166],\n",
      "        [-0.4096],\n",
      "        [-0.5687],\n",
      "        [-1.5434],\n",
      "        [ 0.6202],\n",
      "        [-1.4446],\n",
      "        [ 0.4225],\n",
      "        [-0.4364],\n",
      "        [ 0.4225],\n",
      "        [ 1.2247],\n",
      "        [ 1.1825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 415/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0166,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6526],\n",
      "        [ 0.5876],\n",
      "        [-0.0336],\n",
      "        [ 0.4888],\n",
      "        [ 0.9013],\n",
      "        [ 0.9598],\n",
      "        [ 0.9013],\n",
      "        [ 0.8105],\n",
      "        [-1.5827],\n",
      "        [-0.8867],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.9307],\n",
      "        [-0.2142],\n",
      "        [ 0.5548],\n",
      "        [-0.6220],\n",
      "        [-0.2999],\n",
      "        [ 0.8714],\n",
      "        [ 0.7482],\n",
      "        [ 0.7795],\n",
      "        [ 1.2248],\n",
      "        [ 1.2248],\n",
      "        [ 1.0715],\n",
      "        [-0.2999],\n",
      "        [-1.2115],\n",
      "        [ 1.0715],\n",
      "        [-1.4446],\n",
      "        [ 0.9598],\n",
      "        [-1.3190],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.7482],\n",
      "        [ 0.5219],\n",
      "        [ 1.2248],\n",
      "        [ 0.7482],\n",
      "        [-0.7044],\n",
      "        [-0.1255],\n",
      "        [-1.0625],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8867],\n",
      "        [ 0.6202],\n",
      "        [ 1.2248],\n",
      "        [-1.6001],\n",
      "        [ 0.0610],\n",
      "        [-0.4096],\n",
      "        [-1.3190],\n",
      "        [ 1.0166],\n",
      "        [-0.4096],\n",
      "        [-0.5687],\n",
      "        [-1.5434],\n",
      "        [ 0.6202],\n",
      "        [-1.4446],\n",
      "        [ 0.4225],\n",
      "        [-0.4364],\n",
      "        [ 0.4225],\n",
      "        [ 1.2248],\n",
      "        [ 1.1825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 416/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0165,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6525],\n",
      "        [ 0.5876],\n",
      "        [-0.0336],\n",
      "        [ 0.4888],\n",
      "        [ 0.9012],\n",
      "        [ 0.9598],\n",
      "        [ 0.9012],\n",
      "        [ 0.8105],\n",
      "        [-1.5827],\n",
      "        [-0.8868],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.9307],\n",
      "        [-0.2142],\n",
      "        [ 0.5548],\n",
      "        [-0.6221],\n",
      "        [-0.2998],\n",
      "        [ 0.8714],\n",
      "        [ 0.7482],\n",
      "        [ 0.7795],\n",
      "        [ 1.2248],\n",
      "        [ 1.2248],\n",
      "        [ 1.0715],\n",
      "        [-0.2998],\n",
      "        [-1.2115],\n",
      "        [ 1.0715],\n",
      "        [-1.4446],\n",
      "        [ 0.9598],\n",
      "        [-1.3189],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.7482],\n",
      "        [ 0.5219],\n",
      "        [ 1.2248],\n",
      "        [ 0.7482],\n",
      "        [-0.7044],\n",
      "        [-0.1254],\n",
      "        [-1.0625],\n",
      "        [-1.1370],\n",
      "        [ 0.9598],\n",
      "        [-0.8868],\n",
      "        [ 0.6202],\n",
      "        [ 1.2248],\n",
      "        [-1.6001],\n",
      "        [ 0.0610],\n",
      "        [-0.4096],\n",
      "        [-1.3189],\n",
      "        [ 1.0165],\n",
      "        [-0.4096],\n",
      "        [-0.5688],\n",
      "        [-1.5434],\n",
      "        [ 0.6202],\n",
      "        [-1.4446],\n",
      "        [ 0.4225],\n",
      "        [-0.4364],\n",
      "        [ 0.4225],\n",
      "        [ 1.2248],\n",
      "        [ 1.1825]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 417/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0165,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6525],\n",
      "        [ 0.5875],\n",
      "        [-0.0336],\n",
      "        [ 0.4888],\n",
      "        [ 0.9012],\n",
      "        [ 0.9597],\n",
      "        [ 0.9012],\n",
      "        [ 0.8105],\n",
      "        [-1.5828],\n",
      "        [-0.8868],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.9307],\n",
      "        [-0.2142],\n",
      "        [ 0.5548],\n",
      "        [-0.6221],\n",
      "        [-0.2998],\n",
      "        [ 0.8713],\n",
      "        [ 0.7482],\n",
      "        [ 0.7795],\n",
      "        [ 1.2249],\n",
      "        [ 1.2249],\n",
      "        [ 1.0715],\n",
      "        [-0.2998],\n",
      "        [-1.2115],\n",
      "        [ 1.0715],\n",
      "        [-1.4445],\n",
      "        [ 0.9597],\n",
      "        [-1.3189],\n",
      "        [ 0.5548],\n",
      "        [-0.2142],\n",
      "        [ 0.7482],\n",
      "        [ 0.5218],\n",
      "        [ 1.2249],\n",
      "        [ 0.7482],\n",
      "        [-0.7045],\n",
      "        [-0.1254],\n",
      "        [-1.0626],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8868],\n",
      "        [ 0.6201],\n",
      "        [ 1.2249],\n",
      "        [-1.6002],\n",
      "        [ 0.0610],\n",
      "        [-0.4096],\n",
      "        [-1.3189],\n",
      "        [ 1.0165],\n",
      "        [-0.4096],\n",
      "        [-0.5688],\n",
      "        [-1.5434],\n",
      "        [ 0.6201],\n",
      "        [-1.4445],\n",
      "        [ 0.4225],\n",
      "        [-0.4364],\n",
      "        [ 0.4225],\n",
      "        [ 1.2249],\n",
      "        [ 1.1826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 418/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0165,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6525],\n",
      "        [ 0.5875],\n",
      "        [-0.0335],\n",
      "        [ 0.4888],\n",
      "        [ 0.9012],\n",
      "        [ 0.9597],\n",
      "        [ 0.9012],\n",
      "        [ 0.8104],\n",
      "        [-1.5828],\n",
      "        [-0.8869],\n",
      "        [ 0.5547],\n",
      "        [-0.2141],\n",
      "        [ 0.9307],\n",
      "        [-0.2141],\n",
      "        [ 0.5547],\n",
      "        [-0.6222],\n",
      "        [-0.2998],\n",
      "        [ 0.8713],\n",
      "        [ 0.7481],\n",
      "        [ 0.7794],\n",
      "        [ 1.2249],\n",
      "        [ 1.2249],\n",
      "        [ 1.0715],\n",
      "        [-0.2998],\n",
      "        [-1.2115],\n",
      "        [ 1.0715],\n",
      "        [-1.4445],\n",
      "        [ 0.9597],\n",
      "        [-1.3188],\n",
      "        [ 0.5547],\n",
      "        [-0.2141],\n",
      "        [ 0.7481],\n",
      "        [ 0.5218],\n",
      "        [ 1.2249],\n",
      "        [ 0.7481],\n",
      "        [-0.7046],\n",
      "        [-0.1253],\n",
      "        [-1.0626],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8869],\n",
      "        [ 0.6201],\n",
      "        [ 1.2249],\n",
      "        [-1.6003],\n",
      "        [ 0.0611],\n",
      "        [-0.4096],\n",
      "        [-1.3188],\n",
      "        [ 1.0165],\n",
      "        [-0.4096],\n",
      "        [-0.5688],\n",
      "        [-1.5434],\n",
      "        [ 0.6201],\n",
      "        [-1.4445],\n",
      "        [ 0.4225],\n",
      "        [-0.4364],\n",
      "        [ 0.4225],\n",
      "        [ 1.2249],\n",
      "        [ 1.1826]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 419/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0164,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6525],\n",
      "        [ 0.5875],\n",
      "        [-0.0335],\n",
      "        [ 0.4888],\n",
      "        [ 0.9012],\n",
      "        [ 0.9597],\n",
      "        [ 0.9012],\n",
      "        [ 0.8104],\n",
      "        [-1.5829],\n",
      "        [-0.8870],\n",
      "        [ 0.5547],\n",
      "        [-0.2141],\n",
      "        [ 0.9307],\n",
      "        [-0.2141],\n",
      "        [ 0.5547],\n",
      "        [-0.6222],\n",
      "        [-0.2997],\n",
      "        [ 0.8713],\n",
      "        [ 0.7481],\n",
      "        [ 0.7794],\n",
      "        [ 1.2250],\n",
      "        [ 1.2250],\n",
      "        [ 1.0715],\n",
      "        [-0.2997],\n",
      "        [-1.2115],\n",
      "        [ 1.0715],\n",
      "        [-1.4444],\n",
      "        [ 0.9597],\n",
      "        [-1.3188],\n",
      "        [ 0.5547],\n",
      "        [-0.2141],\n",
      "        [ 0.7481],\n",
      "        [ 0.5218],\n",
      "        [ 1.2250],\n",
      "        [ 0.7481],\n",
      "        [-0.7046],\n",
      "        [-0.1253],\n",
      "        [-1.0626],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8870],\n",
      "        [ 0.6201],\n",
      "        [ 1.2250],\n",
      "        [-1.6003],\n",
      "        [ 0.0611],\n",
      "        [-0.4096],\n",
      "        [-1.3188],\n",
      "        [ 1.0165],\n",
      "        [-0.4096],\n",
      "        [-0.5689],\n",
      "        [-1.5434],\n",
      "        [ 0.6201],\n",
      "        [-1.4444],\n",
      "        [ 0.4224],\n",
      "        [-0.4364],\n",
      "        [ 0.4224],\n",
      "        [ 1.2250],\n",
      "        [ 1.1827]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 420/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0164,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6524],\n",
      "        [ 0.5875],\n",
      "        [-0.0334],\n",
      "        [ 0.4888],\n",
      "        [ 0.9012],\n",
      "        [ 0.9597],\n",
      "        [ 0.9012],\n",
      "        [ 0.8104],\n",
      "        [-1.5829],\n",
      "        [-0.8871],\n",
      "        [ 0.5547],\n",
      "        [-0.2140],\n",
      "        [ 0.9306],\n",
      "        [-0.2140],\n",
      "        [ 0.5547],\n",
      "        [-0.6223],\n",
      "        [-0.2997],\n",
      "        [ 0.8713],\n",
      "        [ 0.7481],\n",
      "        [ 0.7794],\n",
      "        [ 1.2251],\n",
      "        [ 1.2251],\n",
      "        [ 1.0715],\n",
      "        [-0.2997],\n",
      "        [-1.2114],\n",
      "        [ 1.0715],\n",
      "        [-1.4444],\n",
      "        [ 0.9597],\n",
      "        [-1.3187],\n",
      "        [ 0.5547],\n",
      "        [-0.2140],\n",
      "        [ 0.7481],\n",
      "        [ 0.5218],\n",
      "        [ 1.2251],\n",
      "        [ 0.7481],\n",
      "        [-0.7047],\n",
      "        [-0.1252],\n",
      "        [-1.0627],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8871],\n",
      "        [ 0.6201],\n",
      "        [ 1.2251],\n",
      "        [-1.6004],\n",
      "        [ 0.0612],\n",
      "        [-0.4096],\n",
      "        [-1.3187],\n",
      "        [ 1.0165],\n",
      "        [-0.4096],\n",
      "        [-0.5689],\n",
      "        [-1.5434],\n",
      "        [ 0.6201],\n",
      "        [-1.4444],\n",
      "        [ 0.4224],\n",
      "        [-0.4364],\n",
      "        [ 0.4224],\n",
      "        [ 1.2251],\n",
      "        [ 1.1827]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 421/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0164,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6524],\n",
      "        [ 0.5875],\n",
      "        [-0.0334],\n",
      "        [ 0.4888],\n",
      "        [ 0.9011],\n",
      "        [ 0.9597],\n",
      "        [ 0.9011],\n",
      "        [ 0.8103],\n",
      "        [-1.5830],\n",
      "        [-0.8872],\n",
      "        [ 0.5547],\n",
      "        [-0.2140],\n",
      "        [ 0.9306],\n",
      "        [-0.2140],\n",
      "        [ 0.5547],\n",
      "        [-0.6223],\n",
      "        [-0.2997],\n",
      "        [ 0.8712],\n",
      "        [ 0.7481],\n",
      "        [ 0.7794],\n",
      "        [ 1.2251],\n",
      "        [ 1.2251],\n",
      "        [ 1.0715],\n",
      "        [-0.2997],\n",
      "        [-1.2114],\n",
      "        [ 1.0715],\n",
      "        [-1.4443],\n",
      "        [ 0.9597],\n",
      "        [-1.3187],\n",
      "        [ 0.5547],\n",
      "        [-0.2140],\n",
      "        [ 0.7481],\n",
      "        [ 0.5218],\n",
      "        [ 1.2251],\n",
      "        [ 0.7481],\n",
      "        [-0.7048],\n",
      "        [-0.1252],\n",
      "        [-1.0627],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8872],\n",
      "        [ 0.6200],\n",
      "        [ 1.2251],\n",
      "        [-1.6005],\n",
      "        [ 0.0612],\n",
      "        [-0.4095],\n",
      "        [-1.3187],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5689],\n",
      "        [-1.5434],\n",
      "        [ 0.6200],\n",
      "        [-1.4443],\n",
      "        [ 0.4224],\n",
      "        [-0.4364],\n",
      "        [ 0.4224],\n",
      "        [ 1.2251],\n",
      "        [ 1.1828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 422/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0163,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6524],\n",
      "        [ 0.5874],\n",
      "        [-0.0333],\n",
      "        [ 0.4887],\n",
      "        [ 0.9011],\n",
      "        [ 0.9597],\n",
      "        [ 0.9011],\n",
      "        [ 0.8103],\n",
      "        [-1.5830],\n",
      "        [-0.8873],\n",
      "        [ 0.5547],\n",
      "        [-0.2139],\n",
      "        [ 0.9306],\n",
      "        [-0.2139],\n",
      "        [ 0.5547],\n",
      "        [-0.6224],\n",
      "        [-0.2996],\n",
      "        [ 0.8712],\n",
      "        [ 0.7480],\n",
      "        [ 0.7793],\n",
      "        [ 1.2252],\n",
      "        [ 1.2252],\n",
      "        [ 1.0715],\n",
      "        [-0.2996],\n",
      "        [-1.2114],\n",
      "        [ 1.0715],\n",
      "        [-1.4443],\n",
      "        [ 0.9597],\n",
      "        [-1.3186],\n",
      "        [ 0.5547],\n",
      "        [-0.2139],\n",
      "        [ 0.7480],\n",
      "        [ 0.5218],\n",
      "        [ 1.2252],\n",
      "        [ 0.7480],\n",
      "        [-0.7049],\n",
      "        [-0.1251],\n",
      "        [-1.0627],\n",
      "        [-1.1370],\n",
      "        [ 0.9597],\n",
      "        [-0.8873],\n",
      "        [ 0.6200],\n",
      "        [ 1.2252],\n",
      "        [-1.6005],\n",
      "        [ 0.0612],\n",
      "        [-0.4095],\n",
      "        [-1.3186],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5690],\n",
      "        [-1.5435],\n",
      "        [ 0.6200],\n",
      "        [-1.4443],\n",
      "        [ 0.4224],\n",
      "        [-0.4364],\n",
      "        [ 0.4224],\n",
      "        [ 1.2252],\n",
      "        [ 1.1828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 423/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0163,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6524],\n",
      "        [ 0.5874],\n",
      "        [-0.0333],\n",
      "        [ 0.4887],\n",
      "        [ 0.9011],\n",
      "        [ 0.9597],\n",
      "        [ 0.9011],\n",
      "        [ 0.8103],\n",
      "        [-1.5831],\n",
      "        [-0.8873],\n",
      "        [ 0.5547],\n",
      "        [-0.2139],\n",
      "        [ 0.9306],\n",
      "        [-0.2139],\n",
      "        [ 0.5547],\n",
      "        [-0.6224],\n",
      "        [-0.2996],\n",
      "        [ 0.8712],\n",
      "        [ 0.7480],\n",
      "        [ 0.7793],\n",
      "        [ 1.2252],\n",
      "        [ 1.2252],\n",
      "        [ 1.0716],\n",
      "        [-0.2996],\n",
      "        [-1.2114],\n",
      "        [ 1.0716],\n",
      "        [-1.4442],\n",
      "        [ 0.9597],\n",
      "        [-1.3186],\n",
      "        [ 0.5547],\n",
      "        [-0.2139],\n",
      "        [ 0.7480],\n",
      "        [ 0.5218],\n",
      "        [ 1.2252],\n",
      "        [ 0.7480],\n",
      "        [-0.7049],\n",
      "        [-0.1251],\n",
      "        [-1.0628],\n",
      "        [-1.1371],\n",
      "        [ 0.9597],\n",
      "        [-0.8873],\n",
      "        [ 0.6200],\n",
      "        [ 1.2252],\n",
      "        [-1.6006],\n",
      "        [ 0.0613],\n",
      "        [-0.4095],\n",
      "        [-1.3186],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5690],\n",
      "        [-1.5435],\n",
      "        [ 0.6200],\n",
      "        [-1.4442],\n",
      "        [ 0.4224],\n",
      "        [-0.4364],\n",
      "        [ 0.4224],\n",
      "        [ 1.2252],\n",
      "        [ 1.1828]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 424/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0163,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6523],\n",
      "        [ 0.5874],\n",
      "        [-0.0332],\n",
      "        [ 0.4887],\n",
      "        [ 0.9011],\n",
      "        [ 0.9596],\n",
      "        [ 0.9011],\n",
      "        [ 0.8103],\n",
      "        [-1.5831],\n",
      "        [-0.8874],\n",
      "        [ 0.5546],\n",
      "        [-0.2138],\n",
      "        [ 0.9306],\n",
      "        [-0.2138],\n",
      "        [ 0.5546],\n",
      "        [-0.6225],\n",
      "        [-0.2995],\n",
      "        [ 0.8712],\n",
      "        [ 0.7480],\n",
      "        [ 0.7793],\n",
      "        [ 1.2253],\n",
      "        [ 1.2253],\n",
      "        [ 1.0716],\n",
      "        [-0.2995],\n",
      "        [-1.2113],\n",
      "        [ 1.0716],\n",
      "        [-1.4442],\n",
      "        [ 0.9596],\n",
      "        [-1.3185],\n",
      "        [ 0.5546],\n",
      "        [-0.2138],\n",
      "        [ 0.7480],\n",
      "        [ 0.5217],\n",
      "        [ 1.2253],\n",
      "        [ 0.7480],\n",
      "        [-0.7050],\n",
      "        [-0.1250],\n",
      "        [-1.0628],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8874],\n",
      "        [ 0.6200],\n",
      "        [ 1.2253],\n",
      "        [-1.6007],\n",
      "        [ 0.0613],\n",
      "        [-0.4095],\n",
      "        [-1.3185],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5690],\n",
      "        [-1.5435],\n",
      "        [ 0.6200],\n",
      "        [-1.4442],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2253],\n",
      "        [ 1.1829]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 425/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0163,\n",
      " epoch_time_duration: 0.0156\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6523],\n",
      "        [ 0.5874],\n",
      "        [-0.0332],\n",
      "        [ 0.4887],\n",
      "        [ 0.9010],\n",
      "        [ 0.9596],\n",
      "        [ 0.9010],\n",
      "        [ 0.8102],\n",
      "        [-1.5832],\n",
      "        [-0.8875],\n",
      "        [ 0.5546],\n",
      "        [-0.2138],\n",
      "        [ 0.9305],\n",
      "        [-0.2138],\n",
      "        [ 0.5546],\n",
      "        [-0.6225],\n",
      "        [-0.2995],\n",
      "        [ 0.8712],\n",
      "        [ 0.7479],\n",
      "        [ 0.7793],\n",
      "        [ 1.2254],\n",
      "        [ 1.2254],\n",
      "        [ 1.0716],\n",
      "        [-0.2995],\n",
      "        [-1.2113],\n",
      "        [ 1.0716],\n",
      "        [-1.4442],\n",
      "        [ 0.9596],\n",
      "        [-1.3185],\n",
      "        [ 0.5546],\n",
      "        [-0.2138],\n",
      "        [ 0.7479],\n",
      "        [ 0.5217],\n",
      "        [ 1.2254],\n",
      "        [ 0.7479],\n",
      "        [-0.7051],\n",
      "        [-0.1250],\n",
      "        [-1.0629],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8875],\n",
      "        [ 0.6199],\n",
      "        [ 1.2254],\n",
      "        [-1.6007],\n",
      "        [ 0.0614],\n",
      "        [-0.4095],\n",
      "        [-1.3185],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5690],\n",
      "        [-1.5435],\n",
      "        [ 0.6199],\n",
      "        [-1.4442],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2254],\n",
      "        [ 1.1829]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 426/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0162,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6523],\n",
      "        [ 0.5874],\n",
      "        [-0.0331],\n",
      "        [ 0.4887],\n",
      "        [ 0.9010],\n",
      "        [ 0.9596],\n",
      "        [ 0.9010],\n",
      "        [ 0.8102],\n",
      "        [-1.5832],\n",
      "        [-0.8876],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.9305],\n",
      "        [-0.2137],\n",
      "        [ 0.5546],\n",
      "        [-0.6226],\n",
      "        [-0.2995],\n",
      "        [ 0.8711],\n",
      "        [ 0.7479],\n",
      "        [ 0.7792],\n",
      "        [ 1.2254],\n",
      "        [ 1.2254],\n",
      "        [ 1.0716],\n",
      "        [-0.2995],\n",
      "        [-1.2113],\n",
      "        [ 1.0716],\n",
      "        [-1.4441],\n",
      "        [ 0.9596],\n",
      "        [-1.3184],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.7479],\n",
      "        [ 0.5217],\n",
      "        [ 1.2254],\n",
      "        [ 0.7479],\n",
      "        [-0.7051],\n",
      "        [-0.1250],\n",
      "        [-1.0629],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8876],\n",
      "        [ 0.6199],\n",
      "        [ 1.2254],\n",
      "        [-1.6008],\n",
      "        [ 0.0614],\n",
      "        [-0.4095],\n",
      "        [-1.3184],\n",
      "        [ 1.0165],\n",
      "        [-0.4095],\n",
      "        [-0.5691],\n",
      "        [-1.5435],\n",
      "        [ 0.6199],\n",
      "        [-1.4441],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2254],\n",
      "        [ 1.1830]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 427/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0162,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6523],\n",
      "        [ 0.5873],\n",
      "        [-0.0331],\n",
      "        [ 0.4887],\n",
      "        [ 0.9010],\n",
      "        [ 0.9596],\n",
      "        [ 0.9010],\n",
      "        [ 0.8102],\n",
      "        [-1.5833],\n",
      "        [-0.8877],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.9305],\n",
      "        [-0.2137],\n",
      "        [ 0.5546],\n",
      "        [-0.6226],\n",
      "        [-0.2994],\n",
      "        [ 0.8711],\n",
      "        [ 0.7479],\n",
      "        [ 0.7792],\n",
      "        [ 1.2255],\n",
      "        [ 1.2255],\n",
      "        [ 1.0716],\n",
      "        [-0.2994],\n",
      "        [-1.2113],\n",
      "        [ 1.0716],\n",
      "        [-1.4441],\n",
      "        [ 0.9596],\n",
      "        [-1.3184],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.7479],\n",
      "        [ 0.5217],\n",
      "        [ 1.2255],\n",
      "        [ 0.7479],\n",
      "        [-0.7052],\n",
      "        [-0.1249],\n",
      "        [-1.0629],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8877],\n",
      "        [ 0.6199],\n",
      "        [ 1.2255],\n",
      "        [-1.6009],\n",
      "        [ 0.0614],\n",
      "        [-0.4094],\n",
      "        [-1.3184],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5691],\n",
      "        [-1.5435],\n",
      "        [ 0.6199],\n",
      "        [-1.4441],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2255],\n",
      "        [ 1.1830]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 428/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0162,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6522],\n",
      "        [ 0.5873],\n",
      "        [-0.0331],\n",
      "        [ 0.4887],\n",
      "        [ 0.9010],\n",
      "        [ 0.9596],\n",
      "        [ 0.9010],\n",
      "        [ 0.8102],\n",
      "        [-1.5833],\n",
      "        [-0.8878],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.9305],\n",
      "        [-0.2137],\n",
      "        [ 0.5546],\n",
      "        [-0.6226],\n",
      "        [-0.2994],\n",
      "        [ 0.8711],\n",
      "        [ 0.7479],\n",
      "        [ 0.7792],\n",
      "        [ 1.2255],\n",
      "        [ 1.2255],\n",
      "        [ 1.0716],\n",
      "        [-0.2994],\n",
      "        [-1.2113],\n",
      "        [ 1.0716],\n",
      "        [-1.4440],\n",
      "        [ 0.9596],\n",
      "        [-1.3183],\n",
      "        [ 0.5546],\n",
      "        [-0.2137],\n",
      "        [ 0.7479],\n",
      "        [ 0.5217],\n",
      "        [ 1.2255],\n",
      "        [ 0.7479],\n",
      "        [-0.7053],\n",
      "        [-0.1249],\n",
      "        [-1.0630],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8878],\n",
      "        [ 0.6199],\n",
      "        [ 1.2255],\n",
      "        [-1.6009],\n",
      "        [ 0.0615],\n",
      "        [-0.4094],\n",
      "        [-1.3183],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5691],\n",
      "        [-1.5435],\n",
      "        [ 0.6199],\n",
      "        [-1.4440],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2255],\n",
      "        [ 1.1830]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 429/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0161,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6522],\n",
      "        [ 0.5873],\n",
      "        [-0.0330],\n",
      "        [ 0.4887],\n",
      "        [ 0.9010],\n",
      "        [ 0.9596],\n",
      "        [ 0.9010],\n",
      "        [ 0.8101],\n",
      "        [-1.5833],\n",
      "        [-0.8878],\n",
      "        [ 0.5546],\n",
      "        [-0.2136],\n",
      "        [ 0.9305],\n",
      "        [-0.2136],\n",
      "        [ 0.5546],\n",
      "        [-0.6227],\n",
      "        [-0.2994],\n",
      "        [ 0.8711],\n",
      "        [ 0.7478],\n",
      "        [ 0.7791],\n",
      "        [ 1.2256],\n",
      "        [ 1.2256],\n",
      "        [ 1.0716],\n",
      "        [-0.2994],\n",
      "        [-1.2112],\n",
      "        [ 1.0716],\n",
      "        [-1.4440],\n",
      "        [ 0.9596],\n",
      "        [-1.3183],\n",
      "        [ 0.5546],\n",
      "        [-0.2136],\n",
      "        [ 0.7478],\n",
      "        [ 0.5217],\n",
      "        [ 1.2256],\n",
      "        [ 0.7478],\n",
      "        [-0.7054],\n",
      "        [-0.1248],\n",
      "        [-1.0630],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8878],\n",
      "        [ 0.6199],\n",
      "        [ 1.2256],\n",
      "        [-1.6010],\n",
      "        [ 0.0615],\n",
      "        [-0.4094],\n",
      "        [-1.3183],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5692],\n",
      "        [-1.5435],\n",
      "        [ 0.6199],\n",
      "        [-1.4440],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2256],\n",
      "        [ 1.1831]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 430/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0161,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6522],\n",
      "        [ 0.5873],\n",
      "        [-0.0330],\n",
      "        [ 0.4887],\n",
      "        [ 0.9009],\n",
      "        [ 0.9596],\n",
      "        [ 0.9009],\n",
      "        [ 0.8101],\n",
      "        [-1.5834],\n",
      "        [-0.8879],\n",
      "        [ 0.5545],\n",
      "        [-0.2136],\n",
      "        [ 0.9305],\n",
      "        [-0.2136],\n",
      "        [ 0.5545],\n",
      "        [-0.6227],\n",
      "        [-0.2993],\n",
      "        [ 0.8710],\n",
      "        [ 0.7478],\n",
      "        [ 0.7791],\n",
      "        [ 1.2256],\n",
      "        [ 1.2256],\n",
      "        [ 1.0716],\n",
      "        [-0.2993],\n",
      "        [-1.2112],\n",
      "        [ 1.0716],\n",
      "        [-1.4439],\n",
      "        [ 0.9596],\n",
      "        [-1.3182],\n",
      "        [ 0.5545],\n",
      "        [-0.2136],\n",
      "        [ 0.7478],\n",
      "        [ 0.5217],\n",
      "        [ 1.2256],\n",
      "        [ 0.7478],\n",
      "        [-0.7054],\n",
      "        [-0.1248],\n",
      "        [-1.0630],\n",
      "        [-1.1371],\n",
      "        [ 0.9596],\n",
      "        [-0.8879],\n",
      "        [ 0.6198],\n",
      "        [ 1.2256],\n",
      "        [-1.6011],\n",
      "        [ 0.0615],\n",
      "        [-0.4094],\n",
      "        [-1.3182],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5692],\n",
      "        [-1.5435],\n",
      "        [ 0.6198],\n",
      "        [-1.4439],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2256],\n",
      "        [ 1.1831]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 431/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0161,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6522],\n",
      "        [ 0.5873],\n",
      "        [-0.0329],\n",
      "        [ 0.4886],\n",
      "        [ 0.9009],\n",
      "        [ 0.9595],\n",
      "        [ 0.9009],\n",
      "        [ 0.8101],\n",
      "        [-1.5834],\n",
      "        [-0.8880],\n",
      "        [ 0.5545],\n",
      "        [-0.2135],\n",
      "        [ 0.9304],\n",
      "        [-0.2135],\n",
      "        [ 0.5545],\n",
      "        [-0.6228],\n",
      "        [-0.2993],\n",
      "        [ 0.8710],\n",
      "        [ 0.7478],\n",
      "        [ 0.7791],\n",
      "        [ 1.2257],\n",
      "        [ 1.2257],\n",
      "        [ 1.0716],\n",
      "        [-0.2993],\n",
      "        [-1.2112],\n",
      "        [ 1.0716],\n",
      "        [-1.4439],\n",
      "        [ 0.9595],\n",
      "        [-1.3182],\n",
      "        [ 0.5545],\n",
      "        [-0.2135],\n",
      "        [ 0.7478],\n",
      "        [ 0.5216],\n",
      "        [ 1.2257],\n",
      "        [ 0.7478],\n",
      "        [-0.7055],\n",
      "        [-0.1247],\n",
      "        [-1.0631],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8880],\n",
      "        [ 0.6198],\n",
      "        [ 1.2257],\n",
      "        [-1.6011],\n",
      "        [ 0.0616],\n",
      "        [-0.4094],\n",
      "        [-1.3182],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5692],\n",
      "        [-1.5435],\n",
      "        [ 0.6198],\n",
      "        [-1.4439],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2257],\n",
      "        [ 1.1832]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 432/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0160,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6521],\n",
      "        [ 0.5872],\n",
      "        [-0.0329],\n",
      "        [ 0.4886],\n",
      "        [ 0.9009],\n",
      "        [ 0.9595],\n",
      "        [ 0.9009],\n",
      "        [ 0.8100],\n",
      "        [-1.5835],\n",
      "        [-0.8881],\n",
      "        [ 0.5545],\n",
      "        [-0.2135],\n",
      "        [ 0.9304],\n",
      "        [-0.2135],\n",
      "        [ 0.5545],\n",
      "        [-0.6228],\n",
      "        [-0.2993],\n",
      "        [ 0.8710],\n",
      "        [ 0.7478],\n",
      "        [ 0.7791],\n",
      "        [ 1.2258],\n",
      "        [ 1.2258],\n",
      "        [ 1.0716],\n",
      "        [-0.2993],\n",
      "        [-1.2112],\n",
      "        [ 1.0716],\n",
      "        [-1.4439],\n",
      "        [ 0.9595],\n",
      "        [-1.3181],\n",
      "        [ 0.5545],\n",
      "        [-0.2135],\n",
      "        [ 0.7478],\n",
      "        [ 0.5216],\n",
      "        [ 1.2258],\n",
      "        [ 0.7478],\n",
      "        [-0.7056],\n",
      "        [-0.1247],\n",
      "        [-1.0631],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8881],\n",
      "        [ 0.6198],\n",
      "        [ 1.2258],\n",
      "        [-1.6012],\n",
      "        [ 0.0616],\n",
      "        [-0.4094],\n",
      "        [-1.3181],\n",
      "        [ 1.0165],\n",
      "        [-0.4094],\n",
      "        [-0.5693],\n",
      "        [-1.5435],\n",
      "        [ 0.6198],\n",
      "        [-1.4439],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2258],\n",
      "        [ 1.1832]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 433/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0160,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1743],\n",
      "        [-1.1743],\n",
      "        [ 0.6521],\n",
      "        [ 0.5872],\n",
      "        [-0.0328],\n",
      "        [ 0.4886],\n",
      "        [ 0.9009],\n",
      "        [ 0.9595],\n",
      "        [ 0.9009],\n",
      "        [ 0.8100],\n",
      "        [-1.5835],\n",
      "        [-0.8882],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.9304],\n",
      "        [-0.2134],\n",
      "        [ 0.5545],\n",
      "        [-0.6229],\n",
      "        [-0.2992],\n",
      "        [ 0.8710],\n",
      "        [ 0.7477],\n",
      "        [ 0.7790],\n",
      "        [ 1.2258],\n",
      "        [ 1.2258],\n",
      "        [ 1.0716],\n",
      "        [-0.2992],\n",
      "        [-1.2112],\n",
      "        [ 1.0716],\n",
      "        [-1.4438],\n",
      "        [ 0.9595],\n",
      "        [-1.3181],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.7477],\n",
      "        [ 0.5216],\n",
      "        [ 1.2258],\n",
      "        [ 0.7477],\n",
      "        [-0.7056],\n",
      "        [-0.1246],\n",
      "        [-1.0631],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8882],\n",
      "        [ 0.6198],\n",
      "        [ 1.2258],\n",
      "        [-1.6012],\n",
      "        [ 0.0617],\n",
      "        [-0.4093],\n",
      "        [-1.3181],\n",
      "        [ 1.0165],\n",
      "        [-0.4093],\n",
      "        [-0.5693],\n",
      "        [-1.5435],\n",
      "        [ 0.6198],\n",
      "        [-1.4438],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2258],\n",
      "        [ 1.1833]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 434/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0160,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6521],\n",
      "        [ 0.5872],\n",
      "        [-0.0328],\n",
      "        [ 0.4886],\n",
      "        [ 0.9009],\n",
      "        [ 0.9595],\n",
      "        [ 0.9009],\n",
      "        [ 0.8100],\n",
      "        [-1.5836],\n",
      "        [-0.8882],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.9304],\n",
      "        [-0.2134],\n",
      "        [ 0.5545],\n",
      "        [-0.6229],\n",
      "        [-0.2992],\n",
      "        [ 0.8709],\n",
      "        [ 0.7477],\n",
      "        [ 0.7790],\n",
      "        [ 1.2259],\n",
      "        [ 1.2259],\n",
      "        [ 1.0716],\n",
      "        [-0.2992],\n",
      "        [-1.2111],\n",
      "        [ 1.0716],\n",
      "        [-1.4438],\n",
      "        [ 0.9595],\n",
      "        [-1.3180],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.7477],\n",
      "        [ 0.5216],\n",
      "        [ 1.2259],\n",
      "        [ 0.7477],\n",
      "        [-0.7057],\n",
      "        [-0.1246],\n",
      "        [-1.0632],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8882],\n",
      "        [ 0.6197],\n",
      "        [ 1.2259],\n",
      "        [-1.6013],\n",
      "        [ 0.0617],\n",
      "        [-0.4093],\n",
      "        [-1.3180],\n",
      "        [ 1.0165],\n",
      "        [-0.4093],\n",
      "        [-0.5693],\n",
      "        [-1.5436],\n",
      "        [ 0.6197],\n",
      "        [-1.4438],\n",
      "        [ 0.4224],\n",
      "        [-0.4363],\n",
      "        [ 0.4224],\n",
      "        [ 1.2259],\n",
      "        [ 1.1833]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 435/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0160,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6521],\n",
      "        [ 0.5872],\n",
      "        [-0.0327],\n",
      "        [ 0.4886],\n",
      "        [ 0.9008],\n",
      "        [ 0.9595],\n",
      "        [ 0.9008],\n",
      "        [ 0.8100],\n",
      "        [-1.5836],\n",
      "        [-0.8883],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.9304],\n",
      "        [-0.2134],\n",
      "        [ 0.5545],\n",
      "        [-0.6230],\n",
      "        [-0.2991],\n",
      "        [ 0.8709],\n",
      "        [ 0.7477],\n",
      "        [ 0.7790],\n",
      "        [ 1.2259],\n",
      "        [ 1.2259],\n",
      "        [ 1.0716],\n",
      "        [-0.2991],\n",
      "        [-1.2111],\n",
      "        [ 1.0716],\n",
      "        [-1.4437],\n",
      "        [ 0.9595],\n",
      "        [-1.3180],\n",
      "        [ 0.5545],\n",
      "        [-0.2134],\n",
      "        [ 0.7477],\n",
      "        [ 0.5216],\n",
      "        [ 1.2259],\n",
      "        [ 0.7477],\n",
      "        [-0.7058],\n",
      "        [-0.1245],\n",
      "        [-1.0632],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8883],\n",
      "        [ 0.6197],\n",
      "        [ 1.2259],\n",
      "        [-1.6014],\n",
      "        [ 0.0617],\n",
      "        [-0.4093],\n",
      "        [-1.3180],\n",
      "        [ 1.0164],\n",
      "        [-0.4093],\n",
      "        [-0.5693],\n",
      "        [-1.5436],\n",
      "        [ 0.6197],\n",
      "        [-1.4437],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2259],\n",
      "        [ 1.1833]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 436/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0159,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6520],\n",
      "        [ 0.5872],\n",
      "        [-0.0327],\n",
      "        [ 0.4886],\n",
      "        [ 0.9008],\n",
      "        [ 0.9595],\n",
      "        [ 0.9008],\n",
      "        [ 0.8099],\n",
      "        [-1.5837],\n",
      "        [-0.8884],\n",
      "        [ 0.5544],\n",
      "        [-0.2133],\n",
      "        [ 0.9303],\n",
      "        [-0.2133],\n",
      "        [ 0.5544],\n",
      "        [-0.6230],\n",
      "        [-0.2991],\n",
      "        [ 0.8709],\n",
      "        [ 0.7476],\n",
      "        [ 0.7790],\n",
      "        [ 1.2260],\n",
      "        [ 1.2260],\n",
      "        [ 1.0716],\n",
      "        [-0.2991],\n",
      "        [-1.2111],\n",
      "        [ 1.0716],\n",
      "        [-1.4437],\n",
      "        [ 0.9595],\n",
      "        [-1.3179],\n",
      "        [ 0.5544],\n",
      "        [-0.2133],\n",
      "        [ 0.7476],\n",
      "        [ 0.5216],\n",
      "        [ 1.2260],\n",
      "        [ 0.7476],\n",
      "        [-0.7058],\n",
      "        [-0.1245],\n",
      "        [-1.0632],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8884],\n",
      "        [ 0.6197],\n",
      "        [ 1.2260],\n",
      "        [-1.6014],\n",
      "        [ 0.0618],\n",
      "        [-0.4093],\n",
      "        [-1.3179],\n",
      "        [ 1.0164],\n",
      "        [-0.4093],\n",
      "        [-0.5694],\n",
      "        [-1.5436],\n",
      "        [ 0.6197],\n",
      "        [-1.4437],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2260],\n",
      "        [ 1.1834]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 437/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0159,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6520],\n",
      "        [ 0.5871],\n",
      "        [-0.0327],\n",
      "        [ 0.4886],\n",
      "        [ 0.9008],\n",
      "        [ 0.9595],\n",
      "        [ 0.9008],\n",
      "        [ 0.8099],\n",
      "        [-1.5837],\n",
      "        [-0.8885],\n",
      "        [ 0.5544],\n",
      "        [-0.2133],\n",
      "        [ 0.9303],\n",
      "        [-0.2133],\n",
      "        [ 0.5544],\n",
      "        [-0.6231],\n",
      "        [-0.2991],\n",
      "        [ 0.8709],\n",
      "        [ 0.7476],\n",
      "        [ 0.7789],\n",
      "        [ 1.2261],\n",
      "        [ 1.2261],\n",
      "        [ 1.0716],\n",
      "        [-0.2991],\n",
      "        [-1.2111],\n",
      "        [ 1.0716],\n",
      "        [-1.4436],\n",
      "        [ 0.9595],\n",
      "        [-1.3179],\n",
      "        [ 0.5544],\n",
      "        [-0.2133],\n",
      "        [ 0.7476],\n",
      "        [ 0.5216],\n",
      "        [ 1.2261],\n",
      "        [ 0.7476],\n",
      "        [-0.7059],\n",
      "        [-0.1244],\n",
      "        [-1.0633],\n",
      "        [-1.1371],\n",
      "        [ 0.9595],\n",
      "        [-0.8885],\n",
      "        [ 0.6197],\n",
      "        [ 1.2261],\n",
      "        [-1.6015],\n",
      "        [ 0.0618],\n",
      "        [-0.4093],\n",
      "        [-1.3179],\n",
      "        [ 1.0164],\n",
      "        [-0.4093],\n",
      "        [-0.5694],\n",
      "        [-1.5436],\n",
      "        [ 0.6197],\n",
      "        [-1.4436],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2261],\n",
      "        [ 1.1834]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 438/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0159,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6520],\n",
      "        [ 0.5871],\n",
      "        [-0.0326],\n",
      "        [ 0.4886],\n",
      "        [ 0.9008],\n",
      "        [ 0.9594],\n",
      "        [ 0.9008],\n",
      "        [ 0.8099],\n",
      "        [-1.5837],\n",
      "        [-0.8886],\n",
      "        [ 0.5544],\n",
      "        [-0.2132],\n",
      "        [ 0.9303],\n",
      "        [-0.2132],\n",
      "        [ 0.5544],\n",
      "        [-0.6231],\n",
      "        [-0.2990],\n",
      "        [ 0.8708],\n",
      "        [ 0.7476],\n",
      "        [ 0.7789],\n",
      "        [ 1.2261],\n",
      "        [ 1.2261],\n",
      "        [ 1.0717],\n",
      "        [-0.2990],\n",
      "        [-1.2111],\n",
      "        [ 1.0717],\n",
      "        [-1.4436],\n",
      "        [ 0.9594],\n",
      "        [-1.3178],\n",
      "        [ 0.5544],\n",
      "        [-0.2132],\n",
      "        [ 0.7476],\n",
      "        [ 0.5215],\n",
      "        [ 1.2261],\n",
      "        [ 0.7476],\n",
      "        [-0.7060],\n",
      "        [-0.1244],\n",
      "        [-1.0633],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8886],\n",
      "        [ 0.6197],\n",
      "        [ 1.2261],\n",
      "        [-1.6016],\n",
      "        [ 0.0618],\n",
      "        [-0.4093],\n",
      "        [-1.3178],\n",
      "        [ 1.0164],\n",
      "        [-0.4093],\n",
      "        [-0.5694],\n",
      "        [-1.5436],\n",
      "        [ 0.6197],\n",
      "        [-1.4436],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2261],\n",
      "        [ 1.1835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 439/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0158,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6520],\n",
      "        [ 0.5871],\n",
      "        [-0.0326],\n",
      "        [ 0.4886],\n",
      "        [ 0.9008],\n",
      "        [ 0.9594],\n",
      "        [ 0.9008],\n",
      "        [ 0.8099],\n",
      "        [-1.5838],\n",
      "        [-0.8886],\n",
      "        [ 0.5544],\n",
      "        [-0.2132],\n",
      "        [ 0.9303],\n",
      "        [-0.2132],\n",
      "        [ 0.5544],\n",
      "        [-0.6232],\n",
      "        [-0.2990],\n",
      "        [ 0.8708],\n",
      "        [ 0.7476],\n",
      "        [ 0.7789],\n",
      "        [ 1.2262],\n",
      "        [ 1.2262],\n",
      "        [ 1.0717],\n",
      "        [-0.2990],\n",
      "        [-1.2110],\n",
      "        [ 1.0717],\n",
      "        [-1.4436],\n",
      "        [ 0.9594],\n",
      "        [-1.3178],\n",
      "        [ 0.5544],\n",
      "        [-0.2132],\n",
      "        [ 0.7476],\n",
      "        [ 0.5215],\n",
      "        [ 1.2262],\n",
      "        [ 0.7476],\n",
      "        [-0.7060],\n",
      "        [-0.1243],\n",
      "        [-1.0633],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8886],\n",
      "        [ 0.6196],\n",
      "        [ 1.2262],\n",
      "        [-1.6016],\n",
      "        [ 0.0619],\n",
      "        [-0.4092],\n",
      "        [-1.3178],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5695],\n",
      "        [-1.5436],\n",
      "        [ 0.6196],\n",
      "        [-1.4436],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2262],\n",
      "        [ 1.1835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 440/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0158,\n",
      " epoch_time_duration: 0.0125\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6519],\n",
      "        [ 0.5871],\n",
      "        [-0.0325],\n",
      "        [ 0.4885],\n",
      "        [ 0.9007],\n",
      "        [ 0.9594],\n",
      "        [ 0.9007],\n",
      "        [ 0.8098],\n",
      "        [-1.5838],\n",
      "        [-0.8887],\n",
      "        [ 0.5544],\n",
      "        [-0.2131],\n",
      "        [ 0.9303],\n",
      "        [-0.2131],\n",
      "        [ 0.5544],\n",
      "        [-0.6232],\n",
      "        [-0.2990],\n",
      "        [ 0.8708],\n",
      "        [ 0.7475],\n",
      "        [ 0.7788],\n",
      "        [ 1.2262],\n",
      "        [ 1.2262],\n",
      "        [ 1.0717],\n",
      "        [-0.2990],\n",
      "        [-1.2110],\n",
      "        [ 1.0717],\n",
      "        [-1.4435],\n",
      "        [ 0.9594],\n",
      "        [-1.3177],\n",
      "        [ 0.5544],\n",
      "        [-0.2131],\n",
      "        [ 0.7475],\n",
      "        [ 0.5215],\n",
      "        [ 1.2262],\n",
      "        [ 0.7475],\n",
      "        [-0.7061],\n",
      "        [-0.1243],\n",
      "        [-1.0634],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8887],\n",
      "        [ 0.6196],\n",
      "        [ 1.2262],\n",
      "        [-1.6017],\n",
      "        [ 0.0619],\n",
      "        [-0.4092],\n",
      "        [-1.3177],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5695],\n",
      "        [-1.5436],\n",
      "        [ 0.6196],\n",
      "        [-1.4435],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2262],\n",
      "        [ 1.1835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 441/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0158,\n",
      " epoch_time_duration: 0.0109\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6519],\n",
      "        [ 0.5871],\n",
      "        [-0.0325],\n",
      "        [ 0.4885],\n",
      "        [ 0.9007],\n",
      "        [ 0.9594],\n",
      "        [ 0.9007],\n",
      "        [ 0.8098],\n",
      "        [-1.5839],\n",
      "        [-0.8888],\n",
      "        [ 0.5543],\n",
      "        [-0.2131],\n",
      "        [ 0.9303],\n",
      "        [-0.2131],\n",
      "        [ 0.5543],\n",
      "        [-0.6232],\n",
      "        [-0.2989],\n",
      "        [ 0.8708],\n",
      "        [ 0.7475],\n",
      "        [ 0.7788],\n",
      "        [ 1.2263],\n",
      "        [ 1.2263],\n",
      "        [ 1.0717],\n",
      "        [-0.2989],\n",
      "        [-1.2110],\n",
      "        [ 1.0717],\n",
      "        [-1.4435],\n",
      "        [ 0.9594],\n",
      "        [-1.3177],\n",
      "        [ 0.5543],\n",
      "        [-0.2131],\n",
      "        [ 0.7475],\n",
      "        [ 0.5215],\n",
      "        [ 1.2263],\n",
      "        [ 0.7475],\n",
      "        [-0.7062],\n",
      "        [-0.1243],\n",
      "        [-1.0634],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8888],\n",
      "        [ 0.6196],\n",
      "        [ 1.2263],\n",
      "        [-1.6017],\n",
      "        [ 0.0619],\n",
      "        [-0.4092],\n",
      "        [-1.3177],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5695],\n",
      "        [-1.5436],\n",
      "        [ 0.6196],\n",
      "        [-1.4435],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2263],\n",
      "        [ 1.1836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 442/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0158,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6519],\n",
      "        [ 0.5870],\n",
      "        [-0.0324],\n",
      "        [ 0.4885],\n",
      "        [ 0.9007],\n",
      "        [ 0.9594],\n",
      "        [ 0.9007],\n",
      "        [ 0.8098],\n",
      "        [-1.5839],\n",
      "        [-0.8889],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.9302],\n",
      "        [-0.2130],\n",
      "        [ 0.5543],\n",
      "        [-0.6233],\n",
      "        [-0.2989],\n",
      "        [ 0.8708],\n",
      "        [ 0.7475],\n",
      "        [ 0.7788],\n",
      "        [ 1.2263],\n",
      "        [ 1.2263],\n",
      "        [ 1.0717],\n",
      "        [-0.2989],\n",
      "        [-1.2110],\n",
      "        [ 1.0717],\n",
      "        [-1.4434],\n",
      "        [ 0.9594],\n",
      "        [-1.3176],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.7475],\n",
      "        [ 0.5215],\n",
      "        [ 1.2263],\n",
      "        [ 0.7475],\n",
      "        [-0.7062],\n",
      "        [-0.1242],\n",
      "        [-1.0634],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8889],\n",
      "        [ 0.6196],\n",
      "        [ 1.2263],\n",
      "        [-1.6018],\n",
      "        [ 0.0620],\n",
      "        [-0.4092],\n",
      "        [-1.3176],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5695],\n",
      "        [-1.5436],\n",
      "        [ 0.6196],\n",
      "        [-1.4434],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2263],\n",
      "        [ 1.1836]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 443/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0157,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6519],\n",
      "        [ 0.5870],\n",
      "        [-0.0324],\n",
      "        [ 0.4885],\n",
      "        [ 0.9007],\n",
      "        [ 0.9594],\n",
      "        [ 0.9007],\n",
      "        [ 0.8098],\n",
      "        [-1.5840],\n",
      "        [-0.8890],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.9302],\n",
      "        [-0.2130],\n",
      "        [ 0.5543],\n",
      "        [-0.6233],\n",
      "        [-0.2989],\n",
      "        [ 0.8707],\n",
      "        [ 0.7475],\n",
      "        [ 0.7788],\n",
      "        [ 1.2264],\n",
      "        [ 1.2264],\n",
      "        [ 1.0717],\n",
      "        [-0.2989],\n",
      "        [-1.2110],\n",
      "        [ 1.0717],\n",
      "        [-1.4434],\n",
      "        [ 0.9594],\n",
      "        [-1.3176],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.7475],\n",
      "        [ 0.5215],\n",
      "        [ 1.2264],\n",
      "        [ 0.7475],\n",
      "        [-0.7063],\n",
      "        [-0.1242],\n",
      "        [-1.0635],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8890],\n",
      "        [ 0.6195],\n",
      "        [ 1.2264],\n",
      "        [-1.6019],\n",
      "        [ 0.0620],\n",
      "        [-0.4092],\n",
      "        [-1.3176],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5696],\n",
      "        [-1.5436],\n",
      "        [ 0.6195],\n",
      "        [-1.4434],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2264],\n",
      "        [ 1.1837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 444/10000,\n",
      " train_loss: 0.0004,\n",
      " train_mae: 0.0157,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6519],\n",
      "        [ 0.5870],\n",
      "        [-0.0324],\n",
      "        [ 0.4885],\n",
      "        [ 0.9006],\n",
      "        [ 0.9594],\n",
      "        [ 0.9006],\n",
      "        [ 0.8097],\n",
      "        [-1.5840],\n",
      "        [-0.8890],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.9302],\n",
      "        [-0.2130],\n",
      "        [ 0.5543],\n",
      "        [-0.6234],\n",
      "        [-0.2988],\n",
      "        [ 0.8707],\n",
      "        [ 0.7474],\n",
      "        [ 0.7787],\n",
      "        [ 1.2265],\n",
      "        [ 1.2265],\n",
      "        [ 1.0717],\n",
      "        [-0.2988],\n",
      "        [-1.2109],\n",
      "        [ 1.0717],\n",
      "        [-1.4434],\n",
      "        [ 0.9594],\n",
      "        [-1.3175],\n",
      "        [ 0.5543],\n",
      "        [-0.2130],\n",
      "        [ 0.7474],\n",
      "        [ 0.5215],\n",
      "        [ 1.2265],\n",
      "        [ 0.7474],\n",
      "        [-0.7064],\n",
      "        [-0.1241],\n",
      "        [-1.0635],\n",
      "        [-1.1372],\n",
      "        [ 0.9594],\n",
      "        [-0.8890],\n",
      "        [ 0.6195],\n",
      "        [ 1.2265],\n",
      "        [-1.6019],\n",
      "        [ 0.0621],\n",
      "        [-0.4092],\n",
      "        [-1.3175],\n",
      "        [ 1.0164],\n",
      "        [-0.4092],\n",
      "        [-0.5696],\n",
      "        [-1.5436],\n",
      "        [ 0.6195],\n",
      "        [-1.4434],\n",
      "        [ 0.4224],\n",
      "        [-0.4362],\n",
      "        [ 0.4224],\n",
      "        [ 1.2265],\n",
      "        [ 1.1837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 445/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0157,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6518],\n",
      "        [ 0.5870],\n",
      "        [-0.0323],\n",
      "        [ 0.4885],\n",
      "        [ 0.9006],\n",
      "        [ 0.9593],\n",
      "        [ 0.9006],\n",
      "        [ 0.8097],\n",
      "        [-1.5840],\n",
      "        [-0.8891],\n",
      "        [ 0.5543],\n",
      "        [-0.2129],\n",
      "        [ 0.9302],\n",
      "        [-0.2129],\n",
      "        [ 0.5543],\n",
      "        [-0.6234],\n",
      "        [-0.2988],\n",
      "        [ 0.8707],\n",
      "        [ 0.7474],\n",
      "        [ 0.7787],\n",
      "        [ 1.2265],\n",
      "        [ 1.2265],\n",
      "        [ 1.0717],\n",
      "        [-0.2988],\n",
      "        [-1.2109],\n",
      "        [ 1.0717],\n",
      "        [-1.4433],\n",
      "        [ 0.9593],\n",
      "        [-1.3175],\n",
      "        [ 0.5543],\n",
      "        [-0.2129],\n",
      "        [ 0.7474],\n",
      "        [ 0.5214],\n",
      "        [ 1.2265],\n",
      "        [ 0.7474],\n",
      "        [-0.7064],\n",
      "        [-0.1241],\n",
      "        [-1.0635],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8891],\n",
      "        [ 0.6195],\n",
      "        [ 1.2265],\n",
      "        [-1.6020],\n",
      "        [ 0.0621],\n",
      "        [-0.4091],\n",
      "        [-1.3175],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5696],\n",
      "        [-1.5436],\n",
      "        [ 0.6195],\n",
      "        [-1.4433],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2265],\n",
      "        [ 1.1837]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 446/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0156,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6518],\n",
      "        [ 0.5870],\n",
      "        [-0.0323],\n",
      "        [ 0.4885],\n",
      "        [ 0.9006],\n",
      "        [ 0.9593],\n",
      "        [ 0.9006],\n",
      "        [ 0.8097],\n",
      "        [-1.5841],\n",
      "        [-0.8892],\n",
      "        [ 0.5543],\n",
      "        [-0.2129],\n",
      "        [ 0.9302],\n",
      "        [-0.2129],\n",
      "        [ 0.5543],\n",
      "        [-0.6235],\n",
      "        [-0.2988],\n",
      "        [ 0.8707],\n",
      "        [ 0.7474],\n",
      "        [ 0.7787],\n",
      "        [ 1.2266],\n",
      "        [ 1.2266],\n",
      "        [ 1.0717],\n",
      "        [-0.2988],\n",
      "        [-1.2109],\n",
      "        [ 1.0717],\n",
      "        [-1.4433],\n",
      "        [ 0.9593],\n",
      "        [-1.3175],\n",
      "        [ 0.5543],\n",
      "        [-0.2129],\n",
      "        [ 0.7474],\n",
      "        [ 0.5214],\n",
      "        [ 1.2266],\n",
      "        [ 0.7474],\n",
      "        [-0.7065],\n",
      "        [-0.1240],\n",
      "        [-1.0636],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8892],\n",
      "        [ 0.6195],\n",
      "        [ 1.2266],\n",
      "        [-1.6021],\n",
      "        [ 0.0621],\n",
      "        [-0.4091],\n",
      "        [-1.3175],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5697],\n",
      "        [-1.5436],\n",
      "        [ 0.6195],\n",
      "        [-1.4433],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2266],\n",
      "        [ 1.1838]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 447/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0156,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1742],\n",
      "        [-1.1742],\n",
      "        [ 0.6518],\n",
      "        [ 0.5869],\n",
      "        [-0.0322],\n",
      "        [ 0.4885],\n",
      "        [ 0.9006],\n",
      "        [ 0.9593],\n",
      "        [ 0.9006],\n",
      "        [ 0.8097],\n",
      "        [-1.5841],\n",
      "        [-0.8893],\n",
      "        [ 0.5542],\n",
      "        [-0.2128],\n",
      "        [ 0.9301],\n",
      "        [-0.2128],\n",
      "        [ 0.5542],\n",
      "        [-0.6235],\n",
      "        [-0.2987],\n",
      "        [ 0.8706],\n",
      "        [ 0.7474],\n",
      "        [ 0.7787],\n",
      "        [ 1.2266],\n",
      "        [ 1.2266],\n",
      "        [ 1.0717],\n",
      "        [-0.2987],\n",
      "        [-1.2109],\n",
      "        [ 1.0717],\n",
      "        [-1.4432],\n",
      "        [ 0.9593],\n",
      "        [-1.3174],\n",
      "        [ 0.5542],\n",
      "        [-0.2128],\n",
      "        [ 0.7474],\n",
      "        [ 0.5214],\n",
      "        [ 1.2266],\n",
      "        [ 0.7474],\n",
      "        [-0.7066],\n",
      "        [-0.1240],\n",
      "        [-1.0636],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8893],\n",
      "        [ 0.6195],\n",
      "        [ 1.2266],\n",
      "        [-1.6021],\n",
      "        [ 0.0622],\n",
      "        [-0.4091],\n",
      "        [-1.3174],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5697],\n",
      "        [-1.5437],\n",
      "        [ 0.6195],\n",
      "        [-1.4432],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2266],\n",
      "        [ 1.1838]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 448/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0156,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6518],\n",
      "        [ 0.5869],\n",
      "        [-0.0322],\n",
      "        [ 0.4885],\n",
      "        [ 0.9006],\n",
      "        [ 0.9593],\n",
      "        [ 0.9006],\n",
      "        [ 0.8096],\n",
      "        [-1.5842],\n",
      "        [-0.8893],\n",
      "        [ 0.5542],\n",
      "        [-0.2128],\n",
      "        [ 0.9301],\n",
      "        [-0.2128],\n",
      "        [ 0.5542],\n",
      "        [-0.6236],\n",
      "        [-0.2987],\n",
      "        [ 0.8706],\n",
      "        [ 0.7473],\n",
      "        [ 0.7786],\n",
      "        [ 1.2267],\n",
      "        [ 1.2267],\n",
      "        [ 1.0717],\n",
      "        [-0.2987],\n",
      "        [-1.2109],\n",
      "        [ 1.0717],\n",
      "        [-1.4432],\n",
      "        [ 0.9593],\n",
      "        [-1.3174],\n",
      "        [ 0.5542],\n",
      "        [-0.2128],\n",
      "        [ 0.7473],\n",
      "        [ 0.5214],\n",
      "        [ 1.2267],\n",
      "        [ 0.7473],\n",
      "        [-0.7066],\n",
      "        [-0.1239],\n",
      "        [-1.0637],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8893],\n",
      "        [ 0.6194],\n",
      "        [ 1.2267],\n",
      "        [-1.6022],\n",
      "        [ 0.0622],\n",
      "        [-0.4091],\n",
      "        [-1.3174],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5697],\n",
      "        [-1.5437],\n",
      "        [ 0.6194],\n",
      "        [-1.4432],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2267],\n",
      "        [ 1.1838]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 449/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0155,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6517],\n",
      "        [ 0.5869],\n",
      "        [-0.0321],\n",
      "        [ 0.4884],\n",
      "        [ 0.9005],\n",
      "        [ 0.9593],\n",
      "        [ 0.9005],\n",
      "        [ 0.8096],\n",
      "        [-1.5842],\n",
      "        [-0.8894],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.9301],\n",
      "        [-0.2127],\n",
      "        [ 0.5542],\n",
      "        [-0.6236],\n",
      "        [-0.2987],\n",
      "        [ 0.8706],\n",
      "        [ 0.7473],\n",
      "        [ 0.7786],\n",
      "        [ 1.2267],\n",
      "        [ 1.2267],\n",
      "        [ 1.0717],\n",
      "        [-0.2987],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4431],\n",
      "        [ 0.9593],\n",
      "        [-1.3173],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.7473],\n",
      "        [ 0.5214],\n",
      "        [ 1.2267],\n",
      "        [ 0.7473],\n",
      "        [-0.7067],\n",
      "        [-0.1239],\n",
      "        [-1.0637],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8894],\n",
      "        [ 0.6194],\n",
      "        [ 1.2267],\n",
      "        [-1.6022],\n",
      "        [ 0.0622],\n",
      "        [-0.4091],\n",
      "        [-1.3173],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5697],\n",
      "        [-1.5437],\n",
      "        [ 0.6194],\n",
      "        [-1.4431],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2267],\n",
      "        [ 1.1839]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 450/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0155,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6517],\n",
      "        [ 0.5869],\n",
      "        [-0.0321],\n",
      "        [ 0.4884],\n",
      "        [ 0.9005],\n",
      "        [ 0.9593],\n",
      "        [ 0.9005],\n",
      "        [ 0.8096],\n",
      "        [-1.5842],\n",
      "        [-0.8895],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.9301],\n",
      "        [-0.2127],\n",
      "        [ 0.5542],\n",
      "        [-0.6236],\n",
      "        [-0.2986],\n",
      "        [ 0.8706],\n",
      "        [ 0.7473],\n",
      "        [ 0.7786],\n",
      "        [ 1.2268],\n",
      "        [ 1.2268],\n",
      "        [ 1.0717],\n",
      "        [-0.2986],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4431],\n",
      "        [ 0.9593],\n",
      "        [-1.3173],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.7473],\n",
      "        [ 0.5214],\n",
      "        [ 1.2268],\n",
      "        [ 0.7473],\n",
      "        [-0.7068],\n",
      "        [-0.1239],\n",
      "        [-1.0637],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8895],\n",
      "        [ 0.6194],\n",
      "        [ 1.2268],\n",
      "        [-1.6023],\n",
      "        [ 0.0623],\n",
      "        [-0.4091],\n",
      "        [-1.3173],\n",
      "        [ 1.0164],\n",
      "        [-0.4091],\n",
      "        [-0.5698],\n",
      "        [-1.5437],\n",
      "        [ 0.6194],\n",
      "        [-1.4431],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2268],\n",
      "        [ 1.1839]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 451/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0155,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6517],\n",
      "        [ 0.5869],\n",
      "        [-0.0321],\n",
      "        [ 0.4884],\n",
      "        [ 0.9005],\n",
      "        [ 0.9593],\n",
      "        [ 0.9005],\n",
      "        [ 0.8096],\n",
      "        [-1.5843],\n",
      "        [-0.8896],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.9301],\n",
      "        [-0.2127],\n",
      "        [ 0.5542],\n",
      "        [-0.6237],\n",
      "        [-0.2986],\n",
      "        [ 0.8705],\n",
      "        [ 0.7472],\n",
      "        [ 0.7786],\n",
      "        [ 1.2268],\n",
      "        [ 1.2268],\n",
      "        [ 1.0717],\n",
      "        [-0.2986],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4431],\n",
      "        [ 0.9593],\n",
      "        [-1.3172],\n",
      "        [ 0.5542],\n",
      "        [-0.2127],\n",
      "        [ 0.7472],\n",
      "        [ 0.5214],\n",
      "        [ 1.2268],\n",
      "        [ 0.7472],\n",
      "        [-0.7068],\n",
      "        [-0.1238],\n",
      "        [-1.0638],\n",
      "        [-1.1372],\n",
      "        [ 0.9593],\n",
      "        [-0.8896],\n",
      "        [ 0.6194],\n",
      "        [ 1.2268],\n",
      "        [-1.6024],\n",
      "        [ 0.0623],\n",
      "        [-0.4090],\n",
      "        [-1.3172],\n",
      "        [ 1.0164],\n",
      "        [-0.4090],\n",
      "        [-0.5698],\n",
      "        [-1.5437],\n",
      "        [ 0.6194],\n",
      "        [-1.4431],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2268],\n",
      "        [ 1.1840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 452/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0155,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6517],\n",
      "        [ 0.5868],\n",
      "        [-0.0320],\n",
      "        [ 0.4884],\n",
      "        [ 0.9005],\n",
      "        [ 0.9592],\n",
      "        [ 0.9005],\n",
      "        [ 0.8095],\n",
      "        [-1.5843],\n",
      "        [-0.8897],\n",
      "        [ 0.5542],\n",
      "        [-0.2126],\n",
      "        [ 0.9301],\n",
      "        [-0.2126],\n",
      "        [ 0.5542],\n",
      "        [-0.6237],\n",
      "        [-0.2985],\n",
      "        [ 0.8705],\n",
      "        [ 0.7472],\n",
      "        [ 0.7785],\n",
      "        [ 1.2269],\n",
      "        [ 1.2269],\n",
      "        [ 1.0717],\n",
      "        [-0.2985],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4430],\n",
      "        [ 0.9592],\n",
      "        [-1.3172],\n",
      "        [ 0.5542],\n",
      "        [-0.2126],\n",
      "        [ 0.7472],\n",
      "        [ 0.5213],\n",
      "        [ 1.2269],\n",
      "        [ 0.7472],\n",
      "        [-0.7069],\n",
      "        [-0.1238],\n",
      "        [-1.0638],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8897],\n",
      "        [ 0.6193],\n",
      "        [ 1.2269],\n",
      "        [-1.6024],\n",
      "        [ 0.0623],\n",
      "        [-0.4090],\n",
      "        [-1.3172],\n",
      "        [ 1.0164],\n",
      "        [-0.4090],\n",
      "        [-0.5698],\n",
      "        [-1.5437],\n",
      "        [ 0.6193],\n",
      "        [-1.4430],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2269],\n",
      "        [ 1.1840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 453/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0154,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6516],\n",
      "        [ 0.5868],\n",
      "        [-0.0320],\n",
      "        [ 0.4884],\n",
      "        [ 0.9005],\n",
      "        [ 0.9592],\n",
      "        [ 0.9005],\n",
      "        [ 0.8095],\n",
      "        [-1.5844],\n",
      "        [-0.8897],\n",
      "        [ 0.5541],\n",
      "        [-0.2126],\n",
      "        [ 0.9300],\n",
      "        [-0.2126],\n",
      "        [ 0.5541],\n",
      "        [-0.6238],\n",
      "        [-0.2985],\n",
      "        [ 0.8705],\n",
      "        [ 0.7472],\n",
      "        [ 0.7785],\n",
      "        [ 1.2270],\n",
      "        [ 1.2270],\n",
      "        [ 1.0717],\n",
      "        [-0.2985],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4430],\n",
      "        [ 0.9592],\n",
      "        [-1.3171],\n",
      "        [ 0.5541],\n",
      "        [-0.2126],\n",
      "        [ 0.7472],\n",
      "        [ 0.5213],\n",
      "        [ 1.2270],\n",
      "        [ 0.7472],\n",
      "        [-0.7070],\n",
      "        [-0.1237],\n",
      "        [-1.0638],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8897],\n",
      "        [ 0.6193],\n",
      "        [ 1.2270],\n",
      "        [-1.6025],\n",
      "        [ 0.0624],\n",
      "        [-0.4090],\n",
      "        [-1.3171],\n",
      "        [ 1.0163],\n",
      "        [-0.4090],\n",
      "        [-0.5698],\n",
      "        [-1.5437],\n",
      "        [ 0.6193],\n",
      "        [-1.4430],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2270],\n",
      "        [ 1.1840]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 454/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0154,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6516],\n",
      "        [ 0.5868],\n",
      "        [-0.0319],\n",
      "        [ 0.4884],\n",
      "        [ 0.9004],\n",
      "        [ 0.9592],\n",
      "        [ 0.9004],\n",
      "        [ 0.8095],\n",
      "        [-1.5844],\n",
      "        [-0.8898],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.9300],\n",
      "        [-0.2125],\n",
      "        [ 0.5541],\n",
      "        [-0.6238],\n",
      "        [-0.2985],\n",
      "        [ 0.8705],\n",
      "        [ 0.7472],\n",
      "        [ 0.7785],\n",
      "        [ 1.2270],\n",
      "        [ 1.2270],\n",
      "        [ 1.0717],\n",
      "        [-0.2985],\n",
      "        [-1.2108],\n",
      "        [ 1.0717],\n",
      "        [-1.4429],\n",
      "        [ 0.9592],\n",
      "        [-1.3171],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.7472],\n",
      "        [ 0.5213],\n",
      "        [ 1.2270],\n",
      "        [ 0.7472],\n",
      "        [-0.7070],\n",
      "        [-0.1237],\n",
      "        [-1.0639],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8898],\n",
      "        [ 0.6193],\n",
      "        [ 1.2270],\n",
      "        [-1.6025],\n",
      "        [ 0.0624],\n",
      "        [-0.4090],\n",
      "        [-1.3171],\n",
      "        [ 1.0163],\n",
      "        [-0.4090],\n",
      "        [-0.5699],\n",
      "        [-1.5437],\n",
      "        [ 0.6193],\n",
      "        [-1.4429],\n",
      "        [ 0.4223],\n",
      "        [-0.4361],\n",
      "        [ 0.4223],\n",
      "        [ 1.2270],\n",
      "        [ 1.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 455/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0154,\n",
      " epoch_time_duration: 0.0156\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6516],\n",
      "        [ 0.5868],\n",
      "        [-0.0319],\n",
      "        [ 0.4884],\n",
      "        [ 0.9004],\n",
      "        [ 0.9592],\n",
      "        [ 0.9004],\n",
      "        [ 0.8095],\n",
      "        [-1.5845],\n",
      "        [-0.8899],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.9300],\n",
      "        [-0.2125],\n",
      "        [ 0.5541],\n",
      "        [-0.6239],\n",
      "        [-0.2984],\n",
      "        [ 0.8705],\n",
      "        [ 0.7471],\n",
      "        [ 0.7785],\n",
      "        [ 1.2271],\n",
      "        [ 1.2271],\n",
      "        [ 1.0718],\n",
      "        [-0.2984],\n",
      "        [-1.2107],\n",
      "        [ 1.0718],\n",
      "        [-1.4429],\n",
      "        [ 0.9592],\n",
      "        [-1.3170],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.7471],\n",
      "        [ 0.5213],\n",
      "        [ 1.2271],\n",
      "        [ 0.7471],\n",
      "        [-0.7071],\n",
      "        [-0.1236],\n",
      "        [-1.0639],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8899],\n",
      "        [ 0.6193],\n",
      "        [ 1.2271],\n",
      "        [-1.6026],\n",
      "        [ 0.0625],\n",
      "        [-0.4090],\n",
      "        [-1.3170],\n",
      "        [ 1.0163],\n",
      "        [-0.4090],\n",
      "        [-0.5699],\n",
      "        [-1.5437],\n",
      "        [ 0.6193],\n",
      "        [-1.4429],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2271],\n",
      "        [ 1.1841]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 456/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0154,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6516],\n",
      "        [ 0.5868],\n",
      "        [-0.0319],\n",
      "        [ 0.4884],\n",
      "        [ 0.9004],\n",
      "        [ 0.9592],\n",
      "        [ 0.9004],\n",
      "        [ 0.8094],\n",
      "        [-1.5845],\n",
      "        [-0.8900],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.9300],\n",
      "        [-0.2125],\n",
      "        [ 0.5541],\n",
      "        [-0.6239],\n",
      "        [-0.2984],\n",
      "        [ 0.8704],\n",
      "        [ 0.7471],\n",
      "        [ 0.7784],\n",
      "        [ 1.2271],\n",
      "        [ 1.2271],\n",
      "        [ 1.0718],\n",
      "        [-0.2984],\n",
      "        [-1.2107],\n",
      "        [ 1.0718],\n",
      "        [-1.4429],\n",
      "        [ 0.9592],\n",
      "        [-1.3170],\n",
      "        [ 0.5541],\n",
      "        [-0.2125],\n",
      "        [ 0.7471],\n",
      "        [ 0.5213],\n",
      "        [ 1.2271],\n",
      "        [ 0.7471],\n",
      "        [-0.7072],\n",
      "        [-0.1236],\n",
      "        [-1.0639],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8900],\n",
      "        [ 0.6193],\n",
      "        [ 1.2271],\n",
      "        [-1.6027],\n",
      "        [ 0.0625],\n",
      "        [-0.4090],\n",
      "        [-1.3170],\n",
      "        [ 1.0163],\n",
      "        [-0.4090],\n",
      "        [-0.5699],\n",
      "        [-1.5437],\n",
      "        [ 0.6193],\n",
      "        [-1.4429],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2271],\n",
      "        [ 1.1842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 457/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0153,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6516],\n",
      "        [ 0.5867],\n",
      "        [-0.0318],\n",
      "        [ 0.4884],\n",
      "        [ 0.9004],\n",
      "        [ 0.9592],\n",
      "        [ 0.9004],\n",
      "        [ 0.8094],\n",
      "        [-1.5845],\n",
      "        [-0.8900],\n",
      "        [ 0.5541],\n",
      "        [-0.2124],\n",
      "        [ 0.9300],\n",
      "        [-0.2124],\n",
      "        [ 0.5541],\n",
      "        [-0.6239],\n",
      "        [-0.2984],\n",
      "        [ 0.8704],\n",
      "        [ 0.7471],\n",
      "        [ 0.7784],\n",
      "        [ 1.2272],\n",
      "        [ 1.2272],\n",
      "        [ 1.0718],\n",
      "        [-0.2984],\n",
      "        [-1.2107],\n",
      "        [ 1.0718],\n",
      "        [-1.4428],\n",
      "        [ 0.9592],\n",
      "        [-1.3170],\n",
      "        [ 0.5541],\n",
      "        [-0.2124],\n",
      "        [ 0.7471],\n",
      "        [ 0.5213],\n",
      "        [ 1.2272],\n",
      "        [ 0.7471],\n",
      "        [-0.7072],\n",
      "        [-0.1235],\n",
      "        [-1.0640],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8900],\n",
      "        [ 0.6192],\n",
      "        [ 1.2272],\n",
      "        [-1.6027],\n",
      "        [ 0.0625],\n",
      "        [-0.4090],\n",
      "        [-1.3170],\n",
      "        [ 1.0163],\n",
      "        [-0.4090],\n",
      "        [-0.5700],\n",
      "        [-1.5437],\n",
      "        [ 0.6192],\n",
      "        [-1.4428],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2272],\n",
      "        [ 1.1842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 458/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0153,\n",
      " epoch_time_duration: 0.0121\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6515],\n",
      "        [ 0.5867],\n",
      "        [-0.0318],\n",
      "        [ 0.4883],\n",
      "        [ 0.9004],\n",
      "        [ 0.9592],\n",
      "        [ 0.9004],\n",
      "        [ 0.8094],\n",
      "        [-1.5846],\n",
      "        [-0.8901],\n",
      "        [ 0.5541],\n",
      "        [-0.2124],\n",
      "        [ 0.9300],\n",
      "        [-0.2124],\n",
      "        [ 0.5541],\n",
      "        [-0.6240],\n",
      "        [-0.2983],\n",
      "        [ 0.8704],\n",
      "        [ 0.7471],\n",
      "        [ 0.7784],\n",
      "        [ 1.2272],\n",
      "        [ 1.2272],\n",
      "        [ 1.0718],\n",
      "        [-0.2983],\n",
      "        [-1.2107],\n",
      "        [ 1.0718],\n",
      "        [-1.4428],\n",
      "        [ 0.9592],\n",
      "        [-1.3169],\n",
      "        [ 0.5541],\n",
      "        [-0.2124],\n",
      "        [ 0.7471],\n",
      "        [ 0.5213],\n",
      "        [ 1.2272],\n",
      "        [ 0.7471],\n",
      "        [-0.7073],\n",
      "        [-0.1235],\n",
      "        [-1.0640],\n",
      "        [-1.1373],\n",
      "        [ 0.9592],\n",
      "        [-0.8901],\n",
      "        [ 0.6192],\n",
      "        [ 1.2272],\n",
      "        [-1.6028],\n",
      "        [ 0.0626],\n",
      "        [-0.4089],\n",
      "        [-1.3169],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5700],\n",
      "        [-1.5437],\n",
      "        [ 0.6192],\n",
      "        [-1.4428],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2272],\n",
      "        [ 1.1842]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 459/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0153,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6515],\n",
      "        [ 0.5867],\n",
      "        [-0.0317],\n",
      "        [ 0.4883],\n",
      "        [ 0.9003],\n",
      "        [ 0.9591],\n",
      "        [ 0.9003],\n",
      "        [ 0.8094],\n",
      "        [-1.5846],\n",
      "        [-0.8902],\n",
      "        [ 0.5540],\n",
      "        [-0.2123],\n",
      "        [ 0.9299],\n",
      "        [-0.2123],\n",
      "        [ 0.5540],\n",
      "        [-0.6240],\n",
      "        [-0.2983],\n",
      "        [ 0.8704],\n",
      "        [ 0.7470],\n",
      "        [ 0.7783],\n",
      "        [ 1.2273],\n",
      "        [ 1.2273],\n",
      "        [ 1.0718],\n",
      "        [-0.2983],\n",
      "        [-1.2107],\n",
      "        [ 1.0718],\n",
      "        [-1.4427],\n",
      "        [ 0.9591],\n",
      "        [-1.3169],\n",
      "        [ 0.5540],\n",
      "        [-0.2123],\n",
      "        [ 0.7470],\n",
      "        [ 0.5212],\n",
      "        [ 1.2273],\n",
      "        [ 0.7470],\n",
      "        [-0.7074],\n",
      "        [-0.1235],\n",
      "        [-1.0640],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8902],\n",
      "        [ 0.6192],\n",
      "        [ 1.2273],\n",
      "        [-1.6028],\n",
      "        [ 0.0626],\n",
      "        [-0.4089],\n",
      "        [-1.3169],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5700],\n",
      "        [-1.5437],\n",
      "        [ 0.6192],\n",
      "        [-1.4427],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2273],\n",
      "        [ 1.1843]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 460/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0152,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6515],\n",
      "        [ 0.5867],\n",
      "        [-0.0317],\n",
      "        [ 0.4883],\n",
      "        [ 0.9003],\n",
      "        [ 0.9591],\n",
      "        [ 0.9003],\n",
      "        [ 0.8093],\n",
      "        [-1.5847],\n",
      "        [-0.8903],\n",
      "        [ 0.5540],\n",
      "        [-0.2123],\n",
      "        [ 0.9299],\n",
      "        [-0.2123],\n",
      "        [ 0.5540],\n",
      "        [-0.6241],\n",
      "        [-0.2983],\n",
      "        [ 0.8703],\n",
      "        [ 0.7470],\n",
      "        [ 0.7783],\n",
      "        [ 1.2273],\n",
      "        [ 1.2273],\n",
      "        [ 1.0718],\n",
      "        [-0.2983],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4427],\n",
      "        [ 0.9591],\n",
      "        [-1.3168],\n",
      "        [ 0.5540],\n",
      "        [-0.2123],\n",
      "        [ 0.7470],\n",
      "        [ 0.5212],\n",
      "        [ 1.2273],\n",
      "        [ 0.7470],\n",
      "        [-0.7074],\n",
      "        [-0.1234],\n",
      "        [-1.0641],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8903],\n",
      "        [ 0.6192],\n",
      "        [ 1.2273],\n",
      "        [-1.6029],\n",
      "        [ 0.0626],\n",
      "        [-0.4089],\n",
      "        [-1.3168],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5700],\n",
      "        [-1.5437],\n",
      "        [ 0.6192],\n",
      "        [-1.4427],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2273],\n",
      "        [ 1.1843]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 461/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0152,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6515],\n",
      "        [ 0.5867],\n",
      "        [-0.0316],\n",
      "        [ 0.4883],\n",
      "        [ 0.9003],\n",
      "        [ 0.9591],\n",
      "        [ 0.9003],\n",
      "        [ 0.8093],\n",
      "        [-1.5847],\n",
      "        [-0.8903],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.9299],\n",
      "        [-0.2122],\n",
      "        [ 0.5540],\n",
      "        [-0.6241],\n",
      "        [-0.2982],\n",
      "        [ 0.8703],\n",
      "        [ 0.7470],\n",
      "        [ 0.7783],\n",
      "        [ 1.2274],\n",
      "        [ 1.2274],\n",
      "        [ 1.0718],\n",
      "        [-0.2982],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4427],\n",
      "        [ 0.9591],\n",
      "        [-1.3168],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.7470],\n",
      "        [ 0.5212],\n",
      "        [ 1.2274],\n",
      "        [ 0.7470],\n",
      "        [-0.7075],\n",
      "        [-0.1234],\n",
      "        [-1.0641],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8903],\n",
      "        [ 0.6192],\n",
      "        [ 1.2274],\n",
      "        [-1.6029],\n",
      "        [ 0.0627],\n",
      "        [-0.4089],\n",
      "        [-1.3168],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5701],\n",
      "        [-1.5437],\n",
      "        [ 0.6192],\n",
      "        [-1.4427],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2274],\n",
      "        [ 1.1844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 462/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0152,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6514],\n",
      "        [ 0.5866],\n",
      "        [-0.0316],\n",
      "        [ 0.4883],\n",
      "        [ 0.9003],\n",
      "        [ 0.9591],\n",
      "        [ 0.9003],\n",
      "        [ 0.8093],\n",
      "        [-1.5847],\n",
      "        [-0.8904],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.9299],\n",
      "        [-0.2122],\n",
      "        [ 0.5540],\n",
      "        [-0.6242],\n",
      "        [-0.2982],\n",
      "        [ 0.8703],\n",
      "        [ 0.7470],\n",
      "        [ 0.7783],\n",
      "        [ 1.2274],\n",
      "        [ 1.2274],\n",
      "        [ 1.0718],\n",
      "        [-0.2982],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4426],\n",
      "        [ 0.9591],\n",
      "        [-1.3167],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.7470],\n",
      "        [ 0.5212],\n",
      "        [ 1.2274],\n",
      "        [ 0.7470],\n",
      "        [-0.7075],\n",
      "        [-0.1233],\n",
      "        [-1.0641],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8904],\n",
      "        [ 0.6191],\n",
      "        [ 1.2274],\n",
      "        [-1.6030],\n",
      "        [ 0.0627],\n",
      "        [-0.4089],\n",
      "        [-1.3167],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5701],\n",
      "        [-1.5438],\n",
      "        [ 0.6191],\n",
      "        [-1.4426],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2274],\n",
      "        [ 1.1844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 463/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0152,\n",
      " epoch_time_duration: 0.0175\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6514],\n",
      "        [ 0.5866],\n",
      "        [-0.0316],\n",
      "        [ 0.4883],\n",
      "        [ 0.9003],\n",
      "        [ 0.9591],\n",
      "        [ 0.9003],\n",
      "        [ 0.8092],\n",
      "        [-1.5848],\n",
      "        [-0.8905],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.9299],\n",
      "        [-0.2122],\n",
      "        [ 0.5540],\n",
      "        [-0.6242],\n",
      "        [-0.2982],\n",
      "        [ 0.8703],\n",
      "        [ 0.7469],\n",
      "        [ 0.7782],\n",
      "        [ 1.2275],\n",
      "        [ 1.2275],\n",
      "        [ 1.0718],\n",
      "        [-0.2982],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4426],\n",
      "        [ 0.9591],\n",
      "        [-1.3167],\n",
      "        [ 0.5540],\n",
      "        [-0.2122],\n",
      "        [ 0.7469],\n",
      "        [ 0.5212],\n",
      "        [ 1.2275],\n",
      "        [ 0.7469],\n",
      "        [-0.7076],\n",
      "        [-0.1233],\n",
      "        [-1.0642],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8905],\n",
      "        [ 0.6191],\n",
      "        [ 1.2275],\n",
      "        [-1.6031],\n",
      "        [ 0.0627],\n",
      "        [-0.4089],\n",
      "        [-1.3167],\n",
      "        [ 1.0163],\n",
      "        [-0.4089],\n",
      "        [-0.5701],\n",
      "        [-1.5438],\n",
      "        [ 0.6191],\n",
      "        [-1.4426],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2275],\n",
      "        [ 1.1844]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 464/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0151,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1741],\n",
      "        [-1.1741],\n",
      "        [ 0.6514],\n",
      "        [ 0.5866],\n",
      "        [-0.0315],\n",
      "        [ 0.4883],\n",
      "        [ 0.9002],\n",
      "        [ 0.9591],\n",
      "        [ 0.9002],\n",
      "        [ 0.8092],\n",
      "        [-1.5848],\n",
      "        [-0.8906],\n",
      "        [ 0.5540],\n",
      "        [-0.2121],\n",
      "        [ 0.9298],\n",
      "        [-0.2121],\n",
      "        [ 0.5540],\n",
      "        [-0.6242],\n",
      "        [-0.2981],\n",
      "        [ 0.8703],\n",
      "        [ 0.7469],\n",
      "        [ 0.7782],\n",
      "        [ 1.2276],\n",
      "        [ 1.2276],\n",
      "        [ 1.0718],\n",
      "        [-0.2981],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4425],\n",
      "        [ 0.9591],\n",
      "        [-1.3167],\n",
      "        [ 0.5540],\n",
      "        [-0.2121],\n",
      "        [ 0.7469],\n",
      "        [ 0.5212],\n",
      "        [ 1.2276],\n",
      "        [ 0.7469],\n",
      "        [-0.7077],\n",
      "        [-0.1232],\n",
      "        [-1.0642],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8906],\n",
      "        [ 0.6191],\n",
      "        [ 1.2276],\n",
      "        [-1.6031],\n",
      "        [ 0.0628],\n",
      "        [-0.4088],\n",
      "        [-1.3167],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5701],\n",
      "        [-1.5438],\n",
      "        [ 0.6191],\n",
      "        [-1.4425],\n",
      "        [ 0.4223],\n",
      "        [-0.4360],\n",
      "        [ 0.4223],\n",
      "        [ 1.2276],\n",
      "        [ 1.1845]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 465/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0151,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6514],\n",
      "        [ 0.5866],\n",
      "        [-0.0315],\n",
      "        [ 0.4883],\n",
      "        [ 0.9002],\n",
      "        [ 0.9591],\n",
      "        [ 0.9002],\n",
      "        [ 0.8092],\n",
      "        [-1.5849],\n",
      "        [-0.8906],\n",
      "        [ 0.5539],\n",
      "        [-0.2121],\n",
      "        [ 0.9298],\n",
      "        [-0.2121],\n",
      "        [ 0.5539],\n",
      "        [-0.6243],\n",
      "        [-0.2981],\n",
      "        [ 0.8702],\n",
      "        [ 0.7469],\n",
      "        [ 0.7782],\n",
      "        [ 1.2276],\n",
      "        [ 1.2276],\n",
      "        [ 1.0718],\n",
      "        [-0.2981],\n",
      "        [-1.2106],\n",
      "        [ 1.0718],\n",
      "        [-1.4425],\n",
      "        [ 0.9591],\n",
      "        [-1.3166],\n",
      "        [ 0.5539],\n",
      "        [-0.2121],\n",
      "        [ 0.7469],\n",
      "        [ 0.5212],\n",
      "        [ 1.2276],\n",
      "        [ 0.7469],\n",
      "        [-0.7077],\n",
      "        [-0.1232],\n",
      "        [-1.0642],\n",
      "        [-1.1373],\n",
      "        [ 0.9591],\n",
      "        [-0.8906],\n",
      "        [ 0.6191],\n",
      "        [ 1.2276],\n",
      "        [-1.6032],\n",
      "        [ 0.0628],\n",
      "        [-0.4088],\n",
      "        [-1.3166],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5702],\n",
      "        [-1.5438],\n",
      "        [ 0.6191],\n",
      "        [-1.4425],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2276],\n",
      "        [ 1.1845]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 466/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0151,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6513],\n",
      "        [ 0.5866],\n",
      "        [-0.0314],\n",
      "        [ 0.4883],\n",
      "        [ 0.9002],\n",
      "        [ 0.9590],\n",
      "        [ 0.9002],\n",
      "        [ 0.8092],\n",
      "        [-1.5849],\n",
      "        [-0.8907],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.9298],\n",
      "        [-0.2120],\n",
      "        [ 0.5539],\n",
      "        [-0.6243],\n",
      "        [-0.2981],\n",
      "        [ 0.8702],\n",
      "        [ 0.7469],\n",
      "        [ 0.7782],\n",
      "        [ 1.2277],\n",
      "        [ 1.2277],\n",
      "        [ 1.0718],\n",
      "        [-0.2981],\n",
      "        [-1.2105],\n",
      "        [ 1.0718],\n",
      "        [-1.4424],\n",
      "        [ 0.9590],\n",
      "        [-1.3166],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.7469],\n",
      "        [ 0.5212],\n",
      "        [ 1.2277],\n",
      "        [ 0.7469],\n",
      "        [-0.7078],\n",
      "        [-0.1232],\n",
      "        [-1.0643],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8907],\n",
      "        [ 0.6191],\n",
      "        [ 1.2277],\n",
      "        [-1.6032],\n",
      "        [ 0.0628],\n",
      "        [-0.4088],\n",
      "        [-1.3166],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5702],\n",
      "        [-1.5438],\n",
      "        [ 0.6191],\n",
      "        [-1.4424],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2277],\n",
      "        [ 1.1845]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 467/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0150,\n",
      " epoch_time_duration: 0.0136\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6513],\n",
      "        [ 0.5866],\n",
      "        [-0.0314],\n",
      "        [ 0.4883],\n",
      "        [ 0.9002],\n",
      "        [ 0.9590],\n",
      "        [ 0.9002],\n",
      "        [ 0.8092],\n",
      "        [-1.5849],\n",
      "        [-0.8908],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.9298],\n",
      "        [-0.2120],\n",
      "        [ 0.5539],\n",
      "        [-0.6244],\n",
      "        [-0.2980],\n",
      "        [ 0.8702],\n",
      "        [ 0.7468],\n",
      "        [ 0.7781],\n",
      "        [ 1.2277],\n",
      "        [ 1.2277],\n",
      "        [ 1.0718],\n",
      "        [-0.2980],\n",
      "        [-1.2105],\n",
      "        [ 1.0718],\n",
      "        [-1.4424],\n",
      "        [ 0.9590],\n",
      "        [-1.3165],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.7468],\n",
      "        [ 0.5211],\n",
      "        [ 1.2277],\n",
      "        [ 0.7468],\n",
      "        [-0.7079],\n",
      "        [-0.1231],\n",
      "        [-1.0643],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8908],\n",
      "        [ 0.6190],\n",
      "        [ 1.2277],\n",
      "        [-1.6033],\n",
      "        [ 0.0629],\n",
      "        [-0.4088],\n",
      "        [-1.3165],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5702],\n",
      "        [-1.5438],\n",
      "        [ 0.6190],\n",
      "        [-1.4424],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2277],\n",
      "        [ 1.1846]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 468/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0150,\n",
      " epoch_time_duration: 0.0129\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6513],\n",
      "        [ 0.5865],\n",
      "        [-0.0314],\n",
      "        [ 0.4882],\n",
      "        [ 0.9002],\n",
      "        [ 0.9590],\n",
      "        [ 0.9002],\n",
      "        [ 0.8091],\n",
      "        [-1.5850],\n",
      "        [-0.8909],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.9298],\n",
      "        [-0.2120],\n",
      "        [ 0.5539],\n",
      "        [-0.6244],\n",
      "        [-0.2980],\n",
      "        [ 0.8702],\n",
      "        [ 0.7468],\n",
      "        [ 0.7781],\n",
      "        [ 1.2278],\n",
      "        [ 1.2278],\n",
      "        [ 1.0718],\n",
      "        [-0.2980],\n",
      "        [-1.2105],\n",
      "        [ 1.0718],\n",
      "        [-1.4424],\n",
      "        [ 0.9590],\n",
      "        [-1.3165],\n",
      "        [ 0.5539],\n",
      "        [-0.2120],\n",
      "        [ 0.7468],\n",
      "        [ 0.5211],\n",
      "        [ 1.2278],\n",
      "        [ 0.7468],\n",
      "        [-0.7079],\n",
      "        [-0.1231],\n",
      "        [-1.0643],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8909],\n",
      "        [ 0.6190],\n",
      "        [ 1.2278],\n",
      "        [-1.6034],\n",
      "        [ 0.0629],\n",
      "        [-0.4088],\n",
      "        [-1.3165],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5702],\n",
      "        [-1.5438],\n",
      "        [ 0.6190],\n",
      "        [-1.4424],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2278],\n",
      "        [ 1.1846]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 469/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0150,\n",
      " epoch_time_duration: 0.0128\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6513],\n",
      "        [ 0.5865],\n",
      "        [-0.0313],\n",
      "        [ 0.4882],\n",
      "        [ 0.9001],\n",
      "        [ 0.9590],\n",
      "        [ 0.9001],\n",
      "        [ 0.8091],\n",
      "        [-1.5850],\n",
      "        [-0.8909],\n",
      "        [ 0.5539],\n",
      "        [-0.2119],\n",
      "        [ 0.9298],\n",
      "        [-0.2119],\n",
      "        [ 0.5539],\n",
      "        [-0.6244],\n",
      "        [-0.2980],\n",
      "        [ 0.8701],\n",
      "        [ 0.7468],\n",
      "        [ 0.7781],\n",
      "        [ 1.2278],\n",
      "        [ 1.2278],\n",
      "        [ 1.0718],\n",
      "        [-0.2980],\n",
      "        [-1.2105],\n",
      "        [ 1.0718],\n",
      "        [-1.4423],\n",
      "        [ 0.9590],\n",
      "        [-1.3164],\n",
      "        [ 0.5539],\n",
      "        [-0.2119],\n",
      "        [ 0.7468],\n",
      "        [ 0.5211],\n",
      "        [ 1.2278],\n",
      "        [ 0.7468],\n",
      "        [-0.7080],\n",
      "        [-0.1230],\n",
      "        [-1.0644],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8909],\n",
      "        [ 0.6190],\n",
      "        [ 1.2278],\n",
      "        [-1.6034],\n",
      "        [ 0.0629],\n",
      "        [-0.4088],\n",
      "        [-1.3164],\n",
      "        [ 1.0163],\n",
      "        [-0.4088],\n",
      "        [-0.5703],\n",
      "        [-1.5438],\n",
      "        [ 0.6190],\n",
      "        [-1.4423],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2278],\n",
      "        [ 1.1847]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 470/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0150,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6513],\n",
      "        [ 0.5865],\n",
      "        [-0.0313],\n",
      "        [ 0.4882],\n",
      "        [ 0.9001],\n",
      "        [ 0.9590],\n",
      "        [ 0.9001],\n",
      "        [ 0.8091],\n",
      "        [-1.5851],\n",
      "        [-0.8910],\n",
      "        [ 0.5539],\n",
      "        [-0.2119],\n",
      "        [ 0.9297],\n",
      "        [-0.2119],\n",
      "        [ 0.5539],\n",
      "        [-0.6245],\n",
      "        [-0.2979],\n",
      "        [ 0.8701],\n",
      "        [ 0.7468],\n",
      "        [ 0.7781],\n",
      "        [ 1.2279],\n",
      "        [ 1.2279],\n",
      "        [ 1.0718],\n",
      "        [-0.2979],\n",
      "        [-1.2105],\n",
      "        [ 1.0718],\n",
      "        [-1.4423],\n",
      "        [ 0.9590],\n",
      "        [-1.3164],\n",
      "        [ 0.5539],\n",
      "        [-0.2119],\n",
      "        [ 0.7468],\n",
      "        [ 0.5211],\n",
      "        [ 1.2279],\n",
      "        [ 0.7468],\n",
      "        [-0.7080],\n",
      "        [-0.1230],\n",
      "        [-1.0644],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8910],\n",
      "        [ 0.6190],\n",
      "        [ 1.2279],\n",
      "        [-1.6035],\n",
      "        [ 0.0630],\n",
      "        [-0.4087],\n",
      "        [-1.3164],\n",
      "        [ 1.0163],\n",
      "        [-0.4087],\n",
      "        [-0.5703],\n",
      "        [-1.5438],\n",
      "        [ 0.6190],\n",
      "        [-1.4423],\n",
      "        [ 0.4223],\n",
      "        [-0.4359],\n",
      "        [ 0.4223],\n",
      "        [ 1.2279],\n",
      "        [ 1.1847]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 471/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0149,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6512],\n",
      "        [ 0.5865],\n",
      "        [-0.0312],\n",
      "        [ 0.4882],\n",
      "        [ 0.9001],\n",
      "        [ 0.9590],\n",
      "        [ 0.9001],\n",
      "        [ 0.8091],\n",
      "        [-1.5851],\n",
      "        [-0.8911],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.9297],\n",
      "        [-0.2118],\n",
      "        [ 0.5538],\n",
      "        [-0.6245],\n",
      "        [-0.2979],\n",
      "        [ 0.8701],\n",
      "        [ 0.7467],\n",
      "        [ 0.7780],\n",
      "        [ 1.2279],\n",
      "        [ 1.2279],\n",
      "        [ 1.0718],\n",
      "        [-0.2979],\n",
      "        [-1.2104],\n",
      "        [ 1.0718],\n",
      "        [-1.4422],\n",
      "        [ 0.9590],\n",
      "        [-1.3163],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.7467],\n",
      "        [ 0.5211],\n",
      "        [ 1.2279],\n",
      "        [ 0.7467],\n",
      "        [-0.7081],\n",
      "        [-0.1229],\n",
      "        [-1.0644],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8911],\n",
      "        [ 0.6189],\n",
      "        [ 1.2279],\n",
      "        [-1.6035],\n",
      "        [ 0.0630],\n",
      "        [-0.4087],\n",
      "        [-1.3163],\n",
      "        [ 1.0162],\n",
      "        [-0.4087],\n",
      "        [-0.5703],\n",
      "        [-1.5438],\n",
      "        [ 0.6189],\n",
      "        [-1.4422],\n",
      "        [ 0.4222],\n",
      "        [-0.4359],\n",
      "        [ 0.4222],\n",
      "        [ 1.2279],\n",
      "        [ 1.1847]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 472/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0149,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6512],\n",
      "        [ 0.5865],\n",
      "        [-0.0312],\n",
      "        [ 0.4882],\n",
      "        [ 0.9001],\n",
      "        [ 0.9590],\n",
      "        [ 0.9001],\n",
      "        [ 0.8090],\n",
      "        [-1.5851],\n",
      "        [-0.8911],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.9297],\n",
      "        [-0.2118],\n",
      "        [ 0.5538],\n",
      "        [-0.6246],\n",
      "        [-0.2979],\n",
      "        [ 0.8701],\n",
      "        [ 0.7467],\n",
      "        [ 0.7780],\n",
      "        [ 1.2280],\n",
      "        [ 1.2280],\n",
      "        [ 1.0718],\n",
      "        [-0.2979],\n",
      "        [-1.2104],\n",
      "        [ 1.0718],\n",
      "        [-1.4422],\n",
      "        [ 0.9590],\n",
      "        [-1.3163],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.7467],\n",
      "        [ 0.5211],\n",
      "        [ 1.2280],\n",
      "        [ 0.7467],\n",
      "        [-0.7082],\n",
      "        [-0.1229],\n",
      "        [-1.0644],\n",
      "        [-1.1374],\n",
      "        [ 0.9590],\n",
      "        [-0.8911],\n",
      "        [ 0.6189],\n",
      "        [ 1.2280],\n",
      "        [-1.6036],\n",
      "        [ 0.0630],\n",
      "        [-0.4087],\n",
      "        [-1.3163],\n",
      "        [ 1.0162],\n",
      "        [-0.4087],\n",
      "        [-0.5703],\n",
      "        [-1.5438],\n",
      "        [ 0.6189],\n",
      "        [-1.4422],\n",
      "        [ 0.4222],\n",
      "        [-0.4359],\n",
      "        [ 0.4222],\n",
      "        [ 1.2280],\n",
      "        [ 1.1848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 473/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0149,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6512],\n",
      "        [ 0.5864],\n",
      "        [-0.0312],\n",
      "        [ 0.4882],\n",
      "        [ 0.9001],\n",
      "        [ 0.9589],\n",
      "        [ 0.9001],\n",
      "        [ 0.8090],\n",
      "        [-1.5852],\n",
      "        [-0.8912],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.9297],\n",
      "        [-0.2118],\n",
      "        [ 0.5538],\n",
      "        [-0.6246],\n",
      "        [-0.2978],\n",
      "        [ 0.8701],\n",
      "        [ 0.7467],\n",
      "        [ 0.7780],\n",
      "        [ 1.2280],\n",
      "        [ 1.2280],\n",
      "        [ 1.0719],\n",
      "        [-0.2978],\n",
      "        [-1.2104],\n",
      "        [ 1.0719],\n",
      "        [-1.4422],\n",
      "        [ 0.9589],\n",
      "        [-1.3163],\n",
      "        [ 0.5538],\n",
      "        [-0.2118],\n",
      "        [ 0.7467],\n",
      "        [ 0.5211],\n",
      "        [ 1.2280],\n",
      "        [ 0.7467],\n",
      "        [-0.7082],\n",
      "        [-0.1229],\n",
      "        [-1.0645],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8912],\n",
      "        [ 0.6189],\n",
      "        [ 1.2280],\n",
      "        [-1.6036],\n",
      "        [ 0.0631],\n",
      "        [-0.4087],\n",
      "        [-1.3163],\n",
      "        [ 1.0162],\n",
      "        [-0.4087],\n",
      "        [-0.5704],\n",
      "        [-1.5438],\n",
      "        [ 0.6189],\n",
      "        [-1.4422],\n",
      "        [ 0.4222],\n",
      "        [-0.4359],\n",
      "        [ 0.4222],\n",
      "        [ 1.2280],\n",
      "        [ 1.1848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 474/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0149,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6512],\n",
      "        [ 0.5864],\n",
      "        [-0.0311],\n",
      "        [ 0.4882],\n",
      "        [ 0.9000],\n",
      "        [ 0.9589],\n",
      "        [ 0.9000],\n",
      "        [ 0.8090],\n",
      "        [-1.5852],\n",
      "        [-0.8913],\n",
      "        [ 0.5538],\n",
      "        [-0.2117],\n",
      "        [ 0.9297],\n",
      "        [-0.2117],\n",
      "        [ 0.5538],\n",
      "        [-0.6247],\n",
      "        [-0.2978],\n",
      "        [ 0.8700],\n",
      "        [ 0.7467],\n",
      "        [ 0.7780],\n",
      "        [ 1.2281],\n",
      "        [ 1.2281],\n",
      "        [ 1.0719],\n",
      "        [-0.2978],\n",
      "        [-1.2104],\n",
      "        [ 1.0719],\n",
      "        [-1.4421],\n",
      "        [ 0.9589],\n",
      "        [-1.3162],\n",
      "        [ 0.5538],\n",
      "        [-0.2117],\n",
      "        [ 0.7467],\n",
      "        [ 0.5210],\n",
      "        [ 1.2281],\n",
      "        [ 0.7467],\n",
      "        [-0.7083],\n",
      "        [-0.1228],\n",
      "        [-1.0645],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8913],\n",
      "        [ 0.6189],\n",
      "        [ 1.2281],\n",
      "        [-1.6037],\n",
      "        [ 0.0631],\n",
      "        [-0.4087],\n",
      "        [-1.3162],\n",
      "        [ 1.0162],\n",
      "        [-0.4087],\n",
      "        [-0.5704],\n",
      "        [-1.5438],\n",
      "        [ 0.6189],\n",
      "        [-1.4421],\n",
      "        [ 0.4222],\n",
      "        [-0.4359],\n",
      "        [ 0.4222],\n",
      "        [ 1.2281],\n",
      "        [ 1.1848]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 475/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0148,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6511],\n",
      "        [ 0.5864],\n",
      "        [-0.0311],\n",
      "        [ 0.4882],\n",
      "        [ 0.9000],\n",
      "        [ 0.9589],\n",
      "        [ 0.9000],\n",
      "        [ 0.8090],\n",
      "        [-1.5852],\n",
      "        [-0.8914],\n",
      "        [ 0.5538],\n",
      "        [-0.2117],\n",
      "        [ 0.9297],\n",
      "        [-0.2117],\n",
      "        [ 0.5538],\n",
      "        [-0.6247],\n",
      "        [-0.2978],\n",
      "        [ 0.8700],\n",
      "        [ 0.7466],\n",
      "        [ 0.7779],\n",
      "        [ 1.2281],\n",
      "        [ 1.2281],\n",
      "        [ 1.0719],\n",
      "        [-0.2978],\n",
      "        [-1.2104],\n",
      "        [ 1.0719],\n",
      "        [-1.4421],\n",
      "        [ 0.9589],\n",
      "        [-1.3162],\n",
      "        [ 0.5538],\n",
      "        [-0.2117],\n",
      "        [ 0.7466],\n",
      "        [ 0.5210],\n",
      "        [ 1.2281],\n",
      "        [ 0.7466],\n",
      "        [-0.7084],\n",
      "        [-0.1228],\n",
      "        [-1.0645],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8914],\n",
      "        [ 0.6189],\n",
      "        [ 1.2281],\n",
      "        [-1.6037],\n",
      "        [ 0.0631],\n",
      "        [-0.4087],\n",
      "        [-1.3162],\n",
      "        [ 1.0162],\n",
      "        [-0.4087],\n",
      "        [-0.5704],\n",
      "        [-1.5438],\n",
      "        [ 0.6189],\n",
      "        [-1.4421],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2281],\n",
      "        [ 1.1849]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 476/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0148,\n",
      " epoch_time_duration: 0.0128\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6511],\n",
      "        [ 0.5864],\n",
      "        [-0.0310],\n",
      "        [ 0.4882],\n",
      "        [ 0.9000],\n",
      "        [ 0.9589],\n",
      "        [ 0.9000],\n",
      "        [ 0.8089],\n",
      "        [-1.5853],\n",
      "        [-0.8914],\n",
      "        [ 0.5538],\n",
      "        [-0.2116],\n",
      "        [ 0.9296],\n",
      "        [-0.2116],\n",
      "        [ 0.5538],\n",
      "        [-0.6247],\n",
      "        [-0.2977],\n",
      "        [ 0.8700],\n",
      "        [ 0.7466],\n",
      "        [ 0.7779],\n",
      "        [ 1.2282],\n",
      "        [ 1.2282],\n",
      "        [ 1.0719],\n",
      "        [-0.2977],\n",
      "        [-1.2104],\n",
      "        [ 1.0719],\n",
      "        [-1.4420],\n",
      "        [ 0.9589],\n",
      "        [-1.3161],\n",
      "        [ 0.5538],\n",
      "        [-0.2116],\n",
      "        [ 0.7466],\n",
      "        [ 0.5210],\n",
      "        [ 1.2282],\n",
      "        [ 0.7466],\n",
      "        [-0.7084],\n",
      "        [-0.1227],\n",
      "        [-1.0646],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8914],\n",
      "        [ 0.6188],\n",
      "        [ 1.2282],\n",
      "        [-1.6038],\n",
      "        [ 0.0632],\n",
      "        [-0.4086],\n",
      "        [-1.3161],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5704],\n",
      "        [-1.5438],\n",
      "        [ 0.6188],\n",
      "        [-1.4420],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2282],\n",
      "        [ 1.1849]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 477/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0148,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6511],\n",
      "        [ 0.5864],\n",
      "        [-0.0310],\n",
      "        [ 0.4882],\n",
      "        [ 0.9000],\n",
      "        [ 0.9589],\n",
      "        [ 0.9000],\n",
      "        [ 0.8089],\n",
      "        [-1.5853],\n",
      "        [-0.8915],\n",
      "        [ 0.5538],\n",
      "        [-0.2116],\n",
      "        [ 0.9296],\n",
      "        [-0.2116],\n",
      "        [ 0.5538],\n",
      "        [-0.6248],\n",
      "        [-0.2977],\n",
      "        [ 0.8700],\n",
      "        [ 0.7466],\n",
      "        [ 0.7779],\n",
      "        [ 1.2282],\n",
      "        [ 1.2282],\n",
      "        [ 1.0719],\n",
      "        [-0.2977],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4420],\n",
      "        [ 0.9589],\n",
      "        [-1.3161],\n",
      "        [ 0.5538],\n",
      "        [-0.2116],\n",
      "        [ 0.7466],\n",
      "        [ 0.5210],\n",
      "        [ 1.2282],\n",
      "        [ 0.7466],\n",
      "        [-0.7085],\n",
      "        [-0.1227],\n",
      "        [-1.0646],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8915],\n",
      "        [ 0.6188],\n",
      "        [ 1.2282],\n",
      "        [-1.6039],\n",
      "        [ 0.0632],\n",
      "        [-0.4086],\n",
      "        [-1.3161],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5705],\n",
      "        [-1.5438],\n",
      "        [ 0.6188],\n",
      "        [-1.4420],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2282],\n",
      "        [ 1.1849]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 478/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0147,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6511],\n",
      "        [ 0.5863],\n",
      "        [-0.0310],\n",
      "        [ 0.4881],\n",
      "        [ 0.9000],\n",
      "        [ 0.9589],\n",
      "        [ 0.9000],\n",
      "        [ 0.8089],\n",
      "        [-1.5854],\n",
      "        [-0.8916],\n",
      "        [ 0.5537],\n",
      "        [-0.2116],\n",
      "        [ 0.9296],\n",
      "        [-0.2116],\n",
      "        [ 0.5537],\n",
      "        [-0.6248],\n",
      "        [-0.2977],\n",
      "        [ 0.8699],\n",
      "        [ 0.7466],\n",
      "        [ 0.7779],\n",
      "        [ 1.2283],\n",
      "        [ 1.2283],\n",
      "        [ 1.0719],\n",
      "        [-0.2977],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4420],\n",
      "        [ 0.9589],\n",
      "        [-1.3161],\n",
      "        [ 0.5537],\n",
      "        [-0.2116],\n",
      "        [ 0.7466],\n",
      "        [ 0.5210],\n",
      "        [ 1.2283],\n",
      "        [ 0.7466],\n",
      "        [-0.7085],\n",
      "        [-0.1226],\n",
      "        [-1.0646],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8916],\n",
      "        [ 0.6188],\n",
      "        [ 1.2283],\n",
      "        [-1.6039],\n",
      "        [ 0.0632],\n",
      "        [-0.4086],\n",
      "        [-1.3161],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5705],\n",
      "        [-1.5438],\n",
      "        [ 0.6188],\n",
      "        [-1.4420],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2283],\n",
      "        [ 1.1850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 479/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0147,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6511],\n",
      "        [ 0.5863],\n",
      "        [-0.0309],\n",
      "        [ 0.4881],\n",
      "        [ 0.8999],\n",
      "        [ 0.9589],\n",
      "        [ 0.8999],\n",
      "        [ 0.8089],\n",
      "        [-1.5854],\n",
      "        [-0.8917],\n",
      "        [ 0.5537],\n",
      "        [-0.2115],\n",
      "        [ 0.9296],\n",
      "        [-0.2115],\n",
      "        [ 0.5537],\n",
      "        [-0.6249],\n",
      "        [-0.2976],\n",
      "        [ 0.8699],\n",
      "        [ 0.7465],\n",
      "        [ 0.7778],\n",
      "        [ 1.2284],\n",
      "        [ 1.2284],\n",
      "        [ 1.0719],\n",
      "        [-0.2976],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4419],\n",
      "        [ 0.9589],\n",
      "        [-1.3160],\n",
      "        [ 0.5537],\n",
      "        [-0.2115],\n",
      "        [ 0.7465],\n",
      "        [ 0.5210],\n",
      "        [ 1.2284],\n",
      "        [ 0.7465],\n",
      "        [-0.7086],\n",
      "        [-0.1226],\n",
      "        [-1.0647],\n",
      "        [-1.1374],\n",
      "        [ 0.9589],\n",
      "        [-0.8917],\n",
      "        [ 0.6188],\n",
      "        [ 1.2284],\n",
      "        [-1.6040],\n",
      "        [ 0.0633],\n",
      "        [-0.4086],\n",
      "        [-1.3160],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5705],\n",
      "        [-1.5439],\n",
      "        [ 0.6188],\n",
      "        [-1.4419],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2284],\n",
      "        [ 1.1850]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 480/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0147,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6510],\n",
      "        [ 0.5863],\n",
      "        [-0.0309],\n",
      "        [ 0.4881],\n",
      "        [ 0.8999],\n",
      "        [ 0.9588],\n",
      "        [ 0.8999],\n",
      "        [ 0.8088],\n",
      "        [-1.5854],\n",
      "        [-0.8917],\n",
      "        [ 0.5537],\n",
      "        [-0.2115],\n",
      "        [ 0.9296],\n",
      "        [-0.2115],\n",
      "        [ 0.5537],\n",
      "        [-0.6249],\n",
      "        [-0.2976],\n",
      "        [ 0.8699],\n",
      "        [ 0.7465],\n",
      "        [ 0.7778],\n",
      "        [ 1.2284],\n",
      "        [ 1.2284],\n",
      "        [ 1.0719],\n",
      "        [-0.2976],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4419],\n",
      "        [ 0.9588],\n",
      "        [-1.3160],\n",
      "        [ 0.5537],\n",
      "        [-0.2115],\n",
      "        [ 0.7465],\n",
      "        [ 0.5210],\n",
      "        [ 1.2284],\n",
      "        [ 0.7465],\n",
      "        [-0.7087],\n",
      "        [-0.1226],\n",
      "        [-1.0647],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8917],\n",
      "        [ 0.6188],\n",
      "        [ 1.2284],\n",
      "        [-1.6040],\n",
      "        [ 0.0633],\n",
      "        [-0.4086],\n",
      "        [-1.3160],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5705],\n",
      "        [-1.5439],\n",
      "        [ 0.6188],\n",
      "        [-1.4419],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2284],\n",
      "        [ 1.1851]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 481/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0147,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6510],\n",
      "        [ 0.5863],\n",
      "        [-0.0308],\n",
      "        [ 0.4881],\n",
      "        [ 0.8999],\n",
      "        [ 0.9588],\n",
      "        [ 0.8999],\n",
      "        [ 0.8088],\n",
      "        [-1.5855],\n",
      "        [-0.8918],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.9296],\n",
      "        [-0.2114],\n",
      "        [ 0.5537],\n",
      "        [-0.6249],\n",
      "        [-0.2976],\n",
      "        [ 0.8699],\n",
      "        [ 0.7465],\n",
      "        [ 0.7778],\n",
      "        [ 1.2285],\n",
      "        [ 1.2285],\n",
      "        [ 1.0719],\n",
      "        [-0.2976],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4419],\n",
      "        [ 0.9588],\n",
      "        [-1.3159],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.7465],\n",
      "        [ 0.5210],\n",
      "        [ 1.2285],\n",
      "        [ 0.7465],\n",
      "        [-0.7087],\n",
      "        [-0.1225],\n",
      "        [-1.0647],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8918],\n",
      "        [ 0.6187],\n",
      "        [ 1.2285],\n",
      "        [-1.6041],\n",
      "        [ 0.0633],\n",
      "        [-0.4086],\n",
      "        [-1.3159],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5706],\n",
      "        [-1.5439],\n",
      "        [ 0.6187],\n",
      "        [-1.4419],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2285],\n",
      "        [ 1.1851]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 482/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0146,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6510],\n",
      "        [ 0.5863],\n",
      "        [-0.0308],\n",
      "        [ 0.4881],\n",
      "        [ 0.8999],\n",
      "        [ 0.9588],\n",
      "        [ 0.8999],\n",
      "        [ 0.8088],\n",
      "        [-1.5855],\n",
      "        [-0.8919],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.9295],\n",
      "        [-0.2114],\n",
      "        [ 0.5537],\n",
      "        [-0.6250],\n",
      "        [-0.2975],\n",
      "        [ 0.8699],\n",
      "        [ 0.7465],\n",
      "        [ 0.7778],\n",
      "        [ 1.2285],\n",
      "        [ 1.2285],\n",
      "        [ 1.0719],\n",
      "        [-0.2975],\n",
      "        [-1.2103],\n",
      "        [ 1.0719],\n",
      "        [-1.4418],\n",
      "        [ 0.9588],\n",
      "        [-1.3159],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.7465],\n",
      "        [ 0.5209],\n",
      "        [ 1.2285],\n",
      "        [ 0.7465],\n",
      "        [-0.7088],\n",
      "        [-0.1225],\n",
      "        [-1.0648],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8919],\n",
      "        [ 0.6187],\n",
      "        [ 1.2285],\n",
      "        [-1.6041],\n",
      "        [ 0.0634],\n",
      "        [-0.4086],\n",
      "        [-1.3159],\n",
      "        [ 1.0162],\n",
      "        [-0.4086],\n",
      "        [-0.5706],\n",
      "        [-1.5439],\n",
      "        [ 0.6187],\n",
      "        [-1.4418],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2285],\n",
      "        [ 1.1851]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 483/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0146,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6510],\n",
      "        [ 0.5863],\n",
      "        [-0.0308],\n",
      "        [ 0.4881],\n",
      "        [ 0.8999],\n",
      "        [ 0.9588],\n",
      "        [ 0.8999],\n",
      "        [ 0.8088],\n",
      "        [-1.5856],\n",
      "        [-0.8919],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.9295],\n",
      "        [-0.2114],\n",
      "        [ 0.5537],\n",
      "        [-0.6250],\n",
      "        [-0.2975],\n",
      "        [ 0.8698],\n",
      "        [ 0.7464],\n",
      "        [ 0.7777],\n",
      "        [ 1.2286],\n",
      "        [ 1.2286],\n",
      "        [ 1.0719],\n",
      "        [-0.2975],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4418],\n",
      "        [ 0.9588],\n",
      "        [-1.3158],\n",
      "        [ 0.5537],\n",
      "        [-0.2114],\n",
      "        [ 0.7464],\n",
      "        [ 0.5209],\n",
      "        [ 1.2286],\n",
      "        [ 0.7464],\n",
      "        [-0.7088],\n",
      "        [-0.1224],\n",
      "        [-1.0648],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8919],\n",
      "        [ 0.6187],\n",
      "        [ 1.2286],\n",
      "        [-1.6042],\n",
      "        [ 0.0634],\n",
      "        [-0.4085],\n",
      "        [-1.3158],\n",
      "        [ 1.0162],\n",
      "        [-0.4085],\n",
      "        [-0.5706],\n",
      "        [-1.5439],\n",
      "        [ 0.6187],\n",
      "        [-1.4418],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2286],\n",
      "        [ 1.1852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 484/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0146,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1740],\n",
      "        [-1.1740],\n",
      "        [ 0.6509],\n",
      "        [ 0.5862],\n",
      "        [-0.0307],\n",
      "        [ 0.4881],\n",
      "        [ 0.8998],\n",
      "        [ 0.9588],\n",
      "        [ 0.8998],\n",
      "        [ 0.8087],\n",
      "        [-1.5856],\n",
      "        [-0.8920],\n",
      "        [ 0.5536],\n",
      "        [-0.2113],\n",
      "        [ 0.9295],\n",
      "        [-0.2113],\n",
      "        [ 0.5536],\n",
      "        [-0.6250],\n",
      "        [-0.2975],\n",
      "        [ 0.8698],\n",
      "        [ 0.7464],\n",
      "        [ 0.7777],\n",
      "        [ 1.2286],\n",
      "        [ 1.2286],\n",
      "        [ 1.0719],\n",
      "        [-0.2975],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4417],\n",
      "        [ 0.9588],\n",
      "        [-1.3158],\n",
      "        [ 0.5536],\n",
      "        [-0.2113],\n",
      "        [ 0.7464],\n",
      "        [ 0.5209],\n",
      "        [ 1.2286],\n",
      "        [ 0.7464],\n",
      "        [-0.7089],\n",
      "        [-0.1224],\n",
      "        [-1.0648],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8920],\n",
      "        [ 0.6187],\n",
      "        [ 1.2286],\n",
      "        [-1.6043],\n",
      "        [ 0.0634],\n",
      "        [-0.4085],\n",
      "        [-1.3158],\n",
      "        [ 1.0162],\n",
      "        [-0.4085],\n",
      "        [-0.5706],\n",
      "        [-1.5439],\n",
      "        [ 0.6187],\n",
      "        [-1.4417],\n",
      "        [ 0.4222],\n",
      "        [-0.4358],\n",
      "        [ 0.4222],\n",
      "        [ 1.2286],\n",
      "        [ 1.1852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 485/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0146,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6509],\n",
      "        [ 0.5862],\n",
      "        [-0.0307],\n",
      "        [ 0.4881],\n",
      "        [ 0.8998],\n",
      "        [ 0.9588],\n",
      "        [ 0.8998],\n",
      "        [ 0.8087],\n",
      "        [-1.5856],\n",
      "        [-0.8921],\n",
      "        [ 0.5536],\n",
      "        [-0.2113],\n",
      "        [ 0.9295],\n",
      "        [-0.2113],\n",
      "        [ 0.5536],\n",
      "        [-0.6251],\n",
      "        [-0.2974],\n",
      "        [ 0.8698],\n",
      "        [ 0.7464],\n",
      "        [ 0.7777],\n",
      "        [ 1.2287],\n",
      "        [ 1.2287],\n",
      "        [ 1.0719],\n",
      "        [-0.2974],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4417],\n",
      "        [ 0.9588],\n",
      "        [-1.3158],\n",
      "        [ 0.5536],\n",
      "        [-0.2113],\n",
      "        [ 0.7464],\n",
      "        [ 0.5209],\n",
      "        [ 1.2287],\n",
      "        [ 0.7464],\n",
      "        [-0.7090],\n",
      "        [-0.1223],\n",
      "        [-1.0649],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8921],\n",
      "        [ 0.6187],\n",
      "        [ 1.2287],\n",
      "        [-1.6043],\n",
      "        [ 0.0635],\n",
      "        [-0.4085],\n",
      "        [-1.3158],\n",
      "        [ 1.0162],\n",
      "        [-0.4085],\n",
      "        [-0.5707],\n",
      "        [-1.5439],\n",
      "        [ 0.6187],\n",
      "        [-1.4417],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2287],\n",
      "        [ 1.1852]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 486/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0145,\n",
      " epoch_time_duration: 0.0199\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6509],\n",
      "        [ 0.5862],\n",
      "        [-0.0306],\n",
      "        [ 0.4881],\n",
      "        [ 0.8998],\n",
      "        [ 0.9588],\n",
      "        [ 0.8998],\n",
      "        [ 0.8087],\n",
      "        [-1.5857],\n",
      "        [-0.8921],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.9295],\n",
      "        [-0.2112],\n",
      "        [ 0.5536],\n",
      "        [-0.6251],\n",
      "        [-0.2974],\n",
      "        [ 0.8698],\n",
      "        [ 0.7464],\n",
      "        [ 0.7777],\n",
      "        [ 1.2287],\n",
      "        [ 1.2287],\n",
      "        [ 1.0719],\n",
      "        [-0.2974],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4417],\n",
      "        [ 0.9588],\n",
      "        [-1.3157],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.7464],\n",
      "        [ 0.5209],\n",
      "        [ 1.2287],\n",
      "        [ 0.7464],\n",
      "        [-0.7090],\n",
      "        [-0.1223],\n",
      "        [-1.0649],\n",
      "        [-1.1375],\n",
      "        [ 0.9588],\n",
      "        [-0.8921],\n",
      "        [ 0.6186],\n",
      "        [ 1.2287],\n",
      "        [-1.6044],\n",
      "        [ 0.0635],\n",
      "        [-0.4085],\n",
      "        [-1.3157],\n",
      "        [ 1.0162],\n",
      "        [-0.4085],\n",
      "        [-0.5707],\n",
      "        [-1.5439],\n",
      "        [ 0.6186],\n",
      "        [-1.4417],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2287],\n",
      "        [ 1.1853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 487/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0145,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6509],\n",
      "        [ 0.5862],\n",
      "        [-0.0306],\n",
      "        [ 0.4881],\n",
      "        [ 0.8998],\n",
      "        [ 0.9587],\n",
      "        [ 0.8998],\n",
      "        [ 0.8087],\n",
      "        [-1.5857],\n",
      "        [-0.8922],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.9294],\n",
      "        [-0.2112],\n",
      "        [ 0.5536],\n",
      "        [-0.6252],\n",
      "        [-0.2974],\n",
      "        [ 0.8697],\n",
      "        [ 0.7463],\n",
      "        [ 0.7776],\n",
      "        [ 1.2288],\n",
      "        [ 1.2288],\n",
      "        [ 1.0719],\n",
      "        [-0.2974],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4416],\n",
      "        [ 0.9587],\n",
      "        [-1.3157],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.7463],\n",
      "        [ 0.5209],\n",
      "        [ 1.2288],\n",
      "        [ 0.7463],\n",
      "        [-0.7091],\n",
      "        [-0.1223],\n",
      "        [-1.0649],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8922],\n",
      "        [ 0.6186],\n",
      "        [ 1.2288],\n",
      "        [-1.6044],\n",
      "        [ 0.0635],\n",
      "        [-0.4085],\n",
      "        [-1.3157],\n",
      "        [ 1.0162],\n",
      "        [-0.4085],\n",
      "        [-0.5707],\n",
      "        [-1.5439],\n",
      "        [ 0.6186],\n",
      "        [-1.4416],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2288],\n",
      "        [ 1.1853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 488/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0145,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6509],\n",
      "        [ 0.5862],\n",
      "        [-0.0306],\n",
      "        [ 0.4880],\n",
      "        [ 0.8998],\n",
      "        [ 0.9587],\n",
      "        [ 0.8998],\n",
      "        [ 0.8086],\n",
      "        [-1.5857],\n",
      "        [-0.8923],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.9294],\n",
      "        [-0.2112],\n",
      "        [ 0.5536],\n",
      "        [-0.6252],\n",
      "        [-0.2973],\n",
      "        [ 0.8697],\n",
      "        [ 0.7463],\n",
      "        [ 0.7776],\n",
      "        [ 1.2288],\n",
      "        [ 1.2288],\n",
      "        [ 1.0719],\n",
      "        [-0.2973],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4416],\n",
      "        [ 0.9587],\n",
      "        [-1.3156],\n",
      "        [ 0.5536],\n",
      "        [-0.2112],\n",
      "        [ 0.7463],\n",
      "        [ 0.5209],\n",
      "        [ 1.2288],\n",
      "        [ 0.7463],\n",
      "        [-0.7091],\n",
      "        [-0.1222],\n",
      "        [-1.0650],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8923],\n",
      "        [ 0.6186],\n",
      "        [ 1.2288],\n",
      "        [-1.6045],\n",
      "        [ 0.0636],\n",
      "        [-0.4085],\n",
      "        [-1.3156],\n",
      "        [ 1.0161],\n",
      "        [-0.4085],\n",
      "        [-0.5707],\n",
      "        [-1.5439],\n",
      "        [ 0.6186],\n",
      "        [-1.4416],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2288],\n",
      "        [ 1.1853]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 489/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0145,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6508],\n",
      "        [ 0.5862],\n",
      "        [-0.0305],\n",
      "        [ 0.4880],\n",
      "        [ 0.8997],\n",
      "        [ 0.9587],\n",
      "        [ 0.8997],\n",
      "        [ 0.8086],\n",
      "        [-1.5858],\n",
      "        [-0.8924],\n",
      "        [ 0.5536],\n",
      "        [-0.2111],\n",
      "        [ 0.9294],\n",
      "        [-0.2111],\n",
      "        [ 0.5536],\n",
      "        [-0.6252],\n",
      "        [-0.2973],\n",
      "        [ 0.8697],\n",
      "        [ 0.7463],\n",
      "        [ 0.7776],\n",
      "        [ 1.2289],\n",
      "        [ 1.2289],\n",
      "        [ 1.0719],\n",
      "        [-0.2973],\n",
      "        [-1.2102],\n",
      "        [ 1.0719],\n",
      "        [-1.4415],\n",
      "        [ 0.9587],\n",
      "        [-1.3156],\n",
      "        [ 0.5536],\n",
      "        [-0.2111],\n",
      "        [ 0.7463],\n",
      "        [ 0.5208],\n",
      "        [ 1.2289],\n",
      "        [ 0.7463],\n",
      "        [-0.7092],\n",
      "        [-0.1222],\n",
      "        [-1.0650],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8924],\n",
      "        [ 0.6186],\n",
      "        [ 1.2289],\n",
      "        [-1.6045],\n",
      "        [ 0.0636],\n",
      "        [-0.4084],\n",
      "        [-1.3156],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5708],\n",
      "        [-1.5439],\n",
      "        [ 0.6186],\n",
      "        [-1.4415],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2289],\n",
      "        [ 1.1854]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 490/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0144,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6508],\n",
      "        [ 0.5861],\n",
      "        [-0.0305],\n",
      "        [ 0.4880],\n",
      "        [ 0.8997],\n",
      "        [ 0.9587],\n",
      "        [ 0.8997],\n",
      "        [ 0.8086],\n",
      "        [-1.5858],\n",
      "        [-0.8924],\n",
      "        [ 0.5535],\n",
      "        [-0.2111],\n",
      "        [ 0.9294],\n",
      "        [-0.2111],\n",
      "        [ 0.5535],\n",
      "        [-0.6253],\n",
      "        [-0.2973],\n",
      "        [ 0.8697],\n",
      "        [ 0.7463],\n",
      "        [ 0.7776],\n",
      "        [ 1.2289],\n",
      "        [ 1.2289],\n",
      "        [ 1.0719],\n",
      "        [-0.2973],\n",
      "        [-1.2101],\n",
      "        [ 1.0719],\n",
      "        [-1.4415],\n",
      "        [ 0.9587],\n",
      "        [-1.3156],\n",
      "        [ 0.5535],\n",
      "        [-0.2111],\n",
      "        [ 0.7463],\n",
      "        [ 0.5208],\n",
      "        [ 1.2289],\n",
      "        [ 0.7463],\n",
      "        [-0.7092],\n",
      "        [-0.1221],\n",
      "        [-1.0650],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8924],\n",
      "        [ 0.6186],\n",
      "        [ 1.2289],\n",
      "        [-1.6046],\n",
      "        [ 0.0636],\n",
      "        [-0.4084],\n",
      "        [-1.3156],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5708],\n",
      "        [-1.5439],\n",
      "        [ 0.6186],\n",
      "        [-1.4415],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2289],\n",
      "        [ 1.1854]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 491/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0144,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6508],\n",
      "        [ 0.5861],\n",
      "        [-0.0304],\n",
      "        [ 0.4880],\n",
      "        [ 0.8997],\n",
      "        [ 0.9587],\n",
      "        [ 0.8997],\n",
      "        [ 0.8086],\n",
      "        [-1.5858],\n",
      "        [-0.8925],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.9294],\n",
      "        [-0.2110],\n",
      "        [ 0.5535],\n",
      "        [-0.6253],\n",
      "        [-0.2972],\n",
      "        [ 0.8697],\n",
      "        [ 0.7462],\n",
      "        [ 0.7775],\n",
      "        [ 1.2290],\n",
      "        [ 1.2290],\n",
      "        [ 1.0719],\n",
      "        [-0.2972],\n",
      "        [-1.2101],\n",
      "        [ 1.0719],\n",
      "        [-1.4415],\n",
      "        [ 0.9587],\n",
      "        [-1.3155],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.7462],\n",
      "        [ 0.5208],\n",
      "        [ 1.2290],\n",
      "        [ 0.7462],\n",
      "        [-0.7093],\n",
      "        [-0.1221],\n",
      "        [-1.0651],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8925],\n",
      "        [ 0.6185],\n",
      "        [ 1.2290],\n",
      "        [-1.6046],\n",
      "        [ 0.0637],\n",
      "        [-0.4084],\n",
      "        [-1.3155],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5708],\n",
      "        [-1.5439],\n",
      "        [ 0.6185],\n",
      "        [-1.4415],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2290],\n",
      "        [ 1.1854]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 492/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0144,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6508],\n",
      "        [ 0.5861],\n",
      "        [-0.0304],\n",
      "        [ 0.4880],\n",
      "        [ 0.8997],\n",
      "        [ 0.9587],\n",
      "        [ 0.8997],\n",
      "        [ 0.8085],\n",
      "        [-1.5859],\n",
      "        [-0.8926],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.9294],\n",
      "        [-0.2110],\n",
      "        [ 0.5535],\n",
      "        [-0.6254],\n",
      "        [-0.2972],\n",
      "        [ 0.8696],\n",
      "        [ 0.7462],\n",
      "        [ 0.7775],\n",
      "        [ 1.2290],\n",
      "        [ 1.2290],\n",
      "        [ 1.0719],\n",
      "        [-0.2972],\n",
      "        [-1.2101],\n",
      "        [ 1.0719],\n",
      "        [-1.4414],\n",
      "        [ 0.9587],\n",
      "        [-1.3155],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.7462],\n",
      "        [ 0.5208],\n",
      "        [ 1.2290],\n",
      "        [ 0.7462],\n",
      "        [-0.7094],\n",
      "        [-0.1221],\n",
      "        [-1.0651],\n",
      "        [-1.1375],\n",
      "        [ 0.9587],\n",
      "        [-0.8926],\n",
      "        [ 0.6185],\n",
      "        [ 1.2290],\n",
      "        [-1.6047],\n",
      "        [ 0.0637],\n",
      "        [-0.4084],\n",
      "        [-1.3155],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5708],\n",
      "        [-1.5439],\n",
      "        [ 0.6185],\n",
      "        [-1.4414],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2290],\n",
      "        [ 1.1855]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 493/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0143,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6507],\n",
      "        [ 0.5861],\n",
      "        [-0.0304],\n",
      "        [ 0.4880],\n",
      "        [ 0.8997],\n",
      "        [ 0.9587],\n",
      "        [ 0.8997],\n",
      "        [ 0.8085],\n",
      "        [-1.5859],\n",
      "        [-0.8926],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.9293],\n",
      "        [-0.2110],\n",
      "        [ 0.5535],\n",
      "        [-0.6254],\n",
      "        [-0.2972],\n",
      "        [ 0.8696],\n",
      "        [ 0.7462],\n",
      "        [ 0.7775],\n",
      "        [ 1.2291],\n",
      "        [ 1.2291],\n",
      "        [ 1.0719],\n",
      "        [-0.2972],\n",
      "        [-1.2101],\n",
      "        [ 1.0719],\n",
      "        [-1.4414],\n",
      "        [ 0.9587],\n",
      "        [-1.3154],\n",
      "        [ 0.5535],\n",
      "        [-0.2110],\n",
      "        [ 0.7462],\n",
      "        [ 0.5208],\n",
      "        [ 1.2291],\n",
      "        [ 0.7462],\n",
      "        [-0.7094],\n",
      "        [-0.1220],\n",
      "        [-1.0651],\n",
      "        [-1.1376],\n",
      "        [ 0.9587],\n",
      "        [-0.8926],\n",
      "        [ 0.6185],\n",
      "        [ 1.2291],\n",
      "        [-1.6047],\n",
      "        [ 0.0637],\n",
      "        [-0.4084],\n",
      "        [-1.3154],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5709],\n",
      "        [-1.5439],\n",
      "        [ 0.6185],\n",
      "        [-1.4414],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2291],\n",
      "        [ 1.1855]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 494/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0143,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6507],\n",
      "        [ 0.5861],\n",
      "        [-0.0303],\n",
      "        [ 0.4880],\n",
      "        [ 0.8996],\n",
      "        [ 0.9586],\n",
      "        [ 0.8996],\n",
      "        [ 0.8085],\n",
      "        [-1.5860],\n",
      "        [-0.8927],\n",
      "        [ 0.5535],\n",
      "        [-0.2109],\n",
      "        [ 0.9293],\n",
      "        [-0.2109],\n",
      "        [ 0.5535],\n",
      "        [-0.6254],\n",
      "        [-0.2971],\n",
      "        [ 0.8696],\n",
      "        [ 0.7462],\n",
      "        [ 0.7775],\n",
      "        [ 1.2291],\n",
      "        [ 1.2291],\n",
      "        [ 1.0720],\n",
      "        [-0.2971],\n",
      "        [-1.2101],\n",
      "        [ 1.0720],\n",
      "        [-1.4413],\n",
      "        [ 0.9586],\n",
      "        [-1.3154],\n",
      "        [ 0.5535],\n",
      "        [-0.2109],\n",
      "        [ 0.7462],\n",
      "        [ 0.5208],\n",
      "        [ 1.2291],\n",
      "        [ 0.7462],\n",
      "        [-0.7095],\n",
      "        [-0.1220],\n",
      "        [-1.0651],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8927],\n",
      "        [ 0.6185],\n",
      "        [ 1.2291],\n",
      "        [-1.6048],\n",
      "        [ 0.0638],\n",
      "        [-0.4084],\n",
      "        [-1.3154],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5709],\n",
      "        [-1.5439],\n",
      "        [ 0.6185],\n",
      "        [-1.4413],\n",
      "        [ 0.4222],\n",
      "        [-0.4357],\n",
      "        [ 0.4222],\n",
      "        [ 1.2291],\n",
      "        [ 1.1856]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 495/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0143,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6507],\n",
      "        [ 0.5860],\n",
      "        [-0.0303],\n",
      "        [ 0.4880],\n",
      "        [ 0.8996],\n",
      "        [ 0.9586],\n",
      "        [ 0.8996],\n",
      "        [ 0.8085],\n",
      "        [-1.5860],\n",
      "        [-0.8928],\n",
      "        [ 0.5535],\n",
      "        [-0.2109],\n",
      "        [ 0.9293],\n",
      "        [-0.2109],\n",
      "        [ 0.5535],\n",
      "        [-0.6255],\n",
      "        [-0.2971],\n",
      "        [ 0.8696],\n",
      "        [ 0.7461],\n",
      "        [ 0.7774],\n",
      "        [ 1.2292],\n",
      "        [ 1.2292],\n",
      "        [ 1.0720],\n",
      "        [-0.2971],\n",
      "        [-1.2101],\n",
      "        [ 1.0720],\n",
      "        [-1.4413],\n",
      "        [ 0.9586],\n",
      "        [-1.3154],\n",
      "        [ 0.5535],\n",
      "        [-0.2109],\n",
      "        [ 0.7461],\n",
      "        [ 0.5208],\n",
      "        [ 1.2292],\n",
      "        [ 0.7461],\n",
      "        [-0.7095],\n",
      "        [-0.1219],\n",
      "        [-1.0652],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8928],\n",
      "        [ 0.6185],\n",
      "        [ 1.2292],\n",
      "        [-1.6048],\n",
      "        [ 0.0638],\n",
      "        [-0.4084],\n",
      "        [-1.3154],\n",
      "        [ 1.0161],\n",
      "        [-0.4084],\n",
      "        [-0.5709],\n",
      "        [-1.5439],\n",
      "        [ 0.6185],\n",
      "        [-1.4413],\n",
      "        [ 0.4222],\n",
      "        [-0.4356],\n",
      "        [ 0.4222],\n",
      "        [ 1.2292],\n",
      "        [ 1.1856]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 496/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0143,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6507],\n",
      "        [ 0.5860],\n",
      "        [-0.0303],\n",
      "        [ 0.4880],\n",
      "        [ 0.8996],\n",
      "        [ 0.9586],\n",
      "        [ 0.8996],\n",
      "        [ 0.8084],\n",
      "        [-1.5860],\n",
      "        [-0.8928],\n",
      "        [ 0.5535],\n",
      "        [-0.2108],\n",
      "        [ 0.9293],\n",
      "        [-0.2108],\n",
      "        [ 0.5535],\n",
      "        [-0.6255],\n",
      "        [-0.2971],\n",
      "        [ 0.8696],\n",
      "        [ 0.7461],\n",
      "        [ 0.7774],\n",
      "        [ 1.2292],\n",
      "        [ 1.2292],\n",
      "        [ 1.0720],\n",
      "        [-0.2971],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4413],\n",
      "        [ 0.9586],\n",
      "        [-1.3153],\n",
      "        [ 0.5535],\n",
      "        [-0.2108],\n",
      "        [ 0.7461],\n",
      "        [ 0.5208],\n",
      "        [ 1.2292],\n",
      "        [ 0.7461],\n",
      "        [-0.7096],\n",
      "        [-0.1219],\n",
      "        [-1.0652],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8928],\n",
      "        [ 0.6184],\n",
      "        [ 1.2292],\n",
      "        [-1.6049],\n",
      "        [ 0.0638],\n",
      "        [-0.4083],\n",
      "        [-1.3153],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5709],\n",
      "        [-1.5439],\n",
      "        [ 0.6184],\n",
      "        [-1.4413],\n",
      "        [ 0.4222],\n",
      "        [-0.4356],\n",
      "        [ 0.4222],\n",
      "        [ 1.2292],\n",
      "        [ 1.1856]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 497/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0142,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6507],\n",
      "        [ 0.5860],\n",
      "        [-0.0302],\n",
      "        [ 0.4880],\n",
      "        [ 0.8996],\n",
      "        [ 0.9586],\n",
      "        [ 0.8996],\n",
      "        [ 0.8084],\n",
      "        [-1.5861],\n",
      "        [-0.8929],\n",
      "        [ 0.5534],\n",
      "        [-0.2108],\n",
      "        [ 0.9293],\n",
      "        [-0.2108],\n",
      "        [ 0.5534],\n",
      "        [-0.6256],\n",
      "        [-0.2970],\n",
      "        [ 0.8695],\n",
      "        [ 0.7461],\n",
      "        [ 0.7774],\n",
      "        [ 1.2293],\n",
      "        [ 1.2293],\n",
      "        [ 1.0720],\n",
      "        [-0.2970],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4412],\n",
      "        [ 0.9586],\n",
      "        [-1.3153],\n",
      "        [ 0.5534],\n",
      "        [-0.2108],\n",
      "        [ 0.7461],\n",
      "        [ 0.5207],\n",
      "        [ 1.2293],\n",
      "        [ 0.7461],\n",
      "        [-0.7097],\n",
      "        [-0.1219],\n",
      "        [-1.0652],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8929],\n",
      "        [ 0.6184],\n",
      "        [ 1.2293],\n",
      "        [-1.6050],\n",
      "        [ 0.0639],\n",
      "        [-0.4083],\n",
      "        [-1.3153],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5710],\n",
      "        [-1.5439],\n",
      "        [ 0.6184],\n",
      "        [-1.4412],\n",
      "        [ 0.4222],\n",
      "        [-0.4356],\n",
      "        [ 0.4222],\n",
      "        [ 1.2293],\n",
      "        [ 1.1857]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 498/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0142,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6506],\n",
      "        [ 0.5860],\n",
      "        [-0.0302],\n",
      "        [ 0.4879],\n",
      "        [ 0.8996],\n",
      "        [ 0.9586],\n",
      "        [ 0.8996],\n",
      "        [ 0.8084],\n",
      "        [-1.5861],\n",
      "        [-0.8930],\n",
      "        [ 0.5534],\n",
      "        [-0.2108],\n",
      "        [ 0.9293],\n",
      "        [-0.2108],\n",
      "        [ 0.5534],\n",
      "        [-0.6256],\n",
      "        [-0.2970],\n",
      "        [ 0.8695],\n",
      "        [ 0.7461],\n",
      "        [ 0.7774],\n",
      "        [ 1.2293],\n",
      "        [ 1.2293],\n",
      "        [ 1.0720],\n",
      "        [-0.2970],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4412],\n",
      "        [ 0.9586],\n",
      "        [-1.3152],\n",
      "        [ 0.5534],\n",
      "        [-0.2108],\n",
      "        [ 0.7461],\n",
      "        [ 0.5207],\n",
      "        [ 1.2293],\n",
      "        [ 0.7461],\n",
      "        [-0.7097],\n",
      "        [-0.1218],\n",
      "        [-1.0653],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8930],\n",
      "        [ 0.6184],\n",
      "        [ 1.2293],\n",
      "        [-1.6050],\n",
      "        [ 0.0639],\n",
      "        [-0.4083],\n",
      "        [-1.3152],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5710],\n",
      "        [-1.5439],\n",
      "        [ 0.6184],\n",
      "        [-1.4412],\n",
      "        [ 0.4222],\n",
      "        [-0.4356],\n",
      "        [ 0.4222],\n",
      "        [ 1.2293],\n",
      "        [ 1.1857]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 499/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0142,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6506],\n",
      "        [ 0.5860],\n",
      "        [-0.0301],\n",
      "        [ 0.4879],\n",
      "        [ 0.8995],\n",
      "        [ 0.9586],\n",
      "        [ 0.8995],\n",
      "        [ 0.8084],\n",
      "        [-1.5861],\n",
      "        [-0.8930],\n",
      "        [ 0.5534],\n",
      "        [-0.2107],\n",
      "        [ 0.9292],\n",
      "        [-0.2107],\n",
      "        [ 0.5534],\n",
      "        [-0.6256],\n",
      "        [-0.2970],\n",
      "        [ 0.8695],\n",
      "        [ 0.7460],\n",
      "        [ 0.7774],\n",
      "        [ 1.2294],\n",
      "        [ 1.2294],\n",
      "        [ 1.0720],\n",
      "        [-0.2970],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4412],\n",
      "        [ 0.9586],\n",
      "        [-1.3152],\n",
      "        [ 0.5534],\n",
      "        [-0.2107],\n",
      "        [ 0.7460],\n",
      "        [ 0.5207],\n",
      "        [ 1.2294],\n",
      "        [ 0.7460],\n",
      "        [-0.7098],\n",
      "        [-0.1218],\n",
      "        [-1.0653],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8930],\n",
      "        [ 0.6184],\n",
      "        [ 1.2294],\n",
      "        [-1.6051],\n",
      "        [ 0.0639],\n",
      "        [-0.4083],\n",
      "        [-1.3152],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5710],\n",
      "        [-1.5439],\n",
      "        [ 0.6184],\n",
      "        [-1.4412],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2294],\n",
      "        [ 1.1857]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 500/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0142,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6506],\n",
      "        [ 0.5860],\n",
      "        [-0.0301],\n",
      "        [ 0.4879],\n",
      "        [ 0.8995],\n",
      "        [ 0.9586],\n",
      "        [ 0.8995],\n",
      "        [ 0.8083],\n",
      "        [-1.5862],\n",
      "        [-0.8931],\n",
      "        [ 0.5534],\n",
      "        [-0.2107],\n",
      "        [ 0.9292],\n",
      "        [-0.2107],\n",
      "        [ 0.5534],\n",
      "        [-0.6257],\n",
      "        [-0.2969],\n",
      "        [ 0.8695],\n",
      "        [ 0.7460],\n",
      "        [ 0.7773],\n",
      "        [ 1.2294],\n",
      "        [ 1.2294],\n",
      "        [ 1.0720],\n",
      "        [-0.2969],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4411],\n",
      "        [ 0.9586],\n",
      "        [-1.3152],\n",
      "        [ 0.5534],\n",
      "        [-0.2107],\n",
      "        [ 0.7460],\n",
      "        [ 0.5207],\n",
      "        [ 1.2294],\n",
      "        [ 0.7460],\n",
      "        [-0.7098],\n",
      "        [-0.1217],\n",
      "        [-1.0653],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8931],\n",
      "        [ 0.6184],\n",
      "        [ 1.2294],\n",
      "        [-1.6051],\n",
      "        [ 0.0640],\n",
      "        [-0.4083],\n",
      "        [-1.3152],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5710],\n",
      "        [-1.5439],\n",
      "        [ 0.6184],\n",
      "        [-1.4411],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2294],\n",
      "        [ 1.1858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 501/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0141,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6506],\n",
      "        [ 0.5859],\n",
      "        [-0.0301],\n",
      "        [ 0.4879],\n",
      "        [ 0.8995],\n",
      "        [ 0.9586],\n",
      "        [ 0.8995],\n",
      "        [ 0.8083],\n",
      "        [-1.5862],\n",
      "        [-0.8932],\n",
      "        [ 0.5534],\n",
      "        [-0.2106],\n",
      "        [ 0.9292],\n",
      "        [-0.2106],\n",
      "        [ 0.5534],\n",
      "        [-0.6257],\n",
      "        [-0.2969],\n",
      "        [ 0.8694],\n",
      "        [ 0.7460],\n",
      "        [ 0.7773],\n",
      "        [ 1.2295],\n",
      "        [ 1.2295],\n",
      "        [ 1.0720],\n",
      "        [-0.2969],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4411],\n",
      "        [ 0.9586],\n",
      "        [-1.3151],\n",
      "        [ 0.5534],\n",
      "        [-0.2106],\n",
      "        [ 0.7460],\n",
      "        [ 0.5207],\n",
      "        [ 1.2295],\n",
      "        [ 0.7460],\n",
      "        [-0.7099],\n",
      "        [-0.1217],\n",
      "        [-1.0654],\n",
      "        [-1.1376],\n",
      "        [ 0.9586],\n",
      "        [-0.8932],\n",
      "        [ 0.6183],\n",
      "        [ 1.2295],\n",
      "        [-1.6052],\n",
      "        [ 0.0640],\n",
      "        [-0.4083],\n",
      "        [-1.3151],\n",
      "        [ 1.0161],\n",
      "        [-0.4083],\n",
      "        [-0.5710],\n",
      "        [-1.5440],\n",
      "        [ 0.6183],\n",
      "        [-1.4411],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2295],\n",
      "        [ 1.1858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 502/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0141,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6506],\n",
      "        [ 0.5859],\n",
      "        [-0.0300],\n",
      "        [ 0.4879],\n",
      "        [ 0.8995],\n",
      "        [ 0.9585],\n",
      "        [ 0.8995],\n",
      "        [ 0.8083],\n",
      "        [-1.5862],\n",
      "        [-0.8932],\n",
      "        [ 0.5534],\n",
      "        [-0.2106],\n",
      "        [ 0.9292],\n",
      "        [-0.2106],\n",
      "        [ 0.5534],\n",
      "        [-0.6257],\n",
      "        [-0.2969],\n",
      "        [ 0.8694],\n",
      "        [ 0.7460],\n",
      "        [ 0.7773],\n",
      "        [ 1.2295],\n",
      "        [ 1.2295],\n",
      "        [ 1.0720],\n",
      "        [-0.2969],\n",
      "        [-1.2100],\n",
      "        [ 1.0720],\n",
      "        [-1.4410],\n",
      "        [ 0.9585],\n",
      "        [-1.3151],\n",
      "        [ 0.5534],\n",
      "        [-0.2106],\n",
      "        [ 0.7460],\n",
      "        [ 0.5207],\n",
      "        [ 1.2295],\n",
      "        [ 0.7460],\n",
      "        [-0.7099],\n",
      "        [-0.1217],\n",
      "        [-1.0654],\n",
      "        [-1.1376],\n",
      "        [ 0.9585],\n",
      "        [-0.8932],\n",
      "        [ 0.6183],\n",
      "        [ 1.2295],\n",
      "        [-1.6052],\n",
      "        [ 0.0640],\n",
      "        [-0.4082],\n",
      "        [-1.3151],\n",
      "        [ 1.0161],\n",
      "        [-0.4082],\n",
      "        [-0.5711],\n",
      "        [-1.5440],\n",
      "        [ 0.6183],\n",
      "        [-1.4410],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2295],\n",
      "        [ 1.1858]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 503/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0141,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6505],\n",
      "        [ 0.5859],\n",
      "        [-0.0300],\n",
      "        [ 0.4879],\n",
      "        [ 0.8995],\n",
      "        [ 0.9585],\n",
      "        [ 0.8995],\n",
      "        [ 0.8083],\n",
      "        [-1.5863],\n",
      "        [-0.8933],\n",
      "        [ 0.5533],\n",
      "        [-0.2106],\n",
      "        [ 0.9292],\n",
      "        [-0.2106],\n",
      "        [ 0.5533],\n",
      "        [-0.6258],\n",
      "        [-0.2969],\n",
      "        [ 0.8694],\n",
      "        [ 0.7459],\n",
      "        [ 0.7773],\n",
      "        [ 1.2296],\n",
      "        [ 1.2296],\n",
      "        [ 1.0720],\n",
      "        [-0.2969],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4410],\n",
      "        [ 0.9585],\n",
      "        [-1.3150],\n",
      "        [ 0.5533],\n",
      "        [-0.2106],\n",
      "        [ 0.7459],\n",
      "        [ 0.5207],\n",
      "        [ 1.2296],\n",
      "        [ 0.7459],\n",
      "        [-0.7100],\n",
      "        [-0.1216],\n",
      "        [-1.0654],\n",
      "        [-1.1376],\n",
      "        [ 0.9585],\n",
      "        [-0.8933],\n",
      "        [ 0.6183],\n",
      "        [ 1.2296],\n",
      "        [-1.6053],\n",
      "        [ 0.0641],\n",
      "        [-0.4082],\n",
      "        [-1.3150],\n",
      "        [ 1.0161],\n",
      "        [-0.4082],\n",
      "        [-0.5711],\n",
      "        [-1.5440],\n",
      "        [ 0.6183],\n",
      "        [-1.4410],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2296],\n",
      "        [ 1.1859]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 504/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0141,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6505],\n",
      "        [ 0.5859],\n",
      "        [-0.0300],\n",
      "        [ 0.4879],\n",
      "        [ 0.8994],\n",
      "        [ 0.9585],\n",
      "        [ 0.8994],\n",
      "        [ 0.8083],\n",
      "        [-1.5863],\n",
      "        [-0.8934],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.9292],\n",
      "        [-0.2105],\n",
      "        [ 0.5533],\n",
      "        [-0.6258],\n",
      "        [-0.2968],\n",
      "        [ 0.8694],\n",
      "        [ 0.7459],\n",
      "        [ 0.7772],\n",
      "        [ 1.2296],\n",
      "        [ 1.2296],\n",
      "        [ 1.0720],\n",
      "        [-0.2968],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4410],\n",
      "        [ 0.9585],\n",
      "        [-1.3150],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.7459],\n",
      "        [ 0.5207],\n",
      "        [ 1.2296],\n",
      "        [ 0.7459],\n",
      "        [-0.7101],\n",
      "        [-0.1216],\n",
      "        [-1.0655],\n",
      "        [-1.1376],\n",
      "        [ 0.9585],\n",
      "        [-0.8934],\n",
      "        [ 0.6183],\n",
      "        [ 1.2296],\n",
      "        [-1.6053],\n",
      "        [ 0.0641],\n",
      "        [-0.4082],\n",
      "        [-1.3150],\n",
      "        [ 1.0161],\n",
      "        [-0.4082],\n",
      "        [-0.5711],\n",
      "        [-1.5440],\n",
      "        [ 0.6183],\n",
      "        [-1.4410],\n",
      "        [ 0.4221],\n",
      "        [-0.4356],\n",
      "        [ 0.4221],\n",
      "        [ 1.2296],\n",
      "        [ 1.1859]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 505/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0140,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6505],\n",
      "        [ 0.5859],\n",
      "        [-0.0299],\n",
      "        [ 0.4879],\n",
      "        [ 0.8994],\n",
      "        [ 0.9585],\n",
      "        [ 0.8994],\n",
      "        [ 0.8082],\n",
      "        [-1.5863],\n",
      "        [-0.8934],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.9291],\n",
      "        [-0.2105],\n",
      "        [ 0.5533],\n",
      "        [-0.6259],\n",
      "        [-0.2968],\n",
      "        [ 0.8694],\n",
      "        [ 0.7459],\n",
      "        [ 0.7772],\n",
      "        [ 1.2297],\n",
      "        [ 1.2297],\n",
      "        [ 1.0720],\n",
      "        [-0.2968],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4409],\n",
      "        [ 0.9585],\n",
      "        [-1.3150],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.7459],\n",
      "        [ 0.5206],\n",
      "        [ 1.2297],\n",
      "        [ 0.7459],\n",
      "        [-0.7101],\n",
      "        [-0.1215],\n",
      "        [-1.0655],\n",
      "        [-1.1376],\n",
      "        [ 0.9585],\n",
      "        [-0.8934],\n",
      "        [ 0.6183],\n",
      "        [ 1.2297],\n",
      "        [-1.6054],\n",
      "        [ 0.0641],\n",
      "        [-0.4082],\n",
      "        [-1.3150],\n",
      "        [ 1.0160],\n",
      "        [-0.4082],\n",
      "        [-0.5711],\n",
      "        [-1.5440],\n",
      "        [ 0.6183],\n",
      "        [-1.4409],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2297],\n",
      "        [ 1.1859]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 506/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0140,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6505],\n",
      "        [ 0.5859],\n",
      "        [-0.0299],\n",
      "        [ 0.4879],\n",
      "        [ 0.8994],\n",
      "        [ 0.9585],\n",
      "        [ 0.8994],\n",
      "        [ 0.8082],\n",
      "        [-1.5864],\n",
      "        [-0.8935],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.9291],\n",
      "        [-0.2105],\n",
      "        [ 0.5533],\n",
      "        [-0.6259],\n",
      "        [-0.2968],\n",
      "        [ 0.8693],\n",
      "        [ 0.7459],\n",
      "        [ 0.7772],\n",
      "        [ 1.2297],\n",
      "        [ 1.2297],\n",
      "        [ 1.0720],\n",
      "        [-0.2968],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4409],\n",
      "        [ 0.9585],\n",
      "        [-1.3149],\n",
      "        [ 0.5533],\n",
      "        [-0.2105],\n",
      "        [ 0.7459],\n",
      "        [ 0.5206],\n",
      "        [ 1.2297],\n",
      "        [ 0.7459],\n",
      "        [-0.7102],\n",
      "        [-0.1215],\n",
      "        [-1.0655],\n",
      "        [-1.1377],\n",
      "        [ 0.9585],\n",
      "        [-0.8935],\n",
      "        [ 0.6182],\n",
      "        [ 1.2297],\n",
      "        [-1.6054],\n",
      "        [ 0.0642],\n",
      "        [-0.4082],\n",
      "        [-1.3149],\n",
      "        [ 1.0160],\n",
      "        [-0.4082],\n",
      "        [-0.5712],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4409],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2297],\n",
      "        [ 1.1860]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 507/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0140,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6505],\n",
      "        [ 0.5858],\n",
      "        [-0.0298],\n",
      "        [ 0.4879],\n",
      "        [ 0.8994],\n",
      "        [ 0.9585],\n",
      "        [ 0.8994],\n",
      "        [ 0.8082],\n",
      "        [-1.5864],\n",
      "        [-0.8936],\n",
      "        [ 0.5533],\n",
      "        [-0.2104],\n",
      "        [ 0.9291],\n",
      "        [-0.2104],\n",
      "        [ 0.5533],\n",
      "        [-0.6259],\n",
      "        [-0.2967],\n",
      "        [ 0.8693],\n",
      "        [ 0.7459],\n",
      "        [ 0.7772],\n",
      "        [ 1.2298],\n",
      "        [ 1.2298],\n",
      "        [ 1.0720],\n",
      "        [-0.2967],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4409],\n",
      "        [ 0.9585],\n",
      "        [-1.3149],\n",
      "        [ 0.5533],\n",
      "        [-0.2104],\n",
      "        [ 0.7459],\n",
      "        [ 0.5206],\n",
      "        [ 1.2298],\n",
      "        [ 0.7459],\n",
      "        [-0.7102],\n",
      "        [-0.1214],\n",
      "        [-1.0656],\n",
      "        [-1.1377],\n",
      "        [ 0.9585],\n",
      "        [-0.8936],\n",
      "        [ 0.6182],\n",
      "        [ 1.2298],\n",
      "        [-1.6055],\n",
      "        [ 0.0642],\n",
      "        [-0.4082],\n",
      "        [-1.3149],\n",
      "        [ 1.0160],\n",
      "        [-0.4082],\n",
      "        [-0.5712],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4409],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2298],\n",
      "        [ 1.1860]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 508/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0140,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6504],\n",
      "        [ 0.5858],\n",
      "        [-0.0298],\n",
      "        [ 0.4878],\n",
      "        [ 0.8994],\n",
      "        [ 0.9585],\n",
      "        [ 0.8994],\n",
      "        [ 0.8082],\n",
      "        [-1.5865],\n",
      "        [-0.8937],\n",
      "        [ 0.5533],\n",
      "        [-0.2104],\n",
      "        [ 0.9291],\n",
      "        [-0.2104],\n",
      "        [ 0.5533],\n",
      "        [-0.6260],\n",
      "        [-0.2967],\n",
      "        [ 0.8693],\n",
      "        [ 0.7458],\n",
      "        [ 0.7771],\n",
      "        [ 1.2298],\n",
      "        [ 1.2298],\n",
      "        [ 1.0720],\n",
      "        [-0.2967],\n",
      "        [-1.2099],\n",
      "        [ 1.0720],\n",
      "        [-1.4408],\n",
      "        [ 0.9585],\n",
      "        [-1.3148],\n",
      "        [ 0.5533],\n",
      "        [-0.2104],\n",
      "        [ 0.7458],\n",
      "        [ 0.5206],\n",
      "        [ 1.2298],\n",
      "        [ 0.7458],\n",
      "        [-0.7103],\n",
      "        [-0.1214],\n",
      "        [-1.0656],\n",
      "        [-1.1377],\n",
      "        [ 0.9585],\n",
      "        [-0.8937],\n",
      "        [ 0.6182],\n",
      "        [ 1.2298],\n",
      "        [-1.6055],\n",
      "        [ 0.0642],\n",
      "        [-0.4082],\n",
      "        [-1.3148],\n",
      "        [ 1.0160],\n",
      "        [-0.4082],\n",
      "        [-0.5712],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4408],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2298],\n",
      "        [ 1.1860]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 509/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0139,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6504],\n",
      "        [ 0.5858],\n",
      "        [-0.0298],\n",
      "        [ 0.4878],\n",
      "        [ 0.8994],\n",
      "        [ 0.9584],\n",
      "        [ 0.8994],\n",
      "        [ 0.8081],\n",
      "        [-1.5865],\n",
      "        [-0.8937],\n",
      "        [ 0.5533],\n",
      "        [-0.2103],\n",
      "        [ 0.9291],\n",
      "        [-0.2103],\n",
      "        [ 0.5533],\n",
      "        [-0.6260],\n",
      "        [-0.2967],\n",
      "        [ 0.8693],\n",
      "        [ 0.7458],\n",
      "        [ 0.7771],\n",
      "        [ 1.2299],\n",
      "        [ 1.2299],\n",
      "        [ 1.0720],\n",
      "        [-0.2967],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4408],\n",
      "        [ 0.9584],\n",
      "        [-1.3148],\n",
      "        [ 0.5533],\n",
      "        [-0.2103],\n",
      "        [ 0.7458],\n",
      "        [ 0.5206],\n",
      "        [ 1.2299],\n",
      "        [ 0.7458],\n",
      "        [-0.7103],\n",
      "        [-0.1214],\n",
      "        [-1.0656],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8937],\n",
      "        [ 0.6182],\n",
      "        [ 1.2299],\n",
      "        [-1.6056],\n",
      "        [ 0.0643],\n",
      "        [-0.4081],\n",
      "        [-1.3148],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5712],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4408],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2299],\n",
      "        [ 1.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 510/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0139,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6504],\n",
      "        [ 0.5858],\n",
      "        [-0.0297],\n",
      "        [ 0.4878],\n",
      "        [ 0.8993],\n",
      "        [ 0.9584],\n",
      "        [ 0.8993],\n",
      "        [ 0.8081],\n",
      "        [-1.5865],\n",
      "        [-0.8938],\n",
      "        [ 0.5532],\n",
      "        [-0.2103],\n",
      "        [ 0.9291],\n",
      "        [-0.2103],\n",
      "        [ 0.5532],\n",
      "        [-0.6260],\n",
      "        [-0.2966],\n",
      "        [ 0.8693],\n",
      "        [ 0.7458],\n",
      "        [ 0.7771],\n",
      "        [ 1.2299],\n",
      "        [ 1.2299],\n",
      "        [ 1.0720],\n",
      "        [-0.2966],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4407],\n",
      "        [ 0.9584],\n",
      "        [-1.3148],\n",
      "        [ 0.5532],\n",
      "        [-0.2103],\n",
      "        [ 0.7458],\n",
      "        [ 0.5206],\n",
      "        [ 1.2299],\n",
      "        [ 0.7458],\n",
      "        [-0.7104],\n",
      "        [-0.1213],\n",
      "        [-1.0656],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8938],\n",
      "        [ 0.6182],\n",
      "        [ 1.2299],\n",
      "        [-1.6056],\n",
      "        [ 0.0643],\n",
      "        [-0.4081],\n",
      "        [-1.3148],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5713],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4407],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2299],\n",
      "        [ 1.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 511/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0139,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6504],\n",
      "        [ 0.5858],\n",
      "        [-0.0297],\n",
      "        [ 0.4878],\n",
      "        [ 0.8993],\n",
      "        [ 0.9584],\n",
      "        [ 0.8993],\n",
      "        [ 0.8081],\n",
      "        [-1.5866],\n",
      "        [-0.8938],\n",
      "        [ 0.5532],\n",
      "        [-0.2103],\n",
      "        [ 0.9290],\n",
      "        [-0.2103],\n",
      "        [ 0.5532],\n",
      "        [-0.6261],\n",
      "        [-0.2966],\n",
      "        [ 0.8692],\n",
      "        [ 0.7458],\n",
      "        [ 0.7771],\n",
      "        [ 1.2300],\n",
      "        [ 1.2300],\n",
      "        [ 1.0720],\n",
      "        [-0.2966],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4407],\n",
      "        [ 0.9584],\n",
      "        [-1.3147],\n",
      "        [ 0.5532],\n",
      "        [-0.2103],\n",
      "        [ 0.7458],\n",
      "        [ 0.5206],\n",
      "        [ 1.2300],\n",
      "        [ 0.7458],\n",
      "        [-0.7104],\n",
      "        [-0.1213],\n",
      "        [-1.0657],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8938],\n",
      "        [ 0.6182],\n",
      "        [ 1.2300],\n",
      "        [-1.6057],\n",
      "        [ 0.0643],\n",
      "        [-0.4081],\n",
      "        [-1.3147],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5713],\n",
      "        [-1.5440],\n",
      "        [ 0.6182],\n",
      "        [-1.4407],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2300],\n",
      "        [ 1.1861]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 512/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0139,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6503],\n",
      "        [ 0.5857],\n",
      "        [-0.0296],\n",
      "        [ 0.4878],\n",
      "        [ 0.8993],\n",
      "        [ 0.9584],\n",
      "        [ 0.8993],\n",
      "        [ 0.8081],\n",
      "        [-1.5866],\n",
      "        [-0.8939],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.9290],\n",
      "        [-0.2102],\n",
      "        [ 0.5532],\n",
      "        [-0.6261],\n",
      "        [-0.2966],\n",
      "        [ 0.8692],\n",
      "        [ 0.7457],\n",
      "        [ 0.7770],\n",
      "        [ 1.2300],\n",
      "        [ 1.2300],\n",
      "        [ 1.0720],\n",
      "        [-0.2966],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4407],\n",
      "        [ 0.9584],\n",
      "        [-1.3147],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.7457],\n",
      "        [ 0.5206],\n",
      "        [ 1.2300],\n",
      "        [ 0.7457],\n",
      "        [-0.7105],\n",
      "        [-0.1213],\n",
      "        [-1.0657],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8939],\n",
      "        [ 0.6181],\n",
      "        [ 1.2300],\n",
      "        [-1.6057],\n",
      "        [ 0.0644],\n",
      "        [-0.4081],\n",
      "        [-1.3147],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5713],\n",
      "        [-1.5440],\n",
      "        [ 0.6181],\n",
      "        [-1.4407],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2300],\n",
      "        [ 1.1862]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 513/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0138,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6503],\n",
      "        [ 0.5857],\n",
      "        [-0.0296],\n",
      "        [ 0.4878],\n",
      "        [ 0.8993],\n",
      "        [ 0.9584],\n",
      "        [ 0.8993],\n",
      "        [ 0.8080],\n",
      "        [-1.5866],\n",
      "        [-0.8940],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.9290],\n",
      "        [-0.2102],\n",
      "        [ 0.5532],\n",
      "        [-0.6262],\n",
      "        [-0.2965],\n",
      "        [ 0.8692],\n",
      "        [ 0.7457],\n",
      "        [ 0.7770],\n",
      "        [ 1.2301],\n",
      "        [ 1.2301],\n",
      "        [ 1.0720],\n",
      "        [-0.2965],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4406],\n",
      "        [ 0.9584],\n",
      "        [-1.3147],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.7457],\n",
      "        [ 0.5205],\n",
      "        [ 1.2301],\n",
      "        [ 0.7457],\n",
      "        [-0.7106],\n",
      "        [-0.1212],\n",
      "        [-1.0657],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8940],\n",
      "        [ 0.6181],\n",
      "        [ 1.2301],\n",
      "        [-1.6058],\n",
      "        [ 0.0644],\n",
      "        [-0.4081],\n",
      "        [-1.3147],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5713],\n",
      "        [-1.5440],\n",
      "        [ 0.6181],\n",
      "        [-1.4406],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2301],\n",
      "        [ 1.1862]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 514/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0138,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6503],\n",
      "        [ 0.5857],\n",
      "        [-0.0296],\n",
      "        [ 0.4878],\n",
      "        [ 0.8993],\n",
      "        [ 0.9584],\n",
      "        [ 0.8993],\n",
      "        [ 0.8080],\n",
      "        [-1.5867],\n",
      "        [-0.8940],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.9290],\n",
      "        [-0.2102],\n",
      "        [ 0.5532],\n",
      "        [-0.6262],\n",
      "        [-0.2965],\n",
      "        [ 0.8692],\n",
      "        [ 0.7457],\n",
      "        [ 0.7770],\n",
      "        [ 1.2301],\n",
      "        [ 1.2301],\n",
      "        [ 1.0720],\n",
      "        [-0.2965],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4406],\n",
      "        [ 0.9584],\n",
      "        [-1.3146],\n",
      "        [ 0.5532],\n",
      "        [-0.2102],\n",
      "        [ 0.7457],\n",
      "        [ 0.5205],\n",
      "        [ 1.2301],\n",
      "        [ 0.7457],\n",
      "        [-0.7106],\n",
      "        [-0.1212],\n",
      "        [-1.0658],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8940],\n",
      "        [ 0.6181],\n",
      "        [ 1.2301],\n",
      "        [-1.6058],\n",
      "        [ 0.0644],\n",
      "        [-0.4081],\n",
      "        [-1.3146],\n",
      "        [ 1.0160],\n",
      "        [-0.4081],\n",
      "        [-0.5713],\n",
      "        [-1.5440],\n",
      "        [ 0.6181],\n",
      "        [-1.4406],\n",
      "        [ 0.4221],\n",
      "        [-0.4355],\n",
      "        [ 0.4221],\n",
      "        [ 1.2301],\n",
      "        [ 1.1862]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 515/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0138,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6503],\n",
      "        [ 0.5857],\n",
      "        [-0.0295],\n",
      "        [ 0.4878],\n",
      "        [ 0.8992],\n",
      "        [ 0.9584],\n",
      "        [ 0.8992],\n",
      "        [ 0.8080],\n",
      "        [-1.5867],\n",
      "        [-0.8941],\n",
      "        [ 0.5532],\n",
      "        [-0.2101],\n",
      "        [ 0.9290],\n",
      "        [-0.2101],\n",
      "        [ 0.5532],\n",
      "        [-0.6262],\n",
      "        [-0.2965],\n",
      "        [ 0.8691],\n",
      "        [ 0.7457],\n",
      "        [ 0.7770],\n",
      "        [ 1.2302],\n",
      "        [ 1.2302],\n",
      "        [ 1.0720],\n",
      "        [-0.2965],\n",
      "        [-1.2098],\n",
      "        [ 1.0720],\n",
      "        [-1.4406],\n",
      "        [ 0.9584],\n",
      "        [-1.3146],\n",
      "        [ 0.5532],\n",
      "        [-0.2101],\n",
      "        [ 0.7457],\n",
      "        [ 0.5205],\n",
      "        [ 1.2302],\n",
      "        [ 0.7457],\n",
      "        [-0.7107],\n",
      "        [-0.1211],\n",
      "        [-1.0658],\n",
      "        [-1.1377],\n",
      "        [ 0.9584],\n",
      "        [-0.8941],\n",
      "        [ 0.6181],\n",
      "        [ 1.2302],\n",
      "        [-1.6059],\n",
      "        [ 0.0644],\n",
      "        [-0.4080],\n",
      "        [-1.3146],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5714],\n",
      "        [-1.5440],\n",
      "        [ 0.6181],\n",
      "        [-1.4406],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2302],\n",
      "        [ 1.1863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 516/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0138,\n",
      " epoch_time_duration: 0.0159\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6503],\n",
      "        [ 0.5857],\n",
      "        [-0.0295],\n",
      "        [ 0.4878],\n",
      "        [ 0.8992],\n",
      "        [ 0.9583],\n",
      "        [ 0.8992],\n",
      "        [ 0.8080],\n",
      "        [-1.5867],\n",
      "        [-0.8942],\n",
      "        [ 0.5532],\n",
      "        [-0.2101],\n",
      "        [ 0.9290],\n",
      "        [-0.2101],\n",
      "        [ 0.5532],\n",
      "        [-0.6263],\n",
      "        [-0.2964],\n",
      "        [ 0.8691],\n",
      "        [ 0.7456],\n",
      "        [ 0.7769],\n",
      "        [ 1.2302],\n",
      "        [ 1.2302],\n",
      "        [ 1.0720],\n",
      "        [-0.2964],\n",
      "        [-1.2097],\n",
      "        [ 1.0720],\n",
      "        [-1.4405],\n",
      "        [ 0.9583],\n",
      "        [-1.3145],\n",
      "        [ 0.5532],\n",
      "        [-0.2101],\n",
      "        [ 0.7456],\n",
      "        [ 0.5205],\n",
      "        [ 1.2302],\n",
      "        [ 0.7456],\n",
      "        [-0.7107],\n",
      "        [-0.1211],\n",
      "        [-1.0658],\n",
      "        [-1.1377],\n",
      "        [ 0.9583],\n",
      "        [-0.8942],\n",
      "        [ 0.6181],\n",
      "        [ 1.2302],\n",
      "        [-1.6059],\n",
      "        [ 0.0645],\n",
      "        [-0.4080],\n",
      "        [-1.3145],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5714],\n",
      "        [-1.5440],\n",
      "        [ 0.6181],\n",
      "        [-1.4405],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2302],\n",
      "        [ 1.1863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 517/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0137,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6502],\n",
      "        [ 0.5857],\n",
      "        [-0.0295],\n",
      "        [ 0.4878],\n",
      "        [ 0.8992],\n",
      "        [ 0.9583],\n",
      "        [ 0.8992],\n",
      "        [ 0.8080],\n",
      "        [-1.5868],\n",
      "        [-0.8942],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.9289],\n",
      "        [-0.2100],\n",
      "        [ 0.5531],\n",
      "        [-0.6263],\n",
      "        [-0.2964],\n",
      "        [ 0.8691],\n",
      "        [ 0.7456],\n",
      "        [ 0.7769],\n",
      "        [ 1.2303],\n",
      "        [ 1.2303],\n",
      "        [ 1.0720],\n",
      "        [-0.2964],\n",
      "        [-1.2097],\n",
      "        [ 1.0720],\n",
      "        [-1.4405],\n",
      "        [ 0.9583],\n",
      "        [-1.3145],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.7456],\n",
      "        [ 0.5205],\n",
      "        [ 1.2303],\n",
      "        [ 0.7456],\n",
      "        [-0.7108],\n",
      "        [-0.1211],\n",
      "        [-1.0659],\n",
      "        [-1.1377],\n",
      "        [ 0.9583],\n",
      "        [-0.8942],\n",
      "        [ 0.6180],\n",
      "        [ 1.2303],\n",
      "        [-1.6060],\n",
      "        [ 0.0645],\n",
      "        [-0.4080],\n",
      "        [-1.3145],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5714],\n",
      "        [-1.5440],\n",
      "        [ 0.6180],\n",
      "        [-1.4405],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2303],\n",
      "        [ 1.1863]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 518/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0137,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6502],\n",
      "        [ 0.5856],\n",
      "        [-0.0294],\n",
      "        [ 0.4878],\n",
      "        [ 0.8992],\n",
      "        [ 0.9583],\n",
      "        [ 0.8992],\n",
      "        [ 0.8079],\n",
      "        [-1.5868],\n",
      "        [-0.8943],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.9289],\n",
      "        [-0.2100],\n",
      "        [ 0.5531],\n",
      "        [-0.6263],\n",
      "        [-0.2964],\n",
      "        [ 0.8691],\n",
      "        [ 0.7456],\n",
      "        [ 0.7769],\n",
      "        [ 1.2303],\n",
      "        [ 1.2303],\n",
      "        [ 1.0721],\n",
      "        [-0.2964],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4404],\n",
      "        [ 0.9583],\n",
      "        [-1.3145],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.7456],\n",
      "        [ 0.5205],\n",
      "        [ 1.2303],\n",
      "        [ 0.7456],\n",
      "        [-0.7108],\n",
      "        [-0.1210],\n",
      "        [-1.0659],\n",
      "        [-1.1378],\n",
      "        [ 0.9583],\n",
      "        [-0.8943],\n",
      "        [ 0.6180],\n",
      "        [ 1.2303],\n",
      "        [-1.6060],\n",
      "        [ 0.0645],\n",
      "        [-0.4080],\n",
      "        [-1.3145],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5714],\n",
      "        [-1.5440],\n",
      "        [ 0.6180],\n",
      "        [-1.4404],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2303],\n",
      "        [ 1.1864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 519/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0137,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6502],\n",
      "        [ 0.5856],\n",
      "        [-0.0294],\n",
      "        [ 0.4877],\n",
      "        [ 0.8992],\n",
      "        [ 0.9583],\n",
      "        [ 0.8992],\n",
      "        [ 0.8079],\n",
      "        [-1.5868],\n",
      "        [-0.8944],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.9289],\n",
      "        [-0.2100],\n",
      "        [ 0.5531],\n",
      "        [-0.6264],\n",
      "        [-0.2964],\n",
      "        [ 0.8691],\n",
      "        [ 0.7456],\n",
      "        [ 0.7769],\n",
      "        [ 1.2304],\n",
      "        [ 1.2304],\n",
      "        [ 1.0721],\n",
      "        [-0.2964],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4404],\n",
      "        [ 0.9583],\n",
      "        [-1.3144],\n",
      "        [ 0.5531],\n",
      "        [-0.2100],\n",
      "        [ 0.7456],\n",
      "        [ 0.5205],\n",
      "        [ 1.2304],\n",
      "        [ 0.7456],\n",
      "        [-0.7109],\n",
      "        [-0.1210],\n",
      "        [-1.0659],\n",
      "        [-1.1378],\n",
      "        [ 0.9583],\n",
      "        [-0.8944],\n",
      "        [ 0.6180],\n",
      "        [ 1.2304],\n",
      "        [-1.6061],\n",
      "        [ 0.0646],\n",
      "        [-0.4080],\n",
      "        [-1.3144],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5715],\n",
      "        [-1.5440],\n",
      "        [ 0.6180],\n",
      "        [-1.4404],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2304],\n",
      "        [ 1.1864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 520/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0137,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6502],\n",
      "        [ 0.5856],\n",
      "        [-0.0294],\n",
      "        [ 0.4877],\n",
      "        [ 0.8991],\n",
      "        [ 0.9583],\n",
      "        [ 0.8991],\n",
      "        [ 0.8079],\n",
      "        [-1.5869],\n",
      "        [-0.8944],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.9289],\n",
      "        [-0.2099],\n",
      "        [ 0.5531],\n",
      "        [-0.6264],\n",
      "        [-0.2963],\n",
      "        [ 0.8690],\n",
      "        [ 0.7455],\n",
      "        [ 0.7769],\n",
      "        [ 1.2304],\n",
      "        [ 1.2304],\n",
      "        [ 1.0721],\n",
      "        [-0.2963],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4404],\n",
      "        [ 0.9583],\n",
      "        [-1.3144],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.7455],\n",
      "        [ 0.5205],\n",
      "        [ 1.2304],\n",
      "        [ 0.7455],\n",
      "        [-0.7109],\n",
      "        [-0.1209],\n",
      "        [-1.0659],\n",
      "        [-1.1378],\n",
      "        [ 0.9583],\n",
      "        [-0.8944],\n",
      "        [ 0.6180],\n",
      "        [ 1.2304],\n",
      "        [-1.6061],\n",
      "        [ 0.0646],\n",
      "        [-0.4080],\n",
      "        [-1.3144],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5715],\n",
      "        [-1.5440],\n",
      "        [ 0.6180],\n",
      "        [-1.4404],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2304],\n",
      "        [ 1.1864]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 521/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0136,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6502],\n",
      "        [ 0.5856],\n",
      "        [-0.0293],\n",
      "        [ 0.4877],\n",
      "        [ 0.8991],\n",
      "        [ 0.9583],\n",
      "        [ 0.8991],\n",
      "        [ 0.8079],\n",
      "        [-1.5869],\n",
      "        [-0.8945],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.9289],\n",
      "        [-0.2099],\n",
      "        [ 0.5531],\n",
      "        [-0.6264],\n",
      "        [-0.2963],\n",
      "        [ 0.8690],\n",
      "        [ 0.7455],\n",
      "        [ 0.7768],\n",
      "        [ 1.2305],\n",
      "        [ 1.2305],\n",
      "        [ 1.0721],\n",
      "        [-0.2963],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4403],\n",
      "        [ 0.9583],\n",
      "        [-1.3143],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.7455],\n",
      "        [ 0.5205],\n",
      "        [ 1.2305],\n",
      "        [ 0.7455],\n",
      "        [-0.7110],\n",
      "        [-0.1209],\n",
      "        [-1.0660],\n",
      "        [-1.1378],\n",
      "        [ 0.9583],\n",
      "        [-0.8945],\n",
      "        [ 0.6180],\n",
      "        [ 1.2305],\n",
      "        [-1.6062],\n",
      "        [ 0.0646],\n",
      "        [-0.4080],\n",
      "        [-1.3143],\n",
      "        [ 1.0160],\n",
      "        [-0.4080],\n",
      "        [-0.5715],\n",
      "        [-1.5440],\n",
      "        [ 0.6180],\n",
      "        [-1.4403],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2305],\n",
      "        [ 1.1865]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 522/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0136,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6501],\n",
      "        [ 0.5856],\n",
      "        [-0.0293],\n",
      "        [ 0.4877],\n",
      "        [ 0.8991],\n",
      "        [ 0.9583],\n",
      "        [ 0.8991],\n",
      "        [ 0.8078],\n",
      "        [-1.5869],\n",
      "        [-0.8946],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.9289],\n",
      "        [-0.2099],\n",
      "        [ 0.5531],\n",
      "        [-0.6265],\n",
      "        [-0.2963],\n",
      "        [ 0.8690],\n",
      "        [ 0.7455],\n",
      "        [ 0.7768],\n",
      "        [ 1.2305],\n",
      "        [ 1.2305],\n",
      "        [ 1.0721],\n",
      "        [-0.2963],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4403],\n",
      "        [ 0.9583],\n",
      "        [-1.3143],\n",
      "        [ 0.5531],\n",
      "        [-0.2099],\n",
      "        [ 0.7455],\n",
      "        [ 0.5204],\n",
      "        [ 1.2305],\n",
      "        [ 0.7455],\n",
      "        [-0.7111],\n",
      "        [-0.1209],\n",
      "        [-1.0660],\n",
      "        [-1.1378],\n",
      "        [ 0.9583],\n",
      "        [-0.8946],\n",
      "        [ 0.6179],\n",
      "        [ 1.2305],\n",
      "        [-1.6062],\n",
      "        [ 0.0647],\n",
      "        [-0.4079],\n",
      "        [-1.3143],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5715],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4403],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2305],\n",
      "        [ 1.1865]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 523/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0136,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6501],\n",
      "        [ 0.5856],\n",
      "        [-0.0292],\n",
      "        [ 0.4877],\n",
      "        [ 0.8991],\n",
      "        [ 0.9582],\n",
      "        [ 0.8991],\n",
      "        [ 0.8078],\n",
      "        [-1.5870],\n",
      "        [-0.8946],\n",
      "        [ 0.5531],\n",
      "        [-0.2098],\n",
      "        [ 0.9288],\n",
      "        [-0.2098],\n",
      "        [ 0.5531],\n",
      "        [-0.6265],\n",
      "        [-0.2962],\n",
      "        [ 0.8690],\n",
      "        [ 0.7455],\n",
      "        [ 0.7768],\n",
      "        [ 1.2306],\n",
      "        [ 1.2306],\n",
      "        [ 1.0721],\n",
      "        [-0.2962],\n",
      "        [-1.2097],\n",
      "        [ 1.0721],\n",
      "        [-1.4403],\n",
      "        [ 0.9582],\n",
      "        [-1.3143],\n",
      "        [ 0.5531],\n",
      "        [-0.2098],\n",
      "        [ 0.7455],\n",
      "        [ 0.5204],\n",
      "        [ 1.2306],\n",
      "        [ 0.7455],\n",
      "        [-0.7111],\n",
      "        [-0.1208],\n",
      "        [-1.0660],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8946],\n",
      "        [ 0.6179],\n",
      "        [ 1.2306],\n",
      "        [-1.6063],\n",
      "        [ 0.0647],\n",
      "        [-0.4079],\n",
      "        [-1.3143],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5715],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4403],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2306],\n",
      "        [ 1.1865]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 524/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0136,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6501],\n",
      "        [ 0.5855],\n",
      "        [-0.0292],\n",
      "        [ 0.4877],\n",
      "        [ 0.8991],\n",
      "        [ 0.9582],\n",
      "        [ 0.8991],\n",
      "        [ 0.8078],\n",
      "        [-1.5870],\n",
      "        [-0.8947],\n",
      "        [ 0.5530],\n",
      "        [-0.2098],\n",
      "        [ 0.9288],\n",
      "        [-0.2098],\n",
      "        [ 0.5530],\n",
      "        [-0.6266],\n",
      "        [-0.2962],\n",
      "        [ 0.8690],\n",
      "        [ 0.7455],\n",
      "        [ 0.7768],\n",
      "        [ 1.2306],\n",
      "        [ 1.2306],\n",
      "        [ 1.0721],\n",
      "        [-0.2962],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4402],\n",
      "        [ 0.9582],\n",
      "        [-1.3142],\n",
      "        [ 0.5530],\n",
      "        [-0.2098],\n",
      "        [ 0.7455],\n",
      "        [ 0.5204],\n",
      "        [ 1.2306],\n",
      "        [ 0.7455],\n",
      "        [-0.7112],\n",
      "        [-0.1208],\n",
      "        [-1.0661],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8947],\n",
      "        [ 0.6179],\n",
      "        [ 1.2306],\n",
      "        [-1.6063],\n",
      "        [ 0.0647],\n",
      "        [-0.4079],\n",
      "        [-1.3142],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5716],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4402],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2306],\n",
      "        [ 1.1866]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 525/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0135,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6501],\n",
      "        [ 0.5855],\n",
      "        [-0.0292],\n",
      "        [ 0.4877],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8078],\n",
      "        [-1.5870],\n",
      "        [-0.8948],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.9288],\n",
      "        [-0.2097],\n",
      "        [ 0.5530],\n",
      "        [-0.6266],\n",
      "        [-0.2962],\n",
      "        [ 0.8689],\n",
      "        [ 0.7454],\n",
      "        [ 0.7767],\n",
      "        [ 1.2307],\n",
      "        [ 1.2307],\n",
      "        [ 1.0721],\n",
      "        [-0.2962],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4402],\n",
      "        [ 0.9582],\n",
      "        [-1.3142],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.7454],\n",
      "        [ 0.5204],\n",
      "        [ 1.2307],\n",
      "        [ 0.7454],\n",
      "        [-0.7112],\n",
      "        [-0.1207],\n",
      "        [-1.0661],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8948],\n",
      "        [ 0.6179],\n",
      "        [ 1.2307],\n",
      "        [-1.6064],\n",
      "        [ 0.0648],\n",
      "        [-0.4079],\n",
      "        [-1.3142],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5716],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4402],\n",
      "        [ 0.4221],\n",
      "        [-0.4354],\n",
      "        [ 0.4221],\n",
      "        [ 1.2307],\n",
      "        [ 1.1866]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 526/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0135,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6501],\n",
      "        [ 0.5855],\n",
      "        [-0.0291],\n",
      "        [ 0.4877],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8077],\n",
      "        [-1.5871],\n",
      "        [-0.8948],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.9288],\n",
      "        [-0.2097],\n",
      "        [ 0.5530],\n",
      "        [-0.6266],\n",
      "        [-0.2961],\n",
      "        [ 0.8689],\n",
      "        [ 0.7454],\n",
      "        [ 0.7767],\n",
      "        [ 1.2307],\n",
      "        [ 1.2307],\n",
      "        [ 1.0721],\n",
      "        [-0.2961],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4401],\n",
      "        [ 0.9582],\n",
      "        [-1.3142],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.7454],\n",
      "        [ 0.5204],\n",
      "        [ 1.2307],\n",
      "        [ 0.7454],\n",
      "        [-0.7113],\n",
      "        [-0.1207],\n",
      "        [-1.0661],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8948],\n",
      "        [ 0.6179],\n",
      "        [ 1.2307],\n",
      "        [-1.6064],\n",
      "        [ 0.0648],\n",
      "        [-0.4079],\n",
      "        [-1.3142],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5716],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4401],\n",
      "        [ 0.4221],\n",
      "        [-0.4353],\n",
      "        [ 0.4221],\n",
      "        [ 1.2307],\n",
      "        [ 1.1866]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 527/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0135,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6500],\n",
      "        [ 0.5855],\n",
      "        [-0.0291],\n",
      "        [ 0.4877],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8077],\n",
      "        [-1.5871],\n",
      "        [-0.8949],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.9288],\n",
      "        [-0.2097],\n",
      "        [ 0.5530],\n",
      "        [-0.6267],\n",
      "        [-0.2961],\n",
      "        [ 0.8689],\n",
      "        [ 0.7454],\n",
      "        [ 0.7767],\n",
      "        [ 1.2308],\n",
      "        [ 1.2308],\n",
      "        [ 1.0721],\n",
      "        [-0.2961],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4401],\n",
      "        [ 0.9582],\n",
      "        [-1.3141],\n",
      "        [ 0.5530],\n",
      "        [-0.2097],\n",
      "        [ 0.7454],\n",
      "        [ 0.5204],\n",
      "        [ 1.2308],\n",
      "        [ 0.7454],\n",
      "        [-0.7113],\n",
      "        [-0.1207],\n",
      "        [-1.0662],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8949],\n",
      "        [ 0.6179],\n",
      "        [ 1.2308],\n",
      "        [-1.6065],\n",
      "        [ 0.0648],\n",
      "        [-0.4079],\n",
      "        [-1.3141],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5716],\n",
      "        [-1.5440],\n",
      "        [ 0.6179],\n",
      "        [-1.4401],\n",
      "        [ 0.4221],\n",
      "        [-0.4353],\n",
      "        [ 0.4221],\n",
      "        [ 1.2308],\n",
      "        [ 1.1867]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 528/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0135,\n",
      " epoch_time_duration: 0.0130\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6500],\n",
      "        [ 0.5855],\n",
      "        [-0.0291],\n",
      "        [ 0.4877],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8077],\n",
      "        [-1.5871],\n",
      "        [-0.8950],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.9288],\n",
      "        [-0.2096],\n",
      "        [ 0.5530],\n",
      "        [-0.6267],\n",
      "        [-0.2961],\n",
      "        [ 0.8689],\n",
      "        [ 0.7454],\n",
      "        [ 0.7767],\n",
      "        [ 1.2308],\n",
      "        [ 1.2308],\n",
      "        [ 1.0721],\n",
      "        [-0.2961],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4401],\n",
      "        [ 0.9582],\n",
      "        [-1.3141],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.7454],\n",
      "        [ 0.5204],\n",
      "        [ 1.2308],\n",
      "        [ 0.7454],\n",
      "        [-0.7114],\n",
      "        [-0.1206],\n",
      "        [-1.0662],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8950],\n",
      "        [ 0.6178],\n",
      "        [ 1.2308],\n",
      "        [-1.6065],\n",
      "        [ 0.0649],\n",
      "        [-0.4079],\n",
      "        [-1.3141],\n",
      "        [ 1.0159],\n",
      "        [-0.4079],\n",
      "        [-0.5717],\n",
      "        [-1.5440],\n",
      "        [ 0.6178],\n",
      "        [-1.4401],\n",
      "        [ 0.4221],\n",
      "        [-0.4353],\n",
      "        [ 0.4221],\n",
      "        [ 1.2308],\n",
      "        [ 1.1867]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 529/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0134,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6500],\n",
      "        [ 0.5855],\n",
      "        [-0.0290],\n",
      "        [ 0.4876],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8077],\n",
      "        [-1.5872],\n",
      "        [-0.8950],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.9287],\n",
      "        [-0.2096],\n",
      "        [ 0.5530],\n",
      "        [-0.6267],\n",
      "        [-0.2960],\n",
      "        [ 0.8689],\n",
      "        [ 0.7453],\n",
      "        [ 0.7766],\n",
      "        [ 1.2308],\n",
      "        [ 1.2308],\n",
      "        [ 1.0721],\n",
      "        [-0.2960],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4400],\n",
      "        [ 0.9582],\n",
      "        [-1.3141],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.7453],\n",
      "        [ 0.5204],\n",
      "        [ 1.2308],\n",
      "        [ 0.7453],\n",
      "        [-0.7114],\n",
      "        [-0.1206],\n",
      "        [-1.0662],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8950],\n",
      "        [ 0.6178],\n",
      "        [ 1.2308],\n",
      "        [-1.6066],\n",
      "        [ 0.0649],\n",
      "        [-0.4078],\n",
      "        [-1.3141],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5717],\n",
      "        [-1.5440],\n",
      "        [ 0.6178],\n",
      "        [-1.4400],\n",
      "        [ 0.4221],\n",
      "        [-0.4353],\n",
      "        [ 0.4221],\n",
      "        [ 1.2308],\n",
      "        [ 1.1867]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 530/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0134,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6500],\n",
      "        [ 0.5854],\n",
      "        [-0.0290],\n",
      "        [ 0.4876],\n",
      "        [ 0.8990],\n",
      "        [ 0.9582],\n",
      "        [ 0.8990],\n",
      "        [ 0.8077],\n",
      "        [-1.5872],\n",
      "        [-0.8951],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.9287],\n",
      "        [-0.2096],\n",
      "        [ 0.5530],\n",
      "        [-0.6268],\n",
      "        [-0.2960],\n",
      "        [ 0.8688],\n",
      "        [ 0.7453],\n",
      "        [ 0.7766],\n",
      "        [ 1.2309],\n",
      "        [ 1.2309],\n",
      "        [ 1.0721],\n",
      "        [-0.2960],\n",
      "        [-1.2096],\n",
      "        [ 1.0721],\n",
      "        [-1.4400],\n",
      "        [ 0.9582],\n",
      "        [-1.3140],\n",
      "        [ 0.5530],\n",
      "        [-0.2096],\n",
      "        [ 0.7453],\n",
      "        [ 0.5203],\n",
      "        [ 1.2309],\n",
      "        [ 0.7453],\n",
      "        [-0.7115],\n",
      "        [-0.1205],\n",
      "        [-1.0662],\n",
      "        [-1.1378],\n",
      "        [ 0.9582],\n",
      "        [-0.8951],\n",
      "        [ 0.6178],\n",
      "        [ 1.2309],\n",
      "        [-1.6066],\n",
      "        [ 0.0649],\n",
      "        [-0.4078],\n",
      "        [-1.3140],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5717],\n",
      "        [-1.5440],\n",
      "        [ 0.6178],\n",
      "        [-1.4400],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2309],\n",
      "        [ 1.1868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 531/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0134,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6500],\n",
      "        [ 0.5854],\n",
      "        [-0.0290],\n",
      "        [ 0.4876],\n",
      "        [ 0.8989],\n",
      "        [ 0.9581],\n",
      "        [ 0.8989],\n",
      "        [ 0.8076],\n",
      "        [-1.5872],\n",
      "        [-0.8951],\n",
      "        [ 0.5529],\n",
      "        [-0.2095],\n",
      "        [ 0.9287],\n",
      "        [-0.2095],\n",
      "        [ 0.5529],\n",
      "        [-0.6268],\n",
      "        [-0.2960],\n",
      "        [ 0.8688],\n",
      "        [ 0.7453],\n",
      "        [ 0.7766],\n",
      "        [ 1.2309],\n",
      "        [ 1.2309],\n",
      "        [ 1.0721],\n",
      "        [-0.2960],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4400],\n",
      "        [ 0.9581],\n",
      "        [-1.3140],\n",
      "        [ 0.5529],\n",
      "        [-0.2095],\n",
      "        [ 0.7453],\n",
      "        [ 0.5203],\n",
      "        [ 1.2309],\n",
      "        [ 0.7453],\n",
      "        [-0.7115],\n",
      "        [-0.1205],\n",
      "        [-1.0663],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8951],\n",
      "        [ 0.6178],\n",
      "        [ 1.2309],\n",
      "        [-1.6067],\n",
      "        [ 0.0649],\n",
      "        [-0.4078],\n",
      "        [-1.3140],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5717],\n",
      "        [-1.5441],\n",
      "        [ 0.6178],\n",
      "        [-1.4400],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2309],\n",
      "        [ 1.1868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 532/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0134,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6499],\n",
      "        [ 0.5854],\n",
      "        [-0.0289],\n",
      "        [ 0.4876],\n",
      "        [ 0.8989],\n",
      "        [ 0.9581],\n",
      "        [ 0.8989],\n",
      "        [ 0.8076],\n",
      "        [-1.5873],\n",
      "        [-0.8952],\n",
      "        [ 0.5529],\n",
      "        [-0.2095],\n",
      "        [ 0.9287],\n",
      "        [-0.2095],\n",
      "        [ 0.5529],\n",
      "        [-0.6268],\n",
      "        [-0.2960],\n",
      "        [ 0.8688],\n",
      "        [ 0.7453],\n",
      "        [ 0.7766],\n",
      "        [ 1.2310],\n",
      "        [ 1.2310],\n",
      "        [ 1.0721],\n",
      "        [-0.2960],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4399],\n",
      "        [ 0.9581],\n",
      "        [-1.3139],\n",
      "        [ 0.5529],\n",
      "        [-0.2095],\n",
      "        [ 0.7453],\n",
      "        [ 0.5203],\n",
      "        [ 1.2310],\n",
      "        [ 0.7453],\n",
      "        [-0.7116],\n",
      "        [-0.1205],\n",
      "        [-1.0663],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8952],\n",
      "        [ 0.6178],\n",
      "        [ 1.2310],\n",
      "        [-1.6067],\n",
      "        [ 0.0650],\n",
      "        [-0.4078],\n",
      "        [-1.3139],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5717],\n",
      "        [-1.5441],\n",
      "        [ 0.6178],\n",
      "        [-1.4399],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2310],\n",
      "        [ 1.1868]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 533/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0133,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6499],\n",
      "        [ 0.5854],\n",
      "        [-0.0289],\n",
      "        [ 0.4876],\n",
      "        [ 0.8989],\n",
      "        [ 0.9581],\n",
      "        [ 0.8989],\n",
      "        [ 0.8076],\n",
      "        [-1.5873],\n",
      "        [-0.8953],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.9287],\n",
      "        [-0.2094],\n",
      "        [ 0.5529],\n",
      "        [-0.6269],\n",
      "        [-0.2959],\n",
      "        [ 0.8688],\n",
      "        [ 0.7452],\n",
      "        [ 0.7766],\n",
      "        [ 1.2310],\n",
      "        [ 1.2310],\n",
      "        [ 1.0721],\n",
      "        [-0.2959],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4399],\n",
      "        [ 0.9581],\n",
      "        [-1.3139],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.7452],\n",
      "        [ 0.5203],\n",
      "        [ 1.2310],\n",
      "        [ 0.7452],\n",
      "        [-0.7116],\n",
      "        [-0.1204],\n",
      "        [-1.0663],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8953],\n",
      "        [ 0.6177],\n",
      "        [ 1.2310],\n",
      "        [-1.6068],\n",
      "        [ 0.0650],\n",
      "        [-0.4078],\n",
      "        [-1.3139],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5718],\n",
      "        [-1.5441],\n",
      "        [ 0.6177],\n",
      "        [-1.4399],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2310],\n",
      "        [ 1.1869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 534/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0133,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6499],\n",
      "        [ 0.5854],\n",
      "        [-0.0288],\n",
      "        [ 0.4876],\n",
      "        [ 0.8989],\n",
      "        [ 0.9581],\n",
      "        [ 0.8989],\n",
      "        [ 0.8076],\n",
      "        [-1.5873],\n",
      "        [-0.8953],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.9287],\n",
      "        [-0.2094],\n",
      "        [ 0.5529],\n",
      "        [-0.6269],\n",
      "        [-0.2959],\n",
      "        [ 0.8688],\n",
      "        [ 0.7452],\n",
      "        [ 0.7765],\n",
      "        [ 1.2311],\n",
      "        [ 1.2311],\n",
      "        [ 1.0721],\n",
      "        [-0.2959],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4399],\n",
      "        [ 0.9581],\n",
      "        [-1.3139],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.7452],\n",
      "        [ 0.5203],\n",
      "        [ 1.2311],\n",
      "        [ 0.7452],\n",
      "        [-0.7117],\n",
      "        [-0.1204],\n",
      "        [-1.0664],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8953],\n",
      "        [ 0.6177],\n",
      "        [ 1.2311],\n",
      "        [-1.6068],\n",
      "        [ 0.0650],\n",
      "        [-0.4078],\n",
      "        [-1.3139],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5718],\n",
      "        [-1.5441],\n",
      "        [ 0.6177],\n",
      "        [-1.4399],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2311],\n",
      "        [ 1.1869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 535/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0133,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6499],\n",
      "        [ 0.5854],\n",
      "        [-0.0288],\n",
      "        [ 0.4876],\n",
      "        [ 0.8989],\n",
      "        [ 0.9581],\n",
      "        [ 0.8989],\n",
      "        [ 0.8075],\n",
      "        [-1.5874],\n",
      "        [-0.8954],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.9286],\n",
      "        [-0.2094],\n",
      "        [ 0.5529],\n",
      "        [-0.6269],\n",
      "        [-0.2959],\n",
      "        [ 0.8687],\n",
      "        [ 0.7452],\n",
      "        [ 0.7765],\n",
      "        [ 1.2311],\n",
      "        [ 1.2311],\n",
      "        [ 1.0721],\n",
      "        [-0.2959],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4398],\n",
      "        [ 0.9581],\n",
      "        [-1.3138],\n",
      "        [ 0.5529],\n",
      "        [-0.2094],\n",
      "        [ 0.7452],\n",
      "        [ 0.5203],\n",
      "        [ 1.2311],\n",
      "        [ 0.7452],\n",
      "        [-0.7117],\n",
      "        [-0.1204],\n",
      "        [-1.0664],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8954],\n",
      "        [ 0.6177],\n",
      "        [ 1.2311],\n",
      "        [-1.6069],\n",
      "        [ 0.0651],\n",
      "        [-0.4078],\n",
      "        [-1.3138],\n",
      "        [ 1.0159],\n",
      "        [-0.4078],\n",
      "        [-0.5718],\n",
      "        [-1.5441],\n",
      "        [ 0.6177],\n",
      "        [-1.4398],\n",
      "        [ 0.4220],\n",
      "        [-0.4353],\n",
      "        [ 0.4220],\n",
      "        [ 1.2311],\n",
      "        [ 1.1869]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 536/10000,\n",
      " train_loss: 0.0003,\n",
      " train_mae: 0.0133,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6499],\n",
      "        [ 0.5853],\n",
      "        [-0.0288],\n",
      "        [ 0.4876],\n",
      "        [ 0.8988],\n",
      "        [ 0.9581],\n",
      "        [ 0.8988],\n",
      "        [ 0.8075],\n",
      "        [-1.5874],\n",
      "        [-0.8955],\n",
      "        [ 0.5529],\n",
      "        [-0.2093],\n",
      "        [ 0.9286],\n",
      "        [-0.2093],\n",
      "        [ 0.5529],\n",
      "        [-0.6270],\n",
      "        [-0.2958],\n",
      "        [ 0.8687],\n",
      "        [ 0.7452],\n",
      "        [ 0.7765],\n",
      "        [ 1.2312],\n",
      "        [ 1.2312],\n",
      "        [ 1.0721],\n",
      "        [-0.2958],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4398],\n",
      "        [ 0.9581],\n",
      "        [-1.3138],\n",
      "        [ 0.5529],\n",
      "        [-0.2093],\n",
      "        [ 0.7452],\n",
      "        [ 0.5203],\n",
      "        [ 1.2312],\n",
      "        [ 0.7452],\n",
      "        [-0.7118],\n",
      "        [-0.1203],\n",
      "        [-1.0664],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8955],\n",
      "        [ 0.6177],\n",
      "        [ 1.2312],\n",
      "        [-1.6069],\n",
      "        [ 0.0651],\n",
      "        [-0.4077],\n",
      "        [-1.3138],\n",
      "        [ 1.0159],\n",
      "        [-0.4077],\n",
      "        [-0.5718],\n",
      "        [-1.5441],\n",
      "        [ 0.6177],\n",
      "        [-1.4398],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2312],\n",
      "        [ 1.1870]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 537/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0132,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6498],\n",
      "        [ 0.5853],\n",
      "        [-0.0287],\n",
      "        [ 0.4876],\n",
      "        [ 0.8988],\n",
      "        [ 0.9581],\n",
      "        [ 0.8988],\n",
      "        [ 0.8075],\n",
      "        [-1.5874],\n",
      "        [-0.8955],\n",
      "        [ 0.5529],\n",
      "        [-0.2093],\n",
      "        [ 0.9286],\n",
      "        [-0.2093],\n",
      "        [ 0.5529],\n",
      "        [-0.6270],\n",
      "        [-0.2958],\n",
      "        [ 0.8687],\n",
      "        [ 0.7452],\n",
      "        [ 0.7765],\n",
      "        [ 1.2312],\n",
      "        [ 1.2312],\n",
      "        [ 1.0721],\n",
      "        [-0.2958],\n",
      "        [-1.2095],\n",
      "        [ 1.0721],\n",
      "        [-1.4398],\n",
      "        [ 0.9581],\n",
      "        [-1.3138],\n",
      "        [ 0.5529],\n",
      "        [-0.2093],\n",
      "        [ 0.7452],\n",
      "        [ 0.5203],\n",
      "        [ 1.2312],\n",
      "        [ 0.7452],\n",
      "        [-0.7119],\n",
      "        [-0.1203],\n",
      "        [-1.0664],\n",
      "        [-1.1379],\n",
      "        [ 0.9581],\n",
      "        [-0.8955],\n",
      "        [ 0.6177],\n",
      "        [ 1.2312],\n",
      "        [-1.6070],\n",
      "        [ 0.0651],\n",
      "        [-0.4077],\n",
      "        [-1.3138],\n",
      "        [ 1.0159],\n",
      "        [-0.4077],\n",
      "        [-0.5719],\n",
      "        [-1.5441],\n",
      "        [ 0.6177],\n",
      "        [-1.4398],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2312],\n",
      "        [ 1.1870]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 538/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0132,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6498],\n",
      "        [ 0.5853],\n",
      "        [-0.0287],\n",
      "        [ 0.4876],\n",
      "        [ 0.8988],\n",
      "        [ 0.9580],\n",
      "        [ 0.8988],\n",
      "        [ 0.8075],\n",
      "        [-1.5874],\n",
      "        [-0.8956],\n",
      "        [ 0.5528],\n",
      "        [-0.2093],\n",
      "        [ 0.9286],\n",
      "        [-0.2093],\n",
      "        [ 0.5528],\n",
      "        [-0.6270],\n",
      "        [-0.2958],\n",
      "        [ 0.8687],\n",
      "        [ 0.7451],\n",
      "        [ 0.7764],\n",
      "        [ 1.2313],\n",
      "        [ 1.2313],\n",
      "        [ 1.0721],\n",
      "        [-0.2958],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4397],\n",
      "        [ 0.9580],\n",
      "        [-1.3137],\n",
      "        [ 0.5528],\n",
      "        [-0.2093],\n",
      "        [ 0.7451],\n",
      "        [ 0.5203],\n",
      "        [ 1.2313],\n",
      "        [ 0.7451],\n",
      "        [-0.7119],\n",
      "        [-0.1202],\n",
      "        [-1.0665],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8956],\n",
      "        [ 0.6176],\n",
      "        [ 1.2313],\n",
      "        [-1.6070],\n",
      "        [ 0.0652],\n",
      "        [-0.4077],\n",
      "        [-1.3137],\n",
      "        [ 1.0158],\n",
      "        [-0.4077],\n",
      "        [-0.5719],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4397],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2313],\n",
      "        [ 1.1870]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 539/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0132,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1738],\n",
      "        [-1.1738],\n",
      "        [ 0.6498],\n",
      "        [ 0.5853],\n",
      "        [-0.0287],\n",
      "        [ 0.4876],\n",
      "        [ 0.8988],\n",
      "        [ 0.9580],\n",
      "        [ 0.8988],\n",
      "        [ 0.8075],\n",
      "        [-1.5875],\n",
      "        [-0.8956],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.9286],\n",
      "        [-0.2092],\n",
      "        [ 0.5528],\n",
      "        [-0.6271],\n",
      "        [-0.2957],\n",
      "        [ 0.8687],\n",
      "        [ 0.7451],\n",
      "        [ 0.7764],\n",
      "        [ 1.2313],\n",
      "        [ 1.2313],\n",
      "        [ 1.0721],\n",
      "        [-0.2957],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4397],\n",
      "        [ 0.9580],\n",
      "        [-1.3137],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.7451],\n",
      "        [ 0.5202],\n",
      "        [ 1.2313],\n",
      "        [ 0.7451],\n",
      "        [-0.7120],\n",
      "        [-0.1202],\n",
      "        [-1.0665],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8956],\n",
      "        [ 0.6176],\n",
      "        [ 1.2313],\n",
      "        [-1.6071],\n",
      "        [ 0.0652],\n",
      "        [-0.4077],\n",
      "        [-1.3137],\n",
      "        [ 1.0158],\n",
      "        [-0.4077],\n",
      "        [-0.5719],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4397],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2313],\n",
      "        [ 1.1871]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 540/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0132,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6498],\n",
      "        [ 0.5853],\n",
      "        [-0.0286],\n",
      "        [ 0.4876],\n",
      "        [ 0.8988],\n",
      "        [ 0.9580],\n",
      "        [ 0.8988],\n",
      "        [ 0.8074],\n",
      "        [-1.5875],\n",
      "        [-0.8957],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.9286],\n",
      "        [-0.2092],\n",
      "        [ 0.5528],\n",
      "        [-0.6271],\n",
      "        [-0.2957],\n",
      "        [ 0.8686],\n",
      "        [ 0.7451],\n",
      "        [ 0.7764],\n",
      "        [ 1.2314],\n",
      "        [ 1.2314],\n",
      "        [ 1.0721],\n",
      "        [-0.2957],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4396],\n",
      "        [ 0.9580],\n",
      "        [-1.3137],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.7451],\n",
      "        [ 0.5202],\n",
      "        [ 1.2314],\n",
      "        [ 0.7451],\n",
      "        [-0.7120],\n",
      "        [-0.1202],\n",
      "        [-1.0665],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8957],\n",
      "        [ 0.6176],\n",
      "        [ 1.2314],\n",
      "        [-1.6071],\n",
      "        [ 0.0652],\n",
      "        [-0.4077],\n",
      "        [-1.3137],\n",
      "        [ 1.0158],\n",
      "        [-0.4077],\n",
      "        [-0.5719],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4396],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2314],\n",
      "        [ 1.1871]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 541/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0131,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6498],\n",
      "        [ 0.5853],\n",
      "        [-0.0286],\n",
      "        [ 0.4875],\n",
      "        [ 0.8987],\n",
      "        [ 0.9580],\n",
      "        [ 0.8987],\n",
      "        [ 0.8074],\n",
      "        [-1.5875],\n",
      "        [-0.8958],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.9285],\n",
      "        [-0.2092],\n",
      "        [ 0.5528],\n",
      "        [-0.6271],\n",
      "        [-0.2957],\n",
      "        [ 0.8686],\n",
      "        [ 0.7451],\n",
      "        [ 0.7764],\n",
      "        [ 1.2314],\n",
      "        [ 1.2314],\n",
      "        [ 1.0721],\n",
      "        [-0.2957],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4396],\n",
      "        [ 0.9580],\n",
      "        [-1.3136],\n",
      "        [ 0.5528],\n",
      "        [-0.2092],\n",
      "        [ 0.7451],\n",
      "        [ 0.5202],\n",
      "        [ 1.2314],\n",
      "        [ 0.7451],\n",
      "        [-0.7121],\n",
      "        [-0.1201],\n",
      "        [-1.0666],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8958],\n",
      "        [ 0.6176],\n",
      "        [ 1.2314],\n",
      "        [-1.6072],\n",
      "        [ 0.0653],\n",
      "        [-0.4077],\n",
      "        [-1.3136],\n",
      "        [ 1.0158],\n",
      "        [-0.4077],\n",
      "        [-0.5719],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4396],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2314],\n",
      "        [ 1.1871]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 542/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0131,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6497],\n",
      "        [ 0.5852],\n",
      "        [-0.0286],\n",
      "        [ 0.4875],\n",
      "        [ 0.8987],\n",
      "        [ 0.9580],\n",
      "        [ 0.8987],\n",
      "        [ 0.8074],\n",
      "        [-1.5876],\n",
      "        [-0.8958],\n",
      "        [ 0.5528],\n",
      "        [-0.2091],\n",
      "        [ 0.9285],\n",
      "        [-0.2091],\n",
      "        [ 0.5528],\n",
      "        [-0.6272],\n",
      "        [-0.2957],\n",
      "        [ 0.8686],\n",
      "        [ 0.7450],\n",
      "        [ 0.7763],\n",
      "        [ 1.2315],\n",
      "        [ 1.2315],\n",
      "        [ 1.0721],\n",
      "        [-0.2957],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4396],\n",
      "        [ 0.9580],\n",
      "        [-1.3136],\n",
      "        [ 0.5528],\n",
      "        [-0.2091],\n",
      "        [ 0.7450],\n",
      "        [ 0.5202],\n",
      "        [ 1.2315],\n",
      "        [ 0.7450],\n",
      "        [-0.7121],\n",
      "        [-0.1201],\n",
      "        [-1.0666],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8958],\n",
      "        [ 0.6176],\n",
      "        [ 1.2315],\n",
      "        [-1.6072],\n",
      "        [ 0.0653],\n",
      "        [-0.4076],\n",
      "        [-1.3136],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5720],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4396],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2315],\n",
      "        [ 1.1872]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 543/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0131,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6497],\n",
      "        [ 0.5852],\n",
      "        [-0.0285],\n",
      "        [ 0.4875],\n",
      "        [ 0.8987],\n",
      "        [ 0.9580],\n",
      "        [ 0.8987],\n",
      "        [ 0.8074],\n",
      "        [-1.5876],\n",
      "        [-0.8959],\n",
      "        [ 0.5528],\n",
      "        [-0.2091],\n",
      "        [ 0.9285],\n",
      "        [-0.2091],\n",
      "        [ 0.5528],\n",
      "        [-0.6272],\n",
      "        [-0.2956],\n",
      "        [ 0.8686],\n",
      "        [ 0.7450],\n",
      "        [ 0.7763],\n",
      "        [ 1.2315],\n",
      "        [ 1.2315],\n",
      "        [ 1.0721],\n",
      "        [-0.2956],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4395],\n",
      "        [ 0.9580],\n",
      "        [-1.3135],\n",
      "        [ 0.5528],\n",
      "        [-0.2091],\n",
      "        [ 0.7450],\n",
      "        [ 0.5202],\n",
      "        [ 1.2315],\n",
      "        [ 0.7450],\n",
      "        [-0.7122],\n",
      "        [-0.1200],\n",
      "        [-1.0666],\n",
      "        [-1.1379],\n",
      "        [ 0.9580],\n",
      "        [-0.8959],\n",
      "        [ 0.6176],\n",
      "        [ 1.2315],\n",
      "        [-1.6073],\n",
      "        [ 0.0653],\n",
      "        [-0.4076],\n",
      "        [-1.3135],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5720],\n",
      "        [-1.5441],\n",
      "        [ 0.6176],\n",
      "        [-1.4395],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2315],\n",
      "        [ 1.1872]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 544/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0131,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6497],\n",
      "        [ 0.5852],\n",
      "        [-0.0285],\n",
      "        [ 0.4875],\n",
      "        [ 0.8987],\n",
      "        [ 0.9580],\n",
      "        [ 0.8987],\n",
      "        [ 0.8073],\n",
      "        [-1.5876],\n",
      "        [-0.8960],\n",
      "        [ 0.5528],\n",
      "        [-0.2090],\n",
      "        [ 0.9285],\n",
      "        [-0.2090],\n",
      "        [ 0.5528],\n",
      "        [-0.6273],\n",
      "        [-0.2956],\n",
      "        [ 0.8685],\n",
      "        [ 0.7450],\n",
      "        [ 0.7763],\n",
      "        [ 1.2316],\n",
      "        [ 1.2316],\n",
      "        [ 1.0721],\n",
      "        [-0.2956],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4395],\n",
      "        [ 0.9580],\n",
      "        [-1.3135],\n",
      "        [ 0.5528],\n",
      "        [-0.2090],\n",
      "        [ 0.7450],\n",
      "        [ 0.5202],\n",
      "        [ 1.2316],\n",
      "        [ 0.7450],\n",
      "        [-0.7122],\n",
      "        [-0.1200],\n",
      "        [-1.0666],\n",
      "        [-1.1380],\n",
      "        [ 0.9580],\n",
      "        [-0.8960],\n",
      "        [ 0.6175],\n",
      "        [ 1.2316],\n",
      "        [-1.6073],\n",
      "        [ 0.0653],\n",
      "        [-0.4076],\n",
      "        [-1.3135],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5720],\n",
      "        [-1.5441],\n",
      "        [ 0.6175],\n",
      "        [-1.4395],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2316],\n",
      "        [ 1.1872]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 545/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0131,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6497],\n",
      "        [ 0.5852],\n",
      "        [-0.0284],\n",
      "        [ 0.4875],\n",
      "        [ 0.8987],\n",
      "        [ 0.9579],\n",
      "        [ 0.8987],\n",
      "        [ 0.8073],\n",
      "        [-1.5877],\n",
      "        [-0.8960],\n",
      "        [ 0.5527],\n",
      "        [-0.2090],\n",
      "        [ 0.9285],\n",
      "        [-0.2090],\n",
      "        [ 0.5527],\n",
      "        [-0.6273],\n",
      "        [-0.2956],\n",
      "        [ 0.8685],\n",
      "        [ 0.7450],\n",
      "        [ 0.7763],\n",
      "        [ 1.2316],\n",
      "        [ 1.2316],\n",
      "        [ 1.0721],\n",
      "        [-0.2956],\n",
      "        [-1.2094],\n",
      "        [ 1.0721],\n",
      "        [-1.4395],\n",
      "        [ 0.9579],\n",
      "        [-1.3135],\n",
      "        [ 0.5527],\n",
      "        [-0.2090],\n",
      "        [ 0.7450],\n",
      "        [ 0.5202],\n",
      "        [ 1.2316],\n",
      "        [ 0.7450],\n",
      "        [-0.7123],\n",
      "        [-0.1200],\n",
      "        [-1.0667],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8960],\n",
      "        [ 0.6175],\n",
      "        [ 1.2316],\n",
      "        [-1.6074],\n",
      "        [ 0.0654],\n",
      "        [-0.4076],\n",
      "        [-1.3135],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5720],\n",
      "        [-1.5441],\n",
      "        [ 0.6175],\n",
      "        [-1.4395],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2316],\n",
      "        [ 1.1873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 546/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0130,\n",
      " epoch_time_duration: 0.0138\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6497],\n",
      "        [ 0.5852],\n",
      "        [-0.0284],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8073],\n",
      "        [-1.5877],\n",
      "        [-0.8961],\n",
      "        [ 0.5527],\n",
      "        [-0.2090],\n",
      "        [ 0.9285],\n",
      "        [-0.2090],\n",
      "        [ 0.5527],\n",
      "        [-0.6273],\n",
      "        [-0.2955],\n",
      "        [ 0.8685],\n",
      "        [ 0.7450],\n",
      "        [ 0.7763],\n",
      "        [ 1.2316],\n",
      "        [ 1.2316],\n",
      "        [ 1.0721],\n",
      "        [-0.2955],\n",
      "        [-1.2093],\n",
      "        [ 1.0721],\n",
      "        [-1.4394],\n",
      "        [ 0.9579],\n",
      "        [-1.3134],\n",
      "        [ 0.5527],\n",
      "        [-0.2090],\n",
      "        [ 0.7450],\n",
      "        [ 0.5202],\n",
      "        [ 1.2316],\n",
      "        [ 0.7450],\n",
      "        [-0.7123],\n",
      "        [-0.1199],\n",
      "        [-1.0667],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8961],\n",
      "        [ 0.6175],\n",
      "        [ 1.2316],\n",
      "        [-1.6074],\n",
      "        [ 0.0654],\n",
      "        [-0.4076],\n",
      "        [-1.3134],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5720],\n",
      "        [-1.5441],\n",
      "        [ 0.6175],\n",
      "        [-1.4394],\n",
      "        [ 0.4220],\n",
      "        [-0.4352],\n",
      "        [ 0.4220],\n",
      "        [ 1.2316],\n",
      "        [ 1.1873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 547/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0130,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6496],\n",
      "        [ 0.5852],\n",
      "        [-0.0284],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8073],\n",
      "        [-1.5877],\n",
      "        [-0.8961],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.9284],\n",
      "        [-0.2089],\n",
      "        [ 0.5527],\n",
      "        [-0.6274],\n",
      "        [-0.2955],\n",
      "        [ 0.8685],\n",
      "        [ 0.7449],\n",
      "        [ 0.7762],\n",
      "        [ 1.2317],\n",
      "        [ 1.2317],\n",
      "        [ 1.0722],\n",
      "        [-0.2955],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4394],\n",
      "        [ 0.9579],\n",
      "        [-1.3134],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.7449],\n",
      "        [ 0.5201],\n",
      "        [ 1.2317],\n",
      "        [ 0.7449],\n",
      "        [-0.7124],\n",
      "        [-0.1199],\n",
      "        [-1.0667],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8961],\n",
      "        [ 0.6175],\n",
      "        [ 1.2317],\n",
      "        [-1.6075],\n",
      "        [ 0.0654],\n",
      "        [-0.4076],\n",
      "        [-1.3134],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5721],\n",
      "        [-1.5441],\n",
      "        [ 0.6175],\n",
      "        [-1.4394],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2317],\n",
      "        [ 1.1873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 548/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0130,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6496],\n",
      "        [ 0.5852],\n",
      "        [-0.0283],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8072],\n",
      "        [-1.5878],\n",
      "        [-0.8962],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.9284],\n",
      "        [-0.2089],\n",
      "        [ 0.5527],\n",
      "        [-0.6274],\n",
      "        [-0.2955],\n",
      "        [ 0.8685],\n",
      "        [ 0.7449],\n",
      "        [ 0.7762],\n",
      "        [ 1.2317],\n",
      "        [ 1.2317],\n",
      "        [ 1.0722],\n",
      "        [-0.2955],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4394],\n",
      "        [ 0.9579],\n",
      "        [-1.3134],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.7449],\n",
      "        [ 0.5201],\n",
      "        [ 1.2317],\n",
      "        [ 0.7449],\n",
      "        [-0.7124],\n",
      "        [-0.1199],\n",
      "        [-1.0668],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8962],\n",
      "        [ 0.6175],\n",
      "        [ 1.2317],\n",
      "        [-1.6075],\n",
      "        [ 0.0655],\n",
      "        [-0.4076],\n",
      "        [-1.3134],\n",
      "        [ 1.0158],\n",
      "        [-0.4076],\n",
      "        [-0.5721],\n",
      "        [-1.5441],\n",
      "        [ 0.6175],\n",
      "        [-1.4394],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2317],\n",
      "        [ 1.1873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 549/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0130,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6496],\n",
      "        [ 0.5851],\n",
      "        [-0.0283],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8072],\n",
      "        [-1.5878],\n",
      "        [-0.8963],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.9284],\n",
      "        [-0.2089],\n",
      "        [ 0.5527],\n",
      "        [-0.6274],\n",
      "        [-0.2954],\n",
      "        [ 0.8684],\n",
      "        [ 0.7449],\n",
      "        [ 0.7762],\n",
      "        [ 1.2318],\n",
      "        [ 1.2318],\n",
      "        [ 1.0722],\n",
      "        [-0.2954],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4393],\n",
      "        [ 0.9579],\n",
      "        [-1.3133],\n",
      "        [ 0.5527],\n",
      "        [-0.2089],\n",
      "        [ 0.7449],\n",
      "        [ 0.5201],\n",
      "        [ 1.2318],\n",
      "        [ 0.7449],\n",
      "        [-0.7125],\n",
      "        [-0.1198],\n",
      "        [-1.0668],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8963],\n",
      "        [ 0.6174],\n",
      "        [ 1.2318],\n",
      "        [-1.6076],\n",
      "        [ 0.0655],\n",
      "        [-0.4075],\n",
      "        [-1.3133],\n",
      "        [ 1.0158],\n",
      "        [-0.4075],\n",
      "        [-0.5721],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4393],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2318],\n",
      "        [ 1.1874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 550/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0129,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6496],\n",
      "        [ 0.5851],\n",
      "        [-0.0283],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8072],\n",
      "        [-1.5878],\n",
      "        [-0.8963],\n",
      "        [ 0.5527],\n",
      "        [-0.2088],\n",
      "        [ 0.9284],\n",
      "        [-0.2088],\n",
      "        [ 0.5527],\n",
      "        [-0.6275],\n",
      "        [-0.2954],\n",
      "        [ 0.8684],\n",
      "        [ 0.7449],\n",
      "        [ 0.7762],\n",
      "        [ 1.2318],\n",
      "        [ 1.2318],\n",
      "        [ 1.0722],\n",
      "        [-0.2954],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4393],\n",
      "        [ 0.9579],\n",
      "        [-1.3133],\n",
      "        [ 0.5527],\n",
      "        [-0.2088],\n",
      "        [ 0.7449],\n",
      "        [ 0.5201],\n",
      "        [ 1.2318],\n",
      "        [ 0.7449],\n",
      "        [-0.7125],\n",
      "        [-0.1198],\n",
      "        [-1.0668],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8963],\n",
      "        [ 0.6174],\n",
      "        [ 1.2318],\n",
      "        [-1.6076],\n",
      "        [ 0.0655],\n",
      "        [-0.4075],\n",
      "        [-1.3133],\n",
      "        [ 1.0158],\n",
      "        [-0.4075],\n",
      "        [-0.5721],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4393],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2318],\n",
      "        [ 1.1874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 551/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0129,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6496],\n",
      "        [ 0.5851],\n",
      "        [-0.0282],\n",
      "        [ 0.4875],\n",
      "        [ 0.8986],\n",
      "        [ 0.9579],\n",
      "        [ 0.8986],\n",
      "        [ 0.8072],\n",
      "        [-1.5879],\n",
      "        [-0.8964],\n",
      "        [ 0.5527],\n",
      "        [-0.2088],\n",
      "        [ 0.9284],\n",
      "        [-0.2088],\n",
      "        [ 0.5527],\n",
      "        [-0.6275],\n",
      "        [-0.2954],\n",
      "        [ 0.8684],\n",
      "        [ 0.7448],\n",
      "        [ 0.7761],\n",
      "        [ 1.2319],\n",
      "        [ 1.2319],\n",
      "        [ 1.0722],\n",
      "        [-0.2954],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4393],\n",
      "        [ 0.9579],\n",
      "        [-1.3133],\n",
      "        [ 0.5527],\n",
      "        [-0.2088],\n",
      "        [ 0.7448],\n",
      "        [ 0.5201],\n",
      "        [ 1.2319],\n",
      "        [ 0.7448],\n",
      "        [-0.7126],\n",
      "        [-0.1197],\n",
      "        [-1.0668],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8964],\n",
      "        [ 0.6174],\n",
      "        [ 1.2319],\n",
      "        [-1.6076],\n",
      "        [ 0.0656],\n",
      "        [-0.4075],\n",
      "        [-1.3133],\n",
      "        [ 1.0158],\n",
      "        [-0.4075],\n",
      "        [-0.5722],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4393],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2319],\n",
      "        [ 1.1874]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 552/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0129,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6495],\n",
      "        [ 0.5851],\n",
      "        [-0.0282],\n",
      "        [ 0.4874],\n",
      "        [ 0.8985],\n",
      "        [ 0.9579],\n",
      "        [ 0.8985],\n",
      "        [ 0.8072],\n",
      "        [-1.5879],\n",
      "        [-0.8964],\n",
      "        [ 0.5526],\n",
      "        [-0.2088],\n",
      "        [ 0.9284],\n",
      "        [-0.2088],\n",
      "        [ 0.5526],\n",
      "        [-0.6275],\n",
      "        [-0.2954],\n",
      "        [ 0.8684],\n",
      "        [ 0.7448],\n",
      "        [ 0.7761],\n",
      "        [ 1.2319],\n",
      "        [ 1.2319],\n",
      "        [ 1.0722],\n",
      "        [-0.2954],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4392],\n",
      "        [ 0.9579],\n",
      "        [-1.3132],\n",
      "        [ 0.5526],\n",
      "        [-0.2088],\n",
      "        [ 0.7448],\n",
      "        [ 0.5201],\n",
      "        [ 1.2319],\n",
      "        [ 0.7448],\n",
      "        [-0.7126],\n",
      "        [-0.1197],\n",
      "        [-1.0669],\n",
      "        [-1.1380],\n",
      "        [ 0.9579],\n",
      "        [-0.8964],\n",
      "        [ 0.6174],\n",
      "        [ 1.2319],\n",
      "        [-1.6077],\n",
      "        [ 0.0656],\n",
      "        [-0.4075],\n",
      "        [-1.3132],\n",
      "        [ 1.0158],\n",
      "        [-0.4075],\n",
      "        [-0.5722],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4392],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2319],\n",
      "        [ 1.1875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 553/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0129,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6495],\n",
      "        [ 0.5851],\n",
      "        [-0.0282],\n",
      "        [ 0.4874],\n",
      "        [ 0.8985],\n",
      "        [ 0.9578],\n",
      "        [ 0.8985],\n",
      "        [ 0.8071],\n",
      "        [-1.5879],\n",
      "        [-0.8965],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.9283],\n",
      "        [-0.2087],\n",
      "        [ 0.5526],\n",
      "        [-0.6276],\n",
      "        [-0.2953],\n",
      "        [ 0.8684],\n",
      "        [ 0.7448],\n",
      "        [ 0.7761],\n",
      "        [ 1.2320],\n",
      "        [ 1.2320],\n",
      "        [ 1.0722],\n",
      "        [-0.2953],\n",
      "        [-1.2093],\n",
      "        [ 1.0722],\n",
      "        [-1.4392],\n",
      "        [ 0.9578],\n",
      "        [-1.3132],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.7448],\n",
      "        [ 0.5201],\n",
      "        [ 1.2320],\n",
      "        [ 0.7448],\n",
      "        [-0.7127],\n",
      "        [-0.1197],\n",
      "        [-1.0669],\n",
      "        [-1.1380],\n",
      "        [ 0.9578],\n",
      "        [-0.8965],\n",
      "        [ 0.6174],\n",
      "        [ 1.2320],\n",
      "        [-1.6077],\n",
      "        [ 0.0656],\n",
      "        [-0.4075],\n",
      "        [-1.3132],\n",
      "        [ 1.0157],\n",
      "        [-0.4075],\n",
      "        [-0.5722],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4392],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2320],\n",
      "        [ 1.1875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 554/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0128,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6495],\n",
      "        [ 0.5851],\n",
      "        [-0.0281],\n",
      "        [ 0.4874],\n",
      "        [ 0.8985],\n",
      "        [ 0.9578],\n",
      "        [ 0.8985],\n",
      "        [ 0.8071],\n",
      "        [-1.5879],\n",
      "        [-0.8966],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.9283],\n",
      "        [-0.2087],\n",
      "        [ 0.5526],\n",
      "        [-0.6276],\n",
      "        [-0.2953],\n",
      "        [ 0.8683],\n",
      "        [ 0.7448],\n",
      "        [ 0.7761],\n",
      "        [ 1.2320],\n",
      "        [ 1.2320],\n",
      "        [ 1.0722],\n",
      "        [-0.2953],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4391],\n",
      "        [ 0.9578],\n",
      "        [-1.3132],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.7448],\n",
      "        [ 0.5201],\n",
      "        [ 1.2320],\n",
      "        [ 0.7448],\n",
      "        [-0.7127],\n",
      "        [-0.1196],\n",
      "        [-1.0669],\n",
      "        [-1.1380],\n",
      "        [ 0.9578],\n",
      "        [-0.8966],\n",
      "        [ 0.6174],\n",
      "        [ 1.2320],\n",
      "        [-1.6078],\n",
      "        [ 0.0656],\n",
      "        [-0.4075],\n",
      "        [-1.3132],\n",
      "        [ 1.0157],\n",
      "        [-0.4075],\n",
      "        [-0.5722],\n",
      "        [-1.5441],\n",
      "        [ 0.6174],\n",
      "        [-1.4391],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2320],\n",
      "        [ 1.1875]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 555/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0128,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6495],\n",
      "        [ 0.5850],\n",
      "        [-0.0281],\n",
      "        [ 0.4874],\n",
      "        [ 0.8985],\n",
      "        [ 0.9578],\n",
      "        [ 0.8985],\n",
      "        [ 0.8071],\n",
      "        [-1.5880],\n",
      "        [-0.8966],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.9283],\n",
      "        [-0.2087],\n",
      "        [ 0.5526],\n",
      "        [-0.6276],\n",
      "        [-0.2953],\n",
      "        [ 0.8683],\n",
      "        [ 0.7448],\n",
      "        [ 0.7761],\n",
      "        [ 1.2321],\n",
      "        [ 1.2321],\n",
      "        [ 1.0722],\n",
      "        [-0.2953],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4391],\n",
      "        [ 0.9578],\n",
      "        [-1.3131],\n",
      "        [ 0.5526],\n",
      "        [-0.2087],\n",
      "        [ 0.7448],\n",
      "        [ 0.5201],\n",
      "        [ 1.2321],\n",
      "        [ 0.7448],\n",
      "        [-0.7128],\n",
      "        [-0.1196],\n",
      "        [-1.0670],\n",
      "        [-1.1380],\n",
      "        [ 0.9578],\n",
      "        [-0.8966],\n",
      "        [ 0.6173],\n",
      "        [ 1.2321],\n",
      "        [-1.6078],\n",
      "        [ 0.0657],\n",
      "        [-0.4075],\n",
      "        [-1.3131],\n",
      "        [ 1.0157],\n",
      "        [-0.4075],\n",
      "        [-0.5722],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4391],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2321],\n",
      "        [ 1.1876]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 556/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0128,\n",
      " epoch_time_duration: 0.0101\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6495],\n",
      "        [ 0.5850],\n",
      "        [-0.0281],\n",
      "        [ 0.4874],\n",
      "        [ 0.8985],\n",
      "        [ 0.9578],\n",
      "        [ 0.8985],\n",
      "        [ 0.8071],\n",
      "        [-1.5880],\n",
      "        [-0.8967],\n",
      "        [ 0.5526],\n",
      "        [-0.2086],\n",
      "        [ 0.9283],\n",
      "        [-0.2086],\n",
      "        [ 0.5526],\n",
      "        [-0.6277],\n",
      "        [-0.2952],\n",
      "        [ 0.8683],\n",
      "        [ 0.7447],\n",
      "        [ 0.7760],\n",
      "        [ 1.2321],\n",
      "        [ 1.2321],\n",
      "        [ 1.0722],\n",
      "        [-0.2952],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4391],\n",
      "        [ 0.9578],\n",
      "        [-1.3131],\n",
      "        [ 0.5526],\n",
      "        [-0.2086],\n",
      "        [ 0.7447],\n",
      "        [ 0.5200],\n",
      "        [ 1.2321],\n",
      "        [ 0.7447],\n",
      "        [-0.7128],\n",
      "        [-0.1196],\n",
      "        [-1.0670],\n",
      "        [-1.1380],\n",
      "        [ 0.9578],\n",
      "        [-0.8967],\n",
      "        [ 0.6173],\n",
      "        [ 1.2321],\n",
      "        [-1.6079],\n",
      "        [ 0.0657],\n",
      "        [-0.4074],\n",
      "        [-1.3131],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5723],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4391],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2321],\n",
      "        [ 1.1876]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 557/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0128,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6494],\n",
      "        [ 0.5850],\n",
      "        [-0.0280],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9578],\n",
      "        [ 0.8984],\n",
      "        [ 0.8070],\n",
      "        [-1.5880],\n",
      "        [-0.8967],\n",
      "        [ 0.5526],\n",
      "        [-0.2086],\n",
      "        [ 0.9283],\n",
      "        [-0.2086],\n",
      "        [ 0.5526],\n",
      "        [-0.6277],\n",
      "        [-0.2952],\n",
      "        [ 0.8683],\n",
      "        [ 0.7447],\n",
      "        [ 0.7760],\n",
      "        [ 1.2322],\n",
      "        [ 1.2322],\n",
      "        [ 1.0722],\n",
      "        [-0.2952],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4390],\n",
      "        [ 0.9578],\n",
      "        [-1.3131],\n",
      "        [ 0.5526],\n",
      "        [-0.2086],\n",
      "        [ 0.7447],\n",
      "        [ 0.5200],\n",
      "        [ 1.2322],\n",
      "        [ 0.7447],\n",
      "        [-0.7129],\n",
      "        [-0.1195],\n",
      "        [-1.0670],\n",
      "        [-1.1381],\n",
      "        [ 0.9578],\n",
      "        [-0.8967],\n",
      "        [ 0.6173],\n",
      "        [ 1.2322],\n",
      "        [-1.6079],\n",
      "        [ 0.0657],\n",
      "        [-0.4074],\n",
      "        [-1.3131],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5723],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4390],\n",
      "        [ 0.4220],\n",
      "        [-0.4351],\n",
      "        [ 0.4220],\n",
      "        [ 1.2322],\n",
      "        [ 1.1876]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 558/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0127,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6494],\n",
      "        [ 0.5850],\n",
      "        [-0.0280],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9578],\n",
      "        [ 0.8984],\n",
      "        [ 0.8070],\n",
      "        [-1.5881],\n",
      "        [-0.8968],\n",
      "        [ 0.5526],\n",
      "        [-0.2085],\n",
      "        [ 0.9283],\n",
      "        [-0.2085],\n",
      "        [ 0.5526],\n",
      "        [-0.6277],\n",
      "        [-0.2952],\n",
      "        [ 0.8683],\n",
      "        [ 0.7447],\n",
      "        [ 0.7760],\n",
      "        [ 1.2322],\n",
      "        [ 1.2322],\n",
      "        [ 1.0722],\n",
      "        [-0.2952],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4390],\n",
      "        [ 0.9578],\n",
      "        [-1.3130],\n",
      "        [ 0.5526],\n",
      "        [-0.2085],\n",
      "        [ 0.7447],\n",
      "        [ 0.5200],\n",
      "        [ 1.2322],\n",
      "        [ 0.7447],\n",
      "        [-0.7129],\n",
      "        [-0.1195],\n",
      "        [-1.0670],\n",
      "        [-1.1381],\n",
      "        [ 0.9578],\n",
      "        [-0.8968],\n",
      "        [ 0.6173],\n",
      "        [ 1.2322],\n",
      "        [-1.6080],\n",
      "        [ 0.0658],\n",
      "        [-0.4074],\n",
      "        [-1.3130],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5723],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4390],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2322],\n",
      "        [ 1.1877]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 559/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0127,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6494],\n",
      "        [ 0.5850],\n",
      "        [-0.0280],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9578],\n",
      "        [ 0.8984],\n",
      "        [ 0.8070],\n",
      "        [-1.5881],\n",
      "        [-0.8969],\n",
      "        [ 0.5526],\n",
      "        [-0.2085],\n",
      "        [ 0.9282],\n",
      "        [-0.2085],\n",
      "        [ 0.5526],\n",
      "        [-0.6278],\n",
      "        [-0.2951],\n",
      "        [ 0.8682],\n",
      "        [ 0.7447],\n",
      "        [ 0.7760],\n",
      "        [ 1.2323],\n",
      "        [ 1.2323],\n",
      "        [ 1.0722],\n",
      "        [-0.2951],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4390],\n",
      "        [ 0.9578],\n",
      "        [-1.3130],\n",
      "        [ 0.5526],\n",
      "        [-0.2085],\n",
      "        [ 0.7447],\n",
      "        [ 0.5200],\n",
      "        [ 1.2323],\n",
      "        [ 0.7447],\n",
      "        [-0.7130],\n",
      "        [-0.1195],\n",
      "        [-1.0671],\n",
      "        [-1.1381],\n",
      "        [ 0.9578],\n",
      "        [-0.8969],\n",
      "        [ 0.6173],\n",
      "        [ 1.2323],\n",
      "        [-1.6080],\n",
      "        [ 0.0658],\n",
      "        [-0.4074],\n",
      "        [-1.3130],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5723],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4390],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2323],\n",
      "        [ 1.1877]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 560/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0127,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6494],\n",
      "        [ 0.5850],\n",
      "        [-0.0279],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9577],\n",
      "        [ 0.8984],\n",
      "        [ 0.8070],\n",
      "        [-1.5881],\n",
      "        [-0.8969],\n",
      "        [ 0.5525],\n",
      "        [-0.2085],\n",
      "        [ 0.9282],\n",
      "        [-0.2085],\n",
      "        [ 0.5525],\n",
      "        [-0.6278],\n",
      "        [-0.2951],\n",
      "        [ 0.8682],\n",
      "        [ 0.7446],\n",
      "        [ 0.7759],\n",
      "        [ 1.2323],\n",
      "        [ 1.2323],\n",
      "        [ 1.0722],\n",
      "        [-0.2951],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4389],\n",
      "        [ 0.9577],\n",
      "        [-1.3130],\n",
      "        [ 0.5525],\n",
      "        [-0.2085],\n",
      "        [ 0.7446],\n",
      "        [ 0.5200],\n",
      "        [ 1.2323],\n",
      "        [ 0.7446],\n",
      "        [-0.7130],\n",
      "        [-0.1194],\n",
      "        [-1.0671],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8969],\n",
      "        [ 0.6173],\n",
      "        [ 1.2323],\n",
      "        [-1.6081],\n",
      "        [ 0.0658],\n",
      "        [-0.4074],\n",
      "        [-1.3130],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5723],\n",
      "        [-1.5441],\n",
      "        [ 0.6173],\n",
      "        [-1.4389],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2323],\n",
      "        [ 1.1877]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 561/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0127,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6494],\n",
      "        [ 0.5849],\n",
      "        [-0.0279],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9577],\n",
      "        [ 0.8984],\n",
      "        [ 0.8070],\n",
      "        [-1.5882],\n",
      "        [-0.8970],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.9282],\n",
      "        [-0.2084],\n",
      "        [ 0.5525],\n",
      "        [-0.6278],\n",
      "        [-0.2951],\n",
      "        [ 0.8682],\n",
      "        [ 0.7446],\n",
      "        [ 0.7759],\n",
      "        [ 1.2323],\n",
      "        [ 1.2323],\n",
      "        [ 1.0722],\n",
      "        [-0.2951],\n",
      "        [-1.2092],\n",
      "        [ 1.0722],\n",
      "        [-1.4389],\n",
      "        [ 0.9577],\n",
      "        [-1.3129],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.7446],\n",
      "        [ 0.5200],\n",
      "        [ 1.2323],\n",
      "        [ 0.7446],\n",
      "        [-0.7131],\n",
      "        [-0.1194],\n",
      "        [-1.0671],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8970],\n",
      "        [ 0.6172],\n",
      "        [ 1.2323],\n",
      "        [-1.6081],\n",
      "        [ 0.0659],\n",
      "        [-0.4074],\n",
      "        [-1.3129],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5724],\n",
      "        [-1.5441],\n",
      "        [ 0.6172],\n",
      "        [-1.4389],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2323],\n",
      "        [ 1.1878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 562/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0126,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0278],\n",
      "        [ 0.4874],\n",
      "        [ 0.8984],\n",
      "        [ 0.9577],\n",
      "        [ 0.8984],\n",
      "        [ 0.8069],\n",
      "        [-1.5882],\n",
      "        [-0.8970],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.9282],\n",
      "        [-0.2084],\n",
      "        [ 0.5525],\n",
      "        [-0.6279],\n",
      "        [-0.2951],\n",
      "        [ 0.8682],\n",
      "        [ 0.7446],\n",
      "        [ 0.7759],\n",
      "        [ 1.2324],\n",
      "        [ 1.2324],\n",
      "        [ 1.0722],\n",
      "        [-0.2951],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4389],\n",
      "        [ 0.9577],\n",
      "        [-1.3129],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.7446],\n",
      "        [ 0.5200],\n",
      "        [ 1.2324],\n",
      "        [ 0.7446],\n",
      "        [-0.7131],\n",
      "        [-0.1193],\n",
      "        [-1.0671],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8970],\n",
      "        [ 0.6172],\n",
      "        [ 1.2324],\n",
      "        [-1.6082],\n",
      "        [ 0.0659],\n",
      "        [-0.4074],\n",
      "        [-1.3129],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5724],\n",
      "        [-1.5441],\n",
      "        [ 0.6172],\n",
      "        [-1.4389],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2324],\n",
      "        [ 1.1878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 563/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0126,\n",
      " epoch_time_duration: 0.0126\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0278],\n",
      "        [ 0.4874],\n",
      "        [ 0.8983],\n",
      "        [ 0.9577],\n",
      "        [ 0.8983],\n",
      "        [ 0.8069],\n",
      "        [-1.5882],\n",
      "        [-0.8971],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.9282],\n",
      "        [-0.2084],\n",
      "        [ 0.5525],\n",
      "        [-0.6279],\n",
      "        [-0.2950],\n",
      "        [ 0.8682],\n",
      "        [ 0.7446],\n",
      "        [ 0.7759],\n",
      "        [ 1.2324],\n",
      "        [ 1.2324],\n",
      "        [ 1.0722],\n",
      "        [-0.2950],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4388],\n",
      "        [ 0.9577],\n",
      "        [-1.3129],\n",
      "        [ 0.5525],\n",
      "        [-0.2084],\n",
      "        [ 0.7446],\n",
      "        [ 0.5200],\n",
      "        [ 1.2324],\n",
      "        [ 0.7446],\n",
      "        [-0.7132],\n",
      "        [-0.1193],\n",
      "        [-1.0672],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8971],\n",
      "        [ 0.6172],\n",
      "        [ 1.2324],\n",
      "        [-1.6082],\n",
      "        [ 0.0659],\n",
      "        [-0.4074],\n",
      "        [-1.3129],\n",
      "        [ 1.0157],\n",
      "        [-0.4074],\n",
      "        [-0.5724],\n",
      "        [-1.5441],\n",
      "        [ 0.6172],\n",
      "        [-1.4388],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2324],\n",
      "        [ 1.1878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 564/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0126,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0278],\n",
      "        [ 0.4873],\n",
      "        [ 0.8983],\n",
      "        [ 0.9577],\n",
      "        [ 0.8983],\n",
      "        [ 0.8069],\n",
      "        [-1.5883],\n",
      "        [-0.8972],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.9282],\n",
      "        [-0.2083],\n",
      "        [ 0.5525],\n",
      "        [-0.6279],\n",
      "        [-0.2950],\n",
      "        [ 0.8681],\n",
      "        [ 0.7446],\n",
      "        [ 0.7759],\n",
      "        [ 1.2325],\n",
      "        [ 1.2325],\n",
      "        [ 1.0722],\n",
      "        [-0.2950],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4388],\n",
      "        [ 0.9577],\n",
      "        [-1.3128],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.7446],\n",
      "        [ 0.5200],\n",
      "        [ 1.2325],\n",
      "        [ 0.7446],\n",
      "        [-0.7132],\n",
      "        [-0.1193],\n",
      "        [-1.0672],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8972],\n",
      "        [ 0.6172],\n",
      "        [ 1.2325],\n",
      "        [-1.6082],\n",
      "        [ 0.0659],\n",
      "        [-0.4073],\n",
      "        [-1.3128],\n",
      "        [ 1.0157],\n",
      "        [-0.4073],\n",
      "        [-0.5724],\n",
      "        [-1.5441],\n",
      "        [ 0.6172],\n",
      "        [-1.4388],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2325],\n",
      "        [ 1.1878]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 565/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0126,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0277],\n",
      "        [ 0.4873],\n",
      "        [ 0.8983],\n",
      "        [ 0.9577],\n",
      "        [ 0.8983],\n",
      "        [ 0.8069],\n",
      "        [-1.5883],\n",
      "        [-0.8972],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.9282],\n",
      "        [-0.2083],\n",
      "        [ 0.5525],\n",
      "        [-0.6280],\n",
      "        [-0.2950],\n",
      "        [ 0.8681],\n",
      "        [ 0.7445],\n",
      "        [ 0.7758],\n",
      "        [ 1.2325],\n",
      "        [ 1.2325],\n",
      "        [ 1.0722],\n",
      "        [-0.2950],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4388],\n",
      "        [ 0.9577],\n",
      "        [-1.3128],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.7445],\n",
      "        [ 0.5199],\n",
      "        [ 1.2325],\n",
      "        [ 0.7445],\n",
      "        [-0.7133],\n",
      "        [-0.1192],\n",
      "        [-1.0672],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8972],\n",
      "        [ 0.6172],\n",
      "        [ 1.2325],\n",
      "        [-1.6083],\n",
      "        [ 0.0660],\n",
      "        [-0.4073],\n",
      "        [-1.3128],\n",
      "        [ 1.0157],\n",
      "        [-0.4073],\n",
      "        [-0.5724],\n",
      "        [-1.5441],\n",
      "        [ 0.6172],\n",
      "        [-1.4388],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2325],\n",
      "        [ 1.1879]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 566/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0126,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0277],\n",
      "        [ 0.4873],\n",
      "        [ 0.8983],\n",
      "        [ 0.9577],\n",
      "        [ 0.8983],\n",
      "        [ 0.8068],\n",
      "        [-1.5883],\n",
      "        [-0.8973],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.9281],\n",
      "        [-0.2083],\n",
      "        [ 0.5525],\n",
      "        [-0.6280],\n",
      "        [-0.2949],\n",
      "        [ 0.8681],\n",
      "        [ 0.7445],\n",
      "        [ 0.7758],\n",
      "        [ 1.2326],\n",
      "        [ 1.2326],\n",
      "        [ 1.0722],\n",
      "        [-0.2949],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4387],\n",
      "        [ 0.9577],\n",
      "        [-1.3128],\n",
      "        [ 0.5525],\n",
      "        [-0.2083],\n",
      "        [ 0.7445],\n",
      "        [ 0.5199],\n",
      "        [ 1.2326],\n",
      "        [ 0.7445],\n",
      "        [-0.7133],\n",
      "        [-0.1192],\n",
      "        [-1.0673],\n",
      "        [-1.1381],\n",
      "        [ 0.9577],\n",
      "        [-0.8973],\n",
      "        [ 0.6171],\n",
      "        [ 1.2326],\n",
      "        [-1.6083],\n",
      "        [ 0.0660],\n",
      "        [-0.4073],\n",
      "        [-1.3128],\n",
      "        [ 1.0157],\n",
      "        [-0.4073],\n",
      "        [-0.5725],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4387],\n",
      "        [ 0.4220],\n",
      "        [-0.4350],\n",
      "        [ 0.4220],\n",
      "        [ 1.2326],\n",
      "        [ 1.1879]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 567/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0125,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6493],\n",
      "        [ 0.5849],\n",
      "        [-0.0277],\n",
      "        [ 0.4873],\n",
      "        [ 0.8983],\n",
      "        [ 0.9576],\n",
      "        [ 0.8983],\n",
      "        [ 0.8068],\n",
      "        [-1.5883],\n",
      "        [-0.8973],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.9281],\n",
      "        [-0.2082],\n",
      "        [ 0.5524],\n",
      "        [-0.6280],\n",
      "        [-0.2949],\n",
      "        [ 0.8681],\n",
      "        [ 0.7445],\n",
      "        [ 0.7758],\n",
      "        [ 1.2326],\n",
      "        [ 1.2326],\n",
      "        [ 1.0722],\n",
      "        [-0.2949],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4387],\n",
      "        [ 0.9576],\n",
      "        [-1.3127],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.7445],\n",
      "        [ 0.5199],\n",
      "        [ 1.2326],\n",
      "        [ 0.7445],\n",
      "        [-0.7134],\n",
      "        [-0.1192],\n",
      "        [-1.0673],\n",
      "        [-1.1381],\n",
      "        [ 0.9576],\n",
      "        [-0.8973],\n",
      "        [ 0.6171],\n",
      "        [ 1.2326],\n",
      "        [-1.6084],\n",
      "        [ 0.0660],\n",
      "        [-0.4073],\n",
      "        [-1.3127],\n",
      "        [ 1.0157],\n",
      "        [-0.4073],\n",
      "        [-0.5725],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4387],\n",
      "        [ 0.4219],\n",
      "        [-0.4350],\n",
      "        [ 0.4219],\n",
      "        [ 1.2326],\n",
      "        [ 1.1879]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 568/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0125,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6492],\n",
      "        [ 0.5848],\n",
      "        [-0.0276],\n",
      "        [ 0.4873],\n",
      "        [ 0.8982],\n",
      "        [ 0.9576],\n",
      "        [ 0.8982],\n",
      "        [ 0.8068],\n",
      "        [-1.5884],\n",
      "        [-0.8974],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.9281],\n",
      "        [-0.2082],\n",
      "        [ 0.5524],\n",
      "        [-0.6281],\n",
      "        [-0.2949],\n",
      "        [ 0.8681],\n",
      "        [ 0.7445],\n",
      "        [ 0.7758],\n",
      "        [ 1.2327],\n",
      "        [ 1.2327],\n",
      "        [ 1.0722],\n",
      "        [-0.2949],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4387],\n",
      "        [ 0.9576],\n",
      "        [-1.3127],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.7445],\n",
      "        [ 0.5199],\n",
      "        [ 1.2327],\n",
      "        [ 0.7445],\n",
      "        [-0.7134],\n",
      "        [-0.1191],\n",
      "        [-1.0673],\n",
      "        [-1.1381],\n",
      "        [ 0.9576],\n",
      "        [-0.8974],\n",
      "        [ 0.6171],\n",
      "        [ 1.2327],\n",
      "        [-1.6084],\n",
      "        [ 0.0661],\n",
      "        [-0.4073],\n",
      "        [-1.3127],\n",
      "        [ 1.0156],\n",
      "        [-0.4073],\n",
      "        [-0.5725],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4387],\n",
      "        [ 0.4219],\n",
      "        [-0.4350],\n",
      "        [ 0.4219],\n",
      "        [ 1.2327],\n",
      "        [ 1.1880]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 569/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0125,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6492],\n",
      "        [ 0.5848],\n",
      "        [-0.0276],\n",
      "        [ 0.4873],\n",
      "        [ 0.8982],\n",
      "        [ 0.9576],\n",
      "        [ 0.8982],\n",
      "        [ 0.8068],\n",
      "        [-1.5884],\n",
      "        [-0.8975],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.9281],\n",
      "        [-0.2082],\n",
      "        [ 0.5524],\n",
      "        [-0.6281],\n",
      "        [-0.2949],\n",
      "        [ 0.8680],\n",
      "        [ 0.7444],\n",
      "        [ 0.7757],\n",
      "        [ 1.2327],\n",
      "        [ 1.2327],\n",
      "        [ 1.0722],\n",
      "        [-0.2949],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4386],\n",
      "        [ 0.9576],\n",
      "        [-1.3126],\n",
      "        [ 0.5524],\n",
      "        [-0.2082],\n",
      "        [ 0.7444],\n",
      "        [ 0.5199],\n",
      "        [ 1.2327],\n",
      "        [ 0.7444],\n",
      "        [-0.7135],\n",
      "        [-0.1191],\n",
      "        [-1.0673],\n",
      "        [-1.1381],\n",
      "        [ 0.9576],\n",
      "        [-0.8975],\n",
      "        [ 0.6171],\n",
      "        [ 1.2327],\n",
      "        [-1.6085],\n",
      "        [ 0.0661],\n",
      "        [-0.4073],\n",
      "        [-1.3126],\n",
      "        [ 1.0156],\n",
      "        [-0.4073],\n",
      "        [-0.5725],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4386],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2327],\n",
      "        [ 1.1880]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 570/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0125,\n",
      " epoch_time_duration: 0.0147\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6492],\n",
      "        [ 0.5848],\n",
      "        [-0.0276],\n",
      "        [ 0.4873],\n",
      "        [ 0.8982],\n",
      "        [ 0.9576],\n",
      "        [ 0.8982],\n",
      "        [ 0.8068],\n",
      "        [-1.5884],\n",
      "        [-0.8975],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.9281],\n",
      "        [-0.2081],\n",
      "        [ 0.5524],\n",
      "        [-0.6281],\n",
      "        [-0.2948],\n",
      "        [ 0.8680],\n",
      "        [ 0.7444],\n",
      "        [ 0.7757],\n",
      "        [ 1.2328],\n",
      "        [ 1.2328],\n",
      "        [ 1.0722],\n",
      "        [-0.2948],\n",
      "        [-1.2091],\n",
      "        [ 1.0722],\n",
      "        [-1.4386],\n",
      "        [ 0.9576],\n",
      "        [-1.3126],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.7444],\n",
      "        [ 0.5199],\n",
      "        [ 1.2328],\n",
      "        [ 0.7444],\n",
      "        [-0.7135],\n",
      "        [-0.1190],\n",
      "        [-1.0674],\n",
      "        [-1.1382],\n",
      "        [ 0.9576],\n",
      "        [-0.8975],\n",
      "        [ 0.6171],\n",
      "        [ 1.2328],\n",
      "        [-1.6085],\n",
      "        [ 0.0661],\n",
      "        [-0.4073],\n",
      "        [-1.3126],\n",
      "        [ 1.0156],\n",
      "        [-0.4073],\n",
      "        [-0.5725],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4386],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2328],\n",
      "        [ 1.1880]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 571/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0124,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6492],\n",
      "        [ 0.5848],\n",
      "        [-0.0275],\n",
      "        [ 0.4873],\n",
      "        [ 0.8982],\n",
      "        [ 0.9576],\n",
      "        [ 0.8982],\n",
      "        [ 0.8067],\n",
      "        [-1.5885],\n",
      "        [-0.8976],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.9280],\n",
      "        [-0.2081],\n",
      "        [ 0.5524],\n",
      "        [-0.6282],\n",
      "        [-0.2948],\n",
      "        [ 0.8680],\n",
      "        [ 0.7444],\n",
      "        [ 0.7757],\n",
      "        [ 1.2328],\n",
      "        [ 1.2328],\n",
      "        [ 1.0722],\n",
      "        [-0.2948],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4386],\n",
      "        [ 0.9576],\n",
      "        [-1.3126],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.7444],\n",
      "        [ 0.5199],\n",
      "        [ 1.2328],\n",
      "        [ 0.7444],\n",
      "        [-0.7136],\n",
      "        [-0.1190],\n",
      "        [-1.0674],\n",
      "        [-1.1382],\n",
      "        [ 0.9576],\n",
      "        [-0.8976],\n",
      "        [ 0.6171],\n",
      "        [ 1.2328],\n",
      "        [-1.6086],\n",
      "        [ 0.0662],\n",
      "        [-0.4072],\n",
      "        [-1.3126],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5726],\n",
      "        [-1.5441],\n",
      "        [ 0.6171],\n",
      "        [-1.4386],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2328],\n",
      "        [ 1.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 572/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0124,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6492],\n",
      "        [ 0.5848],\n",
      "        [-0.0275],\n",
      "        [ 0.4873],\n",
      "        [ 0.8982],\n",
      "        [ 0.9576],\n",
      "        [ 0.8982],\n",
      "        [ 0.8067],\n",
      "        [-1.5885],\n",
      "        [-0.8976],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.9280],\n",
      "        [-0.2081],\n",
      "        [ 0.5524],\n",
      "        [-0.6282],\n",
      "        [-0.2948],\n",
      "        [ 0.8680],\n",
      "        [ 0.7444],\n",
      "        [ 0.7757],\n",
      "        [ 1.2328],\n",
      "        [ 1.2328],\n",
      "        [ 1.0722],\n",
      "        [-0.2948],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4385],\n",
      "        [ 0.9576],\n",
      "        [-1.3126],\n",
      "        [ 0.5524],\n",
      "        [-0.2081],\n",
      "        [ 0.7444],\n",
      "        [ 0.5199],\n",
      "        [ 1.2328],\n",
      "        [ 0.7444],\n",
      "        [-0.7136],\n",
      "        [-0.1190],\n",
      "        [-1.0674],\n",
      "        [-1.1382],\n",
      "        [ 0.9576],\n",
      "        [-0.8976],\n",
      "        [ 0.6170],\n",
      "        [ 1.2328],\n",
      "        [-1.6086],\n",
      "        [ 0.0662],\n",
      "        [-0.4072],\n",
      "        [-1.3126],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5726],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4385],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2328],\n",
      "        [ 1.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 573/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0124,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6491],\n",
      "        [ 0.5848],\n",
      "        [-0.0275],\n",
      "        [ 0.4873],\n",
      "        [ 0.8981],\n",
      "        [ 0.9576],\n",
      "        [ 0.8981],\n",
      "        [ 0.8067],\n",
      "        [-1.5885],\n",
      "        [-0.8977],\n",
      "        [ 0.5524],\n",
      "        [-0.2080],\n",
      "        [ 0.9280],\n",
      "        [-0.2080],\n",
      "        [ 0.5524],\n",
      "        [-0.6282],\n",
      "        [-0.2947],\n",
      "        [ 0.8680],\n",
      "        [ 0.7444],\n",
      "        [ 0.7757],\n",
      "        [ 1.2329],\n",
      "        [ 1.2329],\n",
      "        [ 1.0722],\n",
      "        [-0.2947],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4385],\n",
      "        [ 0.9576],\n",
      "        [-1.3125],\n",
      "        [ 0.5524],\n",
      "        [-0.2080],\n",
      "        [ 0.7444],\n",
      "        [ 0.5199],\n",
      "        [ 1.2329],\n",
      "        [ 0.7444],\n",
      "        [-0.7137],\n",
      "        [-0.1189],\n",
      "        [-1.0674],\n",
      "        [-1.1382],\n",
      "        [ 0.9576],\n",
      "        [-0.8977],\n",
      "        [ 0.6170],\n",
      "        [ 1.2329],\n",
      "        [-1.6087],\n",
      "        [ 0.0662],\n",
      "        [-0.4072],\n",
      "        [-1.3125],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5726],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4385],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2329],\n",
      "        [ 1.1881]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 574/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0124,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6491],\n",
      "        [ 0.5847],\n",
      "        [-0.0274],\n",
      "        [ 0.4873],\n",
      "        [ 0.8981],\n",
      "        [ 0.9575],\n",
      "        [ 0.8981],\n",
      "        [ 0.8067],\n",
      "        [-1.5885],\n",
      "        [-0.8977],\n",
      "        [ 0.5524],\n",
      "        [-0.2080],\n",
      "        [ 0.9280],\n",
      "        [-0.2080],\n",
      "        [ 0.5524],\n",
      "        [-0.6283],\n",
      "        [-0.2947],\n",
      "        [ 0.8679],\n",
      "        [ 0.7443],\n",
      "        [ 0.7756],\n",
      "        [ 1.2329],\n",
      "        [ 1.2329],\n",
      "        [ 1.0722],\n",
      "        [-0.2947],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4385],\n",
      "        [ 0.9575],\n",
      "        [-1.3125],\n",
      "        [ 0.5524],\n",
      "        [-0.2080],\n",
      "        [ 0.7443],\n",
      "        [ 0.5199],\n",
      "        [ 1.2329],\n",
      "        [ 0.7443],\n",
      "        [-0.7137],\n",
      "        [-0.1189],\n",
      "        [-1.0675],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8977],\n",
      "        [ 0.6170],\n",
      "        [ 1.2329],\n",
      "        [-1.6087],\n",
      "        [ 0.0662],\n",
      "        [-0.4072],\n",
      "        [-1.3125],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5726],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4385],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2329],\n",
      "        [ 1.1882]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 575/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0123,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6491],\n",
      "        [ 0.5847],\n",
      "        [-0.0274],\n",
      "        [ 0.4873],\n",
      "        [ 0.8981],\n",
      "        [ 0.9575],\n",
      "        [ 0.8981],\n",
      "        [ 0.8067],\n",
      "        [-1.5886],\n",
      "        [-0.8978],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.9280],\n",
      "        [-0.2079],\n",
      "        [ 0.5523],\n",
      "        [-0.6283],\n",
      "        [-0.2947],\n",
      "        [ 0.8679],\n",
      "        [ 0.7443],\n",
      "        [ 0.7756],\n",
      "        [ 1.2330],\n",
      "        [ 1.2330],\n",
      "        [ 1.0722],\n",
      "        [-0.2947],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4384],\n",
      "        [ 0.9575],\n",
      "        [-1.3125],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.7443],\n",
      "        [ 0.5198],\n",
      "        [ 1.2330],\n",
      "        [ 0.7443],\n",
      "        [-0.7138],\n",
      "        [-0.1189],\n",
      "        [-1.0675],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8978],\n",
      "        [ 0.6170],\n",
      "        [ 1.2330],\n",
      "        [-1.6087],\n",
      "        [ 0.0663],\n",
      "        [-0.4072],\n",
      "        [-1.3125],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5726],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4384],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2330],\n",
      "        [ 1.1882]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 576/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0123,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6491],\n",
      "        [ 0.5847],\n",
      "        [-0.0274],\n",
      "        [ 0.4872],\n",
      "        [ 0.8981],\n",
      "        [ 0.9575],\n",
      "        [ 0.8981],\n",
      "        [ 0.8066],\n",
      "        [-1.5886],\n",
      "        [-0.8979],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.9280],\n",
      "        [-0.2079],\n",
      "        [ 0.5523],\n",
      "        [-0.6283],\n",
      "        [-0.2947],\n",
      "        [ 0.8679],\n",
      "        [ 0.7443],\n",
      "        [ 0.7756],\n",
      "        [ 1.2330],\n",
      "        [ 1.2330],\n",
      "        [ 1.0722],\n",
      "        [-0.2947],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4384],\n",
      "        [ 0.9575],\n",
      "        [-1.3124],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.7443],\n",
      "        [ 0.5198],\n",
      "        [ 1.2330],\n",
      "        [ 0.7443],\n",
      "        [-0.7138],\n",
      "        [-0.1188],\n",
      "        [-1.0675],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8979],\n",
      "        [ 0.6170],\n",
      "        [ 1.2330],\n",
      "        [-1.6088],\n",
      "        [ 0.0663],\n",
      "        [-0.4072],\n",
      "        [-1.3124],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5727],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4384],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2330],\n",
      "        [ 1.1882]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 577/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0123,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6491],\n",
      "        [ 0.5847],\n",
      "        [-0.0273],\n",
      "        [ 0.4872],\n",
      "        [ 0.8981],\n",
      "        [ 0.9575],\n",
      "        [ 0.8981],\n",
      "        [ 0.8066],\n",
      "        [-1.5886],\n",
      "        [-0.8979],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.9280],\n",
      "        [-0.2079],\n",
      "        [ 0.5523],\n",
      "        [-0.6284],\n",
      "        [-0.2946],\n",
      "        [ 0.8679],\n",
      "        [ 0.7443],\n",
      "        [ 0.7756],\n",
      "        [ 1.2331],\n",
      "        [ 1.2331],\n",
      "        [ 1.0722],\n",
      "        [-0.2946],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4384],\n",
      "        [ 0.9575],\n",
      "        [-1.3124],\n",
      "        [ 0.5523],\n",
      "        [-0.2079],\n",
      "        [ 0.7443],\n",
      "        [ 0.5198],\n",
      "        [ 1.2331],\n",
      "        [ 0.7443],\n",
      "        [-0.7139],\n",
      "        [-0.1188],\n",
      "        [-1.0676],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8979],\n",
      "        [ 0.6170],\n",
      "        [ 1.2331],\n",
      "        [-1.6088],\n",
      "        [ 0.0663],\n",
      "        [-0.4072],\n",
      "        [-1.3124],\n",
      "        [ 1.0156],\n",
      "        [-0.4072],\n",
      "        [-0.5727],\n",
      "        [-1.5441],\n",
      "        [ 0.6170],\n",
      "        [-1.4384],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2331],\n",
      "        [ 1.1882]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 578/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0123,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6490],\n",
      "        [ 0.5847],\n",
      "        [-0.0273],\n",
      "        [ 0.4872],\n",
      "        [ 0.8981],\n",
      "        [ 0.9575],\n",
      "        [ 0.8981],\n",
      "        [ 0.8066],\n",
      "        [-1.5887],\n",
      "        [-0.8980],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.9279],\n",
      "        [-0.2078],\n",
      "        [ 0.5523],\n",
      "        [-0.6284],\n",
      "        [-0.2946],\n",
      "        [ 0.8679],\n",
      "        [ 0.7442],\n",
      "        [ 0.7755],\n",
      "        [ 1.2331],\n",
      "        [ 1.2331],\n",
      "        [ 1.0722],\n",
      "        [-0.2946],\n",
      "        [-1.2090],\n",
      "        [ 1.0722],\n",
      "        [-1.4383],\n",
      "        [ 0.9575],\n",
      "        [-1.3124],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.7442],\n",
      "        [ 0.5198],\n",
      "        [ 1.2331],\n",
      "        [ 0.7442],\n",
      "        [-0.7139],\n",
      "        [-0.1188],\n",
      "        [-1.0676],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8980],\n",
      "        [ 0.6169],\n",
      "        [ 1.2331],\n",
      "        [-1.6089],\n",
      "        [ 0.0664],\n",
      "        [-0.4071],\n",
      "        [-1.3124],\n",
      "        [ 1.0156],\n",
      "        [-0.4071],\n",
      "        [-0.5727],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4383],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2331],\n",
      "        [ 1.1883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 579/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0123,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6490],\n",
      "        [ 0.5847],\n",
      "        [-0.0273],\n",
      "        [ 0.4872],\n",
      "        [ 0.8980],\n",
      "        [ 0.9575],\n",
      "        [ 0.8980],\n",
      "        [ 0.8066],\n",
      "        [-1.5887],\n",
      "        [-0.8980],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.9279],\n",
      "        [-0.2078],\n",
      "        [ 0.5523],\n",
      "        [-0.6284],\n",
      "        [-0.2946],\n",
      "        [ 0.8678],\n",
      "        [ 0.7442],\n",
      "        [ 0.7755],\n",
      "        [ 1.2332],\n",
      "        [ 1.2332],\n",
      "        [ 1.0722],\n",
      "        [-0.2946],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4383],\n",
      "        [ 0.9575],\n",
      "        [-1.3123],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.7442],\n",
      "        [ 0.5198],\n",
      "        [ 1.2332],\n",
      "        [ 0.7442],\n",
      "        [-0.7140],\n",
      "        [-0.1187],\n",
      "        [-1.0676],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8980],\n",
      "        [ 0.6169],\n",
      "        [ 1.2332],\n",
      "        [-1.6089],\n",
      "        [ 0.0664],\n",
      "        [-0.4071],\n",
      "        [-1.3123],\n",
      "        [ 1.0156],\n",
      "        [-0.4071],\n",
      "        [-0.5727],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4383],\n",
      "        [ 0.4219],\n",
      "        [-0.4349],\n",
      "        [ 0.4219],\n",
      "        [ 1.2332],\n",
      "        [ 1.1883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 580/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0122,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6490],\n",
      "        [ 0.5847],\n",
      "        [-0.0272],\n",
      "        [ 0.4872],\n",
      "        [ 0.8980],\n",
      "        [ 0.9575],\n",
      "        [ 0.8980],\n",
      "        [ 0.8065],\n",
      "        [-1.5887],\n",
      "        [-0.8981],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.9279],\n",
      "        [-0.2078],\n",
      "        [ 0.5523],\n",
      "        [-0.6285],\n",
      "        [-0.2945],\n",
      "        [ 0.8678],\n",
      "        [ 0.7442],\n",
      "        [ 0.7755],\n",
      "        [ 1.2332],\n",
      "        [ 1.2332],\n",
      "        [ 1.0722],\n",
      "        [-0.2945],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4383],\n",
      "        [ 0.9575],\n",
      "        [-1.3123],\n",
      "        [ 0.5523],\n",
      "        [-0.2078],\n",
      "        [ 0.7442],\n",
      "        [ 0.5198],\n",
      "        [ 1.2332],\n",
      "        [ 0.7442],\n",
      "        [-0.7140],\n",
      "        [-0.1187],\n",
      "        [-1.0676],\n",
      "        [-1.1382],\n",
      "        [ 0.9575],\n",
      "        [-0.8981],\n",
      "        [ 0.6169],\n",
      "        [ 1.2332],\n",
      "        [-1.6090],\n",
      "        [ 0.0664],\n",
      "        [-0.4071],\n",
      "        [-1.3123],\n",
      "        [ 1.0156],\n",
      "        [-0.4071],\n",
      "        [-0.5727],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4383],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2332],\n",
      "        [ 1.1883]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 581/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0122,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6490],\n",
      "        [ 0.5846],\n",
      "        [-0.0272],\n",
      "        [ 0.4872],\n",
      "        [ 0.8980],\n",
      "        [ 0.9574],\n",
      "        [ 0.8980],\n",
      "        [ 0.8065],\n",
      "        [-1.5888],\n",
      "        [-0.8981],\n",
      "        [ 0.5523],\n",
      "        [-0.2077],\n",
      "        [ 0.9279],\n",
      "        [-0.2077],\n",
      "        [ 0.5523],\n",
      "        [-0.6285],\n",
      "        [-0.2945],\n",
      "        [ 0.8678],\n",
      "        [ 0.7442],\n",
      "        [ 0.7755],\n",
      "        [ 1.2333],\n",
      "        [ 1.2333],\n",
      "        [ 1.0722],\n",
      "        [-0.2945],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4382],\n",
      "        [ 0.9574],\n",
      "        [-1.3123],\n",
      "        [ 0.5523],\n",
      "        [-0.2077],\n",
      "        [ 0.7442],\n",
      "        [ 0.5198],\n",
      "        [ 1.2333],\n",
      "        [ 0.7442],\n",
      "        [-0.7141],\n",
      "        [-0.1186],\n",
      "        [-1.0677],\n",
      "        [-1.1382],\n",
      "        [ 0.9574],\n",
      "        [-0.8981],\n",
      "        [ 0.6169],\n",
      "        [ 1.2333],\n",
      "        [-1.6090],\n",
      "        [ 0.0664],\n",
      "        [-0.4071],\n",
      "        [-1.3123],\n",
      "        [ 1.0156],\n",
      "        [-0.4071],\n",
      "        [-0.5728],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4382],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2333],\n",
      "        [ 1.1884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 582/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0122,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6490],\n",
      "        [ 0.5846],\n",
      "        [-0.0272],\n",
      "        [ 0.4872],\n",
      "        [ 0.8980],\n",
      "        [ 0.9574],\n",
      "        [ 0.8980],\n",
      "        [ 0.8065],\n",
      "        [-1.5888],\n",
      "        [-0.8982],\n",
      "        [ 0.5522],\n",
      "        [-0.2077],\n",
      "        [ 0.9279],\n",
      "        [-0.2077],\n",
      "        [ 0.5522],\n",
      "        [-0.6285],\n",
      "        [-0.2945],\n",
      "        [ 0.8678],\n",
      "        [ 0.7442],\n",
      "        [ 0.7755],\n",
      "        [ 1.2333],\n",
      "        [ 1.2333],\n",
      "        [ 1.0722],\n",
      "        [-0.2945],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4382],\n",
      "        [ 0.9574],\n",
      "        [-1.3122],\n",
      "        [ 0.5522],\n",
      "        [-0.2077],\n",
      "        [ 0.7442],\n",
      "        [ 0.5198],\n",
      "        [ 1.2333],\n",
      "        [ 0.7442],\n",
      "        [-0.7141],\n",
      "        [-0.1186],\n",
      "        [-1.0677],\n",
      "        [-1.1382],\n",
      "        [ 0.9574],\n",
      "        [-0.8982],\n",
      "        [ 0.6169],\n",
      "        [ 1.2333],\n",
      "        [-1.6091],\n",
      "        [ 0.0665],\n",
      "        [-0.4071],\n",
      "        [-1.3122],\n",
      "        [ 1.0155],\n",
      "        [-0.4071],\n",
      "        [-0.5728],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4382],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2333],\n",
      "        [ 1.1884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 583/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0122,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6490],\n",
      "        [ 0.5846],\n",
      "        [-0.0271],\n",
      "        [ 0.4872],\n",
      "        [ 0.8980],\n",
      "        [ 0.9574],\n",
      "        [ 0.8980],\n",
      "        [ 0.8065],\n",
      "        [-1.5888],\n",
      "        [-0.8983],\n",
      "        [ 0.5522],\n",
      "        [-0.2077],\n",
      "        [ 0.9279],\n",
      "        [-0.2077],\n",
      "        [ 0.5522],\n",
      "        [-0.6286],\n",
      "        [-0.2945],\n",
      "        [ 0.8678],\n",
      "        [ 0.7441],\n",
      "        [ 0.7754],\n",
      "        [ 1.2333],\n",
      "        [ 1.2333],\n",
      "        [ 1.0722],\n",
      "        [-0.2945],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4382],\n",
      "        [ 0.9574],\n",
      "        [-1.3122],\n",
      "        [ 0.5522],\n",
      "        [-0.2077],\n",
      "        [ 0.7441],\n",
      "        [ 0.5198],\n",
      "        [ 1.2333],\n",
      "        [ 0.7441],\n",
      "        [-0.7142],\n",
      "        [-0.1186],\n",
      "        [-1.0677],\n",
      "        [-1.1383],\n",
      "        [ 0.9574],\n",
      "        [-0.8983],\n",
      "        [ 0.6169],\n",
      "        [ 1.2333],\n",
      "        [-1.6091],\n",
      "        [ 0.0665],\n",
      "        [-0.4071],\n",
      "        [-1.3122],\n",
      "        [ 1.0155],\n",
      "        [-0.4071],\n",
      "        [-0.5728],\n",
      "        [-1.5441],\n",
      "        [ 0.6169],\n",
      "        [-1.4382],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2333],\n",
      "        [ 1.1884]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 584/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0121,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6489],\n",
      "        [ 0.5846],\n",
      "        [-0.0271],\n",
      "        [ 0.4872],\n",
      "        [ 0.8979],\n",
      "        [ 0.9574],\n",
      "        [ 0.8979],\n",
      "        [ 0.8065],\n",
      "        [-1.5888],\n",
      "        [-0.8983],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.9278],\n",
      "        [-0.2076],\n",
      "        [ 0.5522],\n",
      "        [-0.6286],\n",
      "        [-0.2944],\n",
      "        [ 0.8677],\n",
      "        [ 0.7441],\n",
      "        [ 0.7754],\n",
      "        [ 1.2334],\n",
      "        [ 1.2334],\n",
      "        [ 1.0722],\n",
      "        [-0.2944],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4381],\n",
      "        [ 0.9574],\n",
      "        [-1.3122],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.7441],\n",
      "        [ 0.5197],\n",
      "        [ 1.2334],\n",
      "        [ 0.7441],\n",
      "        [-0.7142],\n",
      "        [-0.1185],\n",
      "        [-1.0677],\n",
      "        [-1.1383],\n",
      "        [ 0.9574],\n",
      "        [-0.8983],\n",
      "        [ 0.6168],\n",
      "        [ 1.2334],\n",
      "        [-1.6091],\n",
      "        [ 0.0665],\n",
      "        [-0.4071],\n",
      "        [-1.3122],\n",
      "        [ 1.0155],\n",
      "        [-0.4071],\n",
      "        [-0.5728],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4381],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2334],\n",
      "        [ 1.1885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 585/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0121,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6489],\n",
      "        [ 0.5846],\n",
      "        [-0.0271],\n",
      "        [ 0.4872],\n",
      "        [ 0.8979],\n",
      "        [ 0.9574],\n",
      "        [ 0.8979],\n",
      "        [ 0.8064],\n",
      "        [-1.5889],\n",
      "        [-0.8984],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.9278],\n",
      "        [-0.2076],\n",
      "        [ 0.5522],\n",
      "        [-0.6286],\n",
      "        [-0.2944],\n",
      "        [ 0.8677],\n",
      "        [ 0.7441],\n",
      "        [ 0.7754],\n",
      "        [ 1.2334],\n",
      "        [ 1.2334],\n",
      "        [ 1.0722],\n",
      "        [-0.2944],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4381],\n",
      "        [ 0.9574],\n",
      "        [-1.3121],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.7441],\n",
      "        [ 0.5197],\n",
      "        [ 1.2334],\n",
      "        [ 0.7441],\n",
      "        [-0.7143],\n",
      "        [-0.1185],\n",
      "        [-1.0678],\n",
      "        [-1.1383],\n",
      "        [ 0.9574],\n",
      "        [-0.8984],\n",
      "        [ 0.6168],\n",
      "        [ 1.2334],\n",
      "        [-1.6092],\n",
      "        [ 0.0666],\n",
      "        [-0.4071],\n",
      "        [-1.3121],\n",
      "        [ 1.0155],\n",
      "        [-0.4071],\n",
      "        [-0.5728],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4381],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2334],\n",
      "        [ 1.1885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 586/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0121,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6489],\n",
      "        [ 0.5846],\n",
      "        [-0.0270],\n",
      "        [ 0.4872],\n",
      "        [ 0.8979],\n",
      "        [ 0.9574],\n",
      "        [ 0.8979],\n",
      "        [ 0.8064],\n",
      "        [-1.5889],\n",
      "        [-0.8984],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.9278],\n",
      "        [-0.2076],\n",
      "        [ 0.5522],\n",
      "        [-0.6286],\n",
      "        [-0.2944],\n",
      "        [ 0.8677],\n",
      "        [ 0.7441],\n",
      "        [ 0.7754],\n",
      "        [ 1.2335],\n",
      "        [ 1.2335],\n",
      "        [ 1.0722],\n",
      "        [-0.2944],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4381],\n",
      "        [ 0.9574],\n",
      "        [-1.3121],\n",
      "        [ 0.5522],\n",
      "        [-0.2076],\n",
      "        [ 0.7441],\n",
      "        [ 0.5197],\n",
      "        [ 1.2335],\n",
      "        [ 0.7441],\n",
      "        [-0.7143],\n",
      "        [-0.1185],\n",
      "        [-1.0678],\n",
      "        [-1.1383],\n",
      "        [ 0.9574],\n",
      "        [-0.8984],\n",
      "        [ 0.6168],\n",
      "        [ 1.2335],\n",
      "        [-1.6092],\n",
      "        [ 0.0666],\n",
      "        [-0.4070],\n",
      "        [-1.3121],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5729],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4381],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2335],\n",
      "        [ 1.1885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 587/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0121,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6489],\n",
      "        [ 0.5845],\n",
      "        [-0.0270],\n",
      "        [ 0.4872],\n",
      "        [ 0.8979],\n",
      "        [ 0.9574],\n",
      "        [ 0.8979],\n",
      "        [ 0.8064],\n",
      "        [-1.5889],\n",
      "        [-0.8985],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.9278],\n",
      "        [-0.2075],\n",
      "        [ 0.5522],\n",
      "        [-0.6287],\n",
      "        [-0.2943],\n",
      "        [ 0.8677],\n",
      "        [ 0.7440],\n",
      "        [ 0.7753],\n",
      "        [ 1.2335],\n",
      "        [ 1.2335],\n",
      "        [ 1.0722],\n",
      "        [-0.2943],\n",
      "        [-1.2089],\n",
      "        [ 1.0722],\n",
      "        [-1.4380],\n",
      "        [ 0.9574],\n",
      "        [-1.3121],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.7440],\n",
      "        [ 0.5197],\n",
      "        [ 1.2335],\n",
      "        [ 0.7440],\n",
      "        [-0.7144],\n",
      "        [-0.1184],\n",
      "        [-1.0678],\n",
      "        [-1.1383],\n",
      "        [ 0.9574],\n",
      "        [-0.8985],\n",
      "        [ 0.6168],\n",
      "        [ 1.2335],\n",
      "        [-1.6093],\n",
      "        [ 0.0666],\n",
      "        [-0.4070],\n",
      "        [-1.3121],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5729],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4380],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2335],\n",
      "        [ 1.1885]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 588/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0121,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6489],\n",
      "        [ 0.5845],\n",
      "        [-0.0269],\n",
      "        [ 0.4872],\n",
      "        [ 0.8979],\n",
      "        [ 0.9573],\n",
      "        [ 0.8979],\n",
      "        [ 0.8064],\n",
      "        [-1.5889],\n",
      "        [-0.8985],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.9278],\n",
      "        [-0.2075],\n",
      "        [ 0.5522],\n",
      "        [-0.6287],\n",
      "        [-0.2943],\n",
      "        [ 0.8677],\n",
      "        [ 0.7440],\n",
      "        [ 0.7753],\n",
      "        [ 1.2336],\n",
      "        [ 1.2336],\n",
      "        [ 1.0722],\n",
      "        [-0.2943],\n",
      "        [-1.2088],\n",
      "        [ 1.0722],\n",
      "        [-1.4380],\n",
      "        [ 0.9573],\n",
      "        [-1.3120],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.7440],\n",
      "        [ 0.5197],\n",
      "        [ 1.2336],\n",
      "        [ 0.7440],\n",
      "        [-0.7144],\n",
      "        [-0.1184],\n",
      "        [-1.0678],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8985],\n",
      "        [ 0.6168],\n",
      "        [ 1.2336],\n",
      "        [-1.6093],\n",
      "        [ 0.0667],\n",
      "        [-0.4070],\n",
      "        [-1.3120],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5729],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4380],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2336],\n",
      "        [ 1.1886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 589/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0120,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6488],\n",
      "        [ 0.5845],\n",
      "        [-0.0269],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8063],\n",
      "        [-1.5890],\n",
      "        [-0.8986],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.9278],\n",
      "        [-0.2075],\n",
      "        [ 0.5522],\n",
      "        [-0.6287],\n",
      "        [-0.2943],\n",
      "        [ 0.8676],\n",
      "        [ 0.7440],\n",
      "        [ 0.7753],\n",
      "        [ 1.2336],\n",
      "        [ 1.2336],\n",
      "        [ 1.0722],\n",
      "        [-0.2943],\n",
      "        [-1.2088],\n",
      "        [ 1.0722],\n",
      "        [-1.4380],\n",
      "        [ 0.9573],\n",
      "        [-1.3120],\n",
      "        [ 0.5522],\n",
      "        [-0.2075],\n",
      "        [ 0.7440],\n",
      "        [ 0.5197],\n",
      "        [ 1.2336],\n",
      "        [ 0.7440],\n",
      "        [-0.7145],\n",
      "        [-0.1184],\n",
      "        [-1.0679],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8986],\n",
      "        [ 0.6168],\n",
      "        [ 1.2336],\n",
      "        [-1.6094],\n",
      "        [ 0.0667],\n",
      "        [-0.4070],\n",
      "        [-1.3120],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5729],\n",
      "        [-1.5441],\n",
      "        [ 0.6168],\n",
      "        [-1.4380],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2336],\n",
      "        [ 1.1886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 590/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0120,\n",
      " epoch_time_duration: 0.0119\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6488],\n",
      "        [ 0.5845],\n",
      "        [-0.0269],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8063],\n",
      "        [-1.5890],\n",
      "        [-0.8987],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.9277],\n",
      "        [-0.2074],\n",
      "        [ 0.5521],\n",
      "        [-0.6288],\n",
      "        [-0.2943],\n",
      "        [ 0.8676],\n",
      "        [ 0.7440],\n",
      "        [ 0.7753],\n",
      "        [ 1.2337],\n",
      "        [ 1.2337],\n",
      "        [ 1.0722],\n",
      "        [-0.2943],\n",
      "        [-1.2088],\n",
      "        [ 1.0722],\n",
      "        [-1.4379],\n",
      "        [ 0.9573],\n",
      "        [-1.3120],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.7440],\n",
      "        [ 0.5197],\n",
      "        [ 1.2337],\n",
      "        [ 0.7440],\n",
      "        [-0.7145],\n",
      "        [-0.1183],\n",
      "        [-1.0679],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8987],\n",
      "        [ 0.6167],\n",
      "        [ 1.2337],\n",
      "        [-1.6094],\n",
      "        [ 0.0667],\n",
      "        [-0.4070],\n",
      "        [-1.3120],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5730],\n",
      "        [-1.5441],\n",
      "        [ 0.6167],\n",
      "        [-1.4379],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2337],\n",
      "        [ 1.1886]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 591/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0120,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6488],\n",
      "        [ 0.5845],\n",
      "        [-0.0268],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8063],\n",
      "        [-1.5890],\n",
      "        [-0.8987],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.9277],\n",
      "        [-0.2074],\n",
      "        [ 0.5521],\n",
      "        [-0.6288],\n",
      "        [-0.2942],\n",
      "        [ 0.8676],\n",
      "        [ 0.7440],\n",
      "        [ 0.7753],\n",
      "        [ 1.2337],\n",
      "        [ 1.2337],\n",
      "        [ 1.0723],\n",
      "        [-0.2942],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4379],\n",
      "        [ 0.9573],\n",
      "        [-1.3119],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.7440],\n",
      "        [ 0.5197],\n",
      "        [ 1.2337],\n",
      "        [ 0.7440],\n",
      "        [-0.7146],\n",
      "        [-0.1183],\n",
      "        [-1.0679],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8987],\n",
      "        [ 0.6167],\n",
      "        [ 1.2337],\n",
      "        [-1.6095],\n",
      "        [ 0.0667],\n",
      "        [-0.4070],\n",
      "        [-1.3119],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5730],\n",
      "        [-1.5441],\n",
      "        [ 0.6167],\n",
      "        [-1.4379],\n",
      "        [ 0.4219],\n",
      "        [-0.4348],\n",
      "        [ 0.4219],\n",
      "        [ 1.2337],\n",
      "        [ 1.1887]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 592/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0120,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6488],\n",
      "        [ 0.5845],\n",
      "        [-0.0268],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8063],\n",
      "        [-1.5891],\n",
      "        [-0.8988],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.9277],\n",
      "        [-0.2074],\n",
      "        [ 0.5521],\n",
      "        [-0.6288],\n",
      "        [-0.2942],\n",
      "        [ 0.8676],\n",
      "        [ 0.7439],\n",
      "        [ 0.7752],\n",
      "        [ 1.2337],\n",
      "        [ 1.2337],\n",
      "        [ 1.0723],\n",
      "        [-0.2942],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4379],\n",
      "        [ 0.9573],\n",
      "        [-1.3119],\n",
      "        [ 0.5521],\n",
      "        [-0.2074],\n",
      "        [ 0.7439],\n",
      "        [ 0.5197],\n",
      "        [ 1.2337],\n",
      "        [ 0.7439],\n",
      "        [-0.7146],\n",
      "        [-0.1182],\n",
      "        [-1.0680],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8988],\n",
      "        [ 0.6167],\n",
      "        [ 1.2337],\n",
      "        [-1.6095],\n",
      "        [ 0.0668],\n",
      "        [-0.4070],\n",
      "        [-1.3119],\n",
      "        [ 1.0155],\n",
      "        [-0.4070],\n",
      "        [-0.5730],\n",
      "        [-1.5441],\n",
      "        [ 0.6167],\n",
      "        [-1.4379],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2337],\n",
      "        [ 1.1887]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 593/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0119,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6488],\n",
      "        [ 0.5845],\n",
      "        [-0.0268],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8063],\n",
      "        [-1.5891],\n",
      "        [-0.8988],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.9277],\n",
      "        [-0.2073],\n",
      "        [ 0.5521],\n",
      "        [-0.6289],\n",
      "        [-0.2942],\n",
      "        [ 0.8676],\n",
      "        [ 0.7439],\n",
      "        [ 0.7752],\n",
      "        [ 1.2338],\n",
      "        [ 1.2338],\n",
      "        [ 1.0723],\n",
      "        [-0.2942],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4378],\n",
      "        [ 0.9573],\n",
      "        [-1.3119],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.7439],\n",
      "        [ 0.5197],\n",
      "        [ 1.2338],\n",
      "        [ 0.7439],\n",
      "        [-0.7147],\n",
      "        [-0.1182],\n",
      "        [-1.0680],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8988],\n",
      "        [ 0.6167],\n",
      "        [ 1.2338],\n",
      "        [-1.6095],\n",
      "        [ 0.0668],\n",
      "        [-0.4069],\n",
      "        [-1.3119],\n",
      "        [ 1.0155],\n",
      "        [-0.4069],\n",
      "        [-0.5730],\n",
      "        [-1.5442],\n",
      "        [ 0.6167],\n",
      "        [-1.4378],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2338],\n",
      "        [ 1.1887]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 594/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0119,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0267],\n",
      "        [ 0.4871],\n",
      "        [ 0.8978],\n",
      "        [ 0.9573],\n",
      "        [ 0.8978],\n",
      "        [ 0.8062],\n",
      "        [-1.5891],\n",
      "        [-0.8989],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.9277],\n",
      "        [-0.2073],\n",
      "        [ 0.5521],\n",
      "        [-0.6289],\n",
      "        [-0.2941],\n",
      "        [ 0.8675],\n",
      "        [ 0.7439],\n",
      "        [ 0.7752],\n",
      "        [ 1.2338],\n",
      "        [ 1.2338],\n",
      "        [ 1.0723],\n",
      "        [-0.2941],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4378],\n",
      "        [ 0.9573],\n",
      "        [-1.3118],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.7439],\n",
      "        [ 0.5196],\n",
      "        [ 1.2338],\n",
      "        [ 0.7439],\n",
      "        [-0.7147],\n",
      "        [-0.1182],\n",
      "        [-1.0680],\n",
      "        [-1.1383],\n",
      "        [ 0.9573],\n",
      "        [-0.8989],\n",
      "        [ 0.6167],\n",
      "        [ 1.2338],\n",
      "        [-1.6096],\n",
      "        [ 0.0668],\n",
      "        [-0.4069],\n",
      "        [-1.3118],\n",
      "        [ 1.0155],\n",
      "        [-0.4069],\n",
      "        [-0.5730],\n",
      "        [-1.5442],\n",
      "        [ 0.6167],\n",
      "        [-1.4378],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2338],\n",
      "        [ 1.1888]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 595/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0119,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0267],\n",
      "        [ 0.4871],\n",
      "        [ 0.8977],\n",
      "        [ 0.9572],\n",
      "        [ 0.8977],\n",
      "        [ 0.8062],\n",
      "        [-1.5891],\n",
      "        [-0.8989],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.9277],\n",
      "        [-0.2073],\n",
      "        [ 0.5521],\n",
      "        [-0.6289],\n",
      "        [-0.2941],\n",
      "        [ 0.8675],\n",
      "        [ 0.7439],\n",
      "        [ 0.7752],\n",
      "        [ 1.2339],\n",
      "        [ 1.2339],\n",
      "        [ 1.0723],\n",
      "        [-0.2941],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4378],\n",
      "        [ 0.9572],\n",
      "        [-1.3118],\n",
      "        [ 0.5521],\n",
      "        [-0.2073],\n",
      "        [ 0.7439],\n",
      "        [ 0.5196],\n",
      "        [ 1.2339],\n",
      "        [ 0.7439],\n",
      "        [-0.7148],\n",
      "        [-0.1181],\n",
      "        [-1.0680],\n",
      "        [-1.1383],\n",
      "        [ 0.9572],\n",
      "        [-0.8989],\n",
      "        [ 0.6167],\n",
      "        [ 1.2339],\n",
      "        [-1.6096],\n",
      "        [ 0.0669],\n",
      "        [-0.4069],\n",
      "        [-1.3118],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5730],\n",
      "        [-1.5442],\n",
      "        [ 0.6167],\n",
      "        [-1.4378],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2339],\n",
      "        [ 1.1888]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 596/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0119,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0267],\n",
      "        [ 0.4871],\n",
      "        [ 0.8977],\n",
      "        [ 0.9572],\n",
      "        [ 0.8977],\n",
      "        [ 0.8062],\n",
      "        [-1.5892],\n",
      "        [-0.8990],\n",
      "        [ 0.5521],\n",
      "        [-0.2072],\n",
      "        [ 0.9276],\n",
      "        [-0.2072],\n",
      "        [ 0.5521],\n",
      "        [-0.6290],\n",
      "        [-0.2941],\n",
      "        [ 0.8675],\n",
      "        [ 0.7439],\n",
      "        [ 0.7751],\n",
      "        [ 1.2339],\n",
      "        [ 1.2339],\n",
      "        [ 1.0723],\n",
      "        [-0.2941],\n",
      "        [-1.2088],\n",
      "        [ 1.0723],\n",
      "        [-1.4377],\n",
      "        [ 0.9572],\n",
      "        [-1.3118],\n",
      "        [ 0.5521],\n",
      "        [-0.2072],\n",
      "        [ 0.7439],\n",
      "        [ 0.5196],\n",
      "        [ 1.2339],\n",
      "        [ 0.7439],\n",
      "        [-0.7148],\n",
      "        [-0.1181],\n",
      "        [-1.0681],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8990],\n",
      "        [ 0.6166],\n",
      "        [ 1.2339],\n",
      "        [-1.6097],\n",
      "        [ 0.0669],\n",
      "        [-0.4069],\n",
      "        [-1.3118],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5731],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4377],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2339],\n",
      "        [ 1.1888]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 597/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0119,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0266],\n",
      "        [ 0.4871],\n",
      "        [ 0.8977],\n",
      "        [ 0.9572],\n",
      "        [ 0.8977],\n",
      "        [ 0.8062],\n",
      "        [-1.5892],\n",
      "        [-0.8990],\n",
      "        [ 0.5521],\n",
      "        [-0.2072],\n",
      "        [ 0.9276],\n",
      "        [-0.2072],\n",
      "        [ 0.5521],\n",
      "        [-0.6290],\n",
      "        [-0.2941],\n",
      "        [ 0.8675],\n",
      "        [ 0.7438],\n",
      "        [ 0.7751],\n",
      "        [ 1.2340],\n",
      "        [ 1.2340],\n",
      "        [ 1.0723],\n",
      "        [-0.2941],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4377],\n",
      "        [ 0.9572],\n",
      "        [-1.3117],\n",
      "        [ 0.5521],\n",
      "        [-0.2072],\n",
      "        [ 0.7438],\n",
      "        [ 0.5196],\n",
      "        [ 1.2340],\n",
      "        [ 0.7438],\n",
      "        [-0.7148],\n",
      "        [-0.1181],\n",
      "        [-1.0681],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8990],\n",
      "        [ 0.6166],\n",
      "        [ 1.2340],\n",
      "        [-1.6097],\n",
      "        [ 0.0669],\n",
      "        [-0.4069],\n",
      "        [-1.3117],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5731],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4377],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2340],\n",
      "        [ 1.1888]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 598/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0118,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0266],\n",
      "        [ 0.4871],\n",
      "        [ 0.8977],\n",
      "        [ 0.9572],\n",
      "        [ 0.8977],\n",
      "        [ 0.8061],\n",
      "        [-1.5892],\n",
      "        [-0.8991],\n",
      "        [ 0.5520],\n",
      "        [-0.2072],\n",
      "        [ 0.9276],\n",
      "        [-0.2072],\n",
      "        [ 0.5520],\n",
      "        [-0.6290],\n",
      "        [-0.2940],\n",
      "        [ 0.8675],\n",
      "        [ 0.7438],\n",
      "        [ 0.7751],\n",
      "        [ 1.2340],\n",
      "        [ 1.2340],\n",
      "        [ 1.0723],\n",
      "        [-0.2940],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4377],\n",
      "        [ 0.9572],\n",
      "        [-1.3117],\n",
      "        [ 0.5520],\n",
      "        [-0.2072],\n",
      "        [ 0.7438],\n",
      "        [ 0.5196],\n",
      "        [ 1.2340],\n",
      "        [ 0.7438],\n",
      "        [-0.7149],\n",
      "        [-0.1180],\n",
      "        [-1.0681],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8991],\n",
      "        [ 0.6166],\n",
      "        [ 1.2340],\n",
      "        [-1.6098],\n",
      "        [ 0.0669],\n",
      "        [-0.4069],\n",
      "        [-1.3117],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5731],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4377],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2340],\n",
      "        [ 1.1889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 599/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0118,\n",
      " epoch_time_duration: 0.0130\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6487],\n",
      "        [ 0.5844],\n",
      "        [-0.0266],\n",
      "        [ 0.4871],\n",
      "        [ 0.8977],\n",
      "        [ 0.9572],\n",
      "        [ 0.8977],\n",
      "        [ 0.8061],\n",
      "        [-1.5893],\n",
      "        [-0.8992],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.9276],\n",
      "        [-0.2071],\n",
      "        [ 0.5520],\n",
      "        [-0.6291],\n",
      "        [-0.2940],\n",
      "        [ 0.8674],\n",
      "        [ 0.7438],\n",
      "        [ 0.7751],\n",
      "        [ 1.2341],\n",
      "        [ 1.2341],\n",
      "        [ 1.0723],\n",
      "        [-0.2940],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4376],\n",
      "        [ 0.9572],\n",
      "        [-1.3117],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.7438],\n",
      "        [ 0.5196],\n",
      "        [ 1.2341],\n",
      "        [ 0.7438],\n",
      "        [-0.7149],\n",
      "        [-0.1180],\n",
      "        [-1.0681],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8992],\n",
      "        [ 0.6166],\n",
      "        [ 1.2341],\n",
      "        [-1.6098],\n",
      "        [ 0.0670],\n",
      "        [-0.4069],\n",
      "        [-1.3117],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5731],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4376],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2341],\n",
      "        [ 1.1889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 600/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0118,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6486],\n",
      "        [ 0.5844],\n",
      "        [-0.0265],\n",
      "        [ 0.4871],\n",
      "        [ 0.8976],\n",
      "        [ 0.9572],\n",
      "        [ 0.8976],\n",
      "        [ 0.8061],\n",
      "        [-1.5893],\n",
      "        [-0.8992],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.9276],\n",
      "        [-0.2071],\n",
      "        [ 0.5520],\n",
      "        [-0.6291],\n",
      "        [-0.2940],\n",
      "        [ 0.8674],\n",
      "        [ 0.7438],\n",
      "        [ 0.7751],\n",
      "        [ 1.2341],\n",
      "        [ 1.2341],\n",
      "        [ 1.0723],\n",
      "        [-0.2940],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4376],\n",
      "        [ 0.9572],\n",
      "        [-1.3116],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.7438],\n",
      "        [ 0.5196],\n",
      "        [ 1.2341],\n",
      "        [ 0.7438],\n",
      "        [-0.7150],\n",
      "        [-0.1180],\n",
      "        [-1.0682],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8992],\n",
      "        [ 0.6166],\n",
      "        [ 1.2341],\n",
      "        [-1.6098],\n",
      "        [ 0.0670],\n",
      "        [-0.4069],\n",
      "        [-1.3116],\n",
      "        [ 1.0154],\n",
      "        [-0.4069],\n",
      "        [-0.5731],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4376],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2341],\n",
      "        [ 1.1889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 601/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0118,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6486],\n",
      "        [ 0.5843],\n",
      "        [-0.0265],\n",
      "        [ 0.4871],\n",
      "        [ 0.8976],\n",
      "        [ 0.9572],\n",
      "        [ 0.8976],\n",
      "        [ 0.8061],\n",
      "        [-1.5893],\n",
      "        [-0.8993],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.9275],\n",
      "        [-0.2071],\n",
      "        [ 0.5520],\n",
      "        [-0.6291],\n",
      "        [-0.2940],\n",
      "        [ 0.8674],\n",
      "        [ 0.7437],\n",
      "        [ 0.7750],\n",
      "        [ 1.2341],\n",
      "        [ 1.2341],\n",
      "        [ 1.0723],\n",
      "        [-0.2940],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4376],\n",
      "        [ 0.9572],\n",
      "        [-1.3116],\n",
      "        [ 0.5520],\n",
      "        [-0.2071],\n",
      "        [ 0.7437],\n",
      "        [ 0.5196],\n",
      "        [ 1.2341],\n",
      "        [ 0.7437],\n",
      "        [-0.7150],\n",
      "        [-0.1179],\n",
      "        [-1.0682],\n",
      "        [-1.1384],\n",
      "        [ 0.9572],\n",
      "        [-0.8993],\n",
      "        [ 0.6166],\n",
      "        [ 1.2341],\n",
      "        [-1.6099],\n",
      "        [ 0.0670],\n",
      "        [-0.4068],\n",
      "        [-1.3116],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5732],\n",
      "        [-1.5442],\n",
      "        [ 0.6166],\n",
      "        [-1.4376],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2341],\n",
      "        [ 1.1890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 602/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0117,\n",
      " epoch_time_duration: 0.0112\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6486],\n",
      "        [ 0.5843],\n",
      "        [-0.0265],\n",
      "        [ 0.4871],\n",
      "        [ 0.8976],\n",
      "        [ 0.9571],\n",
      "        [ 0.8976],\n",
      "        [ 0.8061],\n",
      "        [-1.5893],\n",
      "        [-0.8993],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.9275],\n",
      "        [-0.2070],\n",
      "        [ 0.5520],\n",
      "        [-0.6292],\n",
      "        [-0.2939],\n",
      "        [ 0.8674],\n",
      "        [ 0.7437],\n",
      "        [ 0.7750],\n",
      "        [ 1.2342],\n",
      "        [ 1.2342],\n",
      "        [ 1.0723],\n",
      "        [-0.2939],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4375],\n",
      "        [ 0.9571],\n",
      "        [-1.3116],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.7437],\n",
      "        [ 0.5196],\n",
      "        [ 1.2342],\n",
      "        [ 0.7437],\n",
      "        [-0.7151],\n",
      "        [-0.1179],\n",
      "        [-1.0682],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8993],\n",
      "        [ 0.6165],\n",
      "        [ 1.2342],\n",
      "        [-1.6099],\n",
      "        [ 0.0671],\n",
      "        [-0.4068],\n",
      "        [-1.3116],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5732],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4375],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2342],\n",
      "        [ 1.1890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 603/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0117,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6486],\n",
      "        [ 0.5843],\n",
      "        [-0.0264],\n",
      "        [ 0.4870],\n",
      "        [ 0.8976],\n",
      "        [ 0.9571],\n",
      "        [ 0.8976],\n",
      "        [ 0.8060],\n",
      "        [-1.5894],\n",
      "        [-0.8994],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.9275],\n",
      "        [-0.2070],\n",
      "        [ 0.5520],\n",
      "        [-0.6292],\n",
      "        [-0.2939],\n",
      "        [ 0.8674],\n",
      "        [ 0.7437],\n",
      "        [ 0.7750],\n",
      "        [ 1.2342],\n",
      "        [ 1.2342],\n",
      "        [ 1.0723],\n",
      "        [-0.2939],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4375],\n",
      "        [ 0.9571],\n",
      "        [-1.3116],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.7437],\n",
      "        [ 0.5196],\n",
      "        [ 1.2342],\n",
      "        [ 0.7437],\n",
      "        [-0.7151],\n",
      "        [-0.1179],\n",
      "        [-1.0682],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8994],\n",
      "        [ 0.6165],\n",
      "        [ 1.2342],\n",
      "        [-1.6100],\n",
      "        [ 0.0671],\n",
      "        [-0.4068],\n",
      "        [-1.3116],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5732],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4375],\n",
      "        [ 0.4219],\n",
      "        [-0.4347],\n",
      "        [ 0.4219],\n",
      "        [ 1.2342],\n",
      "        [ 1.1890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 604/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0117,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6486],\n",
      "        [ 0.5843],\n",
      "        [-0.0264],\n",
      "        [ 0.4870],\n",
      "        [ 0.8976],\n",
      "        [ 0.9571],\n",
      "        [ 0.8976],\n",
      "        [ 0.8060],\n",
      "        [-1.5894],\n",
      "        [-0.8994],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.9275],\n",
      "        [-0.2070],\n",
      "        [ 0.5520],\n",
      "        [-0.6292],\n",
      "        [-0.2939],\n",
      "        [ 0.8673],\n",
      "        [ 0.7437],\n",
      "        [ 0.7750],\n",
      "        [ 1.2343],\n",
      "        [ 1.2343],\n",
      "        [ 1.0723],\n",
      "        [-0.2939],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4375],\n",
      "        [ 0.9571],\n",
      "        [-1.3115],\n",
      "        [ 0.5520],\n",
      "        [-0.2070],\n",
      "        [ 0.7437],\n",
      "        [ 0.5195],\n",
      "        [ 1.2343],\n",
      "        [ 0.7437],\n",
      "        [-0.7152],\n",
      "        [-0.1178],\n",
      "        [-1.0683],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8994],\n",
      "        [ 0.6165],\n",
      "        [ 1.2343],\n",
      "        [-1.6100],\n",
      "        [ 0.0671],\n",
      "        [-0.4068],\n",
      "        [-1.3115],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5732],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4375],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2343],\n",
      "        [ 1.1890]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 605/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0117,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5843],\n",
      "        [-0.0264],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9571],\n",
      "        [ 0.8975],\n",
      "        [ 0.8060],\n",
      "        [-1.5894],\n",
      "        [-0.8995],\n",
      "        [ 0.5520],\n",
      "        [-0.2069],\n",
      "        [ 0.9275],\n",
      "        [-0.2069],\n",
      "        [ 0.5520],\n",
      "        [-0.6293],\n",
      "        [-0.2938],\n",
      "        [ 0.8673],\n",
      "        [ 0.7437],\n",
      "        [ 0.7749],\n",
      "        [ 1.2343],\n",
      "        [ 1.2343],\n",
      "        [ 1.0723],\n",
      "        [-0.2938],\n",
      "        [-1.2087],\n",
      "        [ 1.0723],\n",
      "        [-1.4374],\n",
      "        [ 0.9571],\n",
      "        [-1.3115],\n",
      "        [ 0.5520],\n",
      "        [-0.2069],\n",
      "        [ 0.7437],\n",
      "        [ 0.5195],\n",
      "        [ 1.2343],\n",
      "        [ 0.7437],\n",
      "        [-0.7152],\n",
      "        [-0.1178],\n",
      "        [-1.0683],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8995],\n",
      "        [ 0.6165],\n",
      "        [ 1.2343],\n",
      "        [-1.6101],\n",
      "        [ 0.0671],\n",
      "        [-0.4068],\n",
      "        [-1.3115],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5732],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4374],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2343],\n",
      "        [ 1.1891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 606/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0117,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5843],\n",
      "        [-0.0263],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9571],\n",
      "        [ 0.8975],\n",
      "        [ 0.8060],\n",
      "        [-1.5894],\n",
      "        [-0.8995],\n",
      "        [ 0.5519],\n",
      "        [-0.2069],\n",
      "        [ 0.9275],\n",
      "        [-0.2069],\n",
      "        [ 0.5519],\n",
      "        [-0.6293],\n",
      "        [-0.2938],\n",
      "        [ 0.8673],\n",
      "        [ 0.7436],\n",
      "        [ 0.7749],\n",
      "        [ 1.2344],\n",
      "        [ 1.2344],\n",
      "        [ 1.0723],\n",
      "        [-0.2938],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4374],\n",
      "        [ 0.9571],\n",
      "        [-1.3115],\n",
      "        [ 0.5519],\n",
      "        [-0.2069],\n",
      "        [ 0.7436],\n",
      "        [ 0.5195],\n",
      "        [ 1.2344],\n",
      "        [ 0.7436],\n",
      "        [-0.7153],\n",
      "        [-0.1177],\n",
      "        [-1.0683],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8995],\n",
      "        [ 0.6165],\n",
      "        [ 1.2344],\n",
      "        [-1.6101],\n",
      "        [ 0.0672],\n",
      "        [-0.4068],\n",
      "        [-1.3115],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5733],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4374],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2344],\n",
      "        [ 1.1891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 607/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0116,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5843],\n",
      "        [-0.0263],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9571],\n",
      "        [ 0.8975],\n",
      "        [ 0.8060],\n",
      "        [-1.5895],\n",
      "        [-0.8996],\n",
      "        [ 0.5519],\n",
      "        [-0.2069],\n",
      "        [ 0.9274],\n",
      "        [-0.2069],\n",
      "        [ 0.5519],\n",
      "        [-0.6293],\n",
      "        [-0.2938],\n",
      "        [ 0.8673],\n",
      "        [ 0.7436],\n",
      "        [ 0.7749],\n",
      "        [ 1.2344],\n",
      "        [ 1.2344],\n",
      "        [ 1.0723],\n",
      "        [-0.2938],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4374],\n",
      "        [ 0.9571],\n",
      "        [-1.3114],\n",
      "        [ 0.5519],\n",
      "        [-0.2069],\n",
      "        [ 0.7436],\n",
      "        [ 0.5195],\n",
      "        [ 1.2344],\n",
      "        [ 0.7436],\n",
      "        [-0.7153],\n",
      "        [-0.1177],\n",
      "        [-1.0683],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8996],\n",
      "        [ 0.6165],\n",
      "        [ 1.2344],\n",
      "        [-1.6101],\n",
      "        [ 0.0672],\n",
      "        [-0.4068],\n",
      "        [-1.3114],\n",
      "        [ 1.0154],\n",
      "        [-0.4068],\n",
      "        [-0.5733],\n",
      "        [-1.5442],\n",
      "        [ 0.6165],\n",
      "        [-1.4374],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2344],\n",
      "        [ 1.1891]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 608/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0116,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5842],\n",
      "        [-0.0263],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9571],\n",
      "        [ 0.8975],\n",
      "        [ 0.8059],\n",
      "        [-1.5895],\n",
      "        [-0.8996],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.9274],\n",
      "        [-0.2068],\n",
      "        [ 0.5519],\n",
      "        [-0.6293],\n",
      "        [-0.2938],\n",
      "        [ 0.8673],\n",
      "        [ 0.7436],\n",
      "        [ 0.7749],\n",
      "        [ 1.2345],\n",
      "        [ 1.2345],\n",
      "        [ 1.0723],\n",
      "        [-0.2938],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4373],\n",
      "        [ 0.9571],\n",
      "        [-1.3114],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.7436],\n",
      "        [ 0.5195],\n",
      "        [ 1.2345],\n",
      "        [ 0.7436],\n",
      "        [-0.7154],\n",
      "        [-0.1177],\n",
      "        [-1.0684],\n",
      "        [-1.1384],\n",
      "        [ 0.9571],\n",
      "        [-0.8996],\n",
      "        [ 0.6164],\n",
      "        [ 1.2345],\n",
      "        [-1.6102],\n",
      "        [ 0.0672],\n",
      "        [-0.4067],\n",
      "        [-1.3114],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5733],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4373],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2345],\n",
      "        [ 1.1892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 609/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0116,\n",
      " epoch_time_duration: 0.0120\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5842],\n",
      "        [-0.0262],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9570],\n",
      "        [ 0.8975],\n",
      "        [ 0.8059],\n",
      "        [-1.5895],\n",
      "        [-0.8997],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.9274],\n",
      "        [-0.2068],\n",
      "        [ 0.5519],\n",
      "        [-0.6294],\n",
      "        [-0.2937],\n",
      "        [ 0.8672],\n",
      "        [ 0.7436],\n",
      "        [ 0.7749],\n",
      "        [ 1.2345],\n",
      "        [ 1.2345],\n",
      "        [ 1.0723],\n",
      "        [-0.2937],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4373],\n",
      "        [ 0.9570],\n",
      "        [-1.3114],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.7436],\n",
      "        [ 0.5195],\n",
      "        [ 1.2345],\n",
      "        [ 0.7436],\n",
      "        [-0.7154],\n",
      "        [-0.1176],\n",
      "        [-1.0684],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.8997],\n",
      "        [ 0.6164],\n",
      "        [ 1.2345],\n",
      "        [-1.6102],\n",
      "        [ 0.0673],\n",
      "        [-0.4067],\n",
      "        [-1.3114],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5733],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4373],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2345],\n",
      "        [ 1.1892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 610/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0116,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6485],\n",
      "        [ 0.5842],\n",
      "        [-0.0262],\n",
      "        [ 0.4870],\n",
      "        [ 0.8975],\n",
      "        [ 0.9570],\n",
      "        [ 0.8975],\n",
      "        [ 0.8059],\n",
      "        [-1.5896],\n",
      "        [-0.8998],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.9274],\n",
      "        [-0.2068],\n",
      "        [ 0.5519],\n",
      "        [-0.6294],\n",
      "        [-0.2937],\n",
      "        [ 0.8672],\n",
      "        [ 0.7436],\n",
      "        [ 0.7748],\n",
      "        [ 1.2346],\n",
      "        [ 1.2346],\n",
      "        [ 1.0723],\n",
      "        [-0.2937],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4373],\n",
      "        [ 0.9570],\n",
      "        [-1.3113],\n",
      "        [ 0.5519],\n",
      "        [-0.2068],\n",
      "        [ 0.7436],\n",
      "        [ 0.5195],\n",
      "        [ 1.2346],\n",
      "        [ 0.7436],\n",
      "        [-0.7155],\n",
      "        [-0.1176],\n",
      "        [-1.0684],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.8998],\n",
      "        [ 0.6164],\n",
      "        [ 1.2346],\n",
      "        [-1.6103],\n",
      "        [ 0.0673],\n",
      "        [-0.4067],\n",
      "        [-1.3113],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5733],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4373],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2346],\n",
      "        [ 1.1892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 611/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0115,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6484],\n",
      "        [ 0.5842],\n",
      "        [-0.0262],\n",
      "        [ 0.4870],\n",
      "        [ 0.8974],\n",
      "        [ 0.9570],\n",
      "        [ 0.8974],\n",
      "        [ 0.8059],\n",
      "        [-1.5896],\n",
      "        [-0.8998],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.9274],\n",
      "        [-0.2067],\n",
      "        [ 0.5519],\n",
      "        [-0.6294],\n",
      "        [-0.2937],\n",
      "        [ 0.8672],\n",
      "        [ 0.7435],\n",
      "        [ 0.7748],\n",
      "        [ 1.2346],\n",
      "        [ 1.2346],\n",
      "        [ 1.0723],\n",
      "        [-0.2937],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4372],\n",
      "        [ 0.9570],\n",
      "        [-1.3113],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.7435],\n",
      "        [ 0.5195],\n",
      "        [ 1.2346],\n",
      "        [ 0.7435],\n",
      "        [-0.7155],\n",
      "        [-0.1176],\n",
      "        [-1.0684],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.8998],\n",
      "        [ 0.6164],\n",
      "        [ 1.2346],\n",
      "        [-1.6103],\n",
      "        [ 0.0673],\n",
      "        [-0.4067],\n",
      "        [-1.3113],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5734],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4372],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2346],\n",
      "        [ 1.1892]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 612/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0115,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6484],\n",
      "        [ 0.5842],\n",
      "        [-0.0261],\n",
      "        [ 0.4870],\n",
      "        [ 0.8974],\n",
      "        [ 0.9570],\n",
      "        [ 0.8974],\n",
      "        [ 0.8058],\n",
      "        [-1.5896],\n",
      "        [-0.8999],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.9274],\n",
      "        [-0.2067],\n",
      "        [ 0.5519],\n",
      "        [-0.6295],\n",
      "        [-0.2937],\n",
      "        [ 0.8672],\n",
      "        [ 0.7435],\n",
      "        [ 0.7748],\n",
      "        [ 1.2346],\n",
      "        [ 1.2346],\n",
      "        [ 1.0723],\n",
      "        [-0.2937],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4372],\n",
      "        [ 0.9570],\n",
      "        [-1.3113],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.7435],\n",
      "        [ 0.5195],\n",
      "        [ 1.2346],\n",
      "        [ 0.7435],\n",
      "        [-0.7156],\n",
      "        [-0.1175],\n",
      "        [-1.0685],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.8999],\n",
      "        [ 0.6164],\n",
      "        [ 1.2346],\n",
      "        [-1.6103],\n",
      "        [ 0.0674],\n",
      "        [-0.4067],\n",
      "        [-1.3113],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5734],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4372],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2346],\n",
      "        [ 1.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 613/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0115,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6484],\n",
      "        [ 0.5842],\n",
      "        [-0.0261],\n",
      "        [ 0.4870],\n",
      "        [ 0.8974],\n",
      "        [ 0.9570],\n",
      "        [ 0.8974],\n",
      "        [ 0.8058],\n",
      "        [-1.5896],\n",
      "        [-0.8999],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.9273],\n",
      "        [-0.2067],\n",
      "        [ 0.5519],\n",
      "        [-0.6295],\n",
      "        [-0.2936],\n",
      "        [ 0.8671],\n",
      "        [ 0.7435],\n",
      "        [ 0.7748],\n",
      "        [ 1.2347],\n",
      "        [ 1.2347],\n",
      "        [ 1.0723],\n",
      "        [-0.2936],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4372],\n",
      "        [ 0.9570],\n",
      "        [-1.3112],\n",
      "        [ 0.5519],\n",
      "        [-0.2067],\n",
      "        [ 0.7435],\n",
      "        [ 0.5195],\n",
      "        [ 1.2347],\n",
      "        [ 0.7435],\n",
      "        [-0.7156],\n",
      "        [-0.1175],\n",
      "        [-1.0685],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.8999],\n",
      "        [ 0.6164],\n",
      "        [ 1.2347],\n",
      "        [-1.6104],\n",
      "        [ 0.0674],\n",
      "        [-0.4067],\n",
      "        [-1.3112],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5734],\n",
      "        [-1.5442],\n",
      "        [ 0.6164],\n",
      "        [-1.4372],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2347],\n",
      "        [ 1.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 614/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0115,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6484],\n",
      "        [ 0.5842],\n",
      "        [-0.0261],\n",
      "        [ 0.4870],\n",
      "        [ 0.8974],\n",
      "        [ 0.9570],\n",
      "        [ 0.8974],\n",
      "        [ 0.8058],\n",
      "        [-1.5897],\n",
      "        [-0.9000],\n",
      "        [ 0.5519],\n",
      "        [-0.2066],\n",
      "        [ 0.9273],\n",
      "        [-0.2066],\n",
      "        [ 0.5519],\n",
      "        [-0.6295],\n",
      "        [-0.2936],\n",
      "        [ 0.8671],\n",
      "        [ 0.7435],\n",
      "        [ 0.7748],\n",
      "        [ 1.2347],\n",
      "        [ 1.2347],\n",
      "        [ 1.0723],\n",
      "        [-0.2936],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4371],\n",
      "        [ 0.9570],\n",
      "        [-1.3112],\n",
      "        [ 0.5519],\n",
      "        [-0.2066],\n",
      "        [ 0.7435],\n",
      "        [ 0.5194],\n",
      "        [ 1.2347],\n",
      "        [ 0.7435],\n",
      "        [-0.7156],\n",
      "        [-0.1175],\n",
      "        [-1.0685],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.9000],\n",
      "        [ 0.6163],\n",
      "        [ 1.2347],\n",
      "        [-1.6104],\n",
      "        [ 0.0674],\n",
      "        [-0.4067],\n",
      "        [-1.3112],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5734],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4371],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2347],\n",
      "        [ 1.1893]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 615/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0115,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6484],\n",
      "        [ 0.5841],\n",
      "        [-0.0260],\n",
      "        [ 0.4870],\n",
      "        [ 0.8974],\n",
      "        [ 0.9570],\n",
      "        [ 0.8974],\n",
      "        [ 0.8058],\n",
      "        [-1.5897],\n",
      "        [-0.9000],\n",
      "        [ 0.5518],\n",
      "        [-0.2066],\n",
      "        [ 0.9273],\n",
      "        [-0.2066],\n",
      "        [ 0.5518],\n",
      "        [-0.6296],\n",
      "        [-0.2936],\n",
      "        [ 0.8671],\n",
      "        [ 0.7434],\n",
      "        [ 0.7747],\n",
      "        [ 1.2348],\n",
      "        [ 1.2348],\n",
      "        [ 1.0723],\n",
      "        [-0.2936],\n",
      "        [-1.2086],\n",
      "        [ 1.0723],\n",
      "        [-1.4371],\n",
      "        [ 0.9570],\n",
      "        [-1.3112],\n",
      "        [ 0.5518],\n",
      "        [-0.2066],\n",
      "        [ 0.7434],\n",
      "        [ 0.5194],\n",
      "        [ 1.2348],\n",
      "        [ 0.7434],\n",
      "        [-0.7157],\n",
      "        [-0.1174],\n",
      "        [-1.0685],\n",
      "        [-1.1385],\n",
      "        [ 0.9570],\n",
      "        [-0.9000],\n",
      "        [ 0.6163],\n",
      "        [ 1.2348],\n",
      "        [-1.6105],\n",
      "        [ 0.0674],\n",
      "        [-0.4067],\n",
      "        [-1.3112],\n",
      "        [ 1.0153],\n",
      "        [-0.4067],\n",
      "        [-0.5734],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4371],\n",
      "        [ 0.4219],\n",
      "        [-0.4346],\n",
      "        [ 0.4219],\n",
      "        [ 1.2348],\n",
      "        [ 1.1894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 616/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0114,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0260],\n",
      "        [ 0.4870],\n",
      "        [ 0.8973],\n",
      "        [ 0.9569],\n",
      "        [ 0.8973],\n",
      "        [ 0.8058],\n",
      "        [-1.5897],\n",
      "        [-0.9001],\n",
      "        [ 0.5518],\n",
      "        [-0.2066],\n",
      "        [ 0.9273],\n",
      "        [-0.2066],\n",
      "        [ 0.5518],\n",
      "        [-0.6296],\n",
      "        [-0.2935],\n",
      "        [ 0.8671],\n",
      "        [ 0.7434],\n",
      "        [ 0.7747],\n",
      "        [ 1.2348],\n",
      "        [ 1.2348],\n",
      "        [ 1.0723],\n",
      "        [-0.2935],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4371],\n",
      "        [ 0.9569],\n",
      "        [-1.3111],\n",
      "        [ 0.5518],\n",
      "        [-0.2066],\n",
      "        [ 0.7434],\n",
      "        [ 0.5194],\n",
      "        [ 1.2348],\n",
      "        [ 0.7434],\n",
      "        [-0.7157],\n",
      "        [-0.1174],\n",
      "        [-1.0686],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9001],\n",
      "        [ 0.6163],\n",
      "        [ 1.2348],\n",
      "        [-1.6105],\n",
      "        [ 0.0675],\n",
      "        [-0.4066],\n",
      "        [-1.3111],\n",
      "        [ 1.0153],\n",
      "        [-0.4066],\n",
      "        [-0.5735],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4371],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2348],\n",
      "        [ 1.1894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 617/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0114,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0260],\n",
      "        [ 0.4869],\n",
      "        [ 0.8973],\n",
      "        [ 0.9569],\n",
      "        [ 0.8973],\n",
      "        [ 0.8057],\n",
      "        [-1.5897],\n",
      "        [-0.9001],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.9273],\n",
      "        [-0.2065],\n",
      "        [ 0.5518],\n",
      "        [-0.6296],\n",
      "        [-0.2935],\n",
      "        [ 0.8671],\n",
      "        [ 0.7434],\n",
      "        [ 0.7747],\n",
      "        [ 1.2349],\n",
      "        [ 1.2349],\n",
      "        [ 1.0723],\n",
      "        [-0.2935],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4370],\n",
      "        [ 0.9569],\n",
      "        [-1.3111],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.7434],\n",
      "        [ 0.5194],\n",
      "        [ 1.2349],\n",
      "        [ 0.7434],\n",
      "        [-0.7158],\n",
      "        [-0.1174],\n",
      "        [-1.0686],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9001],\n",
      "        [ 0.6163],\n",
      "        [ 1.2349],\n",
      "        [-1.6106],\n",
      "        [ 0.0675],\n",
      "        [-0.4066],\n",
      "        [-1.3111],\n",
      "        [ 1.0153],\n",
      "        [-0.4066],\n",
      "        [-0.5735],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4370],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2349],\n",
      "        [ 1.1894]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 618/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0114,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0259],\n",
      "        [ 0.4869],\n",
      "        [ 0.8973],\n",
      "        [ 0.9569],\n",
      "        [ 0.8973],\n",
      "        [ 0.8057],\n",
      "        [-1.5898],\n",
      "        [-0.9002],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.9273],\n",
      "        [-0.2065],\n",
      "        [ 0.5518],\n",
      "        [-0.6297],\n",
      "        [-0.2935],\n",
      "        [ 0.8670],\n",
      "        [ 0.7434],\n",
      "        [ 0.7747],\n",
      "        [ 1.2349],\n",
      "        [ 1.2349],\n",
      "        [ 1.0723],\n",
      "        [-0.2935],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4370],\n",
      "        [ 0.9569],\n",
      "        [-1.3111],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.7434],\n",
      "        [ 0.5194],\n",
      "        [ 1.2349],\n",
      "        [ 0.7434],\n",
      "        [-0.7158],\n",
      "        [-0.1173],\n",
      "        [-1.0686],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9002],\n",
      "        [ 0.6163],\n",
      "        [ 1.2349],\n",
      "        [-1.6106],\n",
      "        [ 0.0675],\n",
      "        [-0.4066],\n",
      "        [-1.3111],\n",
      "        [ 1.0153],\n",
      "        [-0.4066],\n",
      "        [-0.5735],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4370],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2349],\n",
      "        [ 1.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 619/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0114,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0259],\n",
      "        [ 0.4869],\n",
      "        [ 0.8973],\n",
      "        [ 0.9569],\n",
      "        [ 0.8973],\n",
      "        [ 0.8057],\n",
      "        [-1.5898],\n",
      "        [-0.9002],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.9272],\n",
      "        [-0.2065],\n",
      "        [ 0.5518],\n",
      "        [-0.6297],\n",
      "        [-0.2935],\n",
      "        [ 0.8670],\n",
      "        [ 0.7434],\n",
      "        [ 0.7746],\n",
      "        [ 1.2349],\n",
      "        [ 1.2349],\n",
      "        [ 1.0723],\n",
      "        [-0.2935],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4370],\n",
      "        [ 0.9569],\n",
      "        [-1.3111],\n",
      "        [ 0.5518],\n",
      "        [-0.2065],\n",
      "        [ 0.7434],\n",
      "        [ 0.5194],\n",
      "        [ 1.2349],\n",
      "        [ 0.7434],\n",
      "        [-0.7159],\n",
      "        [-0.1173],\n",
      "        [-1.0686],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9002],\n",
      "        [ 0.6163],\n",
      "        [ 1.2349],\n",
      "        [-1.6106],\n",
      "        [ 0.0676],\n",
      "        [-0.4066],\n",
      "        [-1.3111],\n",
      "        [ 1.0153],\n",
      "        [-0.4066],\n",
      "        [-0.5735],\n",
      "        [-1.5442],\n",
      "        [ 0.6163],\n",
      "        [-1.4370],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2349],\n",
      "        [ 1.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 620/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0113,\n",
      " epoch_time_duration: 0.0137\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0259],\n",
      "        [ 0.4869],\n",
      "        [ 0.8973],\n",
      "        [ 0.9569],\n",
      "        [ 0.8973],\n",
      "        [ 0.8057],\n",
      "        [-1.5898],\n",
      "        [-0.9003],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.9272],\n",
      "        [-0.2064],\n",
      "        [ 0.5518],\n",
      "        [-0.6297],\n",
      "        [-0.2934],\n",
      "        [ 0.8670],\n",
      "        [ 0.7433],\n",
      "        [ 0.7746],\n",
      "        [ 1.2350],\n",
      "        [ 1.2350],\n",
      "        [ 1.0723],\n",
      "        [-0.2934],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4369],\n",
      "        [ 0.9569],\n",
      "        [-1.3110],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.7433],\n",
      "        [ 0.5194],\n",
      "        [ 1.2350],\n",
      "        [ 0.7433],\n",
      "        [-0.7159],\n",
      "        [-0.1173],\n",
      "        [-1.0687],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9003],\n",
      "        [ 0.6162],\n",
      "        [ 1.2350],\n",
      "        [-1.6107],\n",
      "        [ 0.0676],\n",
      "        [-0.4066],\n",
      "        [-1.3110],\n",
      "        [ 1.0153],\n",
      "        [-0.4066],\n",
      "        [-0.5735],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4369],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2350],\n",
      "        [ 1.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 621/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0113,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6483],\n",
      "        [ 0.5841],\n",
      "        [-0.0258],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9569],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5898],\n",
      "        [-0.9003],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.9272],\n",
      "        [-0.2064],\n",
      "        [ 0.5518],\n",
      "        [-0.6298],\n",
      "        [-0.2934],\n",
      "        [ 0.8670],\n",
      "        [ 0.7433],\n",
      "        [ 0.7746],\n",
      "        [ 1.2350],\n",
      "        [ 1.2350],\n",
      "        [ 1.0723],\n",
      "        [-0.2934],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4369],\n",
      "        [ 0.9569],\n",
      "        [-1.3110],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.7433],\n",
      "        [ 0.5194],\n",
      "        [ 1.2350],\n",
      "        [ 0.7433],\n",
      "        [-0.7160],\n",
      "        [-0.1172],\n",
      "        [-1.0687],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9003],\n",
      "        [ 0.6162],\n",
      "        [ 1.2350],\n",
      "        [-1.6107],\n",
      "        [ 0.0676],\n",
      "        [-0.4066],\n",
      "        [-1.3110],\n",
      "        [ 1.0152],\n",
      "        [-0.4066],\n",
      "        [-0.5736],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4369],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2350],\n",
      "        [ 1.1895]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 622/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0113,\n",
      " epoch_time_duration: 0.0101\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6482],\n",
      "        [ 0.5840],\n",
      "        [-0.0258],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9569],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5899],\n",
      "        [-0.9004],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.9272],\n",
      "        [-0.2064],\n",
      "        [ 0.5518],\n",
      "        [-0.6298],\n",
      "        [-0.2934],\n",
      "        [ 0.8670],\n",
      "        [ 0.7433],\n",
      "        [ 0.7746],\n",
      "        [ 1.2351],\n",
      "        [ 1.2351],\n",
      "        [ 1.0723],\n",
      "        [-0.2934],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4369],\n",
      "        [ 0.9569],\n",
      "        [-1.3110],\n",
      "        [ 0.5518],\n",
      "        [-0.2064],\n",
      "        [ 0.7433],\n",
      "        [ 0.5194],\n",
      "        [ 1.2351],\n",
      "        [ 0.7433],\n",
      "        [-0.7160],\n",
      "        [-0.1172],\n",
      "        [-1.0687],\n",
      "        [-1.1385],\n",
      "        [ 0.9569],\n",
      "        [-0.9004],\n",
      "        [ 0.6162],\n",
      "        [ 1.2351],\n",
      "        [-1.6108],\n",
      "        [ 0.0676],\n",
      "        [-0.4066],\n",
      "        [-1.3110],\n",
      "        [ 1.0152],\n",
      "        [-0.4066],\n",
      "        [-0.5736],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4369],\n",
      "        [ 0.4219],\n",
      "        [-0.4345],\n",
      "        [ 0.4219],\n",
      "        [ 1.2351],\n",
      "        [ 1.1896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 623/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0113,\n",
      " epoch_time_duration: 0.0160\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6482],\n",
      "        [ 0.5840],\n",
      "        [-0.0258],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9568],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5899],\n",
      "        [-0.9005],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.9272],\n",
      "        [-0.2063],\n",
      "        [ 0.5517],\n",
      "        [-0.6298],\n",
      "        [-0.2934],\n",
      "        [ 0.8669],\n",
      "        [ 0.7433],\n",
      "        [ 0.7746],\n",
      "        [ 1.2351],\n",
      "        [ 1.2351],\n",
      "        [ 1.0723],\n",
      "        [-0.2934],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4368],\n",
      "        [ 0.9568],\n",
      "        [-1.3109],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.7433],\n",
      "        [ 0.5194],\n",
      "        [ 1.2351],\n",
      "        [ 0.7433],\n",
      "        [-0.7161],\n",
      "        [-0.1171],\n",
      "        [-1.0687],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9005],\n",
      "        [ 0.6162],\n",
      "        [ 1.2351],\n",
      "        [-1.6108],\n",
      "        [ 0.0677],\n",
      "        [-0.4066],\n",
      "        [-1.3109],\n",
      "        [ 1.0152],\n",
      "        [-0.4066],\n",
      "        [-0.5736],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4368],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2351],\n",
      "        [ 1.1896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 624/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0113,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6482],\n",
      "        [ 0.5840],\n",
      "        [-0.0257],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9568],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5899],\n",
      "        [-0.9005],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.9272],\n",
      "        [-0.2063],\n",
      "        [ 0.5517],\n",
      "        [-0.6298],\n",
      "        [-0.2933],\n",
      "        [ 0.8669],\n",
      "        [ 0.7433],\n",
      "        [ 0.7745],\n",
      "        [ 1.2352],\n",
      "        [ 1.2352],\n",
      "        [ 1.0723],\n",
      "        [-0.2933],\n",
      "        [-1.2085],\n",
      "        [ 1.0723],\n",
      "        [-1.4368],\n",
      "        [ 0.9568],\n",
      "        [-1.3109],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.7433],\n",
      "        [ 0.5194],\n",
      "        [ 1.2352],\n",
      "        [ 0.7433],\n",
      "        [-0.7161],\n",
      "        [-0.1171],\n",
      "        [-1.0688],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9005],\n",
      "        [ 0.6162],\n",
      "        [ 1.2352],\n",
      "        [-1.6108],\n",
      "        [ 0.0677],\n",
      "        [-0.4065],\n",
      "        [-1.3109],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5736],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4368],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2352],\n",
      "        [ 1.1896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 625/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0112,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6482],\n",
      "        [ 0.5840],\n",
      "        [-0.0257],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9568],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5900],\n",
      "        [-0.9006],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.9271],\n",
      "        [-0.2063],\n",
      "        [ 0.5517],\n",
      "        [-0.6299],\n",
      "        [-0.2933],\n",
      "        [ 0.8669],\n",
      "        [ 0.7432],\n",
      "        [ 0.7745],\n",
      "        [ 1.2352],\n",
      "        [ 1.2352],\n",
      "        [ 1.0723],\n",
      "        [-0.2933],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4368],\n",
      "        [ 0.9568],\n",
      "        [-1.3109],\n",
      "        [ 0.5517],\n",
      "        [-0.2063],\n",
      "        [ 0.7432],\n",
      "        [ 0.5193],\n",
      "        [ 1.2352],\n",
      "        [ 0.7432],\n",
      "        [-0.7162],\n",
      "        [-0.1171],\n",
      "        [-1.0688],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9006],\n",
      "        [ 0.6162],\n",
      "        [ 1.2352],\n",
      "        [-1.6109],\n",
      "        [ 0.0677],\n",
      "        [-0.4065],\n",
      "        [-1.3109],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5736],\n",
      "        [-1.5442],\n",
      "        [ 0.6162],\n",
      "        [-1.4368],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2352],\n",
      "        [ 1.1897]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 626/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0112,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6482],\n",
      "        [ 0.5840],\n",
      "        [-0.0257],\n",
      "        [ 0.4869],\n",
      "        [ 0.8972],\n",
      "        [ 0.9568],\n",
      "        [ 0.8972],\n",
      "        [ 0.8055],\n",
      "        [-1.5900],\n",
      "        [-0.9006],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.9271],\n",
      "        [-0.2062],\n",
      "        [ 0.5517],\n",
      "        [-0.6299],\n",
      "        [-0.2933],\n",
      "        [ 0.8669],\n",
      "        [ 0.7432],\n",
      "        [ 0.7745],\n",
      "        [ 1.2353],\n",
      "        [ 1.2353],\n",
      "        [ 1.0723],\n",
      "        [-0.2933],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4367],\n",
      "        [ 0.9568],\n",
      "        [-1.3108],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.7432],\n",
      "        [ 0.5193],\n",
      "        [ 1.2353],\n",
      "        [ 0.7432],\n",
      "        [-0.7162],\n",
      "        [-0.1170],\n",
      "        [-1.0688],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9006],\n",
      "        [ 0.6161],\n",
      "        [ 1.2353],\n",
      "        [-1.6109],\n",
      "        [ 0.0678],\n",
      "        [-0.4065],\n",
      "        [-1.3108],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5737],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4367],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2353],\n",
      "        [ 1.1897]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 627/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0112,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5840],\n",
      "        [-0.0256],\n",
      "        [ 0.4869],\n",
      "        [ 0.8971],\n",
      "        [ 0.9568],\n",
      "        [ 0.8971],\n",
      "        [ 0.8055],\n",
      "        [-1.5900],\n",
      "        [-0.9007],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.9271],\n",
      "        [-0.2062],\n",
      "        [ 0.5517],\n",
      "        [-0.6299],\n",
      "        [-0.2933],\n",
      "        [ 0.8669],\n",
      "        [ 0.7432],\n",
      "        [ 0.7745],\n",
      "        [ 1.2353],\n",
      "        [ 1.2353],\n",
      "        [ 1.0723],\n",
      "        [-0.2933],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4367],\n",
      "        [ 0.9568],\n",
      "        [-1.3108],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.7432],\n",
      "        [ 0.5193],\n",
      "        [ 1.2353],\n",
      "        [ 0.7432],\n",
      "        [-0.7162],\n",
      "        [-0.1170],\n",
      "        [-1.0688],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9007],\n",
      "        [ 0.6161],\n",
      "        [ 1.2353],\n",
      "        [-1.6110],\n",
      "        [ 0.0678],\n",
      "        [-0.4065],\n",
      "        [-1.3108],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5737],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4367],\n",
      "        [ 0.4218],\n",
      "        [-0.4345],\n",
      "        [ 0.4218],\n",
      "        [ 1.2353],\n",
      "        [ 1.1897]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 628/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0112,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5840],\n",
      "        [-0.0256],\n",
      "        [ 0.4869],\n",
      "        [ 0.8971],\n",
      "        [ 0.9568],\n",
      "        [ 0.8971],\n",
      "        [ 0.8055],\n",
      "        [-1.5900],\n",
      "        [-0.9007],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.9271],\n",
      "        [-0.2062],\n",
      "        [ 0.5517],\n",
      "        [-0.6300],\n",
      "        [-0.2932],\n",
      "        [ 0.8668],\n",
      "        [ 0.7432],\n",
      "        [ 0.7745],\n",
      "        [ 1.2354],\n",
      "        [ 1.2354],\n",
      "        [ 1.0723],\n",
      "        [-0.2932],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4367],\n",
      "        [ 0.9568],\n",
      "        [-1.3108],\n",
      "        [ 0.5517],\n",
      "        [-0.2062],\n",
      "        [ 0.7432],\n",
      "        [ 0.5193],\n",
      "        [ 1.2354],\n",
      "        [ 0.7432],\n",
      "        [-0.7163],\n",
      "        [-0.1170],\n",
      "        [-1.0689],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9007],\n",
      "        [ 0.6161],\n",
      "        [ 1.2354],\n",
      "        [-1.6110],\n",
      "        [ 0.0678],\n",
      "        [-0.4065],\n",
      "        [-1.3108],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5737],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4367],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2354],\n",
      "        [ 1.1897]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 629/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0112,\n",
      " epoch_time_duration: 0.0175\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5839],\n",
      "        [-0.0256],\n",
      "        [ 0.4869],\n",
      "        [ 0.8971],\n",
      "        [ 0.9567],\n",
      "        [ 0.8971],\n",
      "        [ 0.8055],\n",
      "        [-1.5901],\n",
      "        [-0.9008],\n",
      "        [ 0.5517],\n",
      "        [-0.2061],\n",
      "        [ 0.9271],\n",
      "        [-0.2061],\n",
      "        [ 0.5517],\n",
      "        [-0.6300],\n",
      "        [-0.2932],\n",
      "        [ 0.8668],\n",
      "        [ 0.7431],\n",
      "        [ 0.7744],\n",
      "        [ 1.2354],\n",
      "        [ 1.2354],\n",
      "        [ 1.0723],\n",
      "        [-0.2932],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4366],\n",
      "        [ 0.9567],\n",
      "        [-1.3108],\n",
      "        [ 0.5517],\n",
      "        [-0.2061],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2354],\n",
      "        [ 0.7431],\n",
      "        [-0.7163],\n",
      "        [-0.1169],\n",
      "        [-1.0689],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9008],\n",
      "        [ 0.6161],\n",
      "        [ 1.2354],\n",
      "        [-1.6110],\n",
      "        [ 0.0678],\n",
      "        [-0.4065],\n",
      "        [-1.3108],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5737],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4366],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2354],\n",
      "        [ 1.1898]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 630/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0111,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5839],\n",
      "        [-0.0255],\n",
      "        [ 0.4869],\n",
      "        [ 0.8971],\n",
      "        [ 0.9567],\n",
      "        [ 0.8971],\n",
      "        [ 0.8055],\n",
      "        [-1.5901],\n",
      "        [-0.9008],\n",
      "        [ 0.5517],\n",
      "        [-0.2061],\n",
      "        [ 0.9271],\n",
      "        [-0.2061],\n",
      "        [ 0.5517],\n",
      "        [-0.6300],\n",
      "        [-0.2932],\n",
      "        [ 0.8668],\n",
      "        [ 0.7431],\n",
      "        [ 0.7744],\n",
      "        [ 1.2354],\n",
      "        [ 1.2354],\n",
      "        [ 1.0723],\n",
      "        [-0.2932],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4366],\n",
      "        [ 0.9567],\n",
      "        [-1.3107],\n",
      "        [ 0.5517],\n",
      "        [-0.2061],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2354],\n",
      "        [ 0.7431],\n",
      "        [-0.7164],\n",
      "        [-0.1169],\n",
      "        [-1.0689],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9008],\n",
      "        [ 0.6161],\n",
      "        [ 1.2354],\n",
      "        [-1.6111],\n",
      "        [ 0.0679],\n",
      "        [-0.4065],\n",
      "        [-1.3107],\n",
      "        [ 1.0152],\n",
      "        [-0.4065],\n",
      "        [-0.5737],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4366],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2354],\n",
      "        [ 1.1898]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 631/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0111,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5839],\n",
      "        [-0.0255],\n",
      "        [ 0.4868],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8054],\n",
      "        [-1.5901],\n",
      "        [-0.9009],\n",
      "        [ 0.5516],\n",
      "        [-0.2061],\n",
      "        [ 0.9270],\n",
      "        [-0.2061],\n",
      "        [ 0.5516],\n",
      "        [-0.6301],\n",
      "        [-0.2931],\n",
      "        [ 0.8668],\n",
      "        [ 0.7431],\n",
      "        [ 0.7744],\n",
      "        [ 1.2355],\n",
      "        [ 1.2355],\n",
      "        [ 1.0723],\n",
      "        [-0.2931],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4366],\n",
      "        [ 0.9567],\n",
      "        [-1.3107],\n",
      "        [ 0.5516],\n",
      "        [-0.2061],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2355],\n",
      "        [ 0.7431],\n",
      "        [-0.7164],\n",
      "        [-0.1169],\n",
      "        [-1.0689],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9009],\n",
      "        [ 0.6161],\n",
      "        [ 1.2355],\n",
      "        [-1.6111],\n",
      "        [ 0.0679],\n",
      "        [-0.4065],\n",
      "        [-1.3107],\n",
      "        [ 1.0151],\n",
      "        [-0.4065],\n",
      "        [-0.5738],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4366],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2355],\n",
      "        [ 1.1898]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 632/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0111,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6481],\n",
      "        [ 0.5839],\n",
      "        [-0.0255],\n",
      "        [ 0.4869],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8054],\n",
      "        [-1.5901],\n",
      "        [-0.9009],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.9270],\n",
      "        [-0.2060],\n",
      "        [ 0.5516],\n",
      "        [-0.6301],\n",
      "        [-0.2931],\n",
      "        [ 0.8668],\n",
      "        [ 0.7431],\n",
      "        [ 0.7744],\n",
      "        [ 1.2355],\n",
      "        [ 1.2355],\n",
      "        [ 1.0723],\n",
      "        [-0.2931],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4366],\n",
      "        [ 0.9567],\n",
      "        [-1.3107],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2355],\n",
      "        [ 0.7431],\n",
      "        [-0.7165],\n",
      "        [-0.1168],\n",
      "        [-1.0690],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9009],\n",
      "        [ 0.6161],\n",
      "        [ 1.2355],\n",
      "        [-1.6112],\n",
      "        [ 0.0679],\n",
      "        [-0.4064],\n",
      "        [-1.3107],\n",
      "        [ 1.0152],\n",
      "        [-0.4064],\n",
      "        [-0.5738],\n",
      "        [-1.5442],\n",
      "        [ 0.6161],\n",
      "        [-1.4366],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2355],\n",
      "        [ 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 633/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0111,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6480],\n",
      "        [ 0.5839],\n",
      "        [-0.0254],\n",
      "        [ 0.4868],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8054],\n",
      "        [-1.5902],\n",
      "        [-0.9010],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.9270],\n",
      "        [-0.2060],\n",
      "        [ 0.5516],\n",
      "        [-0.6301],\n",
      "        [-0.2931],\n",
      "        [ 0.8667],\n",
      "        [ 0.7431],\n",
      "        [ 0.7743],\n",
      "        [ 1.2356],\n",
      "        [ 1.2356],\n",
      "        [ 1.0723],\n",
      "        [-0.2931],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4365],\n",
      "        [ 0.9567],\n",
      "        [-1.3106],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2356],\n",
      "        [ 0.7431],\n",
      "        [-0.7165],\n",
      "        [-0.1168],\n",
      "        [-1.0690],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9010],\n",
      "        [ 0.6160],\n",
      "        [ 1.2356],\n",
      "        [-1.6112],\n",
      "        [ 0.0680],\n",
      "        [-0.4064],\n",
      "        [-1.3106],\n",
      "        [ 1.0151],\n",
      "        [-0.4064],\n",
      "        [-0.5738],\n",
      "        [-1.5442],\n",
      "        [ 0.6160],\n",
      "        [-1.4365],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2356],\n",
      "        [ 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 634/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1735],\n",
      "        [-1.1735],\n",
      "        [ 0.6480],\n",
      "        [ 0.5839],\n",
      "        [-0.0254],\n",
      "        [ 0.4868],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8054],\n",
      "        [-1.5902],\n",
      "        [-0.9010],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.9270],\n",
      "        [-0.2060],\n",
      "        [ 0.5516],\n",
      "        [-0.6301],\n",
      "        [-0.2931],\n",
      "        [ 0.8667],\n",
      "        [ 0.7431],\n",
      "        [ 0.7743],\n",
      "        [ 1.2356],\n",
      "        [ 1.2356],\n",
      "        [ 1.0723],\n",
      "        [-0.2931],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4365],\n",
      "        [ 0.9567],\n",
      "        [-1.3106],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.7431],\n",
      "        [ 0.5193],\n",
      "        [ 1.2356],\n",
      "        [ 0.7431],\n",
      "        [-0.7166],\n",
      "        [-0.1168],\n",
      "        [-1.0690],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9010],\n",
      "        [ 0.6160],\n",
      "        [ 1.2356],\n",
      "        [-1.6112],\n",
      "        [ 0.0680],\n",
      "        [-0.4064],\n",
      "        [-1.3106],\n",
      "        [ 1.0151],\n",
      "        [-0.4064],\n",
      "        [-0.5738],\n",
      "        [-1.5442],\n",
      "        [ 0.6160],\n",
      "        [-1.4365],\n",
      "        [ 0.4219],\n",
      "        [-0.4344],\n",
      "        [ 0.4219],\n",
      "        [ 1.2356],\n",
      "        [ 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 635/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6480],\n",
      "        [ 0.5838],\n",
      "        [-0.0254],\n",
      "        [ 0.4868],\n",
      "        [ 0.8970],\n",
      "        [ 0.9566],\n",
      "        [ 0.8970],\n",
      "        [ 0.8053],\n",
      "        [-1.5902],\n",
      "        [-0.9011],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.9269],\n",
      "        [-0.2060],\n",
      "        [ 0.5516],\n",
      "        [-0.6302],\n",
      "        [-0.2930],\n",
      "        [ 0.8667],\n",
      "        [ 0.7430],\n",
      "        [ 0.7743],\n",
      "        [ 1.2356],\n",
      "        [ 1.2356],\n",
      "        [ 1.0723],\n",
      "        [-0.2930],\n",
      "        [-1.2084],\n",
      "        [ 1.0723],\n",
      "        [-1.4365],\n",
      "        [ 0.9566],\n",
      "        [-1.3106],\n",
      "        [ 0.5516],\n",
      "        [-0.2060],\n",
      "        [ 0.7430],\n",
      "        [ 0.5192],\n",
      "        [ 1.2356],\n",
      "        [ 0.7430],\n",
      "        [-0.7166],\n",
      "        [-0.1167],\n",
      "        [-1.0690],\n",
      "        [-1.1386],\n",
      "        [ 0.9566],\n",
      "        [-0.9011],\n",
      "        [ 0.6160],\n",
      "        [ 1.2356],\n",
      "        [-1.6113],\n",
      "        [ 0.0680],\n",
      "        [-0.4064],\n",
      "        [-1.3106],\n",
      "        [ 1.0151],\n",
      "        [-0.4064],\n",
      "        [-0.5738],\n",
      "        [-1.5442],\n",
      "        [ 0.6160],\n",
      "        [-1.4365],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2356],\n",
      "        [ 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 636/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1735],\n",
      "        [-1.1735],\n",
      "        [ 0.6480],\n",
      "        [ 0.5839],\n",
      "        [-0.0253],\n",
      "        [ 0.4868],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8054],\n",
      "        [-1.5902],\n",
      "        [-0.9011],\n",
      "        [ 0.5516],\n",
      "        [-0.2059],\n",
      "        [ 0.9270],\n",
      "        [-0.2059],\n",
      "        [ 0.5516],\n",
      "        [-0.6302],\n",
      "        [-0.2930],\n",
      "        [ 0.8667],\n",
      "        [ 0.7430],\n",
      "        [ 0.7743],\n",
      "        [ 1.2357],\n",
      "        [ 1.2357],\n",
      "        [ 1.0723],\n",
      "        [-0.2930],\n",
      "        [-1.2083],\n",
      "        [ 1.0723],\n",
      "        [-1.4364],\n",
      "        [ 0.9567],\n",
      "        [-1.3105],\n",
      "        [ 0.5516],\n",
      "        [-0.2059],\n",
      "        [ 0.7430],\n",
      "        [ 0.5193],\n",
      "        [ 1.2357],\n",
      "        [ 0.7430],\n",
      "        [-0.7166],\n",
      "        [-0.1167],\n",
      "        [-1.0691],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9011],\n",
      "        [ 0.6160],\n",
      "        [ 1.2357],\n",
      "        [-1.6113],\n",
      "        [ 0.0681],\n",
      "        [-0.4064],\n",
      "        [-1.3105],\n",
      "        [ 1.0151],\n",
      "        [-0.4064],\n",
      "        [-0.5738],\n",
      "        [-1.5441],\n",
      "        [ 0.6160],\n",
      "        [-1.4364],\n",
      "        [ 0.4219],\n",
      "        [-0.4344],\n",
      "        [ 0.4219],\n",
      "        [ 1.2357],\n",
      "        [ 1.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 637/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6479],\n",
      "        [ 0.5838],\n",
      "        [-0.0253],\n",
      "        [ 0.4868],\n",
      "        [ 0.8969],\n",
      "        [ 0.9566],\n",
      "        [ 0.8969],\n",
      "        [ 0.8053],\n",
      "        [-1.5903],\n",
      "        [-0.9012],\n",
      "        [ 0.5515],\n",
      "        [-0.2059],\n",
      "        [ 0.9269],\n",
      "        [-0.2059],\n",
      "        [ 0.5515],\n",
      "        [-0.6303],\n",
      "        [-0.2930],\n",
      "        [ 0.8666],\n",
      "        [ 0.7429],\n",
      "        [ 0.7742],\n",
      "        [ 1.2357],\n",
      "        [ 1.2357],\n",
      "        [ 1.0722],\n",
      "        [-0.2930],\n",
      "        [-1.2083],\n",
      "        [ 1.0722],\n",
      "        [-1.4364],\n",
      "        [ 0.9566],\n",
      "        [-1.3105],\n",
      "        [ 0.5515],\n",
      "        [-0.2059],\n",
      "        [ 0.7429],\n",
      "        [ 0.5192],\n",
      "        [ 1.2357],\n",
      "        [ 0.7429],\n",
      "        [-0.7167],\n",
      "        [-0.1167],\n",
      "        [-1.0691],\n",
      "        [-1.1387],\n",
      "        [ 0.9566],\n",
      "        [-0.9012],\n",
      "        [ 0.6159],\n",
      "        [ 1.2357],\n",
      "        [-1.6114],\n",
      "        [ 0.0680],\n",
      "        [-0.4064],\n",
      "        [-1.3105],\n",
      "        [ 1.0151],\n",
      "        [-0.4064],\n",
      "        [-0.5739],\n",
      "        [-1.5442],\n",
      "        [ 0.6159],\n",
      "        [-1.4364],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2357],\n",
      "        [ 1.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 638/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1735],\n",
      "        [-1.1735],\n",
      "        [ 0.6480],\n",
      "        [ 0.5839],\n",
      "        [-0.0252],\n",
      "        [ 0.4869],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8053],\n",
      "        [-1.5903],\n",
      "        [-0.9012],\n",
      "        [ 0.5516],\n",
      "        [-0.2058],\n",
      "        [ 0.9270],\n",
      "        [-0.2058],\n",
      "        [ 0.5516],\n",
      "        [-0.6303],\n",
      "        [-0.2929],\n",
      "        [ 0.8667],\n",
      "        [ 0.7430],\n",
      "        [ 0.7743],\n",
      "        [ 1.2358],\n",
      "        [ 1.2358],\n",
      "        [ 1.0723],\n",
      "        [-0.2929],\n",
      "        [-1.2083],\n",
      "        [ 1.0723],\n",
      "        [-1.4363],\n",
      "        [ 0.9567],\n",
      "        [-1.3105],\n",
      "        [ 0.5516],\n",
      "        [-0.2058],\n",
      "        [ 0.7430],\n",
      "        [ 0.5193],\n",
      "        [ 1.2358],\n",
      "        [ 0.7430],\n",
      "        [-0.7167],\n",
      "        [-0.1166],\n",
      "        [-1.0691],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9012],\n",
      "        [ 0.6160],\n",
      "        [ 1.2358],\n",
      "        [-1.6114],\n",
      "        [ 0.0681],\n",
      "        [-0.4063],\n",
      "        [-1.3105],\n",
      "        [ 1.0152],\n",
      "        [-0.4063],\n",
      "        [-0.5739],\n",
      "        [-1.5441],\n",
      "        [ 0.6160],\n",
      "        [-1.4363],\n",
      "        [ 0.4219],\n",
      "        [-0.4343],\n",
      "        [ 0.4219],\n",
      "        [ 1.2358],\n",
      "        [ 1.1901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 639/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0109,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6479],\n",
      "        [ 0.5837],\n",
      "        [-0.0253],\n",
      "        [ 0.4867],\n",
      "        [ 0.8968],\n",
      "        [ 0.9565],\n",
      "        [ 0.8968],\n",
      "        [ 0.8052],\n",
      "        [-1.5903],\n",
      "        [-0.9013],\n",
      "        [ 0.5515],\n",
      "        [-0.2059],\n",
      "        [ 0.9268],\n",
      "        [-0.2059],\n",
      "        [ 0.5515],\n",
      "        [-0.6303],\n",
      "        [-0.2930],\n",
      "        [ 0.8665],\n",
      "        [ 0.7429],\n",
      "        [ 0.7741],\n",
      "        [ 1.2358],\n",
      "        [ 1.2358],\n",
      "        [ 1.0722],\n",
      "        [-0.2930],\n",
      "        [-1.2083],\n",
      "        [ 1.0722],\n",
      "        [-1.4364],\n",
      "        [ 0.9565],\n",
      "        [-1.3105],\n",
      "        [ 0.5515],\n",
      "        [-0.2059],\n",
      "        [ 0.7429],\n",
      "        [ 0.5191],\n",
      "        [ 1.2358],\n",
      "        [ 0.7429],\n",
      "        [-0.7168],\n",
      "        [-0.1166],\n",
      "        [-1.0692],\n",
      "        [-1.1387],\n",
      "        [ 0.9565],\n",
      "        [-0.9013],\n",
      "        [ 0.6159],\n",
      "        [ 1.2358],\n",
      "        [-1.6115],\n",
      "        [ 0.0681],\n",
      "        [-0.4064],\n",
      "        [-1.3105],\n",
      "        [ 1.0150],\n",
      "        [-0.4064],\n",
      "        [-0.5739],\n",
      "        [-1.5442],\n",
      "        [ 0.6159],\n",
      "        [-1.4364],\n",
      "        [ 0.4218],\n",
      "        [-0.4344],\n",
      "        [ 0.4218],\n",
      "        [ 1.2358],\n",
      "        [ 1.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 640/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0109,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1735],\n",
      "        [-1.1735],\n",
      "        [ 0.6480],\n",
      "        [ 0.5839],\n",
      "        [-0.0251],\n",
      "        [ 0.4869],\n",
      "        [ 0.8970],\n",
      "        [ 0.9567],\n",
      "        [ 0.8970],\n",
      "        [ 0.8053],\n",
      "        [-1.5903],\n",
      "        [-0.9013],\n",
      "        [ 0.5516],\n",
      "        [-0.2057],\n",
      "        [ 0.9270],\n",
      "        [-0.2057],\n",
      "        [ 0.5516],\n",
      "        [-0.6303],\n",
      "        [-0.2928],\n",
      "        [ 0.8667],\n",
      "        [ 0.7430],\n",
      "        [ 0.7743],\n",
      "        [ 1.2360],\n",
      "        [ 1.2360],\n",
      "        [ 1.0724],\n",
      "        [-0.2928],\n",
      "        [-1.2083],\n",
      "        [ 1.0724],\n",
      "        [-1.4363],\n",
      "        [ 0.9567],\n",
      "        [-1.3104],\n",
      "        [ 0.5516],\n",
      "        [-0.2057],\n",
      "        [ 0.7430],\n",
      "        [ 0.5193],\n",
      "        [ 1.2360],\n",
      "        [ 0.7430],\n",
      "        [-0.7168],\n",
      "        [-0.1165],\n",
      "        [-1.0691],\n",
      "        [-1.1386],\n",
      "        [ 0.9567],\n",
      "        [-0.9013],\n",
      "        [ 0.6160],\n",
      "        [ 1.2360],\n",
      "        [-1.6115],\n",
      "        [ 0.0682],\n",
      "        [-0.4063],\n",
      "        [-1.3104],\n",
      "        [ 1.0152],\n",
      "        [-0.4063],\n",
      "        [-0.5739],\n",
      "        [-1.5441],\n",
      "        [ 0.6160],\n",
      "        [-1.4363],\n",
      "        [ 0.4219],\n",
      "        [-0.4343],\n",
      "        [ 0.4219],\n",
      "        [ 1.2360],\n",
      "        [ 1.1902]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 641/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0109,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6478],\n",
      "        [ 0.5836],\n",
      "        [-0.0253],\n",
      "        [ 0.4866],\n",
      "        [ 0.8967],\n",
      "        [ 0.9564],\n",
      "        [ 0.8967],\n",
      "        [ 0.8051],\n",
      "        [-1.5904],\n",
      "        [-0.9014],\n",
      "        [ 0.5514],\n",
      "        [-0.2058],\n",
      "        [ 0.9267],\n",
      "        [-0.2058],\n",
      "        [ 0.5514],\n",
      "        [-0.6304],\n",
      "        [-0.2930],\n",
      "        [ 0.8664],\n",
      "        [ 0.7427],\n",
      "        [ 0.7740],\n",
      "        [ 1.2358],\n",
      "        [ 1.2358],\n",
      "        [ 1.0721],\n",
      "        [-0.2930],\n",
      "        [-1.2083],\n",
      "        [ 1.0721],\n",
      "        [-1.4363],\n",
      "        [ 0.9564],\n",
      "        [-1.3104],\n",
      "        [ 0.5514],\n",
      "        [-0.2058],\n",
      "        [ 0.7427],\n",
      "        [ 0.5191],\n",
      "        [ 1.2358],\n",
      "        [ 0.7427],\n",
      "        [-0.7169],\n",
      "        [-0.1166],\n",
      "        [-1.0692],\n",
      "        [-1.1387],\n",
      "        [ 0.9564],\n",
      "        [-0.9014],\n",
      "        [ 0.6158],\n",
      "        [ 1.2358],\n",
      "        [-1.6116],\n",
      "        [ 0.0681],\n",
      "        [-0.4064],\n",
      "        [-1.3104],\n",
      "        [ 1.0149],\n",
      "        [-0.4064],\n",
      "        [-0.5740],\n",
      "        [-1.5442],\n",
      "        [ 0.6158],\n",
      "        [-1.4363],\n",
      "        [ 0.4217],\n",
      "        [-0.4344],\n",
      "        [ 0.4217],\n",
      "        [ 1.2358],\n",
      "        [ 1.1900]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 642/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0109,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1735],\n",
      "        [-1.1735],\n",
      "        [ 0.6481],\n",
      "        [ 0.5840],\n",
      "        [-0.0250],\n",
      "        [ 0.4870],\n",
      "        [ 0.8971],\n",
      "        [ 0.9568],\n",
      "        [ 0.8971],\n",
      "        [ 0.8054],\n",
      "        [-1.5903],\n",
      "        [-0.9014],\n",
      "        [ 0.5517],\n",
      "        [-0.2056],\n",
      "        [ 0.9271],\n",
      "        [-0.2056],\n",
      "        [ 0.5517],\n",
      "        [-0.6303],\n",
      "        [-0.2927],\n",
      "        [ 0.8668],\n",
      "        [ 0.7431],\n",
      "        [ 0.7744],\n",
      "        [ 1.2362],\n",
      "        [ 1.2362],\n",
      "        [ 1.0725],\n",
      "        [-0.2927],\n",
      "        [-1.2082],\n",
      "        [ 1.0725],\n",
      "        [-1.4362],\n",
      "        [ 0.9568],\n",
      "        [-1.3103],\n",
      "        [ 0.5517],\n",
      "        [-0.2056],\n",
      "        [ 0.7431],\n",
      "        [ 0.5194],\n",
      "        [ 1.2362],\n",
      "        [ 0.7431],\n",
      "        [-0.7168],\n",
      "        [-0.1163],\n",
      "        [-1.0691],\n",
      "        [-1.1386],\n",
      "        [ 0.9568],\n",
      "        [-0.9014],\n",
      "        [ 0.6161],\n",
      "        [ 1.2362],\n",
      "        [-1.6115],\n",
      "        [ 0.0684],\n",
      "        [-0.4062],\n",
      "        [-1.3103],\n",
      "        [ 1.0153],\n",
      "        [-0.4062],\n",
      "        [-0.5739],\n",
      "        [-1.5441],\n",
      "        [ 0.6161],\n",
      "        [-1.4362],\n",
      "        [ 0.4220],\n",
      "        [-0.4342],\n",
      "        [ 0.4220],\n",
      "        [ 1.2362],\n",
      "        [ 1.1903]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 643/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0108,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1736],\n",
      "        [-1.1736],\n",
      "        [ 0.6476],\n",
      "        [ 0.5835],\n",
      "        [-0.0253],\n",
      "        [ 0.4865],\n",
      "        [ 0.8965],\n",
      "        [ 0.9562],\n",
      "        [ 0.8965],\n",
      "        [ 0.8049],\n",
      "        [-1.5905],\n",
      "        [-0.9016],\n",
      "        [ 0.5512],\n",
      "        [-0.2059],\n",
      "        [ 0.9265],\n",
      "        [-0.2059],\n",
      "        [ 0.5512],\n",
      "        [-0.6306],\n",
      "        [-0.2930],\n",
      "        [ 0.8662],\n",
      "        [ 0.7426],\n",
      "        [ 0.7738],\n",
      "        [ 1.2357],\n",
      "        [ 1.2357],\n",
      "        [ 1.0720],\n",
      "        [-0.2930],\n",
      "        [-1.2084],\n",
      "        [ 1.0720],\n",
      "        [-1.4363],\n",
      "        [ 0.9562],\n",
      "        [-1.3104],\n",
      "        [ 0.5512],\n",
      "        [-0.2059],\n",
      "        [ 0.7426],\n",
      "        [ 0.5189],\n",
      "        [ 1.2357],\n",
      "        [ 0.7426],\n",
      "        [-0.7171],\n",
      "        [-0.1166],\n",
      "        [-1.0693],\n",
      "        [-1.1388],\n",
      "        [ 0.9562],\n",
      "        [-0.9016],\n",
      "        [ 0.6156],\n",
      "        [ 1.2357],\n",
      "        [-1.6117],\n",
      "        [ 0.0680],\n",
      "        [-0.4065],\n",
      "        [-1.3104],\n",
      "        [ 1.0147],\n",
      "        [-0.4065],\n",
      "        [-0.5741],\n",
      "        [-1.5442],\n",
      "        [ 0.6156],\n",
      "        [-1.4363],\n",
      "        [ 0.4216],\n",
      "        [-0.4345],\n",
      "        [ 0.4216],\n",
      "        [ 1.2357],\n",
      "        [ 1.1899]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 644/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0109,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1734],\n",
      "        [-1.1734],\n",
      "        [ 0.6483],\n",
      "        [ 0.5842],\n",
      "        [-0.0248],\n",
      "        [ 0.4872],\n",
      "        [ 0.8972],\n",
      "        [ 0.9570],\n",
      "        [ 0.8972],\n",
      "        [ 0.8056],\n",
      "        [-1.5903],\n",
      "        [-0.9014],\n",
      "        [ 0.5519],\n",
      "        [-0.2054],\n",
      "        [ 0.9272],\n",
      "        [-0.2054],\n",
      "        [ 0.5519],\n",
      "        [-0.6303],\n",
      "        [-0.2926],\n",
      "        [ 0.8670],\n",
      "        [ 0.7433],\n",
      "        [ 0.7745],\n",
      "        [ 1.2365],\n",
      "        [ 1.2365],\n",
      "        [ 1.0727],\n",
      "        [-0.2926],\n",
      "        [-1.2081],\n",
      "        [ 1.0727],\n",
      "        [-1.4361],\n",
      "        [ 0.9570],\n",
      "        [-1.3102],\n",
      "        [ 0.5519],\n",
      "        [-0.2054],\n",
      "        [ 0.7433],\n",
      "        [ 0.5196],\n",
      "        [ 1.2365],\n",
      "        [ 0.7433],\n",
      "        [-0.7168],\n",
      "        [-0.1161],\n",
      "        [-1.0691],\n",
      "        [-1.1386],\n",
      "        [ 0.9570],\n",
      "        [-0.9014],\n",
      "        [ 0.6163],\n",
      "        [ 1.2365],\n",
      "        [-1.6115],\n",
      "        [ 0.0686],\n",
      "        [-0.4061],\n",
      "        [-1.3102],\n",
      "        [ 1.0155],\n",
      "        [-0.4061],\n",
      "        [-0.5738],\n",
      "        [-1.5440],\n",
      "        [ 0.6163],\n",
      "        [-1.4361],\n",
      "        [ 0.4222],\n",
      "        [-0.4341],\n",
      "        [ 0.4222],\n",
      "        [ 1.2365],\n",
      "        [ 1.1906]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 645/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0107,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1737],\n",
      "        [-1.1737],\n",
      "        [ 0.6472],\n",
      "        [ 0.5831],\n",
      "        [-0.0255],\n",
      "        [ 0.4862],\n",
      "        [ 0.8961],\n",
      "        [ 0.9559],\n",
      "        [ 0.8961],\n",
      "        [ 0.8045],\n",
      "        [-1.5906],\n",
      "        [-0.9018],\n",
      "        [ 0.5509],\n",
      "        [-0.2060],\n",
      "        [ 0.9262],\n",
      "        [-0.2060],\n",
      "        [ 0.5509],\n",
      "        [-0.6307],\n",
      "        [-0.2931],\n",
      "        [ 0.8659],\n",
      "        [ 0.7422],\n",
      "        [ 0.7735],\n",
      "        [ 1.2355],\n",
      "        [ 1.2355],\n",
      "        [ 1.0717],\n",
      "        [-0.2931],\n",
      "        [-1.2084],\n",
      "        [ 1.0717],\n",
      "        [-1.4363],\n",
      "        [ 0.9559],\n",
      "        [-1.3105],\n",
      "        [ 0.5509],\n",
      "        [-0.2060],\n",
      "        [ 0.7422],\n",
      "        [ 0.5186],\n",
      "        [ 1.2355],\n",
      "        [ 0.7422],\n",
      "        [-0.7173],\n",
      "        [-0.1168],\n",
      "        [-1.0695],\n",
      "        [-1.1389],\n",
      "        [ 0.9559],\n",
      "        [-0.9018],\n",
      "        [ 0.6152],\n",
      "        [ 1.2355],\n",
      "        [-1.6118],\n",
      "        [ 0.0678],\n",
      "        [-0.4066],\n",
      "        [-1.3105],\n",
      "        [ 1.0144],\n",
      "        [-0.4066],\n",
      "        [-0.5743],\n",
      "        [-1.5443],\n",
      "        [ 0.6152],\n",
      "        [-1.4363],\n",
      "        [ 0.4213],\n",
      "        [-0.4346],\n",
      "        [ 0.4213],\n",
      "        [ 1.2355],\n",
      "        [ 1.1896]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 646/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0110,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1733],\n",
      "        [-1.1733],\n",
      "        [ 0.6487],\n",
      "        [ 0.5846],\n",
      "        [-0.0243],\n",
      "        [ 0.4876],\n",
      "        [ 0.8977],\n",
      "        [ 0.9574],\n",
      "        [ 0.8977],\n",
      "        [ 0.8060],\n",
      "        [-1.5903],\n",
      "        [-0.9013],\n",
      "        [ 0.5524],\n",
      "        [-0.2050],\n",
      "        [ 0.9277],\n",
      "        [-0.2050],\n",
      "        [ 0.5524],\n",
      "        [-0.6301],\n",
      "        [-0.2922],\n",
      "        [ 0.8674],\n",
      "        [ 0.7437],\n",
      "        [ 0.7750],\n",
      "        [ 1.2370],\n",
      "        [ 1.2370],\n",
      "        [ 1.0732],\n",
      "        [-0.2922],\n",
      "        [-1.2080],\n",
      "        [ 1.0732],\n",
      "        [-1.4359],\n",
      "        [ 0.9574],\n",
      "        [-1.3100],\n",
      "        [ 0.5524],\n",
      "        [-0.2050],\n",
      "        [ 0.7437],\n",
      "        [ 0.5200],\n",
      "        [ 1.2370],\n",
      "        [ 0.7437],\n",
      "        [-0.7168],\n",
      "        [-0.1157],\n",
      "        [-1.0690],\n",
      "        [-1.1384],\n",
      "        [ 0.9574],\n",
      "        [-0.9013],\n",
      "        [ 0.6167],\n",
      "        [ 1.2370],\n",
      "        [-1.6115],\n",
      "        [ 0.0690],\n",
      "        [-0.4058],\n",
      "        [-1.3100],\n",
      "        [ 1.0160],\n",
      "        [-0.4058],\n",
      "        [-0.5737],\n",
      "        [-1.5439],\n",
      "        [ 0.6167],\n",
      "        [-1.4359],\n",
      "        [ 0.4227],\n",
      "        [-0.4339],\n",
      "        [ 0.4227],\n",
      "        [ 1.2370],\n",
      "        [ 1.1912]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 647/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0106,\n",
      " epoch_time_duration: 0.0153\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1739],\n",
      "        [-1.1739],\n",
      "        [ 0.6465],\n",
      "        [ 0.5824],\n",
      "        [-0.0259],\n",
      "        [ 0.4855],\n",
      "        [ 0.8954],\n",
      "        [ 0.9551],\n",
      "        [ 0.8954],\n",
      "        [ 0.8037],\n",
      "        [-1.5909],\n",
      "        [-0.9021],\n",
      "        [ 0.5502],\n",
      "        [-0.2064],\n",
      "        [ 0.9254],\n",
      "        [-0.2064],\n",
      "        [ 0.5502],\n",
      "        [-0.6311],\n",
      "        [-0.2935],\n",
      "        [ 0.8651],\n",
      "        [ 0.7414],\n",
      "        [ 0.7727],\n",
      "        [ 1.2349],\n",
      "        [ 1.2349],\n",
      "        [ 1.0709],\n",
      "        [-0.2935],\n",
      "        [-1.2086],\n",
      "        [ 1.0709],\n",
      "        [-1.4364],\n",
      "        [ 0.9551],\n",
      "        [-1.3106],\n",
      "        [ 0.5502],\n",
      "        [-0.2064],\n",
      "        [ 0.7414],\n",
      "        [ 0.5179],\n",
      "        [ 1.2349],\n",
      "        [ 0.7414],\n",
      "        [-0.7177],\n",
      "        [-0.1172],\n",
      "        [-1.0697],\n",
      "        [-1.1391],\n",
      "        [ 0.9551],\n",
      "        [-0.9021],\n",
      "        [ 0.6145],\n",
      "        [ 1.2349],\n",
      "        [-1.6121],\n",
      "        [ 0.0673],\n",
      "        [-0.4070],\n",
      "        [-1.3106],\n",
      "        [ 1.0136],\n",
      "        [-0.4070],\n",
      "        [-0.5747],\n",
      "        [-1.5445],\n",
      "        [ 0.6145],\n",
      "        [-1.4364],\n",
      "        [ 0.4206],\n",
      "        [-0.4350],\n",
      "        [ 0.4206],\n",
      "        [ 1.2349],\n",
      "        [ 1.1889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 648/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0111,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1729],\n",
      "        [-1.1729],\n",
      "        [ 0.6498],\n",
      "        [ 0.5856],\n",
      "        [-0.0235],\n",
      "        [ 0.4886],\n",
      "        [ 0.8988],\n",
      "        [ 0.9585],\n",
      "        [ 0.8988],\n",
      "        [ 0.8071],\n",
      "        [-1.5900],\n",
      "        [-0.9011],\n",
      "        [ 0.5534],\n",
      "        [-0.2043],\n",
      "        [ 0.9288],\n",
      "        [-0.2043],\n",
      "        [ 0.5534],\n",
      "        [-0.6298],\n",
      "        [-0.2916],\n",
      "        [ 0.8685],\n",
      "        [ 0.7448],\n",
      "        [ 0.7760],\n",
      "        [ 1.2382],\n",
      "        [ 1.2382],\n",
      "        [ 1.0743],\n",
      "        [-0.2916],\n",
      "        [-1.2076],\n",
      "        [ 1.0743],\n",
      "        [-1.4355],\n",
      "        [ 0.9585],\n",
      "        [-1.3096],\n",
      "        [ 0.5534],\n",
      "        [-0.2043],\n",
      "        [ 0.7448],\n",
      "        [ 0.5210],\n",
      "        [ 1.2382],\n",
      "        [ 0.7448],\n",
      "        [-0.7164],\n",
      "        [-0.1149],\n",
      "        [-1.0687],\n",
      "        [-1.1381],\n",
      "        [ 0.9585],\n",
      "        [-0.9011],\n",
      "        [ 0.6178],\n",
      "        [ 1.2382],\n",
      "        [-1.6113],\n",
      "        [ 0.0699],\n",
      "        [-0.4052],\n",
      "        [-1.3096],\n",
      "        [ 1.0171],\n",
      "        [-0.4052],\n",
      "        [-0.5732],\n",
      "        [-1.5436],\n",
      "        [ 0.6178],\n",
      "        [-1.4355],\n",
      "        [ 0.4237],\n",
      "        [-0.4333],\n",
      "        [ 0.4237],\n",
      "        [ 1.2382],\n",
      "        [ 1.1923]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 649/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0104,\n",
      " epoch_time_duration: 0.0120\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1744],\n",
      "        [-1.1744],\n",
      "        [ 0.6448],\n",
      "        [ 0.5808],\n",
      "        [-0.0270],\n",
      "        [ 0.4839],\n",
      "        [ 0.8936],\n",
      "        [ 0.9534],\n",
      "        [ 0.8936],\n",
      "        [ 0.8020],\n",
      "        [-1.5913],\n",
      "        [-0.9028],\n",
      "        [ 0.5486],\n",
      "        [-0.2073],\n",
      "        [ 0.9237],\n",
      "        [-0.2073],\n",
      "        [ 0.5486],\n",
      "        [-0.6318],\n",
      "        [-0.2944],\n",
      "        [ 0.8634],\n",
      "        [ 0.7397],\n",
      "        [ 0.7710],\n",
      "        [ 1.2333],\n",
      "        [ 1.2333],\n",
      "        [ 1.0692],\n",
      "        [-0.2944],\n",
      "        [-1.2091],\n",
      "        [ 1.0692],\n",
      "        [-1.4368],\n",
      "        [ 0.9534],\n",
      "        [-1.3110],\n",
      "        [ 0.5486],\n",
      "        [-0.2073],\n",
      "        [ 0.7397],\n",
      "        [ 0.5163],\n",
      "        [ 1.2333],\n",
      "        [ 0.7397],\n",
      "        [-0.7184],\n",
      "        [-0.1182],\n",
      "        [-1.0703],\n",
      "        [-1.1396],\n",
      "        [ 0.9534],\n",
      "        [-0.9028],\n",
      "        [ 0.6129],\n",
      "        [ 1.2333],\n",
      "        [-1.6126],\n",
      "        [ 0.0661],\n",
      "        [-0.4078],\n",
      "        [-1.3110],\n",
      "        [ 1.0119],\n",
      "        [-0.4078],\n",
      "        [-0.5754],\n",
      "        [-1.5449],\n",
      "        [ 0.6129],\n",
      "        [-1.4368],\n",
      "        [ 0.4191],\n",
      "        [-0.4358],\n",
      "        [ 0.4191],\n",
      "        [ 1.2333],\n",
      "        [ 1.1873]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 650/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0116,\n",
      " epoch_time_duration: 0.0121\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1722],\n",
      "        [-1.1722],\n",
      "        [ 0.6522],\n",
      "        [ 0.5880],\n",
      "        [-0.0216],\n",
      "        [ 0.4910],\n",
      "        [ 0.9013],\n",
      "        [ 0.9611],\n",
      "        [ 0.9013],\n",
      "        [ 0.8096],\n",
      "        [-1.5894],\n",
      "        [-0.9003],\n",
      "        [ 0.5558],\n",
      "        [-0.2027],\n",
      "        [ 0.9313],\n",
      "        [-0.2027],\n",
      "        [ 0.5558],\n",
      "        [-0.6288],\n",
      "        [-0.2901],\n",
      "        [ 0.8710],\n",
      "        [ 0.7472],\n",
      "        [ 0.7785],\n",
      "        [ 1.2408],\n",
      "        [ 1.2408],\n",
      "        [ 1.0769],\n",
      "        [-0.2901],\n",
      "        [-1.2069],\n",
      "        [ 1.0769],\n",
      "        [-1.4348],\n",
      "        [ 0.9611],\n",
      "        [-1.3089],\n",
      "        [ 0.5558],\n",
      "        [-0.2027],\n",
      "        [ 0.7472],\n",
      "        [ 0.5234],\n",
      "        [ 1.2408],\n",
      "        [ 0.7472],\n",
      "        [-0.7156],\n",
      "        [-0.1132],\n",
      "        [-1.0680],\n",
      "        [-1.1374],\n",
      "        [ 0.9611],\n",
      "        [-0.9003],\n",
      "        [ 0.6202],\n",
      "        [ 1.2408],\n",
      "        [-1.6107],\n",
      "        [ 0.0719],\n",
      "        [-0.4039],\n",
      "        [-1.3089],\n",
      "        [ 1.0196],\n",
      "        [-0.4039],\n",
      "        [-0.5722],\n",
      "        [-1.5430],\n",
      "        [ 0.6202],\n",
      "        [-1.4348],\n",
      "        [ 0.4260],\n",
      "        [-0.4320],\n",
      "        [ 0.4260],\n",
      "        [ 1.2408],\n",
      "        [ 1.1949]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 651/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0107,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1755],\n",
      "        [-1.1755],\n",
      "        [ 0.6410],\n",
      "        [ 0.5770],\n",
      "        [-0.0297],\n",
      "        [ 0.4803],\n",
      "        [ 0.8897],\n",
      "        [ 0.9494],\n",
      "        [ 0.8897],\n",
      "        [ 0.7981],\n",
      "        [-1.5924],\n",
      "        [-0.9042],\n",
      "        [ 0.5448],\n",
      "        [-0.2097],\n",
      "        [ 0.9197],\n",
      "        [-0.2097],\n",
      "        [ 0.5448],\n",
      "        [-0.6335],\n",
      "        [-0.2965],\n",
      "        [ 0.8594],\n",
      "        [ 0.7358],\n",
      "        [ 0.7670],\n",
      "        [ 1.2296],\n",
      "        [ 1.2296],\n",
      "        [ 1.0653],\n",
      "        [-0.2965],\n",
      "        [-1.2102],\n",
      "        [ 1.0653],\n",
      "        [-1.4378],\n",
      "        [ 0.9494],\n",
      "        [-1.3120],\n",
      "        [ 0.5448],\n",
      "        [-0.2097],\n",
      "        [ 0.7358],\n",
      "        [ 0.5126],\n",
      "        [ 1.2296],\n",
      "        [ 0.7358],\n",
      "        [-0.7199],\n",
      "        [-0.1207],\n",
      "        [-1.0715],\n",
      "        [-1.1408],\n",
      "        [ 0.9494],\n",
      "        [-0.9042],\n",
      "        [ 0.6091],\n",
      "        [ 1.2296],\n",
      "        [-1.6137],\n",
      "        [ 0.0633],\n",
      "        [-0.4097],\n",
      "        [-1.3120],\n",
      "        [ 1.0080],\n",
      "        [-0.4097],\n",
      "        [-0.5771],\n",
      "        [-1.5459],\n",
      "        [ 0.6091],\n",
      "        [-1.4378],\n",
      "        [ 0.4155],\n",
      "        [-0.4377],\n",
      "        [ 0.4155],\n",
      "        [ 1.2296],\n",
      "        [ 1.1835]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 652/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0134,\n",
      " epoch_time_duration: 0.0112\n",
      "\n",
      "batch_graph: Data(x=[60, 1], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], train_mask=[60], val_mask=[60])\n",
      "preds: tensor([[-1.1704],\n",
      "        [-1.1704],\n",
      "        [ 0.6581],\n",
      "        [ 0.5938],\n",
      "        [-0.0173],\n",
      "        [ 0.4966],\n",
      "        [ 0.9074],\n",
      "        [ 0.9672],\n",
      "        [ 0.9074],\n",
      "        [ 0.8156],\n",
      "        [-1.5880],\n",
      "        [-0.8985],\n",
      "        [ 0.5615],\n",
      "        [-0.1989],\n",
      "        [ 0.9374],\n",
      "        [-0.1989],\n",
      "        [ 0.5615],\n",
      "        [-0.6264],\n",
      "        [-0.2866],\n",
      "        [ 0.8771],\n",
      "        [ 0.7532],\n",
      "        [ 0.7846],\n",
      "        [ 1.2468],\n",
      "        [ 1.2468],\n",
      "        [ 1.0830],\n",
      "        [-0.2866],\n",
      "        [-1.2051],\n",
      "        [ 1.0830],\n",
      "        [-1.4331],\n",
      "        [ 0.9672],\n",
      "        [-1.3071],\n",
      "        [ 0.5615],\n",
      "        [-0.1989],\n",
      "        [ 0.7532],\n",
      "        [ 0.5291],\n",
      "        [ 1.2468],\n",
      "        [ 0.7532],\n",
      "        [-0.7134],\n",
      "        [-0.1091],\n",
      "        [-1.0662],\n",
      "        [-1.1356],\n",
      "        [ 0.9672],\n",
      "        [-0.8985],\n",
      "        [ 0.6260],\n",
      "        [ 1.2468],\n",
      "        [-1.6093],\n",
      "        [ 0.0765],\n",
      "        [-0.4008],\n",
      "        [-1.3071],\n",
      "        [ 1.0257],\n",
      "        [-0.4008],\n",
      "        [-0.5696],\n",
      "        [-1.5414],\n",
      "        [ 0.6260],\n",
      "        [-1.4331],\n",
      "        [ 0.4315],\n",
      "        [-0.4291],\n",
      "        [ 0.4315],\n",
      "        [ 1.2468],\n",
      "        [ 1.2010]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "mask: tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True],\n",
      "       device='cuda:0')\n",
      "epoch: 653/10000,\n",
      " train_loss: 0.0002,\n",
      " train_mae: 0.0153,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "early stopping activated\n",
      "== end training ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(1.0531),\n",
       "  tensor(8.9467),\n",
       "  tensor(1.1833),\n",
       "  tensor(0.9495),\n",
       "  tensor(2.0506),\n",
       "  tensor(2.4559),\n",
       "  tensor(2.0469),\n",
       "  tensor(1.3205),\n",
       "  tensor(0.7179),\n",
       "  tensor(0.4403),\n",
       "  tensor(0.4559),\n",
       "  tensor(0.5793),\n",
       "  tensor(0.5944),\n",
       "  tensor(0.3969),\n",
       "  tensor(0.2447),\n",
       "  tensor(0.4728),\n",
       "  tensor(0.5458),\n",
       "  tensor(0.3194),\n",
       "  tensor(0.1212),\n",
       "  tensor(0.1213),\n",
       "  tensor(0.1733),\n",
       "  tensor(0.2154),\n",
       "  tensor(0.2476),\n",
       "  tensor(0.2664),\n",
       "  tensor(0.2676),\n",
       "  tensor(0.2556),\n",
       "  tensor(0.2415),\n",
       "  tensor(0.2336),\n",
       "  tensor(0.2327),\n",
       "  tensor(0.2341),\n",
       "  tensor(0.2329),\n",
       "  tensor(0.2275),\n",
       "  tensor(0.2192),\n",
       "  tensor(0.2105),\n",
       "  tensor(0.2027),\n",
       "  tensor(0.1954),\n",
       "  tensor(0.1871),\n",
       "  tensor(0.1768),\n",
       "  tensor(0.1648),\n",
       "  tensor(0.1527),\n",
       "  tensor(0.1420),\n",
       "  tensor(0.1337),\n",
       "  tensor(0.1273),\n",
       "  tensor(0.1217),\n",
       "  tensor(0.1160),\n",
       "  tensor(0.1102),\n",
       "  tensor(0.1046),\n",
       "  tensor(0.0999),\n",
       "  tensor(0.0958),\n",
       "  tensor(0.0922),\n",
       "  tensor(0.0886),\n",
       "  tensor(0.0851),\n",
       "  tensor(0.0823),\n",
       "  tensor(0.0806),\n",
       "  tensor(0.0802),\n",
       "  tensor(0.0806),\n",
       "  tensor(0.0813),\n",
       "  tensor(0.0820),\n",
       "  tensor(0.0829),\n",
       "  tensor(0.0838),\n",
       "  tensor(0.0847),\n",
       "  tensor(0.0853),\n",
       "  tensor(0.0853),\n",
       "  tensor(0.0846),\n",
       "  tensor(0.0837),\n",
       "  tensor(0.0827),\n",
       "  tensor(0.0817),\n",
       "  tensor(0.0806),\n",
       "  tensor(0.0794),\n",
       "  tensor(0.0782),\n",
       "  tensor(0.0772),\n",
       "  tensor(0.0763),\n",
       "  tensor(0.0756),\n",
       "  tensor(0.0748),\n",
       "  tensor(0.0740),\n",
       "  tensor(0.0732),\n",
       "  tensor(0.0724),\n",
       "  tensor(0.0716),\n",
       "  tensor(0.0708),\n",
       "  tensor(0.0701),\n",
       "  tensor(0.0693),\n",
       "  tensor(0.0686),\n",
       "  tensor(0.0680),\n",
       "  tensor(0.0674),\n",
       "  tensor(0.0668),\n",
       "  tensor(0.0661),\n",
       "  tensor(0.0654),\n",
       "  tensor(0.0646),\n",
       "  tensor(0.0638),\n",
       "  tensor(0.0628),\n",
       "  tensor(0.0618),\n",
       "  tensor(0.0607),\n",
       "  tensor(0.0595),\n",
       "  tensor(0.0583),\n",
       "  tensor(0.0571),\n",
       "  tensor(0.0558),\n",
       "  tensor(0.0545),\n",
       "  tensor(0.0531),\n",
       "  tensor(0.0517),\n",
       "  tensor(0.0502),\n",
       "  tensor(0.0486),\n",
       "  tensor(0.0468),\n",
       "  tensor(0.0450),\n",
       "  tensor(0.0430),\n",
       "  tensor(0.0408),\n",
       "  tensor(0.0384),\n",
       "  tensor(0.0357),\n",
       "  tensor(0.0329),\n",
       "  tensor(0.0300),\n",
       "  tensor(0.0271),\n",
       "  tensor(0.0243),\n",
       "  tensor(0.0220),\n",
       "  tensor(0.0199),\n",
       "  tensor(0.0181),\n",
       "  tensor(0.0163),\n",
       "  tensor(0.0145),\n",
       "  tensor(0.0130),\n",
       "  tensor(0.0120),\n",
       "  tensor(0.0114),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0100),\n",
       "  tensor(0.0085),\n",
       "  tensor(0.0070),\n",
       "  tensor(0.0060),\n",
       "  tensor(0.0055),\n",
       "  tensor(0.0052),\n",
       "  tensor(0.0049),\n",
       "  tensor(0.0043),\n",
       "  tensor(0.0038),\n",
       "  tensor(0.0036),\n",
       "  tensor(0.0036),\n",
       "  tensor(0.0035),\n",
       "  tensor(0.0032),\n",
       "  tensor(0.0027),\n",
       "  tensor(0.0023),\n",
       "  tensor(0.0022),\n",
       "  tensor(0.0021),\n",
       "  tensor(0.0020),\n",
       "  tensor(0.0018),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0018),\n",
       "  tensor(0.0018),\n",
       "  tensor(0.0018),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0017),\n",
       "  tensor(0.0016),\n",
       "  tensor(0.0016),\n",
       "  tensor(0.0016),\n",
       "  tensor(0.0015),\n",
       "  tensor(0.0015),\n",
       "  tensor(0.0015),\n",
       "  tensor(0.0015),\n",
       "  tensor(0.0015),\n",
       "  tensor(0.0014),\n",
       "  tensor(0.0014),\n",
       "  tensor(0.0014),\n",
       "  tensor(0.0014),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0013),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0012),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0011),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0010),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0009),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0008),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0007),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0006),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0005),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0004),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0003),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002),\n",
       "  tensor(0.0002)],\n",
       " 'train_mae': [tensor(2.7359),\n",
       "  tensor(0.9524),\n",
       "  tensor(0.7569),\n",
       "  tensor(1.0610),\n",
       "  tensor(1.1764),\n",
       "  tensor(1.0496),\n",
       "  tensor(0.8366),\n",
       "  tensor(0.6858),\n",
       "  tensor(0.5996),\n",
       "  tensor(0.5381),\n",
       "  tensor(0.6483),\n",
       "  tensor(0.7150),\n",
       "  tensor(0.5941),\n",
       "  tensor(0.4208),\n",
       "  tensor(0.5021),\n",
       "  tensor(0.5316),\n",
       "  tensor(0.4213),\n",
       "  tensor(0.3086),\n",
       "  tensor(0.3212),\n",
       "  tensor(0.3750),\n",
       "  tensor(0.4063),\n",
       "  tensor(0.4240),\n",
       "  tensor(0.4324),\n",
       "  tensor(0.4263),\n",
       "  tensor(0.4135),\n",
       "  tensor(0.4014),\n",
       "  tensor(0.3999),\n",
       "  tensor(0.4107),\n",
       "  tensor(0.4159),\n",
       "  tensor(0.4121),\n",
       "  tensor(0.4058),\n",
       "  tensor(0.3957),\n",
       "  tensor(0.3829),\n",
       "  tensor(0.3681),\n",
       "  tensor(0.3523),\n",
       "  tensor(0.3397),\n",
       "  tensor(0.3298),\n",
       "  tensor(0.3201),\n",
       "  tensor(0.3107),\n",
       "  tensor(0.3030),\n",
       "  tensor(0.2965),\n",
       "  tensor(0.2911),\n",
       "  tensor(0.2864),\n",
       "  tensor(0.2788),\n",
       "  tensor(0.2709),\n",
       "  tensor(0.2624),\n",
       "  tensor(0.2575),\n",
       "  tensor(0.2556),\n",
       "  tensor(0.2540),\n",
       "  tensor(0.2505),\n",
       "  tensor(0.2456),\n",
       "  tensor(0.2415),\n",
       "  tensor(0.2401),\n",
       "  tensor(0.2384),\n",
       "  tensor(0.2371),\n",
       "  tensor(0.2407),\n",
       "  tensor(0.2435),\n",
       "  tensor(0.2455),\n",
       "  tensor(0.2475),\n",
       "  tensor(0.2491),\n",
       "  tensor(0.2504),\n",
       "  tensor(0.2505),\n",
       "  tensor(0.2496),\n",
       "  tensor(0.2482),\n",
       "  tensor(0.2468),\n",
       "  tensor(0.2451),\n",
       "  tensor(0.2436),\n",
       "  tensor(0.2418),\n",
       "  tensor(0.2397),\n",
       "  tensor(0.2373),\n",
       "  tensor(0.2347),\n",
       "  tensor(0.2324),\n",
       "  tensor(0.2317),\n",
       "  tensor(0.2306),\n",
       "  tensor(0.2292),\n",
       "  tensor(0.2276),\n",
       "  tensor(0.2260),\n",
       "  tensor(0.2246),\n",
       "  tensor(0.2233),\n",
       "  tensor(0.2220),\n",
       "  tensor(0.2209),\n",
       "  tensor(0.2201),\n",
       "  tensor(0.2192),\n",
       "  tensor(0.2188),\n",
       "  tensor(0.2182),\n",
       "  tensor(0.2174),\n",
       "  tensor(0.2163),\n",
       "  tensor(0.2150),\n",
       "  tensor(0.2134),\n",
       "  tensor(0.2116),\n",
       "  tensor(0.2096),\n",
       "  tensor(0.2074),\n",
       "  tensor(0.2050),\n",
       "  tensor(0.2027),\n",
       "  tensor(0.2003),\n",
       "  tensor(0.1978),\n",
       "  tensor(0.1951),\n",
       "  tensor(0.1922),\n",
       "  tensor(0.1892),\n",
       "  tensor(0.1859),\n",
       "  tensor(0.1823),\n",
       "  tensor(0.1784),\n",
       "  tensor(0.1740),\n",
       "  tensor(0.1693),\n",
       "  tensor(0.1639),\n",
       "  tensor(0.1577),\n",
       "  tensor(0.1506),\n",
       "  tensor(0.1425),\n",
       "  tensor(0.1332),\n",
       "  tensor(0.1228),\n",
       "  tensor(0.1128),\n",
       "  tensor(0.1066),\n",
       "  tensor(0.1011),\n",
       "  tensor(0.0956),\n",
       "  tensor(0.0899),\n",
       "  tensor(0.0841),\n",
       "  tensor(0.0786),\n",
       "  tensor(0.0751),\n",
       "  tensor(0.0730),\n",
       "  tensor(0.0706),\n",
       "  tensor(0.0672),\n",
       "  tensor(0.0637),\n",
       "  tensor(0.0624),\n",
       "  tensor(0.0625),\n",
       "  tensor(0.0632),\n",
       "  tensor(0.0627),\n",
       "  tensor(0.0598),\n",
       "  tensor(0.0557),\n",
       "  tensor(0.0520),\n",
       "  tensor(0.0484),\n",
       "  tensor(0.0469),\n",
       "  tensor(0.0446),\n",
       "  tensor(0.0420),\n",
       "  tensor(0.0409),\n",
       "  tensor(0.0408),\n",
       "  tensor(0.0406),\n",
       "  tensor(0.0387),\n",
       "  tensor(0.0352),\n",
       "  tensor(0.0324),\n",
       "  tensor(0.0313),\n",
       "  tensor(0.0310),\n",
       "  tensor(0.0312),\n",
       "  tensor(0.0323),\n",
       "  tensor(0.0337),\n",
       "  tensor(0.0352),\n",
       "  tensor(0.0355),\n",
       "  tensor(0.0348),\n",
       "  tensor(0.0334),\n",
       "  tensor(0.0320),\n",
       "  tensor(0.0312),\n",
       "  tensor(0.0311),\n",
       "  tensor(0.0318),\n",
       "  tensor(0.0329),\n",
       "  tensor(0.0337),\n",
       "  tensor(0.0337),\n",
       "  tensor(0.0328),\n",
       "  tensor(0.0314),\n",
       "  tensor(0.0304),\n",
       "  tensor(0.0300),\n",
       "  tensor(0.0299),\n",
       "  tensor(0.0301),\n",
       "  tensor(0.0305),\n",
       "  tensor(0.0307),\n",
       "  tensor(0.0306),\n",
       "  tensor(0.0302),\n",
       "  tensor(0.0295),\n",
       "  tensor(0.0289),\n",
       "  tensor(0.0287),\n",
       "  tensor(0.0287),\n",
       "  tensor(0.0290),\n",
       "  tensor(0.0294),\n",
       "  tensor(0.0295),\n",
       "  tensor(0.0293),\n",
       "  tensor(0.0288),\n",
       "  tensor(0.0283),\n",
       "  tensor(0.0280),\n",
       "  tensor(0.0278),\n",
       "  tensor(0.0278),\n",
       "  tensor(0.0279),\n",
       "  tensor(0.0281),\n",
       "  tensor(0.0282),\n",
       "  tensor(0.0281),\n",
       "  tensor(0.0278),\n",
       "  tensor(0.0276),\n",
       "  tensor(0.0275),\n",
       "  tensor(0.0275),\n",
       "  tensor(0.0276),\n",
       "  tensor(0.0278),\n",
       "  tensor(0.0278),\n",
       "  tensor(0.0277),\n",
       "  tensor(0.0276),\n",
       "  tensor(0.0274),\n",
       "  tensor(0.0272),\n",
       "  tensor(0.0271),\n",
       "  tensor(0.0271),\n",
       "  tensor(0.0271),\n",
       "  tensor(0.0271),\n",
       "  tensor(0.0270),\n",
       "  tensor(0.0269),\n",
       "  tensor(0.0268),\n",
       "  tensor(0.0267),\n",
       "  tensor(0.0266),\n",
       "  tensor(0.0266),\n",
       "  tensor(0.0266),\n",
       "  tensor(0.0266),\n",
       "  tensor(0.0265),\n",
       "  tensor(0.0264),\n",
       "  tensor(0.0263),\n",
       "  tensor(0.0262),\n",
       "  tensor(0.0261),\n",
       "  tensor(0.0260),\n",
       "  tensor(0.0260),\n",
       "  tensor(0.0259),\n",
       "  tensor(0.0258),\n",
       "  tensor(0.0257),\n",
       "  tensor(0.0256),\n",
       "  tensor(0.0255),\n",
       "  tensor(0.0255),\n",
       "  tensor(0.0254),\n",
       "  tensor(0.0254),\n",
       "  tensor(0.0253),\n",
       "  tensor(0.0253),\n",
       "  tensor(0.0252),\n",
       "  tensor(0.0251),\n",
       "  tensor(0.0250),\n",
       "  tensor(0.0249),\n",
       "  tensor(0.0249),\n",
       "  tensor(0.0248),\n",
       "  tensor(0.0248),\n",
       "  tensor(0.0247),\n",
       "  tensor(0.0246),\n",
       "  tensor(0.0245),\n",
       "  tensor(0.0245),\n",
       "  tensor(0.0244),\n",
       "  tensor(0.0243),\n",
       "  tensor(0.0243),\n",
       "  tensor(0.0242),\n",
       "  tensor(0.0242),\n",
       "  tensor(0.0241),\n",
       "  tensor(0.0240),\n",
       "  tensor(0.0240),\n",
       "  tensor(0.0239),\n",
       "  tensor(0.0239),\n",
       "  tensor(0.0238),\n",
       "  tensor(0.0238),\n",
       "  tensor(0.0237),\n",
       "  tensor(0.0236),\n",
       "  tensor(0.0236),\n",
       "  tensor(0.0235),\n",
       "  tensor(0.0234),\n",
       "  tensor(0.0234),\n",
       "  tensor(0.0233),\n",
       "  tensor(0.0233),\n",
       "  tensor(0.0232),\n",
       "  tensor(0.0232),\n",
       "  tensor(0.0231),\n",
       "  tensor(0.0230),\n",
       "  tensor(0.0230),\n",
       "  tensor(0.0229),\n",
       "  tensor(0.0229),\n",
       "  tensor(0.0228),\n",
       "  tensor(0.0228),\n",
       "  tensor(0.0227),\n",
       "  tensor(0.0226),\n",
       "  tensor(0.0226),\n",
       "  tensor(0.0225),\n",
       "  tensor(0.0225),\n",
       "  tensor(0.0224),\n",
       "  tensor(0.0224),\n",
       "  tensor(0.0223),\n",
       "  tensor(0.0223),\n",
       "  tensor(0.0222),\n",
       "  tensor(0.0222),\n",
       "  tensor(0.0221),\n",
       "  tensor(0.0221),\n",
       "  tensor(0.0220),\n",
       "  tensor(0.0220),\n",
       "  tensor(0.0219),\n",
       "  tensor(0.0219),\n",
       "  tensor(0.0218),\n",
       "  tensor(0.0218),\n",
       "  tensor(0.0217),\n",
       "  tensor(0.0217),\n",
       "  tensor(0.0216),\n",
       "  tensor(0.0216),\n",
       "  tensor(0.0215),\n",
       "  tensor(0.0215),\n",
       "  tensor(0.0214),\n",
       "  tensor(0.0214),\n",
       "  tensor(0.0213),\n",
       "  tensor(0.0213),\n",
       "  tensor(0.0212),\n",
       "  tensor(0.0212),\n",
       "  tensor(0.0211),\n",
       "  tensor(0.0211),\n",
       "  tensor(0.0210),\n",
       "  tensor(0.0210),\n",
       "  tensor(0.0209),\n",
       "  tensor(0.0209),\n",
       "  tensor(0.0208),\n",
       "  tensor(0.0208),\n",
       "  tensor(0.0208),\n",
       "  tensor(0.0207),\n",
       "  tensor(0.0207),\n",
       "  tensor(0.0206),\n",
       "  tensor(0.0206),\n",
       "  tensor(0.0205),\n",
       "  tensor(0.0205),\n",
       "  tensor(0.0204),\n",
       "  tensor(0.0204),\n",
       "  tensor(0.0204),\n",
       "  tensor(0.0203),\n",
       "  tensor(0.0203),\n",
       "  tensor(0.0202),\n",
       "  tensor(0.0202),\n",
       "  tensor(0.0201),\n",
       "  tensor(0.0201),\n",
       "  tensor(0.0201),\n",
       "  tensor(0.0200),\n",
       "  tensor(0.0200),\n",
       "  tensor(0.0199),\n",
       "  tensor(0.0199),\n",
       "  tensor(0.0198),\n",
       "  tensor(0.0198),\n",
       "  tensor(0.0198),\n",
       "  tensor(0.0197),\n",
       "  tensor(0.0197),\n",
       "  tensor(0.0196),\n",
       "  tensor(0.0196),\n",
       "  tensor(0.0196),\n",
       "  tensor(0.0195),\n",
       "  tensor(0.0195),\n",
       "  tensor(0.0194),\n",
       "  tensor(0.0194),\n",
       "  tensor(0.0194),\n",
       "  tensor(0.0193),\n",
       "  tensor(0.0193),\n",
       "  tensor(0.0192),\n",
       "  tensor(0.0192),\n",
       "  tensor(0.0192),\n",
       "  tensor(0.0191),\n",
       "  tensor(0.0191),\n",
       "  tensor(0.0190),\n",
       "  tensor(0.0190),\n",
       "  tensor(0.0190),\n",
       "  tensor(0.0189),\n",
       "  tensor(0.0189),\n",
       "  tensor(0.0189),\n",
       "  tensor(0.0188),\n",
       "  tensor(0.0188),\n",
       "  tensor(0.0187),\n",
       "  tensor(0.0187),\n",
       "  tensor(0.0187),\n",
       "  tensor(0.0186),\n",
       "  tensor(0.0186),\n",
       "  tensor(0.0186),\n",
       "  tensor(0.0185),\n",
       "  tensor(0.0185),\n",
       "  tensor(0.0184),\n",
       "  tensor(0.0184),\n",
       "  tensor(0.0184),\n",
       "  tensor(0.0183),\n",
       "  tensor(0.0183),\n",
       "  tensor(0.0183),\n",
       "  tensor(0.0182),\n",
       "  tensor(0.0182),\n",
       "  tensor(0.0182),\n",
       "  tensor(0.0181),\n",
       "  tensor(0.0181),\n",
       "  tensor(0.0181),\n",
       "  tensor(0.0180),\n",
       "  tensor(0.0180),\n",
       "  tensor(0.0179),\n",
       "  tensor(0.0179),\n",
       "  tensor(0.0179),\n",
       "  tensor(0.0178),\n",
       "  tensor(0.0178),\n",
       "  tensor(0.0178),\n",
       "  tensor(0.0177),\n",
       "  tensor(0.0177),\n",
       "  tensor(0.0177),\n",
       "  tensor(0.0176),\n",
       "  tensor(0.0176),\n",
       "  tensor(0.0176),\n",
       "  tensor(0.0175),\n",
       "  tensor(0.0175),\n",
       "  tensor(0.0175),\n",
       "  tensor(0.0174),\n",
       "  tensor(0.0174),\n",
       "  tensor(0.0174),\n",
       "  tensor(0.0173),\n",
       "  tensor(0.0173),\n",
       "  tensor(0.0173),\n",
       "  tensor(0.0172),\n",
       "  tensor(0.0172),\n",
       "  tensor(0.0172),\n",
       "  tensor(0.0171),\n",
       "  tensor(0.0171),\n",
       "  tensor(0.0171),\n",
       "  tensor(0.0170),\n",
       "  tensor(0.0170),\n",
       "  tensor(0.0170),\n",
       "  tensor(0.0169),\n",
       "  tensor(0.0169),\n",
       "  tensor(0.0169),\n",
       "  tensor(0.0168),\n",
       "  tensor(0.0168),\n",
       "  tensor(0.0168),\n",
       "  tensor(0.0168),\n",
       "  tensor(0.0167),\n",
       "  tensor(0.0167),\n",
       "  tensor(0.0167),\n",
       "  tensor(0.0166),\n",
       "  tensor(0.0166),\n",
       "  tensor(0.0166),\n",
       "  tensor(0.0165),\n",
       "  tensor(0.0165),\n",
       "  tensor(0.0165),\n",
       "  tensor(0.0164),\n",
       "  tensor(0.0164),\n",
       "  tensor(0.0164),\n",
       "  tensor(0.0163),\n",
       "  tensor(0.0163),\n",
       "  tensor(0.0163),\n",
       "  tensor(0.0163),\n",
       "  tensor(0.0162),\n",
       "  tensor(0.0162),\n",
       "  tensor(0.0162),\n",
       "  tensor(0.0161),\n",
       "  tensor(0.0161),\n",
       "  tensor(0.0161),\n",
       "  tensor(0.0160),\n",
       "  tensor(0.0160),\n",
       "  tensor(0.0160),\n",
       "  tensor(0.0160),\n",
       "  tensor(0.0159),\n",
       "  tensor(0.0159),\n",
       "  tensor(0.0159),\n",
       "  tensor(0.0158),\n",
       "  tensor(0.0158),\n",
       "  tensor(0.0158),\n",
       "  tensor(0.0158),\n",
       "  tensor(0.0157),\n",
       "  tensor(0.0157),\n",
       "  tensor(0.0157),\n",
       "  tensor(0.0156),\n",
       "  tensor(0.0156),\n",
       "  tensor(0.0156),\n",
       "  tensor(0.0155),\n",
       "  tensor(0.0155),\n",
       "  tensor(0.0155),\n",
       "  tensor(0.0155),\n",
       "  tensor(0.0154),\n",
       "  tensor(0.0154),\n",
       "  tensor(0.0154),\n",
       "  tensor(0.0154),\n",
       "  tensor(0.0153),\n",
       "  tensor(0.0153),\n",
       "  tensor(0.0153),\n",
       "  tensor(0.0152),\n",
       "  tensor(0.0152),\n",
       "  tensor(0.0152),\n",
       "  tensor(0.0152),\n",
       "  tensor(0.0151),\n",
       "  tensor(0.0151),\n",
       "  tensor(0.0151),\n",
       "  tensor(0.0150),\n",
       "  tensor(0.0150),\n",
       "  tensor(0.0150),\n",
       "  tensor(0.0150),\n",
       "  tensor(0.0149),\n",
       "  tensor(0.0149),\n",
       "  tensor(0.0149),\n",
       "  tensor(0.0149),\n",
       "  tensor(0.0148),\n",
       "  tensor(0.0148),\n",
       "  tensor(0.0148),\n",
       "  tensor(0.0147),\n",
       "  tensor(0.0147),\n",
       "  tensor(0.0147),\n",
       "  tensor(0.0147),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0146),\n",
       "  tensor(0.0145),\n",
       "  tensor(0.0145),\n",
       "  tensor(0.0145),\n",
       "  tensor(0.0145),\n",
       "  tensor(0.0144),\n",
       "  tensor(0.0144),\n",
       "  tensor(0.0144),\n",
       "  tensor(0.0143),\n",
       "  tensor(0.0143),\n",
       "  tensor(0.0143),\n",
       "  tensor(0.0143),\n",
       "  tensor(0.0142),\n",
       "  tensor(0.0142),\n",
       "  tensor(0.0142),\n",
       "  tensor(0.0142),\n",
       "  tensor(0.0141),\n",
       "  tensor(0.0141),\n",
       "  tensor(0.0141),\n",
       "  tensor(0.0141),\n",
       "  tensor(0.0140),\n",
       "  tensor(0.0140),\n",
       "  tensor(0.0140),\n",
       "  tensor(0.0140),\n",
       "  tensor(0.0139),\n",
       "  tensor(0.0139),\n",
       "  tensor(0.0139),\n",
       "  tensor(0.0139),\n",
       "  tensor(0.0138),\n",
       "  tensor(0.0138),\n",
       "  tensor(0.0138),\n",
       "  tensor(0.0138),\n",
       "  tensor(0.0137),\n",
       "  tensor(0.0137),\n",
       "  tensor(0.0137),\n",
       "  tensor(0.0137),\n",
       "  tensor(0.0136),\n",
       "  tensor(0.0136),\n",
       "  tensor(0.0136),\n",
       "  tensor(0.0136),\n",
       "  tensor(0.0135),\n",
       "  tensor(0.0135),\n",
       "  tensor(0.0135),\n",
       "  tensor(0.0135),\n",
       "  tensor(0.0134),\n",
       "  tensor(0.0134),\n",
       "  tensor(0.0134),\n",
       "  tensor(0.0134),\n",
       "  tensor(0.0133),\n",
       "  tensor(0.0133),\n",
       "  tensor(0.0133),\n",
       "  tensor(0.0133),\n",
       "  tensor(0.0132),\n",
       "  tensor(0.0132),\n",
       "  tensor(0.0132),\n",
       "  tensor(0.0132),\n",
       "  tensor(0.0131),\n",
       "  tensor(0.0131),\n",
       "  tensor(0.0131),\n",
       "  tensor(0.0131),\n",
       "  tensor(0.0131),\n",
       "  tensor(0.0130),\n",
       "  tensor(0.0130),\n",
       "  tensor(0.0130),\n",
       "  tensor(0.0130),\n",
       "  tensor(0.0129),\n",
       "  tensor(0.0129),\n",
       "  tensor(0.0129),\n",
       "  tensor(0.0129),\n",
       "  tensor(0.0128),\n",
       "  tensor(0.0128),\n",
       "  tensor(0.0128),\n",
       "  tensor(0.0128),\n",
       "  tensor(0.0127),\n",
       "  tensor(0.0127),\n",
       "  tensor(0.0127),\n",
       "  tensor(0.0127),\n",
       "  tensor(0.0126),\n",
       "  tensor(0.0126),\n",
       "  tensor(0.0126),\n",
       "  tensor(0.0126),\n",
       "  tensor(0.0126),\n",
       "  tensor(0.0125),\n",
       "  tensor(0.0125),\n",
       "  tensor(0.0125),\n",
       "  tensor(0.0125),\n",
       "  tensor(0.0124),\n",
       "  tensor(0.0124),\n",
       "  tensor(0.0124),\n",
       "  tensor(0.0124),\n",
       "  tensor(0.0123),\n",
       "  tensor(0.0123),\n",
       "  tensor(0.0123),\n",
       "  tensor(0.0123),\n",
       "  tensor(0.0123),\n",
       "  tensor(0.0122),\n",
       "  tensor(0.0122),\n",
       "  tensor(0.0122),\n",
       "  tensor(0.0122),\n",
       "  tensor(0.0121),\n",
       "  tensor(0.0121),\n",
       "  tensor(0.0121),\n",
       "  tensor(0.0121),\n",
       "  tensor(0.0121),\n",
       "  tensor(0.0120),\n",
       "  tensor(0.0120),\n",
       "  tensor(0.0120),\n",
       "  tensor(0.0120),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0119),\n",
       "  tensor(0.0118),\n",
       "  tensor(0.0118),\n",
       "  tensor(0.0118),\n",
       "  tensor(0.0118),\n",
       "  tensor(0.0117),\n",
       "  tensor(0.0117),\n",
       "  tensor(0.0117),\n",
       "  tensor(0.0117),\n",
       "  tensor(0.0117),\n",
       "  tensor(0.0116),\n",
       "  tensor(0.0116),\n",
       "  tensor(0.0116),\n",
       "  tensor(0.0116),\n",
       "  tensor(0.0115),\n",
       "  tensor(0.0115),\n",
       "  tensor(0.0115),\n",
       "  tensor(0.0115),\n",
       "  tensor(0.0115),\n",
       "  tensor(0.0114),\n",
       "  tensor(0.0114),\n",
       "  tensor(0.0114),\n",
       "  tensor(0.0114),\n",
       "  tensor(0.0113),\n",
       "  tensor(0.0113),\n",
       "  tensor(0.0113),\n",
       "  tensor(0.0113),\n",
       "  tensor(0.0113),\n",
       "  tensor(0.0112),\n",
       "  tensor(0.0112),\n",
       "  tensor(0.0112),\n",
       "  tensor(0.0112),\n",
       "  tensor(0.0112),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0108),\n",
       "  tensor(0.0109),\n",
       "  tensor(0.0107),\n",
       "  tensor(0.0110),\n",
       "  tensor(0.0106),\n",
       "  tensor(0.0111),\n",
       "  tensor(0.0104),\n",
       "  tensor(0.0116),\n",
       "  tensor(0.0107),\n",
       "  tensor(0.0134),\n",
       "  tensor(0.0153)],\n",
       " 'val_loss': [],\n",
       " 'val_mae': []}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLPModel(torch.nn.Module):\n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, dp_rate=0.1):\n",
    "        \"\"\"MLPModel.\n",
    "\n",
    "        Args:\n",
    "            c_in: Dimension of input features\n",
    "            c_hidden: Dimension of hidden features\n",
    "            c_out: Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers: Number of hidden layers\n",
    "            dp_rate: Dropout rate to apply throughout the network\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [torch.nn.Linear(in_channels, out_channels), torch.nn.Sigmoid(), torch.nn.Dropout(dp_rate)]\n",
    "            in_channels = c_hidden\n",
    "        layers += [torch.nn.Linear(in_channels, c_out)]\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        \"\"\"Forward.\n",
    "\n",
    "        Args:\n",
    "            x: Input features per node\n",
    "\n",
    "        \"\"\"\n",
    "        return self.layers(x)\n",
    "\n",
    "my_module = MLPModel(c_in=1, c_hidden=1, c_out=1,num_layers=2,dp_rate=0.0)\n",
    "\n",
    "print([param for param in my_module.parameters()])\n",
    "\n",
    "complete_model = GNN_naive_framework(my_module,device)\n",
    "opt = complete_model.configure_optimizer(lr=1)\n",
    "scheduler = complete_model.configure_scheduler(opt,1,1,10)\n",
    "\n",
    "history = complete_model.train([participant_graph],10000,1,opt,scheduler,\"train_loss\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 2.5801],\n",
       "         [-1.2462],\n",
       "         [-1.2404],\n",
       "         [-0.3156],\n",
       "         [-3.9072]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-8.2896,  0.5276, -9.6809, -8.8769, -4.8124], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 3.5628, -3.3370,  2.6040,  5.0165, -0.7148]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([2.0711], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in my_module.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9899]]], device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_module.forward(torch.Tensor([[[1]]]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1722],\n",
      "        [-1.1722],\n",
      "        [ 0.6404],\n",
      "        [ 0.5790],\n",
      "        [-0.0048],\n",
      "        [ 0.4868],\n",
      "        [ 0.8862],\n",
      "        [ 0.9476],\n",
      "        [ 0.8862],\n",
      "        [ 0.7940],\n",
      "        [-1.6023],\n",
      "        [-0.9264],\n",
      "        [ 0.5483],\n",
      "        [-0.1891],\n",
      "        [ 0.9169],\n",
      "        [-0.1891],\n",
      "        [ 0.5483],\n",
      "        [-0.6499],\n",
      "        [-0.2813],\n",
      "        [ 0.8555],\n",
      "        [ 0.7326],\n",
      "        [ 0.7633],\n",
      "        [ 1.2549],\n",
      "        [ 1.2549],\n",
      "        [ 1.0705],\n",
      "        [-0.2813],\n",
      "        [-1.2029],\n",
      "        [ 1.0705],\n",
      "        [-1.4180],\n",
      "        [ 0.9476],\n",
      "        [-1.2951],\n",
      "        [ 0.5483],\n",
      "        [-0.1891],\n",
      "        [ 0.7326],\n",
      "        [ 0.5175],\n",
      "        [ 1.2549],\n",
      "        [ 0.7326],\n",
      "        [-0.7421],\n",
      "        [-0.0969],\n",
      "        [-1.0801],\n",
      "        [-1.1415],\n",
      "        [ 0.9476],\n",
      "        [-0.9264],\n",
      "        [ 0.6097],\n",
      "        [ 1.2549],\n",
      "        [-1.6331],\n",
      "        [ 0.0874],\n",
      "        [-0.4042],\n",
      "        [-1.2951],\n",
      "        [ 1.0091],\n",
      "        [-0.4042],\n",
      "        [-0.5885],\n",
      "        [-1.5409],\n",
      "        [ 0.6097],\n",
      "        [-1.4180],\n",
      "        [ 0.4254],\n",
      "        [-0.4349],\n",
      "        [ 0.4254],\n",
      "        [ 1.2549],\n",
      "        [ 1.2019]])\n",
      "tensor([[-1.1722],\n",
      "        [-1.1722],\n",
      "        [ 0.6404],\n",
      "        [ 0.5790],\n",
      "        [-0.0048],\n",
      "        [ 0.4868],\n",
      "        [ 0.8862],\n",
      "        [ 0.9476],\n",
      "        [ 0.8862],\n",
      "        [ 0.7940],\n",
      "        [-1.6023],\n",
      "        [-0.9264],\n",
      "        [ 0.5483],\n",
      "        [-0.1891],\n",
      "        [ 0.9169],\n",
      "        [-0.1891],\n",
      "        [ 0.5483],\n",
      "        [-0.6499],\n",
      "        [-0.2813],\n",
      "        [ 0.8555],\n",
      "        [ 0.7326],\n",
      "        [ 0.7633],\n",
      "        [ 1.2549],\n",
      "        [ 1.2549],\n",
      "        [ 1.0705],\n",
      "        [-0.2813],\n",
      "        [-1.2029],\n",
      "        [ 1.0705],\n",
      "        [-1.4180],\n",
      "        [ 0.9476],\n",
      "        [-1.2951],\n",
      "        [ 0.5483],\n",
      "        [-0.1891],\n",
      "        [ 0.7326],\n",
      "        [ 0.5175],\n",
      "        [ 1.2549],\n",
      "        [ 0.7326],\n",
      "        [-0.7421],\n",
      "        [-0.0969],\n",
      "        [-1.0801],\n",
      "        [-1.1415],\n",
      "        [ 0.9476],\n",
      "        [-0.9264],\n",
      "        [ 0.6097],\n",
      "        [ 1.2549],\n",
      "        [-1.6331],\n",
      "        [ 0.0874],\n",
      "        [-0.4042],\n",
      "        [-1.2951],\n",
      "        [ 1.0091],\n",
      "        [-0.4042],\n",
      "        [-0.5885],\n",
      "        [-1.5409],\n",
      "        [ 0.6097],\n",
      "        [-1.4180],\n",
      "        [ 0.4254],\n",
      "        [-0.4349],\n",
      "        [ 0.4254],\n",
      "        [ 1.2549],\n",
      "        [ 1.2019]])\n"
     ]
    }
   ],
   "source": [
    "print(participant_graph.y)\n",
    "\n",
    "print(participant_graph.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           -1.1729376316070557,
           -1.1729376316070557,
           0.6497519016265869,
           0.5856209993362427,
           -0.023499488830566406,
           0.4886244535446167,
           0.8987678289413452,
           0.958511233329773,
           0.8987678289413452,
           0.807091474533081,
           -1.5900251865386963,
           -0.9010846614837646,
           0.5533754825592041,
           -0.20427894592285156,
           0.9287847280502319,
           -0.20427894592285156,
           0.5533754825592041,
           -0.6297619342803955,
           -0.2915523052215576,
           0.8684713840484619,
           0.7447576522827148,
           0.776036262512207,
           1.2382137775421143,
           1.2382137775421143,
           1.0743253231048584,
           -0.2915523052215576,
           -1.2076339721679688,
           1.0743253231048584,
           -1.4355108737945557,
           0.958511233329773,
           -1.3096308708190918,
           0.5533754825592041,
           -0.20427894592285156,
           0.7447576522827148,
           0.5210363864898682,
           1.2382137775421143,
           0.7447576522827148,
           -0.7164273262023926,
           -0.11494565010070801,
           -1.0687370300292969,
           -1.138134241104126,
           0.958511233329773,
           -0.9010846614837646,
           0.6177530288696289,
           1.2382137775421143,
           -1.6112983226776123,
           0.06992363929748535,
           -0.40523242950439453,
           -1.3096308708190918,
           1.017052173614502,
           -0.40523242950439453,
           -0.5732204914093018,
           -1.5436301231384277,
           0.6177530288696289,
           -1.4355108737945557,
           0.42366552352905273,
           -0.43330812454223633,
           0.42366552352905273,
           1.2382137775421143,
           1.1923162937164307
          ]
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          -1.1722218990325928,
          -1.1722218990325928,
          0.6404194831848145,
          0.5789740085601807,
          -0.004757963586598635,
          0.48680579662323,
          0.8862013816833496,
          0.9476468563079834,
          0.8862013816833496,
          0.7940331697463989,
          -1.6023402214050293,
          -0.9264400005340576,
          0.5482512712478638,
          -0.18909437954425812,
          0.9169241189956665,
          -0.18909437954425812,
          0.5482512712478638,
          -0.6499354243278503,
          -0.2812625765800476,
          0.8554786443710327,
          0.7325876951217651,
          0.763310432434082,
          1.2548742294311523,
          1.2548742294311523,
          1.070537805557251,
          -0.2812625765800476,
          -1.2029446363449097,
          1.070537805557251,
          -1.418003797531128,
          0.9476468563079834,
          -1.2951128482818604,
          0.5482512712478638,
          -0.18909437954425812,
          0.7325876951217651,
          0.5175285339355469,
          1.2548742294311523,
          0.7325876951217651,
          -0.742103636264801,
          -0.09692616760730743,
          -1.080053687095642,
          -1.1414991617202759,
          0.9476468563079834,
          -0.9264400005340576,
          0.6096967458724976,
          1.2548742294311523,
          -1.6330629587173462,
          0.08741024136543274,
          -0.4041535258293152,
          -1.2951128482818604,
          1.0090923309326172,
          -0.4041535258293152,
          -0.5884899497032166,
          -1.5408947467803955,
          0.6096967458724976,
          -1.418003797531128,
          0.4253603219985962,
          -0.4348762631416321,
          0.4253603219985962,
          1.2548742294311523,
          1.2018709182739258
         ],
         "y": [
          0.0007157325744628906,
          0.0007157325744628906,
          -0.009332418441772461,
          -0.006646990776062012,
          0.01874152570962906,
          -0.0018186569213867188,
          -0.012566447257995605,
          -0.01086437702178955,
          -0.012566447257995605,
          -0.013058304786682129,
          -0.012315034866333008,
          -0.02535533905029297,
          -0.005124211311340332,
          0.015184566378593445,
          -0.01186060905456543,
          0.015184566378593445,
          -0.005124211311340332,
          -0.020173490047454834,
          0.01028972864151001,
          -0.0129927396774292,
          -0.012169957160949707,
          -0.012725830078125,
          0.016660451889038086,
          0.016660451889038086,
          -0.003787517547607422,
          0.01028972864151001,
          0.004689335823059082,
          -0.003787517547607422,
          0.017507076263427734,
          -0.01086437702178955,
          0.014518022537231445,
          -0.005124211311340332,
          0.015184566378593445,
          -0.012169957160949707,
          -0.003507852554321289,
          0.016660451889038086,
          -0.012169957160949707,
          -0.025676310062408447,
          0.018019482493400574,
          -0.011316657066345215,
          -0.0033649206161499023,
          -0.01086437702178955,
          -0.02535533905029297,
          -0.008056282997131348,
          0.016660451889038086,
          -0.021764636039733887,
          0.017486602067947388,
          0.0010789036750793457,
          0.014518022537231445,
          -0.007959842681884766,
          0.0010789036750793457,
          -0.015269458293914795,
          0.0027353763580322266,
          -0.008056282997131348,
          0.017507076263427734,
          0.001694798469543457,
          -0.001568138599395752,
          0.001694798469543457,
          0.016660451889038086,
          0.009554624557495117
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Residual depending on label value"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Residual"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "histogram",
         "x": [
          -1.1729376316070557,
          -1.1729376316070557,
          0.6497519016265869,
          0.5856209993362427,
          -0.023499488830566406,
          0.4886244535446167,
          0.8987678289413452,
          0.958511233329773,
          0.8987678289413452,
          0.807091474533081,
          -1.5900251865386963,
          -0.9010846614837646,
          0.5533754825592041,
          -0.20427894592285156,
          0.9287847280502319,
          -0.20427894592285156,
          0.5533754825592041,
          -0.6297619342803955,
          -0.2915523052215576,
          0.8684713840484619,
          0.7447576522827148,
          0.776036262512207,
          1.2382137775421143,
          1.2382137775421143,
          1.0743253231048584,
          -0.2915523052215576,
          -1.2076339721679688,
          1.0743253231048584,
          -1.4355108737945557,
          0.958511233329773,
          -1.3096308708190918,
          0.5533754825592041,
          -0.20427894592285156,
          0.7447576522827148,
          0.5210363864898682,
          1.2382137775421143,
          0.7447576522827148,
          -0.7164273262023926,
          -0.11494565010070801,
          -1.0687370300292969,
          -1.138134241104126,
          0.958511233329773,
          -0.9010846614837646,
          0.6177530288696289,
          1.2382137775421143,
          -1.6112983226776123,
          0.06992363929748535,
          -0.40523242950439453,
          -1.3096308708190918,
          1.017052173614502,
          -0.40523242950439453,
          -0.5732204914093018,
          -1.5436301231384277,
          0.6177530288696289,
          -1.4355108737945557,
          0.42366552352905273,
          -0.43330812454223633,
          0.42366552352905273,
          1.2382137775421143,
          1.1923162937164307
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Residual depending on label value"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Residual"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_errors_labels_comparison(model:GNN_naive_framework,graph:torch_geometric.data.Data,plot_attention_weights=False):\n",
    "    if plot_attention_weights:\n",
    "        preds, (adj, alpha) = model.predict(graph.x,\n",
    "                                    graph.edge_index,\n",
    "                                    graph.edge_attr,\n",
    "                                    return_attention_weights=True)\n",
    "    else:\n",
    "        preds = model.predict(graph.x,\n",
    "                                    graph.edge_index,\n",
    "                                    graph.edge_attr,\n",
    "                                    return_attention_weights=False)\n",
    "        \n",
    "    preds = np.array(preds.detach().to(\"cpu\"))\n",
    "    preds = np.squeeze(preds)\n",
    "    labels = np.array(participant_graph.y)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    errors = labels-preds\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x = labels,\n",
    "        y = errors,\n",
    "        mode = \"markers\",\n",
    "        marker=dict(color=preds)\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        title=\"Residual depending on label value\",\n",
    "        xaxis_title=\"Label\",\n",
    "        yaxis_title=\"Residual\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x = preds)\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=\"Residual depending on label value\",\n",
    "        xaxis_title=\"Label\",\n",
    "        yaxis_title=\"Residual\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    if plot_attention_weights:\n",
    "        from torch_geometric.utils import (\n",
    "            add_self_loops,\n",
    "            is_torch_sparse_tensor,\n",
    "            remove_self_loops,\n",
    "            softmax,\n",
    "            to_dense_adj\n",
    "        )\n",
    "\n",
    "        matrix_alpha = to_dense_adj(adj, edge_attr = alpha).cpu().detach()\n",
    "        matrix_alpha = matrix_alpha.squeeze()\n",
    "        fig = px.imshow(matrix_alpha)\n",
    "        fig.update_layout(\n",
    "            title=\"Alpha: the message passing strength between nodes\"\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "plot_errors_labels_comparison(complete_model,participant_graph,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_x_src, param_x_dst = 0.6226500868797302 3384.351806640625\n",
      "params_edge tensor(27.1259, device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "tensor(50.3570, device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin_src_params = [param for param in complete_model.update_node_module.lin_src.parameters()][0]\n",
    "lin_dst_params = [param for param in complete_model.update_node_module.lin_dst.parameters()][0]\n",
    "\n",
    "src_att_lin_params = lin_src_params * complete_model.update_node_module.att_src\n",
    "dst_att_lin_params = lin_dst_params * complete_model.update_node_module.att_dst\n",
    "#lin_params.squeeze()\n",
    "print(\"param_x_src, param_x_dst =\", float(src_att_lin_params), float(dst_att_lin_params))\n",
    "\n",
    "\n",
    "lin_edge_params = [param for param in complete_model.update_node_module.lin_edge.parameters()][0]\n",
    "att_lin_edge_params = lin_edge_params * complete_model.update_node_module.att_edge\n",
    "print(\"params_edge\", att_lin_edge_params.squeeze())\n",
    "\n",
    "bias = [param for param in complete_model.update_node_module.bias][0]\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That param_x_dst is that small is a good sign. It means only $\\alpha_{i,i}$ will keep an influence over the prediction of $x'_i$. The param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id_main = 0\n",
    "edge_mask = participant_graph.edge_index[0,:] == node_id_main\n",
    "edge_mask = edge_mask + participant_graph.edge_index[1,:] == node_id_main\n",
    "edge_index_subgraph = participant_graph.edge_index[:,edge_mask]\n",
    "edge_attr_subgraph = participant_graph.edge_attr[edge_mask]\n",
    "\n",
    "participant_subgraph = Data(\n",
    "        x = participant_graph.x, \n",
    "        edge_index = edge_index_subgraph,\n",
    "        edge_attr = edge_attr_subgraph,\n",
    "        y = participant_graph.x, \n",
    "        train_mask = participant_graph.train_mask, \n",
    "        val_mask = participant_graph.val_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21.],\n",
       "        [ 21.],\n",
       "        [ 80.],\n",
       "        [ 78.],\n",
       "        [ 59.],\n",
       "        [ 75.],\n",
       "        [ 88.],\n",
       "        [ 90.],\n",
       "        [ 88.],\n",
       "        [ 85.],\n",
       "        [  7.],\n",
       "        [ 29.],\n",
       "        [ 77.],\n",
       "        [ 53.],\n",
       "        [ 89.],\n",
       "        [ 53.],\n",
       "        [ 77.],\n",
       "        [ 38.],\n",
       "        [ 50.],\n",
       "        [ 87.],\n",
       "        [ 83.],\n",
       "        [ 84.],\n",
       "        [100.],\n",
       "        [100.],\n",
       "        [ 94.],\n",
       "        [ 50.],\n",
       "        [ 20.],\n",
       "        [ 94.],\n",
       "        [ 13.],\n",
       "        [ 90.],\n",
       "        [ 17.],\n",
       "        [ 77.],\n",
       "        [ 53.],\n",
       "        [ 83.],\n",
       "        [ 76.],\n",
       "        [100.],\n",
       "        [ 83.],\n",
       "        [ 35.],\n",
       "        [ 56.],\n",
       "        [ 24.],\n",
       "        [ 22.],\n",
       "        [ 90.],\n",
       "        [ 29.],\n",
       "        [ 79.],\n",
       "        [100.],\n",
       "        [  6.],\n",
       "        [ 62.],\n",
       "        [ 46.],\n",
       "        [ 17.],\n",
       "        [ 92.],\n",
       "        [ 46.],\n",
       "        [ 40.],\n",
       "        [  9.],\n",
       "        [ 79.],\n",
       "        [ 13.],\n",
       "        [ 73.],\n",
       "        [ 45.],\n",
       "        [ 73.],\n",
       "        [100.],\n",
       "        [100.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_subgraph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[60.7998],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570],\n",
       "        [50.3570]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_model.predict(node_attr=participant_subgraph.x,\n",
    "                       edge_index=participant_subgraph.edge_index,\n",
    "                       edge_attr=participant_subgraph.edge_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[61.5520],\n",
      "        [16.1193],\n",
      "        [50.0500],\n",
      "        [48.8998],\n",
      "        [37.9730],\n",
      "        [47.1745],\n",
      "        [54.6508],\n",
      "        [55.8010],\n",
      "        [54.6508],\n",
      "        [52.9255],\n",
      "        [ 8.0679],\n",
      "        [20.7201],\n",
      "        [48.3247],\n",
      "        [34.5224],\n",
      "        [55.2259],\n",
      "        [34.5224],\n",
      "        [48.3247],\n",
      "        [25.8959],\n",
      "        [32.7971],\n",
      "        [54.0757],\n",
      "        [51.7753],\n",
      "        [52.3504],\n",
      "        [61.5520],\n",
      "        [61.5520],\n",
      "        [58.1014],\n",
      "        [32.7971],\n",
      "        [15.5442],\n",
      "        [58.1014],\n",
      "        [11.5185],\n",
      "        [55.8010],\n",
      "        [13.8189],\n",
      "        [48.3247],\n",
      "        [34.5224],\n",
      "        [51.7753],\n",
      "        [47.7496],\n",
      "        [61.5520],\n",
      "        [51.7753],\n",
      "        [24.1707],\n",
      "        [36.2477],\n",
      "        [17.8446],\n",
      "        [16.6944],\n",
      "        [55.8010],\n",
      "        [20.7201],\n",
      "        [49.4749],\n",
      "        [61.5520],\n",
      "        [ 7.4928],\n",
      "        [39.6983],\n",
      "        [30.4967],\n",
      "        [13.8189],\n",
      "        [56.9512],\n",
      "        [30.4967],\n",
      "        [27.0461],\n",
      "        [ 9.2181],\n",
      "        [49.4749],\n",
      "        [11.5185],\n",
      "        [46.0243],\n",
      "        [29.9216],\n",
      "        [46.0243],\n",
      "        [61.5520],\n",
      "        [61.5520]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "(tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "         19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "         37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "         55, 56, 57, 58, 59,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
      "         31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
      "         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
      "         13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
      "         31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48,\n",
      "         49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]], device='cuda:0'), tensor([[0.0000e+00],\n",
      "        [4.8577e-41],\n",
      "        [4.2039e-45],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [3.2460e-25],\n",
      "        [2.9721e-21],\n",
      "        [2.4658e-25],\n",
      "        [3.0930e-31],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [2.2045e-23],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [3.5304e-27],\n",
      "        [3.0677e-35],\n",
      "        [4.3514e-33],\n",
      "        [1.4563e-01],\n",
      "        [1.8648e-01],\n",
      "        [1.8861e-13],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [2.1064e-13],\n",
      "        [0.0000e+00],\n",
      "        [2.4069e-21],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [2.3206e-35],\n",
      "        [0.0000e+00],\n",
      "        [1.6531e-01],\n",
      "        [4.1804e-35],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [1.5302e-21],\n",
      "        [0.0000e+00],\n",
      "        [3.9657e-43],\n",
      "        [1.7270e-01],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [2.9667e-17],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [5.5491e-43],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [0.0000e+00],\n",
      "        [1.6707e-01],\n",
      "        [1.6281e-01],\n",
      "        [0.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [1.0000e+00]], device='cuda:0', grad_fn=<DivBackward0>))\n"
     ]
    }
   ],
   "source": [
    "res = complete_model.update_node_module(participant_subgraph.x.to(device), participant_subgraph.edge_index.to(device), participant_subgraph.edge_attr.to(device),return_attention_weights=True)\n",
    "\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les derniers qui nous intÃ©ressent sont bien Ã  1 tandis que les autres sont Ã  0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== start training ==\n",
      "epoch: 1/10000,\n",
      " train_loss: 5378.2949,\n",
      " train_mae: 59.1030,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2/10000,\n",
      " train_loss: 4373.0112,\n",
      " train_mae: 52.4354,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3/10000,\n",
      " train_loss: 3608.8101,\n",
      " train_mae: 46.4671,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4/10000,\n",
      " train_loss: 2933.8242,\n",
      " train_mae: 41.5882,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5/10000,\n",
      " train_loss: 2374.7063,\n",
      " train_mae: 37.6855,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 6/10000,\n",
      " train_loss: 1913.9542,\n",
      " train_mae: 34.3410,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 7/10000,\n",
      " train_loss: 1548.0836,\n",
      " train_mae: 31.4919,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 8/10000,\n",
      " train_loss: 1272.1437,\n",
      " train_mae: 29.1906,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 9/10000,\n",
      " train_loss: 1079.2406,\n",
      " train_mae: 27.6272,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 10/10000,\n",
      " train_loss: 960.4120,\n",
      " train_mae: 26.8701,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 11/10000,\n",
      " train_loss: 904.7333,\n",
      " train_mae: 26.4361,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 12/10000,\n",
      " train_loss: 899.6686,\n",
      " train_mae: 26.1699,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 13/10000,\n",
      " train_loss: 931.6901,\n",
      " train_mae: 25.9395,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 14/10000,\n",
      " train_loss: 987.1213,\n",
      " train_mae: 25.8003,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 15/10000,\n",
      " train_loss: 1053.0928,\n",
      " train_mae: 25.8521,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 16/10000,\n",
      " train_loss: 1118.4487,\n",
      " train_mae: 26.0728,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 17/10000,\n",
      " train_loss: 1174.4438,\n",
      " train_mae: 26.3219,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 18/10000,\n",
      " train_loss: 1215.1248,\n",
      " train_mae: 26.4862,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 19/10000,\n",
      " train_loss: 1237.3660,\n",
      " train_mae: 26.5097,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 20/10000,\n",
      " train_loss: 1240.6007,\n",
      " train_mae: 26.4055,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 21/10000,\n",
      " train_loss: 1226.3479,\n",
      " train_mae: 26.2112,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 22/10000,\n",
      " train_loss: 1197.6333,\n",
      " train_mae: 25.9928,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 23/10000,\n",
      " train_loss: 1158.4042,\n",
      " train_mae: 25.8440,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 24/10000,\n",
      " train_loss: 1112.9894,\n",
      " train_mae: 25.8067,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 25/10000,\n",
      " train_loss: 1065.6417,\n",
      " train_mae: 25.8414,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 26/10000,\n",
      " train_loss: 1020.1714,\n",
      " train_mae: 25.9701,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 27/10000,\n",
      " train_loss: 979.6805,\n",
      " train_mae: 26.1025,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 28/10000,\n",
      " train_loss: 946.3939,\n",
      " train_mae: 26.2349,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 29/10000,\n",
      " train_loss: 921.5851,\n",
      " train_mae: 26.3641,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 30/10000,\n",
      " train_loss: 905.5898,\n",
      " train_mae: 26.4870,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 31/10000,\n",
      " train_loss: 897.8991,\n",
      " train_mae: 26.6469,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 32/10000,\n",
      " train_loss: 897.3178,\n",
      " train_mae: 26.8023,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 33/10000,\n",
      " train_loss: 902.1699,\n",
      " train_mae: 26.9827,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 34/10000,\n",
      " train_loss: 910.5287,\n",
      " train_mae: 27.1339,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 35/10000,\n",
      " train_loss: 920.4459,\n",
      " train_mae: 27.2673,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 36/10000,\n",
      " train_loss: 930.1548,\n",
      " train_mae: 27.3756,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 37/10000,\n",
      " train_loss: 938.2309,\n",
      " train_mae: 27.4430,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 38/10000,\n",
      " train_loss: 943.6913,\n",
      " train_mae: 27.4707,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 39/10000,\n",
      " train_loss: 946.0344,\n",
      " train_mae: 27.4611,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 40/10000,\n",
      " train_loss: 945.2186,\n",
      " train_mae: 27.4176,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 41/10000,\n",
      " train_loss: 941.5944,\n",
      " train_mae: 27.3443,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 42/10000,\n",
      " train_loss: 935.8018,\n",
      " train_mae: 27.2457,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 43/10000,\n",
      " train_loss: 928.6495,\n",
      " train_mae: 27.1413,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 44/10000,\n",
      " train_loss: 920.9962,\n",
      " train_mae: 27.0349,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 45/10000,\n",
      " train_loss: 913.6401,\n",
      " train_mae: 26.9209,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 46/10000,\n",
      " train_loss: 907.2347,\n",
      " train_mae: 26.8038,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 47/10000,\n",
      " train_loss: 902.2318,\n",
      " train_mae: 26.7168,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 48/10000,\n",
      " train_loss: 898.8561,\n",
      " train_mae: 26.6331,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 49/10000,\n",
      " train_loss: 897.1130,\n",
      " train_mae: 26.5551,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 50/10000,\n",
      " train_loss: 896.8178,\n",
      " train_mae: 26.4941,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 51/10000,\n",
      " train_loss: 897.6477,\n",
      " train_mae: 26.4541,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 52/10000,\n",
      " train_loss: 899.2006,\n",
      " train_mae: 26.4213,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 53/10000,\n",
      " train_loss: 901.0580,\n",
      " train_mae: 26.3960,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 54/10000,\n",
      " train_loss: 902.8398,\n",
      " train_mae: 26.3786,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 55/10000,\n",
      " train_loss: 904.2454,\n",
      " train_mae: 26.3690,\n",
      " epoch_time_duration: 0.0025\n",
      "\n",
      "epoch: 56/10000,\n",
      " train_loss: 905.0812,\n",
      " train_mae: 26.3669,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 57/10000,\n",
      " train_loss: 905.2675,\n",
      " train_mae: 26.3717,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 58/10000,\n",
      " train_loss: 904.8304,\n",
      " train_mae: 26.3827,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 59/10000,\n",
      " train_loss: 903.8821,\n",
      " train_mae: 26.3989,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 60/10000,\n",
      " train_loss: 902.5900,\n",
      " train_mae: 26.4194,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 61/10000,\n",
      " train_loss: 901.1459,\n",
      " train_mae: 26.4429,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 62/10000,\n",
      " train_loss: 899.7350,\n",
      " train_mae: 26.4684,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 63/10000,\n",
      " train_loss: 898.5111,\n",
      " train_mae: 26.4948,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 64/10000,\n",
      " train_loss: 897.5797,\n",
      " train_mae: 26.5260,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 65/10000,\n",
      " train_loss: 896.9905,\n",
      " train_mae: 26.5640,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 66/10000,\n",
      " train_loss: 896.7395,\n",
      " train_mae: 26.5989,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 67/10000,\n",
      " train_loss: 896.7774,\n",
      " train_mae: 26.6297,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 68/10000,\n",
      " train_loss: 897.0237,\n",
      " train_mae: 26.6555,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 69/10000,\n",
      " train_loss: 897.3837,\n",
      " train_mae: 26.6757,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 70/10000,\n",
      " train_loss: 897.7636,\n",
      " train_mae: 26.6900,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 71/10000,\n",
      " train_loss: 898.0848,\n",
      " train_mae: 26.6984,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 72/10000,\n",
      " train_loss: 898.2922,\n",
      " train_mae: 26.7011,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 73/10000,\n",
      " train_loss: 898.3590,\n",
      " train_mae: 26.6984,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 74/10000,\n",
      " train_loss: 898.2855,\n",
      " train_mae: 26.6909,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 75/10000,\n",
      " train_loss: 898.0945,\n",
      " train_mae: 26.6793,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 76/10000,\n",
      " train_loss: 897.8248,\n",
      " train_mae: 26.6645,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 77/10000,\n",
      " train_loss: 897.5209,\n",
      " train_mae: 26.6474,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 78/10000,\n",
      " train_loss: 897.2268,\n",
      " train_mae: 26.6288,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 79/10000,\n",
      " train_loss: 896.9779,\n",
      " train_mae: 26.6098,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 80/10000,\n",
      " train_loss: 896.7975,\n",
      " train_mae: 26.5910,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 81/10000,\n",
      " train_loss: 896.6945,\n",
      " train_mae: 26.5733,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 82/10000,\n",
      " train_loss: 896.6647,\n",
      " train_mae: 26.5574,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 83/10000,\n",
      " train_loss: 896.6934,\n",
      " train_mae: 26.5437,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 84/10000,\n",
      " train_loss: 896.7594,\n",
      " train_mae: 26.5327,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 85/10000,\n",
      " train_loss: 896.8398,\n",
      " train_mae: 26.5246,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 86/10000,\n",
      " train_loss: 896.9133,\n",
      " train_mae: 26.5195,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 87/10000,\n",
      " train_loss: 896.9642,\n",
      " train_mae: 26.5174,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 88/10000,\n",
      " train_loss: 896.9833,\n",
      " train_mae: 26.5180,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 89/10000,\n",
      " train_loss: 896.9687,\n",
      " train_mae: 26.5211,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 90/10000,\n",
      " train_loss: 896.9245,\n",
      " train_mae: 26.5263,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 91/10000,\n",
      " train_loss: 896.8597,\n",
      " train_mae: 26.5332,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 92/10000,\n",
      " train_loss: 896.7845,\n",
      " train_mae: 26.5414,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 93/10000,\n",
      " train_loss: 896.7097,\n",
      " train_mae: 26.5502,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 94/10000,\n",
      " train_loss: 896.6436,\n",
      " train_mae: 26.5593,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 95/10000,\n",
      " train_loss: 896.5905,\n",
      " train_mae: 26.5681,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 96/10000,\n",
      " train_loss: 896.5512,\n",
      " train_mae: 26.5762,\n",
      " epoch_time_duration: 0.0025\n",
      "\n",
      "epoch: 97/10000,\n",
      " train_loss: 896.5206,\n",
      " train_mae: 26.5831,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 98/10000,\n",
      " train_loss: 896.4871,\n",
      " train_mae: 26.5882,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 99/10000,\n",
      " train_loss: 896.4255,\n",
      " train_mae: 26.5903,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 100/10000,\n",
      " train_loss: 896.2666,\n",
      " train_mae: 26.5845,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 101/10000,\n",
      " train_loss: 895.7122,\n",
      " train_mae: 26.5432,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 102/10000,\n",
      " train_loss: 893.1200,\n",
      " train_mae: 26.4135,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 103/10000,\n",
      " train_loss: 885.1932,\n",
      " train_mae: 26.2009,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 104/10000,\n",
      " train_loss: 873.7490,\n",
      " train_mae: 25.9632,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 105/10000,\n",
      " train_loss: 870.0516,\n",
      " train_mae: 25.8510,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 106/10000,\n",
      " train_loss: 870.5014,\n",
      " train_mae: 25.7739,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 107/10000,\n",
      " train_loss: 867.5229,\n",
      " train_mae: 25.6307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 108/10000,\n",
      " train_loss: 861.7965,\n",
      " train_mae: 25.5927,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 109/10000,\n",
      " train_loss: 864.7092,\n",
      " train_mae: 25.6561,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 110/10000,\n",
      " train_loss: 864.0833,\n",
      " train_mae: 25.5727,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 111/10000,\n",
      " train_loss: 854.4782,\n",
      " train_mae: 25.8484,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 112/10000,\n",
      " train_loss: 856.5946,\n",
      " train_mae: 25.9758,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 113/10000,\n",
      " train_loss: 859.1998,\n",
      " train_mae: 26.0241,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 114/10000,\n",
      " train_loss: 859.7930,\n",
      " train_mae: 25.9942,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 115/10000,\n",
      " train_loss: 857.7511,\n",
      " train_mae: 25.8220,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 116/10000,\n",
      " train_loss: 853.3597,\n",
      " train_mae: 25.8322,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 117/10000,\n",
      " train_loss: 856.7487,\n",
      " train_mae: 25.8709,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 118/10000,\n",
      " train_loss: 858.5410,\n",
      " train_mae: 25.7909,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 119/10000,\n",
      " train_loss: 854.1005,\n",
      " train_mae: 25.9063,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 120/10000,\n",
      " train_loss: 854.8033,\n",
      " train_mae: 25.9781,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 121/10000,\n",
      " train_loss: 856.6354,\n",
      " train_mae: 25.9019,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 122/10000,\n",
      " train_loss: 854.5654,\n",
      " train_mae: 25.7416,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 123/10000,\n",
      " train_loss: 852.1403,\n",
      " train_mae: 25.7391,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 124/10000,\n",
      " train_loss: 853.4782,\n",
      " train_mae: 25.7251,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 125/10000,\n",
      " train_loss: 853.5333,\n",
      " train_mae: 25.6410,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 126/10000,\n",
      " train_loss: 851.4791,\n",
      " train_mae: 25.7086,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 127/10000,\n",
      " train_loss: 851.7664,\n",
      " train_mae: 25.7579,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 128/10000,\n",
      " train_loss: 852.8923,\n",
      " train_mae: 25.6961,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 129/10000,\n",
      " train_loss: 852.1617,\n",
      " train_mae: 25.5788,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 130/10000,\n",
      " train_loss: 851.4123,\n",
      " train_mae: 25.6017,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 131/10000,\n",
      " train_loss: 852.1057,\n",
      " train_mae: 25.6118,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 132/10000,\n",
      " train_loss: 852.4152,\n",
      " train_mae: 25.5874,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 133/10000,\n",
      " train_loss: 851.5861,\n",
      " train_mae: 25.5914,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 134/10000,\n",
      " train_loss: 851.1813,\n",
      " train_mae: 25.6651,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 135/10000,\n",
      " train_loss: 851.5658,\n",
      " train_mae: 25.6731,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 136/10000,\n",
      " train_loss: 851.4209,\n",
      " train_mae: 25.6224,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 137/10000,\n",
      " train_loss: 850.7806,\n",
      " train_mae: 25.6233,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 138/10000,\n",
      " train_loss: 850.7025,\n",
      " train_mae: 25.6531,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 139/10000,\n",
      " train_loss: 850.9678,\n",
      " train_mae: 25.6601,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 140/10000,\n",
      " train_loss: 850.8686,\n",
      " train_mae: 25.6491,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 141/10000,\n",
      " train_loss: 850.5676,\n",
      " train_mae: 25.6560,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 142/10000,\n",
      " train_loss: 850.5908,\n",
      " train_mae: 25.6860,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 143/10000,\n",
      " train_loss: 850.7903,\n",
      " train_mae: 25.6815,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 144/10000,\n",
      " train_loss: 850.7383,\n",
      " train_mae: 25.6509,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 145/10000,\n",
      " train_loss: 850.5205,\n",
      " train_mae: 25.6593,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 146/10000,\n",
      " train_loss: 850.4570,\n",
      " train_mae: 25.6671,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 147/10000,\n",
      " train_loss: 850.5292,\n",
      " train_mae: 25.6630,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 148/10000,\n",
      " train_loss: 850.4819,\n",
      " train_mae: 25.6491,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 149/10000,\n",
      " train_loss: 850.3145,\n",
      " train_mae: 25.6305,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 150/10000,\n",
      " train_loss: 850.2391,\n",
      " train_mae: 25.6143,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 151/10000,\n",
      " train_loss: 850.2735,\n",
      " train_mae: 25.6134,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 152/10000,\n",
      " train_loss: 850.2885,\n",
      " train_mae: 25.6055,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 153/10000,\n",
      " train_loss: 850.2267,\n",
      " train_mae: 25.6128,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 154/10000,\n",
      " train_loss: 850.1678,\n",
      " train_mae: 25.6198,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 155/10000,\n",
      " train_loss: 850.1709,\n",
      " train_mae: 25.6237,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 156/10000,\n",
      " train_loss: 850.1974,\n",
      " train_mae: 25.6238,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 157/10000,\n",
      " train_loss: 850.1793,\n",
      " train_mae: 25.6209,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 158/10000,\n",
      " train_loss: 850.1208,\n",
      " train_mae: 25.6169,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 159/10000,\n",
      " train_loss: 850.0800,\n",
      " train_mae: 25.6141,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 160/10000,\n",
      " train_loss: 850.0727,\n",
      " train_mae: 25.6150,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 161/10000,\n",
      " train_loss: 850.0664,\n",
      " train_mae: 25.6203,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 162/10000,\n",
      " train_loss: 850.0370,\n",
      " train_mae: 25.6283,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 163/10000,\n",
      " train_loss: 849.9974,\n",
      " train_mae: 25.6365,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 164/10000,\n",
      " train_loss: 849.9750,\n",
      " train_mae: 25.6428,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 165/10000,\n",
      " train_loss: 849.9756,\n",
      " train_mae: 25.6463,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 166/10000,\n",
      " train_loss: 849.9736,\n",
      " train_mae: 25.6468,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 167/10000,\n",
      " train_loss: 849.9525,\n",
      " train_mae: 25.6451,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 168/10000,\n",
      " train_loss: 849.9280,\n",
      " train_mae: 25.6426,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 169/10000,\n",
      " train_loss: 849.9171,\n",
      " train_mae: 25.6407,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 170/10000,\n",
      " train_loss: 849.9117,\n",
      " train_mae: 25.6400,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 171/10000,\n",
      " train_loss: 849.8975,\n",
      " train_mae: 25.6405,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 172/10000,\n",
      " train_loss: 849.8740,\n",
      " train_mae: 25.6414,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 173/10000,\n",
      " train_loss: 849.8530,\n",
      " train_mae: 25.6419,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 174/10000,\n",
      " train_loss: 849.8417,\n",
      " train_mae: 25.6414,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 175/10000,\n",
      " train_loss: 849.8331,\n",
      " train_mae: 25.6398,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 176/10000,\n",
      " train_loss: 849.8188,\n",
      " train_mae: 25.6375,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 177/10000,\n",
      " train_loss: 849.8013,\n",
      " train_mae: 25.6352,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 178/10000,\n",
      " train_loss: 849.7888,\n",
      " train_mae: 25.6336,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 179/10000,\n",
      " train_loss: 849.7803,\n",
      " train_mae: 25.6332,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 180/10000,\n",
      " train_loss: 849.7695,\n",
      " train_mae: 25.6339,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 181/10000,\n",
      " train_loss: 849.7550,\n",
      " train_mae: 25.6355,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 182/10000,\n",
      " train_loss: 849.7389,\n",
      " train_mae: 25.6373,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 183/10000,\n",
      " train_loss: 849.7258,\n",
      " train_mae: 25.6389,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 184/10000,\n",
      " train_loss: 849.7150,\n",
      " train_mae: 25.6399,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 185/10000,\n",
      " train_loss: 849.7018,\n",
      " train_mae: 25.6404,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 186/10000,\n",
      " train_loss: 849.6865,\n",
      " train_mae: 25.6407,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 187/10000,\n",
      " train_loss: 849.6728,\n",
      " train_mae: 25.6410,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 188/10000,\n",
      " train_loss: 849.6615,\n",
      " train_mae: 25.6415,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 189/10000,\n",
      " train_loss: 849.6494,\n",
      " train_mae: 25.6423,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 190/10000,\n",
      " train_loss: 849.6364,\n",
      " train_mae: 25.6432,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 191/10000,\n",
      " train_loss: 849.6221,\n",
      " train_mae: 25.6439,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 192/10000,\n",
      " train_loss: 849.6096,\n",
      " train_mae: 25.6441,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 193/10000,\n",
      " train_loss: 849.5977,\n",
      " train_mae: 25.6438,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 194/10000,\n",
      " train_loss: 849.5837,\n",
      " train_mae: 25.6431,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 195/10000,\n",
      " train_loss: 849.5697,\n",
      " train_mae: 25.6423,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 196/10000,\n",
      " train_loss: 849.5560,\n",
      " train_mae: 25.6415,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 197/10000,\n",
      " train_loss: 849.5429,\n",
      " train_mae: 25.6410,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 198/10000,\n",
      " train_loss: 849.5292,\n",
      " train_mae: 25.6407,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 199/10000,\n",
      " train_loss: 849.5147,\n",
      " train_mae: 25.6406,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 200/10000,\n",
      " train_loss: 849.5012,\n",
      " train_mae: 25.6405,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 201/10000,\n",
      " train_loss: 849.4873,\n",
      " train_mae: 25.6403,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 202/10000,\n",
      " train_loss: 849.4738,\n",
      " train_mae: 25.6401,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 203/10000,\n",
      " train_loss: 849.4594,\n",
      " train_mae: 25.6398,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 204/10000,\n",
      " train_loss: 849.4448,\n",
      " train_mae: 25.6397,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 205/10000,\n",
      " train_loss: 849.4305,\n",
      " train_mae: 25.6397,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 206/10000,\n",
      " train_loss: 849.4160,\n",
      " train_mae: 25.6400,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 207/10000,\n",
      " train_loss: 849.4007,\n",
      " train_mae: 25.6403,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 208/10000,\n",
      " train_loss: 849.3856,\n",
      " train_mae: 25.6406,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 209/10000,\n",
      " train_loss: 849.3711,\n",
      " train_mae: 25.6408,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 210/10000,\n",
      " train_loss: 849.3560,\n",
      " train_mae: 25.6408,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 211/10000,\n",
      " train_loss: 849.3405,\n",
      " train_mae: 25.6407,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 212/10000,\n",
      " train_loss: 849.3253,\n",
      " train_mae: 25.6405,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 213/10000,\n",
      " train_loss: 849.3098,\n",
      " train_mae: 25.6404,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 214/10000,\n",
      " train_loss: 849.2939,\n",
      " train_mae: 25.6402,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 215/10000,\n",
      " train_loss: 849.2778,\n",
      " train_mae: 25.6401,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 216/10000,\n",
      " train_loss: 849.2621,\n",
      " train_mae: 25.6398,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 217/10000,\n",
      " train_loss: 849.2457,\n",
      " train_mae: 25.6394,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 218/10000,\n",
      " train_loss: 849.2291,\n",
      " train_mae: 25.6390,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 219/10000,\n",
      " train_loss: 849.2126,\n",
      " train_mae: 25.6385,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 220/10000,\n",
      " train_loss: 849.1959,\n",
      " train_mae: 25.6381,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 221/10000,\n",
      " train_loss: 849.1791,\n",
      " train_mae: 25.6378,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 222/10000,\n",
      " train_loss: 849.1620,\n",
      " train_mae: 25.6375,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 223/10000,\n",
      " train_loss: 849.1448,\n",
      " train_mae: 25.6372,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 224/10000,\n",
      " train_loss: 849.1271,\n",
      " train_mae: 25.6370,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 225/10000,\n",
      " train_loss: 849.1099,\n",
      " train_mae: 25.6367,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 226/10000,\n",
      " train_loss: 849.0915,\n",
      " train_mae: 25.6364,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 227/10000,\n",
      " train_loss: 849.0737,\n",
      " train_mae: 25.6361,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 228/10000,\n",
      " train_loss: 849.0557,\n",
      " train_mae: 25.6359,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 229/10000,\n",
      " train_loss: 849.0374,\n",
      " train_mae: 25.6357,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 230/10000,\n",
      " train_loss: 849.0189,\n",
      " train_mae: 25.6355,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 231/10000,\n",
      " train_loss: 849.0002,\n",
      " train_mae: 25.6353,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 232/10000,\n",
      " train_loss: 848.9812,\n",
      " train_mae: 25.6350,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 233/10000,\n",
      " train_loss: 848.9623,\n",
      " train_mae: 25.6347,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 234/10000,\n",
      " train_loss: 848.9433,\n",
      " train_mae: 25.6344,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 235/10000,\n",
      " train_loss: 848.9235,\n",
      " train_mae: 25.6340,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 236/10000,\n",
      " train_loss: 848.9047,\n",
      " train_mae: 25.6337,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 237/10000,\n",
      " train_loss: 848.8844,\n",
      " train_mae: 25.6333,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 238/10000,\n",
      " train_loss: 848.8645,\n",
      " train_mae: 25.6329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 239/10000,\n",
      " train_loss: 848.8450,\n",
      " train_mae: 25.6324,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 240/10000,\n",
      " train_loss: 848.8243,\n",
      " train_mae: 25.6320,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 241/10000,\n",
      " train_loss: 848.8040,\n",
      " train_mae: 25.6315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 242/10000,\n",
      " train_loss: 848.7834,\n",
      " train_mae: 25.6311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 243/10000,\n",
      " train_loss: 848.7628,\n",
      " train_mae: 25.6307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 244/10000,\n",
      " train_loss: 848.7416,\n",
      " train_mae: 25.6303,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 245/10000,\n",
      " train_loss: 848.7206,\n",
      " train_mae: 25.6299,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 246/10000,\n",
      " train_loss: 848.6993,\n",
      " train_mae: 25.6295,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 247/10000,\n",
      " train_loss: 848.6780,\n",
      " train_mae: 25.6290,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 248/10000,\n",
      " train_loss: 848.6562,\n",
      " train_mae: 25.6286,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 249/10000,\n",
      " train_loss: 848.6345,\n",
      " train_mae: 25.6283,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 250/10000,\n",
      " train_loss: 848.6125,\n",
      " train_mae: 25.6279,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 251/10000,\n",
      " train_loss: 848.5901,\n",
      " train_mae: 25.6275,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 252/10000,\n",
      " train_loss: 848.5680,\n",
      " train_mae: 25.6270,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 253/10000,\n",
      " train_loss: 848.5456,\n",
      " train_mae: 25.6266,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 254/10000,\n",
      " train_loss: 848.5232,\n",
      " train_mae: 25.6262,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 255/10000,\n",
      " train_loss: 848.5009,\n",
      " train_mae: 25.6257,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 256/10000,\n",
      " train_loss: 848.4779,\n",
      " train_mae: 25.6253,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 257/10000,\n",
      " train_loss: 848.4548,\n",
      " train_mae: 25.6248,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 258/10000,\n",
      " train_loss: 848.4319,\n",
      " train_mae: 25.6244,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 259/10000,\n",
      " train_loss: 848.4088,\n",
      " train_mae: 25.6239,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 260/10000,\n",
      " train_loss: 848.3853,\n",
      " train_mae: 25.6234,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 261/10000,\n",
      " train_loss: 848.3620,\n",
      " train_mae: 25.6229,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 262/10000,\n",
      " train_loss: 848.3382,\n",
      " train_mae: 25.6224,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 263/10000,\n",
      " train_loss: 848.3146,\n",
      " train_mae: 25.6219,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 264/10000,\n",
      " train_loss: 848.2905,\n",
      " train_mae: 25.6214,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 265/10000,\n",
      " train_loss: 848.2667,\n",
      " train_mae: 25.6210,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 266/10000,\n",
      " train_loss: 848.2430,\n",
      " train_mae: 25.6205,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 267/10000,\n",
      " train_loss: 848.2187,\n",
      " train_mae: 25.6200,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 268/10000,\n",
      " train_loss: 848.1947,\n",
      " train_mae: 25.6195,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 269/10000,\n",
      " train_loss: 848.1706,\n",
      " train_mae: 25.6191,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 270/10000,\n",
      " train_loss: 848.1458,\n",
      " train_mae: 25.6186,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 271/10000,\n",
      " train_loss: 848.1213,\n",
      " train_mae: 25.6181,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 272/10000,\n",
      " train_loss: 848.0968,\n",
      " train_mae: 25.6176,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 273/10000,\n",
      " train_loss: 848.0722,\n",
      " train_mae: 25.6171,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 274/10000,\n",
      " train_loss: 848.0474,\n",
      " train_mae: 25.6167,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 275/10000,\n",
      " train_loss: 848.0225,\n",
      " train_mae: 25.6162,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 276/10000,\n",
      " train_loss: 847.9977,\n",
      " train_mae: 25.6157,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 277/10000,\n",
      " train_loss: 847.9730,\n",
      " train_mae: 25.6152,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 278/10000,\n",
      " train_loss: 847.9478,\n",
      " train_mae: 25.6147,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 279/10000,\n",
      " train_loss: 847.9231,\n",
      " train_mae: 25.6142,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 280/10000,\n",
      " train_loss: 847.8984,\n",
      " train_mae: 25.6137,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 281/10000,\n",
      " train_loss: 847.8730,\n",
      " train_mae: 25.6132,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 282/10000,\n",
      " train_loss: 847.8479,\n",
      " train_mae: 25.6127,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 283/10000,\n",
      " train_loss: 847.8229,\n",
      " train_mae: 25.6122,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 284/10000,\n",
      " train_loss: 847.7980,\n",
      " train_mae: 25.6117,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 285/10000,\n",
      " train_loss: 847.7729,\n",
      " train_mae: 25.6112,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 286/10000,\n",
      " train_loss: 847.7477,\n",
      " train_mae: 25.6107,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 287/10000,\n",
      " train_loss: 847.7221,\n",
      " train_mae: 25.6103,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 288/10000,\n",
      " train_loss: 847.6971,\n",
      " train_mae: 25.6098,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 289/10000,\n",
      " train_loss: 847.6721,\n",
      " train_mae: 25.6093,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 290/10000,\n",
      " train_loss: 847.6474,\n",
      " train_mae: 25.6088,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 291/10000,\n",
      " train_loss: 847.6217,\n",
      " train_mae: 25.6083,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 292/10000,\n",
      " train_loss: 847.5967,\n",
      " train_mae: 25.6079,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 293/10000,\n",
      " train_loss: 847.5717,\n",
      " train_mae: 25.6074,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 294/10000,\n",
      " train_loss: 847.5466,\n",
      " train_mae: 25.6069,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 295/10000,\n",
      " train_loss: 847.5217,\n",
      " train_mae: 25.6064,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 296/10000,\n",
      " train_loss: 847.4965,\n",
      " train_mae: 25.6059,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 297/10000,\n",
      " train_loss: 847.4718,\n",
      " train_mae: 25.6055,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 298/10000,\n",
      " train_loss: 847.4467,\n",
      " train_mae: 25.6050,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 299/10000,\n",
      " train_loss: 847.4221,\n",
      " train_mae: 25.6045,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 300/10000,\n",
      " train_loss: 847.3972,\n",
      " train_mae: 25.6040,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 301/10000,\n",
      " train_loss: 847.3725,\n",
      " train_mae: 25.6036,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 302/10000,\n",
      " train_loss: 847.3481,\n",
      " train_mae: 25.6031,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 303/10000,\n",
      " train_loss: 847.3234,\n",
      " train_mae: 25.6026,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 304/10000,\n",
      " train_loss: 847.2991,\n",
      " train_mae: 25.6022,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 305/10000,\n",
      " train_loss: 847.2745,\n",
      " train_mae: 25.6017,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 306/10000,\n",
      " train_loss: 847.2503,\n",
      " train_mae: 25.6013,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 307/10000,\n",
      " train_loss: 847.2260,\n",
      " train_mae: 25.6008,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 308/10000,\n",
      " train_loss: 847.2019,\n",
      " train_mae: 25.6004,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 309/10000,\n",
      " train_loss: 847.1777,\n",
      " train_mae: 25.5999,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 310/10000,\n",
      " train_loss: 847.1537,\n",
      " train_mae: 25.5995,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 311/10000,\n",
      " train_loss: 847.1301,\n",
      " train_mae: 25.5990,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 312/10000,\n",
      " train_loss: 847.1063,\n",
      " train_mae: 25.5986,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 313/10000,\n",
      " train_loss: 847.0827,\n",
      " train_mae: 25.5982,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 314/10000,\n",
      " train_loss: 847.0591,\n",
      " train_mae: 25.5977,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 315/10000,\n",
      " train_loss: 847.0358,\n",
      " train_mae: 25.5973,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 316/10000,\n",
      " train_loss: 847.0121,\n",
      " train_mae: 25.5969,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 317/10000,\n",
      " train_loss: 846.9893,\n",
      " train_mae: 25.5964,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 318/10000,\n",
      " train_loss: 846.9661,\n",
      " train_mae: 25.5960,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 319/10000,\n",
      " train_loss: 846.9434,\n",
      " train_mae: 25.5956,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 320/10000,\n",
      " train_loss: 846.9203,\n",
      " train_mae: 25.5952,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 321/10000,\n",
      " train_loss: 846.8975,\n",
      " train_mae: 25.5948,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 322/10000,\n",
      " train_loss: 846.8755,\n",
      " train_mae: 25.5944,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 323/10000,\n",
      " train_loss: 846.8527,\n",
      " train_mae: 25.5940,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 324/10000,\n",
      " train_loss: 846.8305,\n",
      " train_mae: 25.5936,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 325/10000,\n",
      " train_loss: 846.8087,\n",
      " train_mae: 25.5932,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 326/10000,\n",
      " train_loss: 846.7864,\n",
      " train_mae: 25.5928,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 327/10000,\n",
      " train_loss: 846.7649,\n",
      " train_mae: 25.5924,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 328/10000,\n",
      " train_loss: 846.7433,\n",
      " train_mae: 25.5920,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 329/10000,\n",
      " train_loss: 846.7213,\n",
      " train_mae: 25.5916,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 330/10000,\n",
      " train_loss: 846.6998,\n",
      " train_mae: 25.5912,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 331/10000,\n",
      " train_loss: 846.6787,\n",
      " train_mae: 25.5908,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 332/10000,\n",
      " train_loss: 846.6575,\n",
      " train_mae: 25.5904,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 333/10000,\n",
      " train_loss: 846.6367,\n",
      " train_mae: 25.5901,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 334/10000,\n",
      " train_loss: 846.6158,\n",
      " train_mae: 25.5897,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 335/10000,\n",
      " train_loss: 846.5952,\n",
      " train_mae: 25.5893,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 336/10000,\n",
      " train_loss: 846.5748,\n",
      " train_mae: 25.5890,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 337/10000,\n",
      " train_loss: 846.5546,\n",
      " train_mae: 25.5886,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 338/10000,\n",
      " train_loss: 846.5342,\n",
      " train_mae: 25.5882,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 339/10000,\n",
      " train_loss: 846.5142,\n",
      " train_mae: 25.5879,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 340/10000,\n",
      " train_loss: 846.4944,\n",
      " train_mae: 25.5875,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 341/10000,\n",
      " train_loss: 846.4744,\n",
      " train_mae: 25.5872,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 342/10000,\n",
      " train_loss: 846.4550,\n",
      " train_mae: 25.5868,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 343/10000,\n",
      " train_loss: 846.4356,\n",
      " train_mae: 25.5865,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 344/10000,\n",
      " train_loss: 846.4166,\n",
      " train_mae: 25.5861,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 345/10000,\n",
      " train_loss: 846.3973,\n",
      " train_mae: 25.5858,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 346/10000,\n",
      " train_loss: 846.3783,\n",
      " train_mae: 25.5855,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 347/10000,\n",
      " train_loss: 846.3595,\n",
      " train_mae: 25.5851,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 348/10000,\n",
      " train_loss: 846.3411,\n",
      " train_mae: 25.5848,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 349/10000,\n",
      " train_loss: 846.3226,\n",
      " train_mae: 25.5845,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 350/10000,\n",
      " train_loss: 846.3040,\n",
      " train_mae: 25.5842,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 351/10000,\n",
      " train_loss: 846.2860,\n",
      " train_mae: 25.5838,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 352/10000,\n",
      " train_loss: 846.2680,\n",
      " train_mae: 25.5835,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 353/10000,\n",
      " train_loss: 846.2498,\n",
      " train_mae: 25.5832,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 354/10000,\n",
      " train_loss: 846.2322,\n",
      " train_mae: 25.5829,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 355/10000,\n",
      " train_loss: 846.2148,\n",
      " train_mae: 25.5826,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 356/10000,\n",
      " train_loss: 846.1975,\n",
      " train_mae: 25.5823,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 357/10000,\n",
      " train_loss: 846.1801,\n",
      " train_mae: 25.5820,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 358/10000,\n",
      " train_loss: 846.1632,\n",
      " train_mae: 25.5817,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 359/10000,\n",
      " train_loss: 846.1462,\n",
      " train_mae: 25.5814,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 360/10000,\n",
      " train_loss: 846.1292,\n",
      " train_mae: 25.5811,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 361/10000,\n",
      " train_loss: 846.1125,\n",
      " train_mae: 25.5808,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 362/10000,\n",
      " train_loss: 846.0961,\n",
      " train_mae: 25.5805,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 363/10000,\n",
      " train_loss: 846.0801,\n",
      " train_mae: 25.5802,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 364/10000,\n",
      " train_loss: 846.0638,\n",
      " train_mae: 25.5799,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 365/10000,\n",
      " train_loss: 846.0476,\n",
      " train_mae: 25.5796,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 366/10000,\n",
      " train_loss: 846.0317,\n",
      " train_mae: 25.5794,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 367/10000,\n",
      " train_loss: 846.0159,\n",
      " train_mae: 25.5791,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 368/10000,\n",
      " train_loss: 846.0002,\n",
      " train_mae: 25.5788,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 369/10000,\n",
      " train_loss: 845.9847,\n",
      " train_mae: 25.5785,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 370/10000,\n",
      " train_loss: 845.9694,\n",
      " train_mae: 25.5783,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 371/10000,\n",
      " train_loss: 845.9543,\n",
      " train_mae: 25.5780,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 372/10000,\n",
      " train_loss: 845.9391,\n",
      " train_mae: 25.5777,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 373/10000,\n",
      " train_loss: 845.9244,\n",
      " train_mae: 25.5775,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 374/10000,\n",
      " train_loss: 845.9094,\n",
      " train_mae: 25.5772,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 375/10000,\n",
      " train_loss: 845.8948,\n",
      " train_mae: 25.5769,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 376/10000,\n",
      " train_loss: 845.8801,\n",
      " train_mae: 25.5767,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 377/10000,\n",
      " train_loss: 845.8657,\n",
      " train_mae: 25.5764,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 378/10000,\n",
      " train_loss: 845.8515,\n",
      " train_mae: 25.5762,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 379/10000,\n",
      " train_loss: 845.8375,\n",
      " train_mae: 25.5759,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 380/10000,\n",
      " train_loss: 845.8232,\n",
      " train_mae: 25.5757,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 381/10000,\n",
      " train_loss: 845.8095,\n",
      " train_mae: 25.5754,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 382/10000,\n",
      " train_loss: 845.7958,\n",
      " train_mae: 25.5752,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 383/10000,\n",
      " train_loss: 845.7821,\n",
      " train_mae: 25.5749,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 384/10000,\n",
      " train_loss: 845.7686,\n",
      " train_mae: 25.5747,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 385/10000,\n",
      " train_loss: 845.7548,\n",
      " train_mae: 25.5745,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 386/10000,\n",
      " train_loss: 845.7418,\n",
      " train_mae: 25.5742,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 387/10000,\n",
      " train_loss: 845.7286,\n",
      " train_mae: 25.5740,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 388/10000,\n",
      " train_loss: 845.7157,\n",
      " train_mae: 25.5738,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 389/10000,\n",
      " train_loss: 845.7026,\n",
      " train_mae: 25.5735,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 390/10000,\n",
      " train_loss: 845.6900,\n",
      " train_mae: 25.5733,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 391/10000,\n",
      " train_loss: 845.6771,\n",
      " train_mae: 25.5731,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 392/10000,\n",
      " train_loss: 845.6645,\n",
      " train_mae: 25.5729,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 393/10000,\n",
      " train_loss: 845.6523,\n",
      " train_mae: 25.5726,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 394/10000,\n",
      " train_loss: 845.6398,\n",
      " train_mae: 25.5724,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 395/10000,\n",
      " train_loss: 845.6275,\n",
      " train_mae: 25.5722,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 396/10000,\n",
      " train_loss: 845.6154,\n",
      " train_mae: 25.5720,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 397/10000,\n",
      " train_loss: 845.6035,\n",
      " train_mae: 25.5718,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 398/10000,\n",
      " train_loss: 845.5912,\n",
      " train_mae: 25.5715,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 399/10000,\n",
      " train_loss: 845.5795,\n",
      " train_mae: 25.5713,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 400/10000,\n",
      " train_loss: 845.5676,\n",
      " train_mae: 25.5711,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 401/10000,\n",
      " train_loss: 845.5561,\n",
      " train_mae: 25.5709,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 402/10000,\n",
      " train_loss: 845.5446,\n",
      " train_mae: 25.5707,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 403/10000,\n",
      " train_loss: 845.5331,\n",
      " train_mae: 25.5705,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 404/10000,\n",
      " train_loss: 845.5217,\n",
      " train_mae: 25.5703,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 405/10000,\n",
      " train_loss: 845.5108,\n",
      " train_mae: 25.5701,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 406/10000,\n",
      " train_loss: 845.4991,\n",
      " train_mae: 25.5698,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 407/10000,\n",
      " train_loss: 845.4882,\n",
      " train_mae: 25.5696,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 408/10000,\n",
      " train_loss: 845.4772,\n",
      " train_mae: 25.5694,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 409/10000,\n",
      " train_loss: 845.4664,\n",
      " train_mae: 25.5692,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 410/10000,\n",
      " train_loss: 845.4556,\n",
      " train_mae: 25.5690,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 411/10000,\n",
      " train_loss: 845.4450,\n",
      " train_mae: 25.5689,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 412/10000,\n",
      " train_loss: 845.4344,\n",
      " train_mae: 25.5687,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 413/10000,\n",
      " train_loss: 845.4238,\n",
      " train_mae: 25.5685,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 414/10000,\n",
      " train_loss: 845.4133,\n",
      " train_mae: 25.5683,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 415/10000,\n",
      " train_loss: 845.4030,\n",
      " train_mae: 25.5681,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 416/10000,\n",
      " train_loss: 845.3928,\n",
      " train_mae: 25.5679,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 417/10000,\n",
      " train_loss: 845.3825,\n",
      " train_mae: 25.5677,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 418/10000,\n",
      " train_loss: 845.3725,\n",
      " train_mae: 25.5675,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 419/10000,\n",
      " train_loss: 845.3625,\n",
      " train_mae: 25.5673,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 420/10000,\n",
      " train_loss: 845.3524,\n",
      " train_mae: 25.5671,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 421/10000,\n",
      " train_loss: 845.3423,\n",
      " train_mae: 25.5669,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 422/10000,\n",
      " train_loss: 845.3329,\n",
      " train_mae: 25.5667,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 423/10000,\n",
      " train_loss: 845.3228,\n",
      " train_mae: 25.5665,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 424/10000,\n",
      " train_loss: 845.3135,\n",
      " train_mae: 25.5664,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 425/10000,\n",
      " train_loss: 845.3037,\n",
      " train_mae: 25.5662,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 426/10000,\n",
      " train_loss: 845.2943,\n",
      " train_mae: 25.5660,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 427/10000,\n",
      " train_loss: 845.2850,\n",
      " train_mae: 25.5658,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 428/10000,\n",
      " train_loss: 845.2755,\n",
      " train_mae: 25.5656,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 429/10000,\n",
      " train_loss: 845.2661,\n",
      " train_mae: 25.5655,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 430/10000,\n",
      " train_loss: 845.2569,\n",
      " train_mae: 25.5653,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 431/10000,\n",
      " train_loss: 845.2477,\n",
      " train_mae: 25.5651,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 432/10000,\n",
      " train_loss: 845.2386,\n",
      " train_mae: 25.5649,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 433/10000,\n",
      " train_loss: 845.2296,\n",
      " train_mae: 25.5647,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 434/10000,\n",
      " train_loss: 845.2205,\n",
      " train_mae: 25.5646,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 435/10000,\n",
      " train_loss: 845.2115,\n",
      " train_mae: 25.5644,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 436/10000,\n",
      " train_loss: 845.2030,\n",
      " train_mae: 25.5642,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 437/10000,\n",
      " train_loss: 845.1940,\n",
      " train_mae: 25.5640,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 438/10000,\n",
      " train_loss: 845.1850,\n",
      " train_mae: 25.5639,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 439/10000,\n",
      " train_loss: 845.1765,\n",
      " train_mae: 25.5637,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 440/10000,\n",
      " train_loss: 845.1682,\n",
      " train_mae: 25.5635,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 441/10000,\n",
      " train_loss: 845.1594,\n",
      " train_mae: 25.5633,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 442/10000,\n",
      " train_loss: 845.1511,\n",
      " train_mae: 25.5632,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 443/10000,\n",
      " train_loss: 845.1426,\n",
      " train_mae: 25.5630,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 444/10000,\n",
      " train_loss: 845.1342,\n",
      " train_mae: 25.5628,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 445/10000,\n",
      " train_loss: 845.1260,\n",
      " train_mae: 25.5627,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 446/10000,\n",
      " train_loss: 845.1175,\n",
      " train_mae: 25.5625,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 447/10000,\n",
      " train_loss: 845.1094,\n",
      " train_mae: 25.5623,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 448/10000,\n",
      " train_loss: 845.1010,\n",
      " train_mae: 25.5621,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 449/10000,\n",
      " train_loss: 845.0928,\n",
      " train_mae: 25.5620,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 450/10000,\n",
      " train_loss: 845.0848,\n",
      " train_mae: 25.5618,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 451/10000,\n",
      " train_loss: 845.0769,\n",
      " train_mae: 25.5616,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 452/10000,\n",
      " train_loss: 845.0688,\n",
      " train_mae: 25.5615,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 453/10000,\n",
      " train_loss: 845.0611,\n",
      " train_mae: 25.5613,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 454/10000,\n",
      " train_loss: 845.0529,\n",
      " train_mae: 25.5611,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 455/10000,\n",
      " train_loss: 845.0451,\n",
      " train_mae: 25.5610,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 456/10000,\n",
      " train_loss: 845.0374,\n",
      " train_mae: 25.5608,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 457/10000,\n",
      " train_loss: 845.0295,\n",
      " train_mae: 25.5606,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 458/10000,\n",
      " train_loss: 845.0218,\n",
      " train_mae: 25.5605,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 459/10000,\n",
      " train_loss: 845.0142,\n",
      " train_mae: 25.5603,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 460/10000,\n",
      " train_loss: 845.0065,\n",
      " train_mae: 25.5601,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 461/10000,\n",
      " train_loss: 844.9990,\n",
      " train_mae: 25.5600,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 462/10000,\n",
      " train_loss: 844.9916,\n",
      " train_mae: 25.5598,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 463/10000,\n",
      " train_loss: 844.9840,\n",
      " train_mae: 25.5597,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 464/10000,\n",
      " train_loss: 844.9766,\n",
      " train_mae: 25.5595,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 465/10000,\n",
      " train_loss: 844.9692,\n",
      " train_mae: 25.5593,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 466/10000,\n",
      " train_loss: 844.9620,\n",
      " train_mae: 25.5592,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 467/10000,\n",
      " train_loss: 844.9543,\n",
      " train_mae: 25.5590,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 468/10000,\n",
      " train_loss: 844.9473,\n",
      " train_mae: 25.5588,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 469/10000,\n",
      " train_loss: 844.9399,\n",
      " train_mae: 25.5587,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 470/10000,\n",
      " train_loss: 844.9326,\n",
      " train_mae: 25.5585,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 471/10000,\n",
      " train_loss: 844.9254,\n",
      " train_mae: 25.5584,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 472/10000,\n",
      " train_loss: 844.9183,\n",
      " train_mae: 25.5582,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 473/10000,\n",
      " train_loss: 844.9111,\n",
      " train_mae: 25.5580,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 474/10000,\n",
      " train_loss: 844.9042,\n",
      " train_mae: 25.5579,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 475/10000,\n",
      " train_loss: 844.8971,\n",
      " train_mae: 25.5577,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 476/10000,\n",
      " train_loss: 844.8901,\n",
      " train_mae: 25.5576,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 477/10000,\n",
      " train_loss: 844.8831,\n",
      " train_mae: 25.5574,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 478/10000,\n",
      " train_loss: 844.8762,\n",
      " train_mae: 25.5572,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 479/10000,\n",
      " train_loss: 844.8692,\n",
      " train_mae: 25.5571,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 480/10000,\n",
      " train_loss: 844.8623,\n",
      " train_mae: 25.5569,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 481/10000,\n",
      " train_loss: 844.8552,\n",
      " train_mae: 25.5567,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 482/10000,\n",
      " train_loss: 844.8486,\n",
      " train_mae: 25.5566,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 483/10000,\n",
      " train_loss: 844.8419,\n",
      " train_mae: 25.5564,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 484/10000,\n",
      " train_loss: 844.8350,\n",
      " train_mae: 25.5563,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 485/10000,\n",
      " train_loss: 844.8283,\n",
      " train_mae: 25.5561,\n",
      " epoch_time_duration: 0.0199\n",
      "\n",
      "epoch: 486/10000,\n",
      " train_loss: 844.8217,\n",
      " train_mae: 25.5559,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 487/10000,\n",
      " train_loss: 844.8149,\n",
      " train_mae: 25.5558,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 488/10000,\n",
      " train_loss: 844.8082,\n",
      " train_mae: 25.5556,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 489/10000,\n",
      " train_loss: 844.8015,\n",
      " train_mae: 25.5555,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 490/10000,\n",
      " train_loss: 844.7952,\n",
      " train_mae: 25.5553,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 491/10000,\n",
      " train_loss: 844.7885,\n",
      " train_mae: 25.5551,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 492/10000,\n",
      " train_loss: 844.7819,\n",
      " train_mae: 25.5550,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 493/10000,\n",
      " train_loss: 844.7753,\n",
      " train_mae: 25.5548,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 494/10000,\n",
      " train_loss: 844.7689,\n",
      " train_mae: 25.5547,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 495/10000,\n",
      " train_loss: 844.7623,\n",
      " train_mae: 25.5545,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 496/10000,\n",
      " train_loss: 844.7559,\n",
      " train_mae: 25.5543,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 497/10000,\n",
      " train_loss: 844.7494,\n",
      " train_mae: 25.5542,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 498/10000,\n",
      " train_loss: 844.7432,\n",
      " train_mae: 25.5540,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 499/10000,\n",
      " train_loss: 844.7366,\n",
      " train_mae: 25.5539,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 500/10000,\n",
      " train_loss: 844.7305,\n",
      " train_mae: 25.5537,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 501/10000,\n",
      " train_loss: 844.7238,\n",
      " train_mae: 25.5536,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 502/10000,\n",
      " train_loss: 844.7175,\n",
      " train_mae: 25.5534,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 503/10000,\n",
      " train_loss: 844.7111,\n",
      " train_mae: 25.5532,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 504/10000,\n",
      " train_loss: 844.7051,\n",
      " train_mae: 25.5531,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 505/10000,\n",
      " train_loss: 844.6986,\n",
      " train_mae: 25.5529,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 506/10000,\n",
      " train_loss: 844.6924,\n",
      " train_mae: 25.5527,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 507/10000,\n",
      " train_loss: 844.6861,\n",
      " train_mae: 25.5526,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 508/10000,\n",
      " train_loss: 844.6799,\n",
      " train_mae: 25.5524,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 509/10000,\n",
      " train_loss: 844.6738,\n",
      " train_mae: 25.5523,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 510/10000,\n",
      " train_loss: 844.6675,\n",
      " train_mae: 25.5521,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 511/10000,\n",
      " train_loss: 844.6615,\n",
      " train_mae: 25.5520,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 512/10000,\n",
      " train_loss: 844.6553,\n",
      " train_mae: 25.5518,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 513/10000,\n",
      " train_loss: 844.6494,\n",
      " train_mae: 25.5516,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 514/10000,\n",
      " train_loss: 844.6431,\n",
      " train_mae: 25.5515,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 515/10000,\n",
      " train_loss: 844.6369,\n",
      " train_mae: 25.5513,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 516/10000,\n",
      " train_loss: 844.6310,\n",
      " train_mae: 25.5511,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 517/10000,\n",
      " train_loss: 844.6248,\n",
      " train_mae: 25.5510,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 518/10000,\n",
      " train_loss: 844.6190,\n",
      " train_mae: 25.5508,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 519/10000,\n",
      " train_loss: 844.6127,\n",
      " train_mae: 25.5507,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 520/10000,\n",
      " train_loss: 844.6067,\n",
      " train_mae: 25.5505,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 521/10000,\n",
      " train_loss: 844.6008,\n",
      " train_mae: 25.5503,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 522/10000,\n",
      " train_loss: 844.5947,\n",
      " train_mae: 25.5502,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 523/10000,\n",
      " train_loss: 844.5888,\n",
      " train_mae: 25.5500,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 524/10000,\n",
      " train_loss: 844.5828,\n",
      " train_mae: 25.5498,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 525/10000,\n",
      " train_loss: 844.5770,\n",
      " train_mae: 25.5497,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 526/10000,\n",
      " train_loss: 844.5709,\n",
      " train_mae: 25.5495,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 527/10000,\n",
      " train_loss: 844.5650,\n",
      " train_mae: 25.5493,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 528/10000,\n",
      " train_loss: 844.5590,\n",
      " train_mae: 25.5492,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 529/10000,\n",
      " train_loss: 844.5530,\n",
      " train_mae: 25.5490,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 530/10000,\n",
      " train_loss: 844.5472,\n",
      " train_mae: 25.5489,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 531/10000,\n",
      " train_loss: 844.5413,\n",
      " train_mae: 25.5487,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 532/10000,\n",
      " train_loss: 844.5355,\n",
      " train_mae: 25.5485,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 533/10000,\n",
      " train_loss: 844.5295,\n",
      " train_mae: 25.5484,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 534/10000,\n",
      " train_loss: 844.5238,\n",
      " train_mae: 25.5482,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 535/10000,\n",
      " train_loss: 844.5180,\n",
      " train_mae: 25.5480,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 536/10000,\n",
      " train_loss: 844.5121,\n",
      " train_mae: 25.5479,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 537/10000,\n",
      " train_loss: 844.5061,\n",
      " train_mae: 25.5477,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 538/10000,\n",
      " train_loss: 844.5003,\n",
      " train_mae: 25.5475,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 539/10000,\n",
      " train_loss: 844.4946,\n",
      " train_mae: 25.5474,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 540/10000,\n",
      " train_loss: 844.4888,\n",
      " train_mae: 25.5472,\n",
      " epoch_time_duration: 0.0155\n",
      "\n",
      "epoch: 541/10000,\n",
      " train_loss: 844.4830,\n",
      " train_mae: 25.5470,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 542/10000,\n",
      " train_loss: 844.4771,\n",
      " train_mae: 25.5469,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 543/10000,\n",
      " train_loss: 844.4713,\n",
      " train_mae: 25.5467,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 544/10000,\n",
      " train_loss: 844.4653,\n",
      " train_mae: 25.5465,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 545/10000,\n",
      " train_loss: 844.4598,\n",
      " train_mae: 25.5464,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 546/10000,\n",
      " train_loss: 844.4541,\n",
      " train_mae: 25.5462,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 547/10000,\n",
      " train_loss: 844.4484,\n",
      " train_mae: 25.5460,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 548/10000,\n",
      " train_loss: 844.4427,\n",
      " train_mae: 25.5459,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 549/10000,\n",
      " train_loss: 844.4370,\n",
      " train_mae: 25.5457,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 550/10000,\n",
      " train_loss: 844.4310,\n",
      " train_mae: 25.5455,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 551/10000,\n",
      " train_loss: 844.4254,\n",
      " train_mae: 25.5454,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 552/10000,\n",
      " train_loss: 844.4197,\n",
      " train_mae: 25.5452,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 553/10000,\n",
      " train_loss: 844.4138,\n",
      " train_mae: 25.5450,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 554/10000,\n",
      " train_loss: 844.4083,\n",
      " train_mae: 25.5449,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 555/10000,\n",
      " train_loss: 844.4025,\n",
      " train_mae: 25.5447,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 556/10000,\n",
      " train_loss: 844.3969,\n",
      " train_mae: 25.5445,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 557/10000,\n",
      " train_loss: 844.3912,\n",
      " train_mae: 25.5443,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 558/10000,\n",
      " train_loss: 844.3852,\n",
      " train_mae: 25.5442,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 559/10000,\n",
      " train_loss: 844.3798,\n",
      " train_mae: 25.5440,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 560/10000,\n",
      " train_loss: 844.3741,\n",
      " train_mae: 25.5438,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 561/10000,\n",
      " train_loss: 844.3684,\n",
      " train_mae: 25.5437,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 562/10000,\n",
      " train_loss: 844.3625,\n",
      " train_mae: 25.5435,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 563/10000,\n",
      " train_loss: 844.3569,\n",
      " train_mae: 25.5433,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 564/10000,\n",
      " train_loss: 844.3513,\n",
      " train_mae: 25.5432,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 565/10000,\n",
      " train_loss: 844.3453,\n",
      " train_mae: 25.5430,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 566/10000,\n",
      " train_loss: 844.3400,\n",
      " train_mae: 25.5428,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 567/10000,\n",
      " train_loss: 844.3343,\n",
      " train_mae: 25.5426,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 568/10000,\n",
      " train_loss: 844.3286,\n",
      " train_mae: 25.5425,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 569/10000,\n",
      " train_loss: 844.3231,\n",
      " train_mae: 25.5423,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 570/10000,\n",
      " train_loss: 844.3174,\n",
      " train_mae: 25.5421,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 571/10000,\n",
      " train_loss: 844.3119,\n",
      " train_mae: 25.5420,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 572/10000,\n",
      " train_loss: 844.3062,\n",
      " train_mae: 25.5418,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 573/10000,\n",
      " train_loss: 844.3007,\n",
      " train_mae: 25.5416,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 574/10000,\n",
      " train_loss: 844.2948,\n",
      " train_mae: 25.5414,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 575/10000,\n",
      " train_loss: 844.2892,\n",
      " train_mae: 25.5413,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 576/10000,\n",
      " train_loss: 844.2838,\n",
      " train_mae: 25.5411,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 577/10000,\n",
      " train_loss: 844.2779,\n",
      " train_mae: 25.5409,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 578/10000,\n",
      " train_loss: 844.2725,\n",
      " train_mae: 25.5407,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 579/10000,\n",
      " train_loss: 844.2665,\n",
      " train_mae: 25.5406,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 580/10000,\n",
      " train_loss: 844.2609,\n",
      " train_mae: 25.5404,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 581/10000,\n",
      " train_loss: 844.2554,\n",
      " train_mae: 25.5402,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 582/10000,\n",
      " train_loss: 844.2499,\n",
      " train_mae: 25.5400,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 583/10000,\n",
      " train_loss: 844.2443,\n",
      " train_mae: 25.5399,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 584/10000,\n",
      " train_loss: 844.2387,\n",
      " train_mae: 25.5397,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 585/10000,\n",
      " train_loss: 844.2327,\n",
      " train_mae: 25.5395,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 586/10000,\n",
      " train_loss: 844.2271,\n",
      " train_mae: 25.5393,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 587/10000,\n",
      " train_loss: 844.2217,\n",
      " train_mae: 25.5391,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 588/10000,\n",
      " train_loss: 844.2160,\n",
      " train_mae: 25.5390,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 589/10000,\n",
      " train_loss: 844.2103,\n",
      " train_mae: 25.5388,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 590/10000,\n",
      " train_loss: 844.2050,\n",
      " train_mae: 25.5386,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 591/10000,\n",
      " train_loss: 844.1992,\n",
      " train_mae: 25.5384,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 592/10000,\n",
      " train_loss: 844.1933,\n",
      " train_mae: 25.5383,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 593/10000,\n",
      " train_loss: 844.1880,\n",
      " train_mae: 25.5381,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 594/10000,\n",
      " train_loss: 844.1822,\n",
      " train_mae: 25.5379,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 595/10000,\n",
      " train_loss: 844.1766,\n",
      " train_mae: 25.5377,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 596/10000,\n",
      " train_loss: 844.1708,\n",
      " train_mae: 25.5375,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 597/10000,\n",
      " train_loss: 844.1653,\n",
      " train_mae: 25.5374,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 598/10000,\n",
      " train_loss: 844.1596,\n",
      " train_mae: 25.5372,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 599/10000,\n",
      " train_loss: 844.1542,\n",
      " train_mae: 25.5370,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 600/10000,\n",
      " train_loss: 844.1483,\n",
      " train_mae: 25.5369,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 601/10000,\n",
      " train_loss: 844.1430,\n",
      " train_mae: 25.5367,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 602/10000,\n",
      " train_loss: 844.1371,\n",
      " train_mae: 25.5365,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 603/10000,\n",
      " train_loss: 844.1317,\n",
      " train_mae: 25.5363,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 604/10000,\n",
      " train_loss: 844.1260,\n",
      " train_mae: 25.5361,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 605/10000,\n",
      " train_loss: 844.1205,\n",
      " train_mae: 25.5359,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 606/10000,\n",
      " train_loss: 844.1148,\n",
      " train_mae: 25.5358,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 607/10000,\n",
      " train_loss: 844.1090,\n",
      " train_mae: 25.5356,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 608/10000,\n",
      " train_loss: 844.1033,\n",
      " train_mae: 25.5354,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 609/10000,\n",
      " train_loss: 844.0978,\n",
      " train_mae: 25.5352,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 610/10000,\n",
      " train_loss: 844.0922,\n",
      " train_mae: 25.5350,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 611/10000,\n",
      " train_loss: 844.0866,\n",
      " train_mae: 25.5348,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 612/10000,\n",
      " train_loss: 844.0806,\n",
      " train_mae: 25.5347,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 613/10000,\n",
      " train_loss: 844.0753,\n",
      " train_mae: 25.5345,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 614/10000,\n",
      " train_loss: 844.0697,\n",
      " train_mae: 25.5343,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 615/10000,\n",
      " train_loss: 844.0638,\n",
      " train_mae: 25.5341,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 616/10000,\n",
      " train_loss: 844.0583,\n",
      " train_mae: 25.5340,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 617/10000,\n",
      " train_loss: 844.0527,\n",
      " train_mae: 25.5338,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 618/10000,\n",
      " train_loss: 844.0471,\n",
      " train_mae: 25.5336,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 619/10000,\n",
      " train_loss: 844.0414,\n",
      " train_mae: 25.5334,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 620/10000,\n",
      " train_loss: 844.0360,\n",
      " train_mae: 25.5332,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 621/10000,\n",
      " train_loss: 844.0300,\n",
      " train_mae: 25.5331,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 622/10000,\n",
      " train_loss: 844.0245,\n",
      " train_mae: 25.5329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 623/10000,\n",
      " train_loss: 844.0189,\n",
      " train_mae: 25.5327,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 624/10000,\n",
      " train_loss: 844.0131,\n",
      " train_mae: 25.5325,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 625/10000,\n",
      " train_loss: 844.0073,\n",
      " train_mae: 25.5323,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 626/10000,\n",
      " train_loss: 844.0014,\n",
      " train_mae: 25.5321,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 627/10000,\n",
      " train_loss: 843.9962,\n",
      " train_mae: 25.5319,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 628/10000,\n",
      " train_loss: 843.9904,\n",
      " train_mae: 25.5318,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 629/10000,\n",
      " train_loss: 843.9848,\n",
      " train_mae: 25.5316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 630/10000,\n",
      " train_loss: 843.9791,\n",
      " train_mae: 25.5314,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 631/10000,\n",
      " train_loss: 843.9735,\n",
      " train_mae: 25.5312,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 632/10000,\n",
      " train_loss: 843.9677,\n",
      " train_mae: 25.5310,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 633/10000,\n",
      " train_loss: 843.9621,\n",
      " train_mae: 25.5308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 634/10000,\n",
      " train_loss: 843.9563,\n",
      " train_mae: 25.5306,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 635/10000,\n",
      " train_loss: 843.9508,\n",
      " train_mae: 25.5305,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 636/10000,\n",
      " train_loss: 843.9449,\n",
      " train_mae: 25.5303,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 637/10000,\n",
      " train_loss: 843.9396,\n",
      " train_mae: 25.5301,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 638/10000,\n",
      " train_loss: 843.9335,\n",
      " train_mae: 25.5299,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 639/10000,\n",
      " train_loss: 843.9279,\n",
      " train_mae: 25.5297,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 640/10000,\n",
      " train_loss: 843.9227,\n",
      " train_mae: 25.5295,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 641/10000,\n",
      " train_loss: 843.9163,\n",
      " train_mae: 25.5293,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 642/10000,\n",
      " train_loss: 843.9108,\n",
      " train_mae: 25.5292,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 643/10000,\n",
      " train_loss: 843.9052,\n",
      " train_mae: 25.5290,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 644/10000,\n",
      " train_loss: 843.8996,\n",
      " train_mae: 25.5288,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 645/10000,\n",
      " train_loss: 843.8941,\n",
      " train_mae: 25.5286,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 646/10000,\n",
      " train_loss: 843.8882,\n",
      " train_mae: 25.5284,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 647/10000,\n",
      " train_loss: 843.8823,\n",
      " train_mae: 25.5282,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 648/10000,\n",
      " train_loss: 843.8768,\n",
      " train_mae: 25.5280,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 649/10000,\n",
      " train_loss: 843.8707,\n",
      " train_mae: 25.5279,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 650/10000,\n",
      " train_loss: 843.8654,\n",
      " train_mae: 25.5277,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 651/10000,\n",
      " train_loss: 843.8595,\n",
      " train_mae: 25.5275,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 652/10000,\n",
      " train_loss: 843.8539,\n",
      " train_mae: 25.5273,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 653/10000,\n",
      " train_loss: 843.8481,\n",
      " train_mae: 25.5271,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 654/10000,\n",
      " train_loss: 843.8424,\n",
      " train_mae: 25.5269,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 655/10000,\n",
      " train_loss: 843.8368,\n",
      " train_mae: 25.5267,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 656/10000,\n",
      " train_loss: 843.8307,\n",
      " train_mae: 25.5265,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 657/10000,\n",
      " train_loss: 843.8254,\n",
      " train_mae: 25.5264,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 658/10000,\n",
      " train_loss: 843.8195,\n",
      " train_mae: 25.5262,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 659/10000,\n",
      " train_loss: 843.8137,\n",
      " train_mae: 25.5260,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 660/10000,\n",
      " train_loss: 843.8077,\n",
      " train_mae: 25.5258,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 661/10000,\n",
      " train_loss: 843.8020,\n",
      " train_mae: 25.5256,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 662/10000,\n",
      " train_loss: 843.7963,\n",
      " train_mae: 25.5254,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 663/10000,\n",
      " train_loss: 843.7905,\n",
      " train_mae: 25.5252,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 664/10000,\n",
      " train_loss: 843.7851,\n",
      " train_mae: 25.5250,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 665/10000,\n",
      " train_loss: 843.7794,\n",
      " train_mae: 25.5248,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 666/10000,\n",
      " train_loss: 843.7734,\n",
      " train_mae: 25.5247,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 667/10000,\n",
      " train_loss: 843.7677,\n",
      " train_mae: 25.5244,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 668/10000,\n",
      " train_loss: 843.7618,\n",
      " train_mae: 25.5242,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 669/10000,\n",
      " train_loss: 843.7562,\n",
      " train_mae: 25.5241,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 670/10000,\n",
      " train_loss: 843.7505,\n",
      " train_mae: 25.5239,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 671/10000,\n",
      " train_loss: 843.7443,\n",
      " train_mae: 25.5237,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 672/10000,\n",
      " train_loss: 843.7389,\n",
      " train_mae: 25.5235,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 673/10000,\n",
      " train_loss: 843.7330,\n",
      " train_mae: 25.5233,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 674/10000,\n",
      " train_loss: 843.7271,\n",
      " train_mae: 25.5231,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 675/10000,\n",
      " train_loss: 843.7211,\n",
      " train_mae: 25.5229,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 676/10000,\n",
      " train_loss: 843.7158,\n",
      " train_mae: 25.5227,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 677/10000,\n",
      " train_loss: 843.7098,\n",
      " train_mae: 25.5225,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 678/10000,\n",
      " train_loss: 843.7038,\n",
      " train_mae: 25.5224,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 679/10000,\n",
      " train_loss: 843.6984,\n",
      " train_mae: 25.5222,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 680/10000,\n",
      " train_loss: 843.6921,\n",
      " train_mae: 25.5219,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 681/10000,\n",
      " train_loss: 843.6862,\n",
      " train_mae: 25.5217,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 682/10000,\n",
      " train_loss: 843.6807,\n",
      " train_mae: 25.5216,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 683/10000,\n",
      " train_loss: 843.6747,\n",
      " train_mae: 25.5214,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 684/10000,\n",
      " train_loss: 843.6691,\n",
      " train_mae: 25.5212,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 685/10000,\n",
      " train_loss: 843.6633,\n",
      " train_mae: 25.5210,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 686/10000,\n",
      " train_loss: 843.6572,\n",
      " train_mae: 25.5208,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 687/10000,\n",
      " train_loss: 843.6516,\n",
      " train_mae: 25.5206,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 688/10000,\n",
      " train_loss: 843.6456,\n",
      " train_mae: 25.5204,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 689/10000,\n",
      " train_loss: 843.6400,\n",
      " train_mae: 25.5202,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 690/10000,\n",
      " train_loss: 843.6340,\n",
      " train_mae: 25.5200,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 691/10000,\n",
      " train_loss: 843.6282,\n",
      " train_mae: 25.5198,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 692/10000,\n",
      " train_loss: 843.6225,\n",
      " train_mae: 25.5196,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 693/10000,\n",
      " train_loss: 843.6164,\n",
      " train_mae: 25.5194,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 694/10000,\n",
      " train_loss: 843.6104,\n",
      " train_mae: 25.5192,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 695/10000,\n",
      " train_loss: 843.6045,\n",
      " train_mae: 25.5190,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 696/10000,\n",
      " train_loss: 843.5991,\n",
      " train_mae: 25.5189,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 697/10000,\n",
      " train_loss: 843.5929,\n",
      " train_mae: 25.5187,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 698/10000,\n",
      " train_loss: 843.5873,\n",
      " train_mae: 25.5185,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 699/10000,\n",
      " train_loss: 843.5815,\n",
      " train_mae: 25.5183,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 700/10000,\n",
      " train_loss: 843.5756,\n",
      " train_mae: 25.5181,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 701/10000,\n",
      " train_loss: 843.5697,\n",
      " train_mae: 25.5179,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 702/10000,\n",
      " train_loss: 843.5638,\n",
      " train_mae: 25.5177,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 703/10000,\n",
      " train_loss: 843.5579,\n",
      " train_mae: 25.5175,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 704/10000,\n",
      " train_loss: 843.5519,\n",
      " train_mae: 25.5173,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 705/10000,\n",
      " train_loss: 843.5459,\n",
      " train_mae: 25.5171,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 706/10000,\n",
      " train_loss: 843.5403,\n",
      " train_mae: 25.5169,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 707/10000,\n",
      " train_loss: 843.5342,\n",
      " train_mae: 25.5167,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 708/10000,\n",
      " train_loss: 843.5287,\n",
      " train_mae: 25.5165,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 709/10000,\n",
      " train_loss: 843.5229,\n",
      " train_mae: 25.5163,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 710/10000,\n",
      " train_loss: 843.5166,\n",
      " train_mae: 25.5161,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 711/10000,\n",
      " train_loss: 843.5104,\n",
      " train_mae: 25.5159,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 712/10000,\n",
      " train_loss: 843.5049,\n",
      " train_mae: 25.5157,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 713/10000,\n",
      " train_loss: 843.4990,\n",
      " train_mae: 25.5155,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 714/10000,\n",
      " train_loss: 843.4929,\n",
      " train_mae: 25.5153,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 715/10000,\n",
      " train_loss: 843.4872,\n",
      " train_mae: 25.5151,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 716/10000,\n",
      " train_loss: 843.4811,\n",
      " train_mae: 25.5149,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 717/10000,\n",
      " train_loss: 843.4752,\n",
      " train_mae: 25.5147,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 718/10000,\n",
      " train_loss: 843.4694,\n",
      " train_mae: 25.5146,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 719/10000,\n",
      " train_loss: 843.4640,\n",
      " train_mae: 25.5144,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 720/10000,\n",
      " train_loss: 843.4576,\n",
      " train_mae: 25.5142,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 721/10000,\n",
      " train_loss: 843.4520,\n",
      " train_mae: 25.5140,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 722/10000,\n",
      " train_loss: 843.4457,\n",
      " train_mae: 25.5138,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 723/10000,\n",
      " train_loss: 843.4403,\n",
      " train_mae: 25.5136,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 724/10000,\n",
      " train_loss: 843.4339,\n",
      " train_mae: 25.5134,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 725/10000,\n",
      " train_loss: 843.4280,\n",
      " train_mae: 25.5132,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 726/10000,\n",
      " train_loss: 843.4223,\n",
      " train_mae: 25.5130,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 727/10000,\n",
      " train_loss: 843.4161,\n",
      " train_mae: 25.5128,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 728/10000,\n",
      " train_loss: 843.4103,\n",
      " train_mae: 25.5126,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 729/10000,\n",
      " train_loss: 843.4043,\n",
      " train_mae: 25.5124,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 730/10000,\n",
      " train_loss: 843.3984,\n",
      " train_mae: 25.5122,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 731/10000,\n",
      " train_loss: 843.3925,\n",
      " train_mae: 25.5120,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 732/10000,\n",
      " train_loss: 843.3864,\n",
      " train_mae: 25.5118,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 733/10000,\n",
      " train_loss: 843.3804,\n",
      " train_mae: 25.5116,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 734/10000,\n",
      " train_loss: 843.3746,\n",
      " train_mae: 25.5114,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 735/10000,\n",
      " train_loss: 843.3684,\n",
      " train_mae: 25.5112,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 736/10000,\n",
      " train_loss: 843.3625,\n",
      " train_mae: 25.5110,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 737/10000,\n",
      " train_loss: 843.3564,\n",
      " train_mae: 25.5108,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 738/10000,\n",
      " train_loss: 843.3506,\n",
      " train_mae: 25.5106,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 739/10000,\n",
      " train_loss: 843.3448,\n",
      " train_mae: 25.5104,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 740/10000,\n",
      " train_loss: 843.3386,\n",
      " train_mae: 25.5102,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 741/10000,\n",
      " train_loss: 843.3327,\n",
      " train_mae: 25.5100,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 742/10000,\n",
      " train_loss: 843.3270,\n",
      " train_mae: 25.5098,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 743/10000,\n",
      " train_loss: 843.3206,\n",
      " train_mae: 25.5096,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 744/10000,\n",
      " train_loss: 843.3150,\n",
      " train_mae: 25.5094,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 745/10000,\n",
      " train_loss: 843.3089,\n",
      " train_mae: 25.5092,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 746/10000,\n",
      " train_loss: 843.3030,\n",
      " train_mae: 25.5090,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 747/10000,\n",
      " train_loss: 843.2968,\n",
      " train_mae: 25.5088,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 748/10000,\n",
      " train_loss: 843.2911,\n",
      " train_mae: 25.5086,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 749/10000,\n",
      " train_loss: 843.2848,\n",
      " train_mae: 25.5084,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 750/10000,\n",
      " train_loss: 843.2787,\n",
      " train_mae: 25.5082,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 751/10000,\n",
      " train_loss: 843.2731,\n",
      " train_mae: 25.5080,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 752/10000,\n",
      " train_loss: 843.2668,\n",
      " train_mae: 25.5078,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 753/10000,\n",
      " train_loss: 843.2607,\n",
      " train_mae: 25.5076,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 754/10000,\n",
      " train_loss: 843.2549,\n",
      " train_mae: 25.5074,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 755/10000,\n",
      " train_loss: 843.2491,\n",
      " train_mae: 25.5072,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 756/10000,\n",
      " train_loss: 843.2431,\n",
      " train_mae: 25.5070,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 757/10000,\n",
      " train_loss: 843.2369,\n",
      " train_mae: 25.5068,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 758/10000,\n",
      " train_loss: 843.2310,\n",
      " train_mae: 25.5066,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 759/10000,\n",
      " train_loss: 843.2250,\n",
      " train_mae: 25.5064,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 760/10000,\n",
      " train_loss: 843.2188,\n",
      " train_mae: 25.5062,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 761/10000,\n",
      " train_loss: 843.2128,\n",
      " train_mae: 25.5060,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 762/10000,\n",
      " train_loss: 843.2070,\n",
      " train_mae: 25.5058,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 763/10000,\n",
      " train_loss: 843.2009,\n",
      " train_mae: 25.5056,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 764/10000,\n",
      " train_loss: 843.1947,\n",
      " train_mae: 25.5054,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 765/10000,\n",
      " train_loss: 843.1888,\n",
      " train_mae: 25.5052,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 766/10000,\n",
      " train_loss: 843.1826,\n",
      " train_mae: 25.5050,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 767/10000,\n",
      " train_loss: 843.1768,\n",
      " train_mae: 25.5048,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 768/10000,\n",
      " train_loss: 843.1710,\n",
      " train_mae: 25.5046,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 769/10000,\n",
      " train_loss: 843.1649,\n",
      " train_mae: 25.5044,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 770/10000,\n",
      " train_loss: 843.1586,\n",
      " train_mae: 25.5042,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 771/10000,\n",
      " train_loss: 843.1529,\n",
      " train_mae: 25.5040,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 772/10000,\n",
      " train_loss: 843.1469,\n",
      " train_mae: 25.5038,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 773/10000,\n",
      " train_loss: 843.1409,\n",
      " train_mae: 25.5036,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 774/10000,\n",
      " train_loss: 843.1348,\n",
      " train_mae: 25.5034,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 775/10000,\n",
      " train_loss: 843.1289,\n",
      " train_mae: 25.5032,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 776/10000,\n",
      " train_loss: 843.1227,\n",
      " train_mae: 25.5030,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 777/10000,\n",
      " train_loss: 843.1166,\n",
      " train_mae: 25.5027,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 778/10000,\n",
      " train_loss: 843.1105,\n",
      " train_mae: 25.5025,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 779/10000,\n",
      " train_loss: 843.1044,\n",
      " train_mae: 25.5024,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 780/10000,\n",
      " train_loss: 843.0990,\n",
      " train_mae: 25.5022,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 781/10000,\n",
      " train_loss: 843.0923,\n",
      " train_mae: 25.5019,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 782/10000,\n",
      " train_loss: 843.0865,\n",
      " train_mae: 25.5017,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 783/10000,\n",
      " train_loss: 843.0805,\n",
      " train_mae: 25.5015,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 784/10000,\n",
      " train_loss: 843.0744,\n",
      " train_mae: 25.5013,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 785/10000,\n",
      " train_loss: 843.0684,\n",
      " train_mae: 25.5011,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 786/10000,\n",
      " train_loss: 843.0626,\n",
      " train_mae: 25.5009,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 787/10000,\n",
      " train_loss: 843.0561,\n",
      " train_mae: 25.5007,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 788/10000,\n",
      " train_loss: 843.0505,\n",
      " train_mae: 25.5005,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 789/10000,\n",
      " train_loss: 843.0442,\n",
      " train_mae: 25.5003,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 790/10000,\n",
      " train_loss: 843.0381,\n",
      " train_mae: 25.5001,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 791/10000,\n",
      " train_loss: 843.0319,\n",
      " train_mae: 25.4999,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 792/10000,\n",
      " train_loss: 843.0262,\n",
      " train_mae: 25.4997,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 793/10000,\n",
      " train_loss: 843.0200,\n",
      " train_mae: 25.4995,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 794/10000,\n",
      " train_loss: 843.0141,\n",
      " train_mae: 25.4993,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 795/10000,\n",
      " train_loss: 843.0079,\n",
      " train_mae: 25.4991,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 796/10000,\n",
      " train_loss: 843.0018,\n",
      " train_mae: 25.4989,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 797/10000,\n",
      " train_loss: 842.9957,\n",
      " train_mae: 25.4987,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 798/10000,\n",
      " train_loss: 842.9897,\n",
      " train_mae: 25.4985,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 799/10000,\n",
      " train_loss: 842.9836,\n",
      " train_mae: 25.4983,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 800/10000,\n",
      " train_loss: 842.9779,\n",
      " train_mae: 25.4981,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 801/10000,\n",
      " train_loss: 842.9713,\n",
      " train_mae: 25.4979,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 802/10000,\n",
      " train_loss: 842.9654,\n",
      " train_mae: 25.4977,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 803/10000,\n",
      " train_loss: 842.9591,\n",
      " train_mae: 25.4975,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 804/10000,\n",
      " train_loss: 842.9534,\n",
      " train_mae: 25.4973,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 805/10000,\n",
      " train_loss: 842.9476,\n",
      " train_mae: 25.4971,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 806/10000,\n",
      " train_loss: 842.9413,\n",
      " train_mae: 25.4969,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 807/10000,\n",
      " train_loss: 842.9352,\n",
      " train_mae: 25.4967,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 808/10000,\n",
      " train_loss: 842.9291,\n",
      " train_mae: 25.4964,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 809/10000,\n",
      " train_loss: 842.9230,\n",
      " train_mae: 25.4962,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 810/10000,\n",
      " train_loss: 842.9172,\n",
      " train_mae: 25.4960,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 811/10000,\n",
      " train_loss: 842.9111,\n",
      " train_mae: 25.4958,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 812/10000,\n",
      " train_loss: 842.9052,\n",
      " train_mae: 25.4956,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 813/10000,\n",
      " train_loss: 842.8990,\n",
      " train_mae: 25.4954,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 814/10000,\n",
      " train_loss: 842.8928,\n",
      " train_mae: 25.4952,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 815/10000,\n",
      " train_loss: 842.8867,\n",
      " train_mae: 25.4950,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 816/10000,\n",
      " train_loss: 842.8805,\n",
      " train_mae: 25.4948,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 817/10000,\n",
      " train_loss: 842.8748,\n",
      " train_mae: 25.4946,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 818/10000,\n",
      " train_loss: 842.8685,\n",
      " train_mae: 25.4944,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 819/10000,\n",
      " train_loss: 842.8624,\n",
      " train_mae: 25.4942,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 820/10000,\n",
      " train_loss: 842.8564,\n",
      " train_mae: 25.4940,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 821/10000,\n",
      " train_loss: 842.8506,\n",
      " train_mae: 25.4938,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 822/10000,\n",
      " train_loss: 842.8443,\n",
      " train_mae: 25.4936,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 823/10000,\n",
      " train_loss: 842.8385,\n",
      " train_mae: 25.4934,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 824/10000,\n",
      " train_loss: 842.8323,\n",
      " train_mae: 25.4932,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 825/10000,\n",
      " train_loss: 842.8262,\n",
      " train_mae: 25.4930,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 826/10000,\n",
      " train_loss: 842.8201,\n",
      " train_mae: 25.4928,\n",
      " epoch_time_duration: 0.0136\n",
      "\n",
      "epoch: 827/10000,\n",
      " train_loss: 842.8139,\n",
      " train_mae: 25.4926,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 828/10000,\n",
      " train_loss: 842.8079,\n",
      " train_mae: 25.4923,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 829/10000,\n",
      " train_loss: 842.8018,\n",
      " train_mae: 25.4921,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 830/10000,\n",
      " train_loss: 842.7959,\n",
      " train_mae: 25.4919,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 831/10000,\n",
      " train_loss: 842.7899,\n",
      " train_mae: 25.4918,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 832/10000,\n",
      " train_loss: 842.7836,\n",
      " train_mae: 25.4915,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 833/10000,\n",
      " train_loss: 842.7775,\n",
      " train_mae: 25.4913,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 834/10000,\n",
      " train_loss: 842.7714,\n",
      " train_mae: 25.4911,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 835/10000,\n",
      " train_loss: 842.7653,\n",
      " train_mae: 25.4909,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 836/10000,\n",
      " train_loss: 842.7594,\n",
      " train_mae: 25.4907,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 837/10000,\n",
      " train_loss: 842.7535,\n",
      " train_mae: 25.4905,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 838/10000,\n",
      " train_loss: 842.7469,\n",
      " train_mae: 25.4903,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 839/10000,\n",
      " train_loss: 842.7412,\n",
      " train_mae: 25.4901,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 840/10000,\n",
      " train_loss: 842.7348,\n",
      " train_mae: 25.4899,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 841/10000,\n",
      " train_loss: 842.7289,\n",
      " train_mae: 25.4897,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 842/10000,\n",
      " train_loss: 842.7230,\n",
      " train_mae: 25.4895,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 843/10000,\n",
      " train_loss: 842.7167,\n",
      " train_mae: 25.4893,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 844/10000,\n",
      " train_loss: 842.7110,\n",
      " train_mae: 25.4891,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 845/10000,\n",
      " train_loss: 842.7048,\n",
      " train_mae: 25.4889,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 846/10000,\n",
      " train_loss: 842.6989,\n",
      " train_mae: 25.4887,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 847/10000,\n",
      " train_loss: 842.6926,\n",
      " train_mae: 25.4884,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 848/10000,\n",
      " train_loss: 842.6864,\n",
      " train_mae: 25.4882,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 849/10000,\n",
      " train_loss: 842.6802,\n",
      " train_mae: 25.4880,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 850/10000,\n",
      " train_loss: 842.6739,\n",
      " train_mae: 25.4878,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 851/10000,\n",
      " train_loss: 842.6684,\n",
      " train_mae: 25.4876,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 852/10000,\n",
      " train_loss: 842.6622,\n",
      " train_mae: 25.4874,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 853/10000,\n",
      " train_loss: 842.6564,\n",
      " train_mae: 25.4872,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 854/10000,\n",
      " train_loss: 842.6504,\n",
      " train_mae: 25.4870,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 855/10000,\n",
      " train_loss: 842.6442,\n",
      " train_mae: 25.4868,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 856/10000,\n",
      " train_loss: 842.6379,\n",
      " train_mae: 25.4866,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 857/10000,\n",
      " train_loss: 842.6319,\n",
      " train_mae: 25.4864,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 858/10000,\n",
      " train_loss: 842.6261,\n",
      " train_mae: 25.4862,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 859/10000,\n",
      " train_loss: 842.6200,\n",
      " train_mae: 25.4860,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 860/10000,\n",
      " train_loss: 842.6139,\n",
      " train_mae: 25.4858,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 861/10000,\n",
      " train_loss: 842.6080,\n",
      " train_mae: 25.4856,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 862/10000,\n",
      " train_loss: 842.6017,\n",
      " train_mae: 25.4854,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 863/10000,\n",
      " train_loss: 842.5956,\n",
      " train_mae: 25.4851,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 864/10000,\n",
      " train_loss: 842.5894,\n",
      " train_mae: 25.4849,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 865/10000,\n",
      " train_loss: 842.5834,\n",
      " train_mae: 25.4847,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 866/10000,\n",
      " train_loss: 842.5771,\n",
      " train_mae: 25.4845,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 867/10000,\n",
      " train_loss: 842.5713,\n",
      " train_mae: 25.4843,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 868/10000,\n",
      " train_loss: 842.5654,\n",
      " train_mae: 25.4841,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 869/10000,\n",
      " train_loss: 842.5591,\n",
      " train_mae: 25.4839,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 870/10000,\n",
      " train_loss: 842.5532,\n",
      " train_mae: 25.4837,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 871/10000,\n",
      " train_loss: 842.5471,\n",
      " train_mae: 25.4835,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 872/10000,\n",
      " train_loss: 842.5411,\n",
      " train_mae: 25.4833,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 873/10000,\n",
      " train_loss: 842.5349,\n",
      " train_mae: 25.4831,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 874/10000,\n",
      " train_loss: 842.5289,\n",
      " train_mae: 25.4829,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 875/10000,\n",
      " train_loss: 842.5231,\n",
      " train_mae: 25.4827,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 876/10000,\n",
      " train_loss: 842.5170,\n",
      " train_mae: 25.4825,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 877/10000,\n",
      " train_loss: 842.5107,\n",
      " train_mae: 25.4823,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 878/10000,\n",
      " train_loss: 842.5051,\n",
      " train_mae: 25.4821,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 879/10000,\n",
      " train_loss: 842.4991,\n",
      " train_mae: 25.4818,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 880/10000,\n",
      " train_loss: 842.4927,\n",
      " train_mae: 25.4816,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 881/10000,\n",
      " train_loss: 842.4869,\n",
      " train_mae: 25.4814,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 882/10000,\n",
      " train_loss: 842.4809,\n",
      " train_mae: 25.4812,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 883/10000,\n",
      " train_loss: 842.4745,\n",
      " train_mae: 25.4810,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 884/10000,\n",
      " train_loss: 842.4688,\n",
      " train_mae: 25.4808,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 885/10000,\n",
      " train_loss: 842.4625,\n",
      " train_mae: 25.4806,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 886/10000,\n",
      " train_loss: 842.4564,\n",
      " train_mae: 25.4804,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 887/10000,\n",
      " train_loss: 842.4503,\n",
      " train_mae: 25.4802,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 888/10000,\n",
      " train_loss: 842.4446,\n",
      " train_mae: 25.4800,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 889/10000,\n",
      " train_loss: 842.4384,\n",
      " train_mae: 25.4798,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 890/10000,\n",
      " train_loss: 842.4322,\n",
      " train_mae: 25.4796,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 891/10000,\n",
      " train_loss: 842.4265,\n",
      " train_mae: 25.4794,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 892/10000,\n",
      " train_loss: 842.4201,\n",
      " train_mae: 25.4791,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 893/10000,\n",
      " train_loss: 842.4140,\n",
      " train_mae: 25.4789,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 894/10000,\n",
      " train_loss: 842.4081,\n",
      " train_mae: 25.4787,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 895/10000,\n",
      " train_loss: 842.4023,\n",
      " train_mae: 25.4785,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 896/10000,\n",
      " train_loss: 842.3964,\n",
      " train_mae: 25.4783,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 897/10000,\n",
      " train_loss: 842.3898,\n",
      " train_mae: 25.4781,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 898/10000,\n",
      " train_loss: 842.3839,\n",
      " train_mae: 25.4779,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 899/10000,\n",
      " train_loss: 842.3779,\n",
      " train_mae: 25.4777,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 900/10000,\n",
      " train_loss: 842.3717,\n",
      " train_mae: 25.4775,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 901/10000,\n",
      " train_loss: 842.3658,\n",
      " train_mae: 25.4773,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 902/10000,\n",
      " train_loss: 842.3599,\n",
      " train_mae: 25.4771,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 903/10000,\n",
      " train_loss: 842.3542,\n",
      " train_mae: 25.4769,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 904/10000,\n",
      " train_loss: 842.3482,\n",
      " train_mae: 25.4767,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 905/10000,\n",
      " train_loss: 842.3420,\n",
      " train_mae: 25.4765,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 906/10000,\n",
      " train_loss: 842.3359,\n",
      " train_mae: 25.4762,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 907/10000,\n",
      " train_loss: 842.3302,\n",
      " train_mae: 25.4760,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 908/10000,\n",
      " train_loss: 842.3236,\n",
      " train_mae: 25.4758,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 909/10000,\n",
      " train_loss: 842.3181,\n",
      " train_mae: 25.4756,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 910/10000,\n",
      " train_loss: 842.3120,\n",
      " train_mae: 25.4754,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 911/10000,\n",
      " train_loss: 842.3058,\n",
      " train_mae: 25.4752,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 912/10000,\n",
      " train_loss: 842.2998,\n",
      " train_mae: 25.4750,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 913/10000,\n",
      " train_loss: 842.2935,\n",
      " train_mae: 25.4748,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 914/10000,\n",
      " train_loss: 842.2878,\n",
      " train_mae: 25.4746,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 915/10000,\n",
      " train_loss: 842.2819,\n",
      " train_mae: 25.4744,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 916/10000,\n",
      " train_loss: 842.2759,\n",
      " train_mae: 25.4742,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 917/10000,\n",
      " train_loss: 842.2701,\n",
      " train_mae: 25.4740,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 918/10000,\n",
      " train_loss: 842.2641,\n",
      " train_mae: 25.4738,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 919/10000,\n",
      " train_loss: 842.2576,\n",
      " train_mae: 25.4736,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 920/10000,\n",
      " train_loss: 842.2521,\n",
      " train_mae: 25.4734,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 921/10000,\n",
      " train_loss: 842.2457,\n",
      " train_mae: 25.4731,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 922/10000,\n",
      " train_loss: 842.2399,\n",
      " train_mae: 25.4729,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 923/10000,\n",
      " train_loss: 842.2338,\n",
      " train_mae: 25.4727,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 924/10000,\n",
      " train_loss: 842.2278,\n",
      " train_mae: 25.4725,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 925/10000,\n",
      " train_loss: 842.2219,\n",
      " train_mae: 25.4723,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 926/10000,\n",
      " train_loss: 842.2162,\n",
      " train_mae: 25.4721,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 927/10000,\n",
      " train_loss: 842.2101,\n",
      " train_mae: 25.4719,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 928/10000,\n",
      " train_loss: 842.2042,\n",
      " train_mae: 25.4717,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 929/10000,\n",
      " train_loss: 842.1984,\n",
      " train_mae: 25.4715,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 930/10000,\n",
      " train_loss: 842.1924,\n",
      " train_mae: 25.4713,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 931/10000,\n",
      " train_loss: 842.1862,\n",
      " train_mae: 25.4711,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 932/10000,\n",
      " train_loss: 842.1802,\n",
      " train_mae: 25.4709,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 933/10000,\n",
      " train_loss: 842.1742,\n",
      " train_mae: 25.4707,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 934/10000,\n",
      " train_loss: 842.1680,\n",
      " train_mae: 25.4704,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 935/10000,\n",
      " train_loss: 842.1627,\n",
      " train_mae: 25.4702,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 936/10000,\n",
      " train_loss: 842.1563,\n",
      " train_mae: 25.4700,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 937/10000,\n",
      " train_loss: 842.1500,\n",
      " train_mae: 25.4698,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 938/10000,\n",
      " train_loss: 842.1443,\n",
      " train_mae: 25.4696,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 939/10000,\n",
      " train_loss: 842.1384,\n",
      " train_mae: 25.4694,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 940/10000,\n",
      " train_loss: 842.1328,\n",
      " train_mae: 25.4692,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 941/10000,\n",
      " train_loss: 842.1264,\n",
      " train_mae: 25.4690,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 942/10000,\n",
      " train_loss: 842.1205,\n",
      " train_mae: 25.4688,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 943/10000,\n",
      " train_loss: 842.1146,\n",
      " train_mae: 25.4686,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 944/10000,\n",
      " train_loss: 842.1086,\n",
      " train_mae: 25.4684,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 945/10000,\n",
      " train_loss: 842.1027,\n",
      " train_mae: 25.4682,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 946/10000,\n",
      " train_loss: 842.0971,\n",
      " train_mae: 25.4680,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 947/10000,\n",
      " train_loss: 842.0911,\n",
      " train_mae: 25.4678,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 948/10000,\n",
      " train_loss: 842.0850,\n",
      " train_mae: 25.4675,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 949/10000,\n",
      " train_loss: 842.0788,\n",
      " train_mae: 25.4674,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 950/10000,\n",
      " train_loss: 842.0734,\n",
      " train_mae: 25.4672,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 951/10000,\n",
      " train_loss: 842.0675,\n",
      " train_mae: 25.4669,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 952/10000,\n",
      " train_loss: 842.0615,\n",
      " train_mae: 25.4667,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 953/10000,\n",
      " train_loss: 842.0552,\n",
      " train_mae: 25.4665,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 954/10000,\n",
      " train_loss: 842.0494,\n",
      " train_mae: 25.4663,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 955/10000,\n",
      " train_loss: 842.0438,\n",
      " train_mae: 25.4661,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 956/10000,\n",
      " train_loss: 842.0375,\n",
      " train_mae: 25.4659,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 957/10000,\n",
      " train_loss: 842.0320,\n",
      " train_mae: 25.4657,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 958/10000,\n",
      " train_loss: 842.0261,\n",
      " train_mae: 25.4655,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 959/10000,\n",
      " train_loss: 842.0201,\n",
      " train_mae: 25.4653,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 960/10000,\n",
      " train_loss: 842.0141,\n",
      " train_mae: 25.4651,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 961/10000,\n",
      " train_loss: 842.0085,\n",
      " train_mae: 25.4649,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 962/10000,\n",
      " train_loss: 842.0026,\n",
      " train_mae: 25.4647,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 963/10000,\n",
      " train_loss: 841.9966,\n",
      " train_mae: 25.4645,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 964/10000,\n",
      " train_loss: 841.9905,\n",
      " train_mae: 25.4643,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 965/10000,\n",
      " train_loss: 841.9852,\n",
      " train_mae: 25.4641,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 966/10000,\n",
      " train_loss: 841.9786,\n",
      " train_mae: 25.4639,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 967/10000,\n",
      " train_loss: 841.9732,\n",
      " train_mae: 25.4636,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 968/10000,\n",
      " train_loss: 841.9673,\n",
      " train_mae: 25.4634,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 969/10000,\n",
      " train_loss: 841.9614,\n",
      " train_mae: 25.4632,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 970/10000,\n",
      " train_loss: 841.9554,\n",
      " train_mae: 25.4630,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 971/10000,\n",
      " train_loss: 841.9498,\n",
      " train_mae: 25.4628,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 972/10000,\n",
      " train_loss: 841.9437,\n",
      " train_mae: 25.4626,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 973/10000,\n",
      " train_loss: 841.9378,\n",
      " train_mae: 25.4624,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 974/10000,\n",
      " train_loss: 841.9321,\n",
      " train_mae: 25.4622,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 975/10000,\n",
      " train_loss: 841.9262,\n",
      " train_mae: 25.4620,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 976/10000,\n",
      " train_loss: 841.9207,\n",
      " train_mae: 25.4618,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 977/10000,\n",
      " train_loss: 841.9152,\n",
      " train_mae: 25.4616,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 978/10000,\n",
      " train_loss: 841.9088,\n",
      " train_mae: 25.4614,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 979/10000,\n",
      " train_loss: 841.9030,\n",
      " train_mae: 25.4612,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 980/10000,\n",
      " train_loss: 841.8976,\n",
      " train_mae: 25.4610,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 981/10000,\n",
      " train_loss: 841.8915,\n",
      " train_mae: 25.4608,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 982/10000,\n",
      " train_loss: 841.8856,\n",
      " train_mae: 25.4606,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 983/10000,\n",
      " train_loss: 841.8798,\n",
      " train_mae: 25.4604,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 984/10000,\n",
      " train_loss: 841.8741,\n",
      " train_mae: 25.4602,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 985/10000,\n",
      " train_loss: 841.8682,\n",
      " train_mae: 25.4599,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 986/10000,\n",
      " train_loss: 841.8625,\n",
      " train_mae: 25.4598,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 987/10000,\n",
      " train_loss: 841.8566,\n",
      " train_mae: 25.4596,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 988/10000,\n",
      " train_loss: 841.8510,\n",
      " train_mae: 25.4593,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 989/10000,\n",
      " train_loss: 841.8450,\n",
      " train_mae: 25.4591,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 990/10000,\n",
      " train_loss: 841.8392,\n",
      " train_mae: 25.4589,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 991/10000,\n",
      " train_loss: 841.8339,\n",
      " train_mae: 25.4587,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 992/10000,\n",
      " train_loss: 841.8278,\n",
      " train_mae: 25.4585,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 993/10000,\n",
      " train_loss: 841.8220,\n",
      " train_mae: 25.4583,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 994/10000,\n",
      " train_loss: 841.8163,\n",
      " train_mae: 25.4581,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 995/10000,\n",
      " train_loss: 841.8104,\n",
      " train_mae: 25.4579,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 996/10000,\n",
      " train_loss: 841.8050,\n",
      " train_mae: 25.4577,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 997/10000,\n",
      " train_loss: 841.7991,\n",
      " train_mae: 25.4575,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 998/10000,\n",
      " train_loss: 841.7930,\n",
      " train_mae: 25.4573,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 999/10000,\n",
      " train_loss: 841.7874,\n",
      " train_mae: 25.4571,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1000/10000,\n",
      " train_loss: 841.7816,\n",
      " train_mae: 25.4569,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1001/10000,\n",
      " train_loss: 841.7758,\n",
      " train_mae: 25.4567,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1002/10000,\n",
      " train_loss: 841.7701,\n",
      " train_mae: 25.4565,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1003/10000,\n",
      " train_loss: 841.7646,\n",
      " train_mae: 25.4563,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1004/10000,\n",
      " train_loss: 841.7590,\n",
      " train_mae: 25.4561,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1005/10000,\n",
      " train_loss: 841.7532,\n",
      " train_mae: 25.4559,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1006/10000,\n",
      " train_loss: 841.7477,\n",
      " train_mae: 25.4557,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1007/10000,\n",
      " train_loss: 841.7416,\n",
      " train_mae: 25.4555,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1008/10000,\n",
      " train_loss: 841.7361,\n",
      " train_mae: 25.4553,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1009/10000,\n",
      " train_loss: 841.7301,\n",
      " train_mae: 25.4551,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1010/10000,\n",
      " train_loss: 841.7248,\n",
      " train_mae: 25.4549,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1011/10000,\n",
      " train_loss: 841.7186,\n",
      " train_mae: 25.4546,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1012/10000,\n",
      " train_loss: 841.7130,\n",
      " train_mae: 25.4544,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1013/10000,\n",
      " train_loss: 841.7073,\n",
      " train_mae: 25.4543,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1014/10000,\n",
      " train_loss: 841.7019,\n",
      " train_mae: 25.4541,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1015/10000,\n",
      " train_loss: 841.6960,\n",
      " train_mae: 25.4538,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1016/10000,\n",
      " train_loss: 841.6904,\n",
      " train_mae: 25.4536,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1017/10000,\n",
      " train_loss: 841.6849,\n",
      " train_mae: 25.4535,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1018/10000,\n",
      " train_loss: 841.6790,\n",
      " train_mae: 25.4532,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1019/10000,\n",
      " train_loss: 841.6733,\n",
      " train_mae: 25.4530,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1020/10000,\n",
      " train_loss: 841.6680,\n",
      " train_mae: 25.4529,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1021/10000,\n",
      " train_loss: 841.6622,\n",
      " train_mae: 25.4527,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1022/10000,\n",
      " train_loss: 841.6567,\n",
      " train_mae: 25.4524,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1023/10000,\n",
      " train_loss: 841.6509,\n",
      " train_mae: 25.4522,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1024/10000,\n",
      " train_loss: 841.6456,\n",
      " train_mae: 25.4521,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1025/10000,\n",
      " train_loss: 841.6400,\n",
      " train_mae: 25.4518,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1026/10000,\n",
      " train_loss: 841.6345,\n",
      " train_mae: 25.4516,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1027/10000,\n",
      " train_loss: 841.6285,\n",
      " train_mae: 25.4515,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1028/10000,\n",
      " train_loss: 841.6233,\n",
      " train_mae: 25.4512,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1029/10000,\n",
      " train_loss: 841.6172,\n",
      " train_mae: 25.4510,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1030/10000,\n",
      " train_loss: 841.6116,\n",
      " train_mae: 25.4508,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1031/10000,\n",
      " train_loss: 841.6061,\n",
      " train_mae: 25.4506,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1032/10000,\n",
      " train_loss: 841.6007,\n",
      " train_mae: 25.4504,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1033/10000,\n",
      " train_loss: 841.5948,\n",
      " train_mae: 25.4502,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1034/10000,\n",
      " train_loss: 841.5895,\n",
      " train_mae: 25.4500,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1035/10000,\n",
      " train_loss: 841.5834,\n",
      " train_mae: 25.4498,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1036/10000,\n",
      " train_loss: 841.5782,\n",
      " train_mae: 25.4496,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1037/10000,\n",
      " train_loss: 841.5726,\n",
      " train_mae: 25.4494,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1038/10000,\n",
      " train_loss: 841.5673,\n",
      " train_mae: 25.4492,\n",
      " epoch_time_duration: 0.0109\n",
      "\n",
      "epoch: 1039/10000,\n",
      " train_loss: 841.5616,\n",
      " train_mae: 25.4490,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1040/10000,\n",
      " train_loss: 841.5560,\n",
      " train_mae: 25.4488,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1041/10000,\n",
      " train_loss: 841.5504,\n",
      " train_mae: 25.4486,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "epoch: 1042/10000,\n",
      " train_loss: 841.5449,\n",
      " train_mae: 25.4484,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 1043/10000,\n",
      " train_loss: 841.5395,\n",
      " train_mae: 25.4482,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 1044/10000,\n",
      " train_loss: 841.5335,\n",
      " train_mae: 25.4480,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1045/10000,\n",
      " train_loss: 841.5283,\n",
      " train_mae: 25.4478,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1046/10000,\n",
      " train_loss: 841.5228,\n",
      " train_mae: 25.4476,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1047/10000,\n",
      " train_loss: 841.5175,\n",
      " train_mae: 25.4474,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1048/10000,\n",
      " train_loss: 841.5117,\n",
      " train_mae: 25.4472,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1049/10000,\n",
      " train_loss: 841.5062,\n",
      " train_mae: 25.4470,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1050/10000,\n",
      " train_loss: 841.5010,\n",
      " train_mae: 25.4468,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1051/10000,\n",
      " train_loss: 841.4952,\n",
      " train_mae: 25.4466,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1052/10000,\n",
      " train_loss: 841.4900,\n",
      " train_mae: 25.4464,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1053/10000,\n",
      " train_loss: 841.4843,\n",
      " train_mae: 25.4462,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1054/10000,\n",
      " train_loss: 841.4788,\n",
      " train_mae: 25.4460,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1055/10000,\n",
      " train_loss: 841.4732,\n",
      " train_mae: 25.4458,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1056/10000,\n",
      " train_loss: 841.4680,\n",
      " train_mae: 25.4456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1057/10000,\n",
      " train_loss: 841.4623,\n",
      " train_mae: 25.4454,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1058/10000,\n",
      " train_loss: 841.4571,\n",
      " train_mae: 25.4452,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1059/10000,\n",
      " train_loss: 841.4516,\n",
      " train_mae: 25.4450,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1060/10000,\n",
      " train_loss: 841.4460,\n",
      " train_mae: 25.4448,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1061/10000,\n",
      " train_loss: 841.4407,\n",
      " train_mae: 25.4446,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1062/10000,\n",
      " train_loss: 841.4349,\n",
      " train_mae: 25.4444,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1063/10000,\n",
      " train_loss: 841.4296,\n",
      " train_mae: 25.4442,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1064/10000,\n",
      " train_loss: 841.4245,\n",
      " train_mae: 25.4440,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1065/10000,\n",
      " train_loss: 841.4186,\n",
      " train_mae: 25.4438,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1066/10000,\n",
      " train_loss: 841.4135,\n",
      " train_mae: 25.4436,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1067/10000,\n",
      " train_loss: 841.4085,\n",
      " train_mae: 25.4434,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1068/10000,\n",
      " train_loss: 841.4026,\n",
      " train_mae: 25.4432,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1069/10000,\n",
      " train_loss: 841.3972,\n",
      " train_mae: 25.4430,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1070/10000,\n",
      " train_loss: 841.3918,\n",
      " train_mae: 25.4429,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1071/10000,\n",
      " train_loss: 841.3869,\n",
      " train_mae: 25.4427,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1072/10000,\n",
      " train_loss: 841.3810,\n",
      " train_mae: 25.4424,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1073/10000,\n",
      " train_loss: 841.3755,\n",
      " train_mae: 25.4423,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1074/10000,\n",
      " train_loss: 841.3702,\n",
      " train_mae: 25.4421,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1075/10000,\n",
      " train_loss: 841.3648,\n",
      " train_mae: 25.4418,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1076/10000,\n",
      " train_loss: 841.3596,\n",
      " train_mae: 25.4417,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1077/10000,\n",
      " train_loss: 841.3539,\n",
      " train_mae: 25.4415,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1078/10000,\n",
      " train_loss: 841.3491,\n",
      " train_mae: 25.4413,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1079/10000,\n",
      " train_loss: 841.3435,\n",
      " train_mae: 25.4411,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1080/10000,\n",
      " train_loss: 841.3383,\n",
      " train_mae: 25.4409,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1081/10000,\n",
      " train_loss: 841.3331,\n",
      " train_mae: 25.4407,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1082/10000,\n",
      " train_loss: 841.3279,\n",
      " train_mae: 25.4405,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1083/10000,\n",
      " train_loss: 841.3223,\n",
      " train_mae: 25.4403,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1084/10000,\n",
      " train_loss: 841.3168,\n",
      " train_mae: 25.4401,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1085/10000,\n",
      " train_loss: 841.3114,\n",
      " train_mae: 25.4399,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1086/10000,\n",
      " train_loss: 841.3063,\n",
      " train_mae: 25.4397,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1087/10000,\n",
      " train_loss: 841.3011,\n",
      " train_mae: 25.4395,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1088/10000,\n",
      " train_loss: 841.2956,\n",
      " train_mae: 25.4393,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 1089/10000,\n",
      " train_loss: 841.2904,\n",
      " train_mae: 25.4391,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "epoch: 1090/10000,\n",
      " train_loss: 841.2850,\n",
      " train_mae: 25.4390,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 1091/10000,\n",
      " train_loss: 841.2803,\n",
      " train_mae: 25.4387,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1092/10000,\n",
      " train_loss: 841.2748,\n",
      " train_mae: 25.4385,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1093/10000,\n",
      " train_loss: 841.2692,\n",
      " train_mae: 25.4384,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1094/10000,\n",
      " train_loss: 841.2641,\n",
      " train_mae: 25.4382,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1095/10000,\n",
      " train_loss: 841.2592,\n",
      " train_mae: 25.4380,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1096/10000,\n",
      " train_loss: 841.2538,\n",
      " train_mae: 25.4378,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1097/10000,\n",
      " train_loss: 841.2487,\n",
      " train_mae: 25.4376,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1098/10000,\n",
      " train_loss: 841.2434,\n",
      " train_mae: 25.4374,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1099/10000,\n",
      " train_loss: 841.2379,\n",
      " train_mae: 25.4372,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1100/10000,\n",
      " train_loss: 841.2331,\n",
      " train_mae: 25.4370,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1101/10000,\n",
      " train_loss: 841.2278,\n",
      " train_mae: 25.4368,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1102/10000,\n",
      " train_loss: 841.2226,\n",
      " train_mae: 25.4366,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1103/10000,\n",
      " train_loss: 841.2173,\n",
      " train_mae: 25.4364,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1104/10000,\n",
      " train_loss: 841.2123,\n",
      " train_mae: 25.4362,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1105/10000,\n",
      " train_loss: 841.2066,\n",
      " train_mae: 25.4360,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1106/10000,\n",
      " train_loss: 841.2016,\n",
      " train_mae: 25.4359,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1107/10000,\n",
      " train_loss: 841.1967,\n",
      " train_mae: 25.4356,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1108/10000,\n",
      " train_loss: 841.1913,\n",
      " train_mae: 25.4355,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1109/10000,\n",
      " train_loss: 841.1868,\n",
      " train_mae: 25.4353,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1110/10000,\n",
      " train_loss: 841.1816,\n",
      " train_mae: 25.4351,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1111/10000,\n",
      " train_loss: 841.1762,\n",
      " train_mae: 25.4349,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1112/10000,\n",
      " train_loss: 841.1711,\n",
      " train_mae: 25.4347,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1113/10000,\n",
      " train_loss: 841.1660,\n",
      " train_mae: 25.4345,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1114/10000,\n",
      " train_loss: 841.1609,\n",
      " train_mae: 25.4343,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1115/10000,\n",
      " train_loss: 841.1557,\n",
      " train_mae: 25.4342,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1116/10000,\n",
      " train_loss: 841.1508,\n",
      " train_mae: 25.4339,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1117/10000,\n",
      " train_loss: 841.1458,\n",
      " train_mae: 25.4337,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1118/10000,\n",
      " train_loss: 841.1407,\n",
      " train_mae: 25.4336,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1119/10000,\n",
      " train_loss: 841.1357,\n",
      " train_mae: 25.4334,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1120/10000,\n",
      " train_loss: 841.1305,\n",
      " train_mae: 25.4332,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1121/10000,\n",
      " train_loss: 841.1253,\n",
      " train_mae: 25.4330,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1122/10000,\n",
      " train_loss: 841.1207,\n",
      " train_mae: 25.4328,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1123/10000,\n",
      " train_loss: 841.1155,\n",
      " train_mae: 25.4326,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1124/10000,\n",
      " train_loss: 841.1103,\n",
      " train_mae: 25.4324,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1125/10000,\n",
      " train_loss: 841.1052,\n",
      " train_mae: 25.4322,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1126/10000,\n",
      " train_loss: 841.1002,\n",
      " train_mae: 25.4320,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1127/10000,\n",
      " train_loss: 841.0953,\n",
      " train_mae: 25.4319,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1128/10000,\n",
      " train_loss: 841.0904,\n",
      " train_mae: 25.4317,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1129/10000,\n",
      " train_loss: 841.0852,\n",
      " train_mae: 25.4315,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1130/10000,\n",
      " train_loss: 841.0803,\n",
      " train_mae: 25.4313,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1131/10000,\n",
      " train_loss: 841.0754,\n",
      " train_mae: 25.4311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1132/10000,\n",
      " train_loss: 841.0701,\n",
      " train_mae: 25.4309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1133/10000,\n",
      " train_loss: 841.0651,\n",
      " train_mae: 25.4307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1134/10000,\n",
      " train_loss: 841.0600,\n",
      " train_mae: 25.4305,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1135/10000,\n",
      " train_loss: 841.0552,\n",
      " train_mae: 25.4303,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1136/10000,\n",
      " train_loss: 841.0504,\n",
      " train_mae: 25.4302,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1137/10000,\n",
      " train_loss: 841.0455,\n",
      " train_mae: 25.4300,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1138/10000,\n",
      " train_loss: 841.0403,\n",
      " train_mae: 25.4298,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 1139/10000,\n",
      " train_loss: 841.0355,\n",
      " train_mae: 25.4296,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1140/10000,\n",
      " train_loss: 841.0306,\n",
      " train_mae: 25.4294,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1141/10000,\n",
      " train_loss: 841.0256,\n",
      " train_mae: 25.4292,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1142/10000,\n",
      " train_loss: 841.0207,\n",
      " train_mae: 25.4291,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1143/10000,\n",
      " train_loss: 841.0161,\n",
      " train_mae: 25.4288,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1144/10000,\n",
      " train_loss: 841.0108,\n",
      " train_mae: 25.4287,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 1145/10000,\n",
      " train_loss: 841.0060,\n",
      " train_mae: 25.4285,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 1146/10000,\n",
      " train_loss: 841.0010,\n",
      " train_mae: 25.4283,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 1147/10000,\n",
      " train_loss: 840.9963,\n",
      " train_mae: 25.4281,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1148/10000,\n",
      " train_loss: 840.9913,\n",
      " train_mae: 25.4279,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1149/10000,\n",
      " train_loss: 840.9863,\n",
      " train_mae: 25.4277,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1150/10000,\n",
      " train_loss: 840.9818,\n",
      " train_mae: 25.4276,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1151/10000,\n",
      " train_loss: 840.9771,\n",
      " train_mae: 25.4274,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1152/10000,\n",
      " train_loss: 840.9720,\n",
      " train_mae: 25.4272,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1153/10000,\n",
      " train_loss: 840.9671,\n",
      " train_mae: 25.4270,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1154/10000,\n",
      " train_loss: 840.9623,\n",
      " train_mae: 25.4268,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1155/10000,\n",
      " train_loss: 840.9575,\n",
      " train_mae: 25.4266,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1156/10000,\n",
      " train_loss: 840.9528,\n",
      " train_mae: 25.4265,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1157/10000,\n",
      " train_loss: 840.9478,\n",
      " train_mae: 25.4263,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1158/10000,\n",
      " train_loss: 840.9430,\n",
      " train_mae: 25.4261,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1159/10000,\n",
      " train_loss: 840.9385,\n",
      " train_mae: 25.4259,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1160/10000,\n",
      " train_loss: 840.9338,\n",
      " train_mae: 25.4257,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1161/10000,\n",
      " train_loss: 840.9288,\n",
      " train_mae: 25.4255,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1162/10000,\n",
      " train_loss: 840.9244,\n",
      " train_mae: 25.4254,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1163/10000,\n",
      " train_loss: 840.9192,\n",
      " train_mae: 25.4252,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1164/10000,\n",
      " train_loss: 840.9146,\n",
      " train_mae: 25.4250,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1165/10000,\n",
      " train_loss: 840.9099,\n",
      " train_mae: 25.4248,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1166/10000,\n",
      " train_loss: 840.9050,\n",
      " train_mae: 25.4246,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1167/10000,\n",
      " train_loss: 840.9003,\n",
      " train_mae: 25.4244,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1168/10000,\n",
      " train_loss: 840.8958,\n",
      " train_mae: 25.4243,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1169/10000,\n",
      " train_loss: 840.8909,\n",
      " train_mae: 25.4241,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1170/10000,\n",
      " train_loss: 840.8864,\n",
      " train_mae: 25.4239,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1171/10000,\n",
      " train_loss: 840.8815,\n",
      " train_mae: 25.4237,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1172/10000,\n",
      " train_loss: 840.8773,\n",
      " train_mae: 25.4235,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1173/10000,\n",
      " train_loss: 840.8724,\n",
      " train_mae: 25.4234,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1174/10000,\n",
      " train_loss: 840.8676,\n",
      " train_mae: 25.4232,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1175/10000,\n",
      " train_loss: 840.8627,\n",
      " train_mae: 25.4230,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1176/10000,\n",
      " train_loss: 840.8583,\n",
      " train_mae: 25.4228,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1177/10000,\n",
      " train_loss: 840.8537,\n",
      " train_mae: 25.4226,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1178/10000,\n",
      " train_loss: 840.8488,\n",
      " train_mae: 25.4224,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1179/10000,\n",
      " train_loss: 840.8444,\n",
      " train_mae: 25.4223,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1180/10000,\n",
      " train_loss: 840.8398,\n",
      " train_mae: 25.4221,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1181/10000,\n",
      " train_loss: 840.8351,\n",
      " train_mae: 25.4219,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1182/10000,\n",
      " train_loss: 840.8304,\n",
      " train_mae: 25.4218,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 1183/10000,\n",
      " train_loss: 840.8258,\n",
      " train_mae: 25.4215,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1184/10000,\n",
      " train_loss: 840.8215,\n",
      " train_mae: 25.4214,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1185/10000,\n",
      " train_loss: 840.8167,\n",
      " train_mae: 25.4212,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1186/10000,\n",
      " train_loss: 840.8120,\n",
      " train_mae: 25.4210,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1187/10000,\n",
      " train_loss: 840.8078,\n",
      " train_mae: 25.4209,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1188/10000,\n",
      " train_loss: 840.8030,\n",
      " train_mae: 25.4207,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1189/10000,\n",
      " train_loss: 840.7984,\n",
      " train_mae: 25.4205,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1190/10000,\n",
      " train_loss: 840.7941,\n",
      " train_mae: 25.4203,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1191/10000,\n",
      " train_loss: 840.7894,\n",
      " train_mae: 25.4201,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1192/10000,\n",
      " train_loss: 840.7848,\n",
      " train_mae: 25.4200,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1193/10000,\n",
      " train_loss: 840.7804,\n",
      " train_mae: 25.4198,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1194/10000,\n",
      " train_loss: 840.7758,\n",
      " train_mae: 25.4196,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1195/10000,\n",
      " train_loss: 840.7711,\n",
      " train_mae: 25.4195,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1196/10000,\n",
      " train_loss: 840.7666,\n",
      " train_mae: 25.4192,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1197/10000,\n",
      " train_loss: 840.7623,\n",
      " train_mae: 25.4191,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1198/10000,\n",
      " train_loss: 840.7579,\n",
      " train_mae: 25.4190,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1199/10000,\n",
      " train_loss: 840.7533,\n",
      " train_mae: 25.4187,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1200/10000,\n",
      " train_loss: 840.7488,\n",
      " train_mae: 25.4186,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1201/10000,\n",
      " train_loss: 840.7443,\n",
      " train_mae: 25.4184,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1202/10000,\n",
      " train_loss: 840.7399,\n",
      " train_mae: 25.4182,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1203/10000,\n",
      " train_loss: 840.7356,\n",
      " train_mae: 25.4181,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1204/10000,\n",
      " train_loss: 840.7310,\n",
      " train_mae: 25.4179,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1205/10000,\n",
      " train_loss: 840.7267,\n",
      " train_mae: 25.4177,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1206/10000,\n",
      " train_loss: 840.7226,\n",
      " train_mae: 25.4176,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1207/10000,\n",
      " train_loss: 840.7179,\n",
      " train_mae: 25.4173,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1208/10000,\n",
      " train_loss: 840.7134,\n",
      " train_mae: 25.4172,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1209/10000,\n",
      " train_loss: 840.7089,\n",
      " train_mae: 25.4170,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1210/10000,\n",
      " train_loss: 840.7047,\n",
      " train_mae: 25.4168,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1211/10000,\n",
      " train_loss: 840.7003,\n",
      " train_mae: 25.4167,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1212/10000,\n",
      " train_loss: 840.6962,\n",
      " train_mae: 25.4165,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1213/10000,\n",
      " train_loss: 840.6918,\n",
      " train_mae: 25.4163,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1214/10000,\n",
      " train_loss: 840.6873,\n",
      " train_mae: 25.4161,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1215/10000,\n",
      " train_loss: 840.6830,\n",
      " train_mae: 25.4160,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1216/10000,\n",
      " train_loss: 840.6786,\n",
      " train_mae: 25.4158,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1217/10000,\n",
      " train_loss: 840.6743,\n",
      " train_mae: 25.4156,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1218/10000,\n",
      " train_loss: 840.6700,\n",
      " train_mae: 25.4155,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1219/10000,\n",
      " train_loss: 840.6660,\n",
      " train_mae: 25.4153,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1220/10000,\n",
      " train_loss: 840.6615,\n",
      " train_mae: 25.4151,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1221/10000,\n",
      " train_loss: 840.6572,\n",
      " train_mae: 25.4150,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1222/10000,\n",
      " train_loss: 840.6530,\n",
      " train_mae: 25.4148,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1223/10000,\n",
      " train_loss: 840.6492,\n",
      " train_mae: 25.4146,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1224/10000,\n",
      " train_loss: 840.6445,\n",
      " train_mae: 25.4145,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1225/10000,\n",
      " train_loss: 840.6401,\n",
      " train_mae: 25.4143,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1226/10000,\n",
      " train_loss: 840.6360,\n",
      " train_mae: 25.4141,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1227/10000,\n",
      " train_loss: 840.6316,\n",
      " train_mae: 25.4139,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1228/10000,\n",
      " train_loss: 840.6276,\n",
      " train_mae: 25.4138,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 1229/10000,\n",
      " train_loss: 840.6232,\n",
      " train_mae: 25.4136,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 1230/10000,\n",
      " train_loss: 840.6191,\n",
      " train_mae: 25.4134,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 1231/10000,\n",
      " train_loss: 840.6147,\n",
      " train_mae: 25.4133,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 1232/10000,\n",
      " train_loss: 840.6106,\n",
      " train_mae: 25.4131,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1233/10000,\n",
      " train_loss: 840.6066,\n",
      " train_mae: 25.4129,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 1234/10000,\n",
      " train_loss: 840.6022,\n",
      " train_mae: 25.4128,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1235/10000,\n",
      " train_loss: 840.5983,\n",
      " train_mae: 25.4126,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1236/10000,\n",
      " train_loss: 840.5939,\n",
      " train_mae: 25.4124,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1237/10000,\n",
      " train_loss: 840.5898,\n",
      " train_mae: 25.4123,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1238/10000,\n",
      " train_loss: 840.5857,\n",
      " train_mae: 25.4121,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1239/10000,\n",
      " train_loss: 840.5814,\n",
      " train_mae: 25.4119,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1240/10000,\n",
      " train_loss: 840.5776,\n",
      " train_mae: 25.4118,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1241/10000,\n",
      " train_loss: 840.5729,\n",
      " train_mae: 25.4116,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1242/10000,\n",
      " train_loss: 840.5693,\n",
      " train_mae: 25.4115,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1243/10000,\n",
      " train_loss: 840.5650,\n",
      " train_mae: 25.4113,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1244/10000,\n",
      " train_loss: 840.5612,\n",
      " train_mae: 25.4111,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1245/10000,\n",
      " train_loss: 840.5570,\n",
      " train_mae: 25.4110,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1246/10000,\n",
      " train_loss: 840.5529,\n",
      " train_mae: 25.4107,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1247/10000,\n",
      " train_loss: 840.5486,\n",
      " train_mae: 25.4106,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1248/10000,\n",
      " train_loss: 840.5449,\n",
      " train_mae: 25.4105,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1249/10000,\n",
      " train_loss: 840.5405,\n",
      " train_mae: 25.4102,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1250/10000,\n",
      " train_loss: 840.5367,\n",
      " train_mae: 25.4102,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1251/10000,\n",
      " train_loss: 840.5327,\n",
      " train_mae: 25.4099,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1252/10000,\n",
      " train_loss: 840.5287,\n",
      " train_mae: 25.4098,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1253/10000,\n",
      " train_loss: 840.5247,\n",
      " train_mae: 25.4097,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1254/10000,\n",
      " train_loss: 840.5206,\n",
      " train_mae: 25.4094,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1255/10000,\n",
      " train_loss: 840.5163,\n",
      " train_mae: 25.4093,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1256/10000,\n",
      " train_loss: 840.5127,\n",
      " train_mae: 25.4091,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1257/10000,\n",
      " train_loss: 840.5084,\n",
      " train_mae: 25.4090,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1258/10000,\n",
      " train_loss: 840.5048,\n",
      " train_mae: 25.4089,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1259/10000,\n",
      " train_loss: 840.5005,\n",
      " train_mae: 25.4086,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1260/10000,\n",
      " train_loss: 840.4966,\n",
      " train_mae: 25.4085,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1261/10000,\n",
      " train_loss: 840.4927,\n",
      " train_mae: 25.4083,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1262/10000,\n",
      " train_loss: 840.4889,\n",
      " train_mae: 25.4081,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1263/10000,\n",
      " train_loss: 840.4848,\n",
      " train_mae: 25.4081,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1264/10000,\n",
      " train_loss: 840.4808,\n",
      " train_mae: 25.4078,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1265/10000,\n",
      " train_loss: 840.4772,\n",
      " train_mae: 25.4077,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1266/10000,\n",
      " train_loss: 840.4733,\n",
      " train_mae: 25.4075,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1267/10000,\n",
      " train_loss: 840.4693,\n",
      " train_mae: 25.4074,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1268/10000,\n",
      " train_loss: 840.4651,\n",
      " train_mae: 25.4072,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 1269/10000,\n",
      " train_loss: 840.4615,\n",
      " train_mae: 25.4071,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 1270/10000,\n",
      " train_loss: 840.4576,\n",
      " train_mae: 25.4069,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1271/10000,\n",
      " train_loss: 840.4534,\n",
      " train_mae: 25.4068,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1272/10000,\n",
      " train_loss: 840.4501,\n",
      " train_mae: 25.4066,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1273/10000,\n",
      " train_loss: 840.4459,\n",
      " train_mae: 25.4064,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1274/10000,\n",
      " train_loss: 840.4420,\n",
      " train_mae: 25.4063,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1275/10000,\n",
      " train_loss: 840.4382,\n",
      " train_mae: 25.4061,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1276/10000,\n",
      " train_loss: 840.4347,\n",
      " train_mae: 25.4060,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1277/10000,\n",
      " train_loss: 840.4305,\n",
      " train_mae: 25.4058,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1278/10000,\n",
      " train_loss: 840.4268,\n",
      " train_mae: 25.4056,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1279/10000,\n",
      " train_loss: 840.4228,\n",
      " train_mae: 25.4055,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1280/10000,\n",
      " train_loss: 840.4191,\n",
      " train_mae: 25.4053,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1281/10000,\n",
      " train_loss: 840.4152,\n",
      " train_mae: 25.4052,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1282/10000,\n",
      " train_loss: 840.4117,\n",
      " train_mae: 25.4050,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1283/10000,\n",
      " train_loss: 840.4078,\n",
      " train_mae: 25.4048,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1284/10000,\n",
      " train_loss: 840.4041,\n",
      " train_mae: 25.4047,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1285/10000,\n",
      " train_loss: 840.4003,\n",
      " train_mae: 25.4045,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1286/10000,\n",
      " train_loss: 840.3967,\n",
      " train_mae: 25.4044,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1287/10000,\n",
      " train_loss: 840.3930,\n",
      " train_mae: 25.4042,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1288/10000,\n",
      " train_loss: 840.3892,\n",
      " train_mae: 25.4041,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1289/10000,\n",
      " train_loss: 840.3854,\n",
      " train_mae: 25.4039,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1290/10000,\n",
      " train_loss: 840.3818,\n",
      " train_mae: 25.4038,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1291/10000,\n",
      " train_loss: 840.3782,\n",
      " train_mae: 25.4036,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1292/10000,\n",
      " train_loss: 840.3746,\n",
      " train_mae: 25.4035,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1293/10000,\n",
      " train_loss: 840.3705,\n",
      " train_mae: 25.4033,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1294/10000,\n",
      " train_loss: 840.3671,\n",
      " train_mae: 25.4032,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1295/10000,\n",
      " train_loss: 840.3633,\n",
      " train_mae: 25.4030,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1296/10000,\n",
      " train_loss: 840.3597,\n",
      " train_mae: 25.4029,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1297/10000,\n",
      " train_loss: 840.3563,\n",
      " train_mae: 25.4027,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1298/10000,\n",
      " train_loss: 840.3525,\n",
      " train_mae: 25.4026,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1299/10000,\n",
      " train_loss: 840.3488,\n",
      " train_mae: 25.4024,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1300/10000,\n",
      " train_loss: 840.3451,\n",
      " train_mae: 25.4023,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1301/10000,\n",
      " train_loss: 840.3415,\n",
      " train_mae: 25.4021,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1302/10000,\n",
      " train_loss: 840.3380,\n",
      " train_mae: 25.4020,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1303/10000,\n",
      " train_loss: 840.3344,\n",
      " train_mae: 25.4018,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1304/10000,\n",
      " train_loss: 840.3306,\n",
      " train_mae: 25.4016,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1305/10000,\n",
      " train_loss: 840.3270,\n",
      " train_mae: 25.4015,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1306/10000,\n",
      " train_loss: 840.3235,\n",
      " train_mae: 25.4013,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1307/10000,\n",
      " train_loss: 840.3202,\n",
      " train_mae: 25.4012,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1308/10000,\n",
      " train_loss: 840.3167,\n",
      " train_mae: 25.4011,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1309/10000,\n",
      " train_loss: 840.3129,\n",
      " train_mae: 25.4009,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1310/10000,\n",
      " train_loss: 840.3094,\n",
      " train_mae: 25.4008,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 1311/10000,\n",
      " train_loss: 840.3058,\n",
      " train_mae: 25.4006,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 1312/10000,\n",
      " train_loss: 840.3022,\n",
      " train_mae: 25.4005,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 1313/10000,\n",
      " train_loss: 840.2988,\n",
      " train_mae: 25.4003,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1314/10000,\n",
      " train_loss: 840.2953,\n",
      " train_mae: 25.4001,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 1315/10000,\n",
      " train_loss: 840.2916,\n",
      " train_mae: 25.4000,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 1316/10000,\n",
      " train_loss: 840.2883,\n",
      " train_mae: 25.3998,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1317/10000,\n",
      " train_loss: 840.2846,\n",
      " train_mae: 25.3997,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 1318/10000,\n",
      " train_loss: 840.2812,\n",
      " train_mae: 25.3995,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1319/10000,\n",
      " train_loss: 840.2779,\n",
      " train_mae: 25.3994,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1320/10000,\n",
      " train_loss: 840.2745,\n",
      " train_mae: 25.3993,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1321/10000,\n",
      " train_loss: 840.2709,\n",
      " train_mae: 25.3991,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1322/10000,\n",
      " train_loss: 840.2673,\n",
      " train_mae: 25.3990,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1323/10000,\n",
      " train_loss: 840.2639,\n",
      " train_mae: 25.3988,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1324/10000,\n",
      " train_loss: 840.2604,\n",
      " train_mae: 25.3987,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1325/10000,\n",
      " train_loss: 840.2571,\n",
      " train_mae: 25.3985,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1326/10000,\n",
      " train_loss: 840.2538,\n",
      " train_mae: 25.3984,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1327/10000,\n",
      " train_loss: 840.2503,\n",
      " train_mae: 25.3983,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1328/10000,\n",
      " train_loss: 840.2468,\n",
      " train_mae: 25.3981,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1329/10000,\n",
      " train_loss: 840.2436,\n",
      " train_mae: 25.3980,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1330/10000,\n",
      " train_loss: 840.2403,\n",
      " train_mae: 25.3978,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1331/10000,\n",
      " train_loss: 840.2369,\n",
      " train_mae: 25.3977,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1332/10000,\n",
      " train_loss: 840.2333,\n",
      " train_mae: 25.3975,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1333/10000,\n",
      " train_loss: 840.2301,\n",
      " train_mae: 25.3974,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1334/10000,\n",
      " train_loss: 840.2269,\n",
      " train_mae: 25.3973,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1335/10000,\n",
      " train_loss: 840.2233,\n",
      " train_mae: 25.3971,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1336/10000,\n",
      " train_loss: 840.2200,\n",
      " train_mae: 25.3970,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1337/10000,\n",
      " train_loss: 840.2170,\n",
      " train_mae: 25.3968,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 1338/10000,\n",
      " train_loss: 840.2136,\n",
      " train_mae: 25.3967,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1339/10000,\n",
      " train_loss: 840.2102,\n",
      " train_mae: 25.3965,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1340/10000,\n",
      " train_loss: 840.2067,\n",
      " train_mae: 25.3964,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1341/10000,\n",
      " train_loss: 840.2037,\n",
      " train_mae: 25.3963,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1342/10000,\n",
      " train_loss: 840.2004,\n",
      " train_mae: 25.3961,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1343/10000,\n",
      " train_loss: 840.1970,\n",
      " train_mae: 25.3960,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1344/10000,\n",
      " train_loss: 840.1936,\n",
      " train_mae: 25.3958,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1345/10000,\n",
      " train_loss: 840.1904,\n",
      " train_mae: 25.3957,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1346/10000,\n",
      " train_loss: 840.1870,\n",
      " train_mae: 25.3955,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1347/10000,\n",
      " train_loss: 840.1843,\n",
      " train_mae: 25.3954,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1348/10000,\n",
      " train_loss: 840.1807,\n",
      " train_mae: 25.3953,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 1349/10000,\n",
      " train_loss: 840.1778,\n",
      " train_mae: 25.3951,\n",
      " epoch_time_duration: 0.0118\n",
      "\n",
      "epoch: 1350/10000,\n",
      " train_loss: 840.1741,\n",
      " train_mae: 25.3950,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1351/10000,\n",
      " train_loss: 840.1708,\n",
      " train_mae: 25.3948,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1352/10000,\n",
      " train_loss: 840.1677,\n",
      " train_mae: 25.3947,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1353/10000,\n",
      " train_loss: 840.1644,\n",
      " train_mae: 25.3946,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1354/10000,\n",
      " train_loss: 840.1614,\n",
      " train_mae: 25.3945,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1355/10000,\n",
      " train_loss: 840.1585,\n",
      " train_mae: 25.3943,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1356/10000,\n",
      " train_loss: 840.1549,\n",
      " train_mae: 25.3942,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1357/10000,\n",
      " train_loss: 840.1520,\n",
      " train_mae: 25.3940,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1358/10000,\n",
      " train_loss: 840.1489,\n",
      " train_mae: 25.3938,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1359/10000,\n",
      " train_loss: 840.1455,\n",
      " train_mae: 25.3938,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1360/10000,\n",
      " train_loss: 840.1425,\n",
      " train_mae: 25.3936,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1361/10000,\n",
      " train_loss: 840.1392,\n",
      " train_mae: 25.3935,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1362/10000,\n",
      " train_loss: 840.1362,\n",
      " train_mae: 25.3933,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1363/10000,\n",
      " train_loss: 840.1331,\n",
      " train_mae: 25.3932,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1364/10000,\n",
      " train_loss: 840.1301,\n",
      " train_mae: 25.3931,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1365/10000,\n",
      " train_loss: 840.1269,\n",
      " train_mae: 25.3929,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1366/10000,\n",
      " train_loss: 840.1237,\n",
      " train_mae: 25.3928,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1367/10000,\n",
      " train_loss: 840.1208,\n",
      " train_mae: 25.3927,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1368/10000,\n",
      " train_loss: 840.1176,\n",
      " train_mae: 25.3925,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1369/10000,\n",
      " train_loss: 840.1145,\n",
      " train_mae: 25.3924,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1370/10000,\n",
      " train_loss: 840.1112,\n",
      " train_mae: 25.3922,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1371/10000,\n",
      " train_loss: 840.1084,\n",
      " train_mae: 25.3921,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1372/10000,\n",
      " train_loss: 840.1056,\n",
      " train_mae: 25.3920,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1373/10000,\n",
      " train_loss: 840.1025,\n",
      " train_mae: 25.3918,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1374/10000,\n",
      " train_loss: 840.0992,\n",
      " train_mae: 25.3917,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1375/10000,\n",
      " train_loss: 840.0960,\n",
      " train_mae: 25.3916,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1376/10000,\n",
      " train_loss: 840.0932,\n",
      " train_mae: 25.3915,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1377/10000,\n",
      " train_loss: 840.0902,\n",
      " train_mae: 25.3913,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1378/10000,\n",
      " train_loss: 840.0872,\n",
      " train_mae: 25.3912,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1379/10000,\n",
      " train_loss: 840.0845,\n",
      " train_mae: 25.3911,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1380/10000,\n",
      " train_loss: 840.0812,\n",
      " train_mae: 25.3909,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1381/10000,\n",
      " train_loss: 840.0786,\n",
      " train_mae: 25.3908,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1382/10000,\n",
      " train_loss: 840.0754,\n",
      " train_mae: 25.3906,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1383/10000,\n",
      " train_loss: 840.0724,\n",
      " train_mae: 25.3905,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1384/10000,\n",
      " train_loss: 840.0692,\n",
      " train_mae: 25.3904,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1385/10000,\n",
      " train_loss: 840.0663,\n",
      " train_mae: 25.3903,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1386/10000,\n",
      " train_loss: 840.0635,\n",
      " train_mae: 25.3901,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1387/10000,\n",
      " train_loss: 840.0605,\n",
      " train_mae: 25.3900,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1388/10000,\n",
      " train_loss: 840.0577,\n",
      " train_mae: 25.3898,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1389/10000,\n",
      " train_loss: 840.0547,\n",
      " train_mae: 25.3898,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1390/10000,\n",
      " train_loss: 840.0519,\n",
      " train_mae: 25.3896,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 1391/10000,\n",
      " train_loss: 840.0486,\n",
      " train_mae: 25.3895,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 1392/10000,\n",
      " train_loss: 840.0460,\n",
      " train_mae: 25.3894,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1393/10000,\n",
      " train_loss: 840.0430,\n",
      " train_mae: 25.3892,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1394/10000,\n",
      " train_loss: 840.0400,\n",
      " train_mae: 25.3891,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1395/10000,\n",
      " train_loss: 840.0374,\n",
      " train_mae: 25.3890,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1396/10000,\n",
      " train_loss: 840.0344,\n",
      " train_mae: 25.3888,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 1397/10000,\n",
      " train_loss: 840.0319,\n",
      " train_mae: 25.3887,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1398/10000,\n",
      " train_loss: 840.0287,\n",
      " train_mae: 25.3886,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1399/10000,\n",
      " train_loss: 840.0258,\n",
      " train_mae: 25.3885,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 1400/10000,\n",
      " train_loss: 840.0229,\n",
      " train_mae: 25.3883,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1401/10000,\n",
      " train_loss: 840.0204,\n",
      " train_mae: 25.3882,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1402/10000,\n",
      " train_loss: 840.0173,\n",
      " train_mae: 25.3881,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1403/10000,\n",
      " train_loss: 840.0143,\n",
      " train_mae: 25.3880,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1404/10000,\n",
      " train_loss: 840.0118,\n",
      " train_mae: 25.3878,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1405/10000,\n",
      " train_loss: 840.0089,\n",
      " train_mae: 25.3877,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1406/10000,\n",
      " train_loss: 840.0062,\n",
      " train_mae: 25.3876,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1407/10000,\n",
      " train_loss: 840.0034,\n",
      " train_mae: 25.3874,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1408/10000,\n",
      " train_loss: 840.0005,\n",
      " train_mae: 25.3873,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1409/10000,\n",
      " train_loss: 839.9978,\n",
      " train_mae: 25.3872,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1410/10000,\n",
      " train_loss: 839.9951,\n",
      " train_mae: 25.3871,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1411/10000,\n",
      " train_loss: 839.9923,\n",
      " train_mae: 25.3870,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1412/10000,\n",
      " train_loss: 839.9896,\n",
      " train_mae: 25.3868,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1413/10000,\n",
      " train_loss: 839.9869,\n",
      " train_mae: 25.3867,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1414/10000,\n",
      " train_loss: 839.9838,\n",
      " train_mae: 25.3866,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1415/10000,\n",
      " train_loss: 839.9815,\n",
      " train_mae: 25.3865,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1416/10000,\n",
      " train_loss: 839.9786,\n",
      " train_mae: 25.3863,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1417/10000,\n",
      " train_loss: 839.9759,\n",
      " train_mae: 25.3862,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1418/10000,\n",
      " train_loss: 839.9732,\n",
      " train_mae: 25.3861,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1419/10000,\n",
      " train_loss: 839.9706,\n",
      " train_mae: 25.3859,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1420/10000,\n",
      " train_loss: 839.9679,\n",
      " train_mae: 25.3858,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1421/10000,\n",
      " train_loss: 839.9652,\n",
      " train_mae: 25.3857,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1422/10000,\n",
      " train_loss: 839.9623,\n",
      " train_mae: 25.3856,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1423/10000,\n",
      " train_loss: 839.9596,\n",
      " train_mae: 25.3855,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1424/10000,\n",
      " train_loss: 839.9573,\n",
      " train_mae: 25.3853,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1425/10000,\n",
      " train_loss: 839.9545,\n",
      " train_mae: 25.3852,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 1426/10000,\n",
      " train_loss: 839.9518,\n",
      " train_mae: 25.3851,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "epoch: 1427/10000,\n",
      " train_loss: 839.9490,\n",
      " train_mae: 25.3850,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1428/10000,\n",
      " train_loss: 839.9464,\n",
      " train_mae: 25.3849,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1429/10000,\n",
      " train_loss: 839.9439,\n",
      " train_mae: 25.3847,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1430/10000,\n",
      " train_loss: 839.9413,\n",
      " train_mae: 25.3846,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 1431/10000,\n",
      " train_loss: 839.9385,\n",
      " train_mae: 25.3845,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1432/10000,\n",
      " train_loss: 839.9360,\n",
      " train_mae: 25.3844,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1433/10000,\n",
      " train_loss: 839.9333,\n",
      " train_mae: 25.3843,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1434/10000,\n",
      " train_loss: 839.9305,\n",
      " train_mae: 25.3841,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1435/10000,\n",
      " train_loss: 839.9282,\n",
      " train_mae: 25.3840,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1436/10000,\n",
      " train_loss: 839.9257,\n",
      " train_mae: 25.3839,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1437/10000,\n",
      " train_loss: 839.9228,\n",
      " train_mae: 25.3838,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1438/10000,\n",
      " train_loss: 839.9205,\n",
      " train_mae: 25.3837,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1439/10000,\n",
      " train_loss: 839.9175,\n",
      " train_mae: 25.3835,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1440/10000,\n",
      " train_loss: 839.9153,\n",
      " train_mae: 25.3834,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1441/10000,\n",
      " train_loss: 839.9127,\n",
      " train_mae: 25.3833,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1442/10000,\n",
      " train_loss: 839.9103,\n",
      " train_mae: 25.3832,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1443/10000,\n",
      " train_loss: 839.9076,\n",
      " train_mae: 25.3831,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1444/10000,\n",
      " train_loss: 839.9053,\n",
      " train_mae: 25.3830,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1445/10000,\n",
      " train_loss: 839.9025,\n",
      " train_mae: 25.3829,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1446/10000,\n",
      " train_loss: 839.9000,\n",
      " train_mae: 25.3827,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1447/10000,\n",
      " train_loss: 839.8975,\n",
      " train_mae: 25.3826,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1448/10000,\n",
      " train_loss: 839.8952,\n",
      " train_mae: 25.3825,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1449/10000,\n",
      " train_loss: 839.8927,\n",
      " train_mae: 25.3824,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1450/10000,\n",
      " train_loss: 839.8898,\n",
      " train_mae: 25.3823,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1451/10000,\n",
      " train_loss: 839.8876,\n",
      " train_mae: 25.3822,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1452/10000,\n",
      " train_loss: 839.8852,\n",
      " train_mae: 25.3820,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1453/10000,\n",
      " train_loss: 839.8829,\n",
      " train_mae: 25.3819,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1454/10000,\n",
      " train_loss: 839.8801,\n",
      " train_mae: 25.3818,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1455/10000,\n",
      " train_loss: 839.8779,\n",
      " train_mae: 25.3817,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1456/10000,\n",
      " train_loss: 839.8753,\n",
      " train_mae: 25.3816,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1457/10000,\n",
      " train_loss: 839.8728,\n",
      " train_mae: 25.3815,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1458/10000,\n",
      " train_loss: 839.8705,\n",
      " train_mae: 25.3814,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1459/10000,\n",
      " train_loss: 839.8679,\n",
      " train_mae: 25.3812,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1460/10000,\n",
      " train_loss: 839.8658,\n",
      " train_mae: 25.3812,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1461/10000,\n",
      " train_loss: 839.8632,\n",
      " train_mae: 25.3810,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1462/10000,\n",
      " train_loss: 839.8610,\n",
      " train_mae: 25.3809,\n",
      " epoch_time_duration: 0.0129\n",
      "\n",
      "epoch: 1463/10000,\n",
      " train_loss: 839.8583,\n",
      " train_mae: 25.3808,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1464/10000,\n",
      " train_loss: 839.8558,\n",
      " train_mae: 25.3806,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1465/10000,\n",
      " train_loss: 839.8537,\n",
      " train_mae: 25.3806,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1466/10000,\n",
      " train_loss: 839.8512,\n",
      " train_mae: 25.3804,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1467/10000,\n",
      " train_loss: 839.8490,\n",
      " train_mae: 25.3804,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 1468/10000,\n",
      " train_loss: 839.8464,\n",
      " train_mae: 25.3802,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1469/10000,\n",
      " train_loss: 839.8440,\n",
      " train_mae: 25.3801,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1470/10000,\n",
      " train_loss: 839.8417,\n",
      " train_mae: 25.3800,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1471/10000,\n",
      " train_loss: 839.8393,\n",
      " train_mae: 25.3799,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 1472/10000,\n",
      " train_loss: 839.8370,\n",
      " train_mae: 25.3798,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 1473/10000,\n",
      " train_loss: 839.8346,\n",
      " train_mae: 25.3797,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 1474/10000,\n",
      " train_loss: 839.8324,\n",
      " train_mae: 25.3796,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 1475/10000,\n",
      " train_loss: 839.8298,\n",
      " train_mae: 25.3795,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1476/10000,\n",
      " train_loss: 839.8278,\n",
      " train_mae: 25.3793,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1477/10000,\n",
      " train_loss: 839.8254,\n",
      " train_mae: 25.3793,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1478/10000,\n",
      " train_loss: 839.8232,\n",
      " train_mae: 25.3791,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1479/10000,\n",
      " train_loss: 839.8209,\n",
      " train_mae: 25.3790,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1480/10000,\n",
      " train_loss: 839.8185,\n",
      " train_mae: 25.3789,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1481/10000,\n",
      " train_loss: 839.8163,\n",
      " train_mae: 25.3788,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1482/10000,\n",
      " train_loss: 839.8136,\n",
      " train_mae: 25.3787,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1483/10000,\n",
      " train_loss: 839.8116,\n",
      " train_mae: 25.3786,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1484/10000,\n",
      " train_loss: 839.8093,\n",
      " train_mae: 25.3785,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1485/10000,\n",
      " train_loss: 839.8071,\n",
      " train_mae: 25.3784,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1486/10000,\n",
      " train_loss: 839.8049,\n",
      " train_mae: 25.3782,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1487/10000,\n",
      " train_loss: 839.8027,\n",
      " train_mae: 25.3782,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1488/10000,\n",
      " train_loss: 839.8002,\n",
      " train_mae: 25.3780,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1489/10000,\n",
      " train_loss: 839.7982,\n",
      " train_mae: 25.3779,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1490/10000,\n",
      " train_loss: 839.7960,\n",
      " train_mae: 25.3778,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1491/10000,\n",
      " train_loss: 839.7936,\n",
      " train_mae: 25.3777,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1492/10000,\n",
      " train_loss: 839.7914,\n",
      " train_mae: 25.3776,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1493/10000,\n",
      " train_loss: 839.7892,\n",
      " train_mae: 25.3775,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1494/10000,\n",
      " train_loss: 839.7872,\n",
      " train_mae: 25.3774,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 1495/10000,\n",
      " train_loss: 839.7848,\n",
      " train_mae: 25.3773,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1496/10000,\n",
      " train_loss: 839.7825,\n",
      " train_mae: 25.3772,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1497/10000,\n",
      " train_loss: 839.7804,\n",
      " train_mae: 25.3771,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1498/10000,\n",
      " train_loss: 839.7782,\n",
      " train_mae: 25.3770,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1499/10000,\n",
      " train_loss: 839.7763,\n",
      " train_mae: 25.3769,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1500/10000,\n",
      " train_loss: 839.7740,\n",
      " train_mae: 25.3768,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1501/10000,\n",
      " train_loss: 839.7717,\n",
      " train_mae: 25.3767,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1502/10000,\n",
      " train_loss: 839.7696,\n",
      " train_mae: 25.3766,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1503/10000,\n",
      " train_loss: 839.7673,\n",
      " train_mae: 25.3765,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1504/10000,\n",
      " train_loss: 839.7654,\n",
      " train_mae: 25.3764,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1505/10000,\n",
      " train_loss: 839.7631,\n",
      " train_mae: 25.3763,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1506/10000,\n",
      " train_loss: 839.7611,\n",
      " train_mae: 25.3761,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1507/10000,\n",
      " train_loss: 839.7588,\n",
      " train_mae: 25.3761,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1508/10000,\n",
      " train_loss: 839.7567,\n",
      " train_mae: 25.3759,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1509/10000,\n",
      " train_loss: 839.7548,\n",
      " train_mae: 25.3759,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1510/10000,\n",
      " train_loss: 839.7526,\n",
      " train_mae: 25.3757,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1511/10000,\n",
      " train_loss: 839.7505,\n",
      " train_mae: 25.3756,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1512/10000,\n",
      " train_loss: 839.7484,\n",
      " train_mae: 25.3756,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1513/10000,\n",
      " train_loss: 839.7464,\n",
      " train_mae: 25.3754,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1514/10000,\n",
      " train_loss: 839.7441,\n",
      " train_mae: 25.3753,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1515/10000,\n",
      " train_loss: 839.7421,\n",
      " train_mae: 25.3753,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1516/10000,\n",
      " train_loss: 839.7400,\n",
      " train_mae: 25.3751,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1517/10000,\n",
      " train_loss: 839.7380,\n",
      " train_mae: 25.3751,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1518/10000,\n",
      " train_loss: 839.7357,\n",
      " train_mae: 25.3749,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1519/10000,\n",
      " train_loss: 839.7340,\n",
      " train_mae: 25.3749,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1520/10000,\n",
      " train_loss: 839.7318,\n",
      " train_mae: 25.3747,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1521/10000,\n",
      " train_loss: 839.7297,\n",
      " train_mae: 25.3747,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1522/10000,\n",
      " train_loss: 839.7277,\n",
      " train_mae: 25.3745,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1523/10000,\n",
      " train_loss: 839.7253,\n",
      " train_mae: 25.3744,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1524/10000,\n",
      " train_loss: 839.7236,\n",
      " train_mae: 25.3744,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1525/10000,\n",
      " train_loss: 839.7216,\n",
      " train_mae: 25.3742,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1526/10000,\n",
      " train_loss: 839.7194,\n",
      " train_mae: 25.3742,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1527/10000,\n",
      " train_loss: 839.7177,\n",
      " train_mae: 25.3741,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1528/10000,\n",
      " train_loss: 839.7155,\n",
      " train_mae: 25.3739,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1529/10000,\n",
      " train_loss: 839.7137,\n",
      " train_mae: 25.3739,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1530/10000,\n",
      " train_loss: 839.7116,\n",
      " train_mae: 25.3737,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1531/10000,\n",
      " train_loss: 839.7095,\n",
      " train_mae: 25.3737,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1532/10000,\n",
      " train_loss: 839.7076,\n",
      " train_mae: 25.3736,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1533/10000,\n",
      " train_loss: 839.7054,\n",
      " train_mae: 25.3734,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 1534/10000,\n",
      " train_loss: 839.7037,\n",
      " train_mae: 25.3734,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1535/10000,\n",
      " train_loss: 839.7017,\n",
      " train_mae: 25.3732,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1536/10000,\n",
      " train_loss: 839.6998,\n",
      " train_mae: 25.3732,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1537/10000,\n",
      " train_loss: 839.6978,\n",
      " train_mae: 25.3731,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1538/10000,\n",
      " train_loss: 839.6959,\n",
      " train_mae: 25.3730,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1539/10000,\n",
      " train_loss: 839.6940,\n",
      " train_mae: 25.3729,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1540/10000,\n",
      " train_loss: 839.6920,\n",
      " train_mae: 25.3728,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1541/10000,\n",
      " train_loss: 839.6900,\n",
      " train_mae: 25.3727,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1542/10000,\n",
      " train_loss: 839.6882,\n",
      " train_mae: 25.3726,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1543/10000,\n",
      " train_loss: 839.6860,\n",
      " train_mae: 25.3725,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1544/10000,\n",
      " train_loss: 839.6843,\n",
      " train_mae: 25.3725,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1545/10000,\n",
      " train_loss: 839.6823,\n",
      " train_mae: 25.3723,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1546/10000,\n",
      " train_loss: 839.6804,\n",
      " train_mae: 25.3722,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1547/10000,\n",
      " train_loss: 839.6783,\n",
      " train_mae: 25.3722,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1548/10000,\n",
      " train_loss: 839.6765,\n",
      " train_mae: 25.3720,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1549/10000,\n",
      " train_loss: 839.6745,\n",
      " train_mae: 25.3720,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1550/10000,\n",
      " train_loss: 839.6727,\n",
      " train_mae: 25.3718,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1551/10000,\n",
      " train_loss: 839.6710,\n",
      " train_mae: 25.3717,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1552/10000,\n",
      " train_loss: 839.6691,\n",
      " train_mae: 25.3717,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1553/10000,\n",
      " train_loss: 839.6672,\n",
      " train_mae: 25.3715,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1554/10000,\n",
      " train_loss: 839.6655,\n",
      " train_mae: 25.3715,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1555/10000,\n",
      " train_loss: 839.6633,\n",
      " train_mae: 25.3714,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1556/10000,\n",
      " train_loss: 839.6617,\n",
      " train_mae: 25.3713,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1557/10000,\n",
      " train_loss: 839.6597,\n",
      " train_mae: 25.3712,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1558/10000,\n",
      " train_loss: 839.6578,\n",
      " train_mae: 25.3711,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1559/10000,\n",
      " train_loss: 839.6560,\n",
      " train_mae: 25.3710,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1560/10000,\n",
      " train_loss: 839.6543,\n",
      " train_mae: 25.3709,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 1561/10000,\n",
      " train_loss: 839.6525,\n",
      " train_mae: 25.3708,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 1562/10000,\n",
      " train_loss: 839.6506,\n",
      " train_mae: 25.3707,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 1563/10000,\n",
      " train_loss: 839.6487,\n",
      " train_mae: 25.3706,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 1564/10000,\n",
      " train_loss: 839.6470,\n",
      " train_mae: 25.3706,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 1565/10000,\n",
      " train_loss: 839.6451,\n",
      " train_mae: 25.3704,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1566/10000,\n",
      " train_loss: 839.6433,\n",
      " train_mae: 25.3704,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 1567/10000,\n",
      " train_loss: 839.6416,\n",
      " train_mae: 25.3703,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1568/10000,\n",
      " train_loss: 839.6396,\n",
      " train_mae: 25.3702,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "epoch: 1569/10000,\n",
      " train_loss: 839.6380,\n",
      " train_mae: 25.3701,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1570/10000,\n",
      " train_loss: 839.6362,\n",
      " train_mae: 25.3700,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 1571/10000,\n",
      " train_loss: 839.6342,\n",
      " train_mae: 25.3699,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 1572/10000,\n",
      " train_loss: 839.6325,\n",
      " train_mae: 25.3699,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1573/10000,\n",
      " train_loss: 839.6309,\n",
      " train_mae: 25.3697,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1574/10000,\n",
      " train_loss: 839.6289,\n",
      " train_mae: 25.3697,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1575/10000,\n",
      " train_loss: 839.6271,\n",
      " train_mae: 25.3696,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1576/10000,\n",
      " train_loss: 839.6255,\n",
      " train_mae: 25.3695,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1577/10000,\n",
      " train_loss: 839.6239,\n",
      " train_mae: 25.3694,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1578/10000,\n",
      " train_loss: 839.6221,\n",
      " train_mae: 25.3693,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1579/10000,\n",
      " train_loss: 839.6202,\n",
      " train_mae: 25.3692,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1580/10000,\n",
      " train_loss: 839.6186,\n",
      " train_mae: 25.3691,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1581/10000,\n",
      " train_loss: 839.6168,\n",
      " train_mae: 25.3690,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1582/10000,\n",
      " train_loss: 839.6151,\n",
      " train_mae: 25.3689,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1583/10000,\n",
      " train_loss: 839.6135,\n",
      " train_mae: 25.3689,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1584/10000,\n",
      " train_loss: 839.6116,\n",
      " train_mae: 25.3688,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1585/10000,\n",
      " train_loss: 839.6099,\n",
      " train_mae: 25.3687,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1586/10000,\n",
      " train_loss: 839.6083,\n",
      " train_mae: 25.3686,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1587/10000,\n",
      " train_loss: 839.6066,\n",
      " train_mae: 25.3685,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1588/10000,\n",
      " train_loss: 839.6048,\n",
      " train_mae: 25.3684,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1589/10000,\n",
      " train_loss: 839.6031,\n",
      " train_mae: 25.3683,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1590/10000,\n",
      " train_loss: 839.6012,\n",
      " train_mae: 25.3682,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1591/10000,\n",
      " train_loss: 839.5997,\n",
      " train_mae: 25.3682,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1592/10000,\n",
      " train_loss: 839.5980,\n",
      " train_mae: 25.3680,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1593/10000,\n",
      " train_loss: 839.5964,\n",
      " train_mae: 25.3680,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1594/10000,\n",
      " train_loss: 839.5944,\n",
      " train_mae: 25.3679,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1595/10000,\n",
      " train_loss: 839.5931,\n",
      " train_mae: 25.3678,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1596/10000,\n",
      " train_loss: 839.5912,\n",
      " train_mae: 25.3678,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1597/10000,\n",
      " train_loss: 839.5898,\n",
      " train_mae: 25.3676,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1598/10000,\n",
      " train_loss: 839.5881,\n",
      " train_mae: 25.3676,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1599/10000,\n",
      " train_loss: 839.5865,\n",
      " train_mae: 25.3675,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1600/10000,\n",
      " train_loss: 839.5848,\n",
      " train_mae: 25.3674,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1601/10000,\n",
      " train_loss: 839.5833,\n",
      " train_mae: 25.3673,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1602/10000,\n",
      " train_loss: 839.5814,\n",
      " train_mae: 25.3672,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1603/10000,\n",
      " train_loss: 839.5800,\n",
      " train_mae: 25.3672,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 1604/10000,\n",
      " train_loss: 839.5784,\n",
      " train_mae: 25.3671,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1605/10000,\n",
      " train_loss: 839.5766,\n",
      " train_mae: 25.3670,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1606/10000,\n",
      " train_loss: 839.5751,\n",
      " train_mae: 25.3669,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1607/10000,\n",
      " train_loss: 839.5735,\n",
      " train_mae: 25.3668,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1608/10000,\n",
      " train_loss: 839.5719,\n",
      " train_mae: 25.3668,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1609/10000,\n",
      " train_loss: 839.5703,\n",
      " train_mae: 25.3667,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1610/10000,\n",
      " train_loss: 839.5687,\n",
      " train_mae: 25.3666,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1611/10000,\n",
      " train_loss: 839.5668,\n",
      " train_mae: 25.3665,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1612/10000,\n",
      " train_loss: 839.5656,\n",
      " train_mae: 25.3664,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1613/10000,\n",
      " train_loss: 839.5637,\n",
      " train_mae: 25.3663,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1614/10000,\n",
      " train_loss: 839.5623,\n",
      " train_mae: 25.3663,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1615/10000,\n",
      " train_loss: 839.5607,\n",
      " train_mae: 25.3662,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1616/10000,\n",
      " train_loss: 839.5591,\n",
      " train_mae: 25.3661,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1617/10000,\n",
      " train_loss: 839.5575,\n",
      " train_mae: 25.3660,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1618/10000,\n",
      " train_loss: 839.5558,\n",
      " train_mae: 25.3659,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1619/10000,\n",
      " train_loss: 839.5544,\n",
      " train_mae: 25.3659,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1620/10000,\n",
      " train_loss: 839.5529,\n",
      " train_mae: 25.3658,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1621/10000,\n",
      " train_loss: 839.5512,\n",
      " train_mae: 25.3657,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1622/10000,\n",
      " train_loss: 839.5499,\n",
      " train_mae: 25.3656,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1623/10000,\n",
      " train_loss: 839.5483,\n",
      " train_mae: 25.3655,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1624/10000,\n",
      " train_loss: 839.5469,\n",
      " train_mae: 25.3654,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1625/10000,\n",
      " train_loss: 839.5452,\n",
      " train_mae: 25.3654,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1626/10000,\n",
      " train_loss: 839.5436,\n",
      " train_mae: 25.3653,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1627/10000,\n",
      " train_loss: 839.5424,\n",
      " train_mae: 25.3652,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1628/10000,\n",
      " train_loss: 839.5408,\n",
      " train_mae: 25.3651,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1629/10000,\n",
      " train_loss: 839.5392,\n",
      " train_mae: 25.3651,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1630/10000,\n",
      " train_loss: 839.5377,\n",
      " train_mae: 25.3650,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1631/10000,\n",
      " train_loss: 839.5360,\n",
      " train_mae: 25.3649,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1632/10000,\n",
      " train_loss: 839.5344,\n",
      " train_mae: 25.3648,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1633/10000,\n",
      " train_loss: 839.5333,\n",
      " train_mae: 25.3647,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1634/10000,\n",
      " train_loss: 839.5317,\n",
      " train_mae: 25.3646,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1635/10000,\n",
      " train_loss: 839.5302,\n",
      " train_mae: 25.3646,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1636/10000,\n",
      " train_loss: 839.5286,\n",
      " train_mae: 25.3645,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1637/10000,\n",
      " train_loss: 839.5271,\n",
      " train_mae: 25.3644,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1638/10000,\n",
      " train_loss: 839.5258,\n",
      " train_mae: 25.3644,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 1639/10000,\n",
      " train_loss: 839.5244,\n",
      " train_mae: 25.3643,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "epoch: 1640/10000,\n",
      " train_loss: 839.5228,\n",
      " train_mae: 25.3642,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1641/10000,\n",
      " train_loss: 839.5212,\n",
      " train_mae: 25.3641,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1642/10000,\n",
      " train_loss: 839.5198,\n",
      " train_mae: 25.3640,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1643/10000,\n",
      " train_loss: 839.5184,\n",
      " train_mae: 25.3640,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1644/10000,\n",
      " train_loss: 839.5169,\n",
      " train_mae: 25.3639,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1645/10000,\n",
      " train_loss: 839.5156,\n",
      " train_mae: 25.3638,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1646/10000,\n",
      " train_loss: 839.5142,\n",
      " train_mae: 25.3638,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1647/10000,\n",
      " train_loss: 839.5128,\n",
      " train_mae: 25.3637,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1648/10000,\n",
      " train_loss: 839.5112,\n",
      " train_mae: 25.3636,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1649/10000,\n",
      " train_loss: 839.5098,\n",
      " train_mae: 25.3635,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1650/10000,\n",
      " train_loss: 839.5084,\n",
      " train_mae: 25.3634,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1651/10000,\n",
      " train_loss: 839.5069,\n",
      " train_mae: 25.3634,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1652/10000,\n",
      " train_loss: 839.5054,\n",
      " train_mae: 25.3633,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1653/10000,\n",
      " train_loss: 839.5040,\n",
      " train_mae: 25.3632,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1654/10000,\n",
      " train_loss: 839.5026,\n",
      " train_mae: 25.3632,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1655/10000,\n",
      " train_loss: 839.5012,\n",
      " train_mae: 25.3630,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1656/10000,\n",
      " train_loss: 839.4998,\n",
      " train_mae: 25.3630,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1657/10000,\n",
      " train_loss: 839.4984,\n",
      " train_mae: 25.3629,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1658/10000,\n",
      " train_loss: 839.4971,\n",
      " train_mae: 25.3628,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1659/10000,\n",
      " train_loss: 839.4955,\n",
      " train_mae: 25.3628,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1660/10000,\n",
      " train_loss: 839.4943,\n",
      " train_mae: 25.3627,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1661/10000,\n",
      " train_loss: 839.4929,\n",
      " train_mae: 25.3626,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1662/10000,\n",
      " train_loss: 839.4916,\n",
      " train_mae: 25.3626,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1663/10000,\n",
      " train_loss: 839.4900,\n",
      " train_mae: 25.3625,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1664/10000,\n",
      " train_loss: 839.4888,\n",
      " train_mae: 25.3624,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1665/10000,\n",
      " train_loss: 839.4873,\n",
      " train_mae: 25.3623,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1666/10000,\n",
      " train_loss: 839.4860,\n",
      " train_mae: 25.3622,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1667/10000,\n",
      " train_loss: 839.4847,\n",
      " train_mae: 25.3622,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1668/10000,\n",
      " train_loss: 839.4835,\n",
      " train_mae: 25.3621,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1669/10000,\n",
      " train_loss: 839.4819,\n",
      " train_mae: 25.3620,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1670/10000,\n",
      " train_loss: 839.4807,\n",
      " train_mae: 25.3620,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1671/10000,\n",
      " train_loss: 839.4795,\n",
      " train_mae: 25.3619,\n",
      " epoch_time_duration: 0.0137\n",
      "\n",
      "epoch: 1672/10000,\n",
      " train_loss: 839.4782,\n",
      " train_mae: 25.3618,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1673/10000,\n",
      " train_loss: 839.4767,\n",
      " train_mae: 25.3618,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1674/10000,\n",
      " train_loss: 839.4753,\n",
      " train_mae: 25.3617,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1675/10000,\n",
      " train_loss: 839.4740,\n",
      " train_mae: 25.3616,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1676/10000,\n",
      " train_loss: 839.4726,\n",
      " train_mae: 25.3616,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1677/10000,\n",
      " train_loss: 839.4714,\n",
      " train_mae: 25.3615,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1678/10000,\n",
      " train_loss: 839.4702,\n",
      " train_mae: 25.3614,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1679/10000,\n",
      " train_loss: 839.4689,\n",
      " train_mae: 25.3613,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 1680/10000,\n",
      " train_loss: 839.4675,\n",
      " train_mae: 25.3613,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1681/10000,\n",
      " train_loss: 839.4662,\n",
      " train_mae: 25.3612,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1682/10000,\n",
      " train_loss: 839.4648,\n",
      " train_mae: 25.3611,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1683/10000,\n",
      " train_loss: 839.4636,\n",
      " train_mae: 25.3611,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1684/10000,\n",
      " train_loss: 839.4623,\n",
      " train_mae: 25.3610,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1685/10000,\n",
      " train_loss: 839.4609,\n",
      " train_mae: 25.3609,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1686/10000,\n",
      " train_loss: 839.4596,\n",
      " train_mae: 25.3608,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1687/10000,\n",
      " train_loss: 839.4583,\n",
      " train_mae: 25.3608,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1688/10000,\n",
      " train_loss: 839.4570,\n",
      " train_mae: 25.3607,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1689/10000,\n",
      " train_loss: 839.4560,\n",
      " train_mae: 25.3607,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1690/10000,\n",
      " train_loss: 839.4545,\n",
      " train_mae: 25.3606,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1691/10000,\n",
      " train_loss: 839.4533,\n",
      " train_mae: 25.3605,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1692/10000,\n",
      " train_loss: 839.4520,\n",
      " train_mae: 25.3605,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1693/10000,\n",
      " train_loss: 839.4506,\n",
      " train_mae: 25.3604,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1694/10000,\n",
      " train_loss: 839.4495,\n",
      " train_mae: 25.3603,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1695/10000,\n",
      " train_loss: 839.4482,\n",
      " train_mae: 25.3602,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1696/10000,\n",
      " train_loss: 839.4468,\n",
      " train_mae: 25.3602,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1697/10000,\n",
      " train_loss: 839.4459,\n",
      " train_mae: 25.3601,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1698/10000,\n",
      " train_loss: 839.4443,\n",
      " train_mae: 25.3600,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1699/10000,\n",
      " train_loss: 839.4431,\n",
      " train_mae: 25.3600,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1700/10000,\n",
      " train_loss: 839.4418,\n",
      " train_mae: 25.3599,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1701/10000,\n",
      " train_loss: 839.4407,\n",
      " train_mae: 25.3598,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1702/10000,\n",
      " train_loss: 839.4395,\n",
      " train_mae: 25.3598,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1703/10000,\n",
      " train_loss: 839.4382,\n",
      " train_mae: 25.3597,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1704/10000,\n",
      " train_loss: 839.4370,\n",
      " train_mae: 25.3596,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "epoch: 1705/10000,\n",
      " train_loss: 839.4359,\n",
      " train_mae: 25.3596,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 1706/10000,\n",
      " train_loss: 839.4346,\n",
      " train_mae: 25.3595,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 1707/10000,\n",
      " train_loss: 839.4333,\n",
      " train_mae: 25.3594,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1708/10000,\n",
      " train_loss: 839.4322,\n",
      " train_mae: 25.3594,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1709/10000,\n",
      " train_loss: 839.4310,\n",
      " train_mae: 25.3593,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1710/10000,\n",
      " train_loss: 839.4299,\n",
      " train_mae: 25.3592,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 1711/10000,\n",
      " train_loss: 839.4286,\n",
      " train_mae: 25.3592,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1712/10000,\n",
      " train_loss: 839.4273,\n",
      " train_mae: 25.3591,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1713/10000,\n",
      " train_loss: 839.4263,\n",
      " train_mae: 25.3591,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1714/10000,\n",
      " train_loss: 839.4250,\n",
      " train_mae: 25.3590,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1715/10000,\n",
      " train_loss: 839.4239,\n",
      " train_mae: 25.3589,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1716/10000,\n",
      " train_loss: 839.4227,\n",
      " train_mae: 25.3589,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1717/10000,\n",
      " train_loss: 839.4215,\n",
      " train_mae: 25.3588,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1718/10000,\n",
      " train_loss: 839.4202,\n",
      " train_mae: 25.3587,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1719/10000,\n",
      " train_loss: 839.4191,\n",
      " train_mae: 25.3587,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1720/10000,\n",
      " train_loss: 839.4179,\n",
      " train_mae: 25.3586,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1721/10000,\n",
      " train_loss: 839.4166,\n",
      " train_mae: 25.3585,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1722/10000,\n",
      " train_loss: 839.4155,\n",
      " train_mae: 25.3585,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1723/10000,\n",
      " train_loss: 839.4146,\n",
      " train_mae: 25.3584,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1724/10000,\n",
      " train_loss: 839.4132,\n",
      " train_mae: 25.3584,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1725/10000,\n",
      " train_loss: 839.4120,\n",
      " train_mae: 25.3583,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1726/10000,\n",
      " train_loss: 839.4110,\n",
      " train_mae: 25.3582,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1727/10000,\n",
      " train_loss: 839.4097,\n",
      " train_mae: 25.3582,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1728/10000,\n",
      " train_loss: 839.4088,\n",
      " train_mae: 25.3581,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1729/10000,\n",
      " train_loss: 839.4075,\n",
      " train_mae: 25.3580,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1730/10000,\n",
      " train_loss: 839.4064,\n",
      " train_mae: 25.3580,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1731/10000,\n",
      " train_loss: 839.4052,\n",
      " train_mae: 25.3579,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1732/10000,\n",
      " train_loss: 839.4041,\n",
      " train_mae: 25.3578,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1733/10000,\n",
      " train_loss: 839.4029,\n",
      " train_mae: 25.3578,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1734/10000,\n",
      " train_loss: 839.4017,\n",
      " train_mae: 25.3577,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1735/10000,\n",
      " train_loss: 839.4006,\n",
      " train_mae: 25.3577,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1736/10000,\n",
      " train_loss: 839.3998,\n",
      " train_mae: 25.3576,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1737/10000,\n",
      " train_loss: 839.3985,\n",
      " train_mae: 25.3575,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1738/10000,\n",
      " train_loss: 839.3973,\n",
      " train_mae: 25.3575,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 1739/10000,\n",
      " train_loss: 839.3962,\n",
      " train_mae: 25.3574,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "epoch: 1740/10000,\n",
      " train_loss: 839.3951,\n",
      " train_mae: 25.3573,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1741/10000,\n",
      " train_loss: 839.3940,\n",
      " train_mae: 25.3573,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1742/10000,\n",
      " train_loss: 839.3929,\n",
      " train_mae: 25.3572,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1743/10000,\n",
      " train_loss: 839.3920,\n",
      " train_mae: 25.3572,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1744/10000,\n",
      " train_loss: 839.3908,\n",
      " train_mae: 25.3571,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1745/10000,\n",
      " train_loss: 839.3896,\n",
      " train_mae: 25.3570,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1746/10000,\n",
      " train_loss: 839.3884,\n",
      " train_mae: 25.3570,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1747/10000,\n",
      " train_loss: 839.3875,\n",
      " train_mae: 25.3570,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1748/10000,\n",
      " train_loss: 839.3862,\n",
      " train_mae: 25.3568,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1749/10000,\n",
      " train_loss: 839.3852,\n",
      " train_mae: 25.3568,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1750/10000,\n",
      " train_loss: 839.3842,\n",
      " train_mae: 25.3568,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1751/10000,\n",
      " train_loss: 839.3831,\n",
      " train_mae: 25.3567,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1752/10000,\n",
      " train_loss: 839.3821,\n",
      " train_mae: 25.3566,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1753/10000,\n",
      " train_loss: 839.3809,\n",
      " train_mae: 25.3566,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1754/10000,\n",
      " train_loss: 839.3799,\n",
      " train_mae: 25.3565,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1755/10000,\n",
      " train_loss: 839.3788,\n",
      " train_mae: 25.3565,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1756/10000,\n",
      " train_loss: 839.3777,\n",
      " train_mae: 25.3564,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1757/10000,\n",
      " train_loss: 839.3766,\n",
      " train_mae: 25.3563,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1758/10000,\n",
      " train_loss: 839.3755,\n",
      " train_mae: 25.3563,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1759/10000,\n",
      " train_loss: 839.3745,\n",
      " train_mae: 25.3562,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1760/10000,\n",
      " train_loss: 839.3736,\n",
      " train_mae: 25.3562,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1761/10000,\n",
      " train_loss: 839.3724,\n",
      " train_mae: 25.3561,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1762/10000,\n",
      " train_loss: 839.3713,\n",
      " train_mae: 25.3560,\n",
      " epoch_time_duration: 0.0120\n",
      "\n",
      "epoch: 1763/10000,\n",
      " train_loss: 839.3702,\n",
      " train_mae: 25.3560,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1764/10000,\n",
      " train_loss: 839.3693,\n",
      " train_mae: 25.3560,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1765/10000,\n",
      " train_loss: 839.3683,\n",
      " train_mae: 25.3558,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1766/10000,\n",
      " train_loss: 839.3671,\n",
      " train_mae: 25.3558,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1767/10000,\n",
      " train_loss: 839.3661,\n",
      " train_mae: 25.3558,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1768/10000,\n",
      " train_loss: 839.3652,\n",
      " train_mae: 25.3557,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1769/10000,\n",
      " train_loss: 839.3641,\n",
      " train_mae: 25.3557,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1770/10000,\n",
      " train_loss: 839.3629,\n",
      " train_mae: 25.3556,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1771/10000,\n",
      " train_loss: 839.3620,\n",
      " train_mae: 25.3555,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 1772/10000,\n",
      " train_loss: 839.3609,\n",
      " train_mae: 25.3555,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1773/10000,\n",
      " train_loss: 839.3600,\n",
      " train_mae: 25.3554,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1774/10000,\n",
      " train_loss: 839.3589,\n",
      " train_mae: 25.3554,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1775/10000,\n",
      " train_loss: 839.3580,\n",
      " train_mae: 25.3553,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1776/10000,\n",
      " train_loss: 839.3569,\n",
      " train_mae: 25.3552,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1777/10000,\n",
      " train_loss: 839.3560,\n",
      " train_mae: 25.3552,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1778/10000,\n",
      " train_loss: 839.3549,\n",
      " train_mae: 25.3552,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1779/10000,\n",
      " train_loss: 839.3539,\n",
      " train_mae: 25.3551,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1780/10000,\n",
      " train_loss: 839.3528,\n",
      " train_mae: 25.3550,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1781/10000,\n",
      " train_loss: 839.3520,\n",
      " train_mae: 25.3550,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1782/10000,\n",
      " train_loss: 839.3509,\n",
      " train_mae: 25.3549,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1783/10000,\n",
      " train_loss: 839.3500,\n",
      " train_mae: 25.3549,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1784/10000,\n",
      " train_loss: 839.3489,\n",
      " train_mae: 25.3548,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1785/10000,\n",
      " train_loss: 839.3480,\n",
      " train_mae: 25.3547,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1786/10000,\n",
      " train_loss: 839.3470,\n",
      " train_mae: 25.3547,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1787/10000,\n",
      " train_loss: 839.3460,\n",
      " train_mae: 25.3547,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1788/10000,\n",
      " train_loss: 839.3452,\n",
      " train_mae: 25.3546,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1789/10000,\n",
      " train_loss: 839.3442,\n",
      " train_mae: 25.3545,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1790/10000,\n",
      " train_loss: 839.3431,\n",
      " train_mae: 25.3545,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1791/10000,\n",
      " train_loss: 839.3422,\n",
      " train_mae: 25.3544,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1792/10000,\n",
      " train_loss: 839.3411,\n",
      " train_mae: 25.3544,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1793/10000,\n",
      " train_loss: 839.3401,\n",
      " train_mae: 25.3543,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1794/10000,\n",
      " train_loss: 839.3392,\n",
      " train_mae: 25.3543,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1795/10000,\n",
      " train_loss: 839.3383,\n",
      " train_mae: 25.3542,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "epoch: 1796/10000,\n",
      " train_loss: 839.3372,\n",
      " train_mae: 25.3542,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1797/10000,\n",
      " train_loss: 839.3364,\n",
      " train_mae: 25.3541,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1798/10000,\n",
      " train_loss: 839.3356,\n",
      " train_mae: 25.3541,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1799/10000,\n",
      " train_loss: 839.3345,\n",
      " train_mae: 25.3540,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1800/10000,\n",
      " train_loss: 839.3336,\n",
      " train_mae: 25.3539,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1801/10000,\n",
      " train_loss: 839.3326,\n",
      " train_mae: 25.3539,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1802/10000,\n",
      " train_loss: 839.3317,\n",
      " train_mae: 25.3538,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1803/10000,\n",
      " train_loss: 839.3307,\n",
      " train_mae: 25.3538,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1804/10000,\n",
      " train_loss: 839.3298,\n",
      " train_mae: 25.3537,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1805/10000,\n",
      " train_loss: 839.3289,\n",
      " train_mae: 25.3537,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1806/10000,\n",
      " train_loss: 839.3281,\n",
      " train_mae: 25.3536,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1807/10000,\n",
      " train_loss: 839.3271,\n",
      " train_mae: 25.3536,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1808/10000,\n",
      " train_loss: 839.3261,\n",
      " train_mae: 25.3535,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1809/10000,\n",
      " train_loss: 839.3252,\n",
      " train_mae: 25.3535,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1810/10000,\n",
      " train_loss: 839.3243,\n",
      " train_mae: 25.3534,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 1811/10000,\n",
      " train_loss: 839.3234,\n",
      " train_mae: 25.3534,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1812/10000,\n",
      " train_loss: 839.3224,\n",
      " train_mae: 25.3533,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1813/10000,\n",
      " train_loss: 839.3215,\n",
      " train_mae: 25.3533,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1814/10000,\n",
      " train_loss: 839.3206,\n",
      " train_mae: 25.3532,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1815/10000,\n",
      " train_loss: 839.3198,\n",
      " train_mae: 25.3532,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 1816/10000,\n",
      " train_loss: 839.3189,\n",
      " train_mae: 25.3531,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1817/10000,\n",
      " train_loss: 839.3180,\n",
      " train_mae: 25.3531,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1818/10000,\n",
      " train_loss: 839.3170,\n",
      " train_mae: 25.3530,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 1819/10000,\n",
      " train_loss: 839.3162,\n",
      " train_mae: 25.3530,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1820/10000,\n",
      " train_loss: 839.3153,\n",
      " train_mae: 25.3529,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1821/10000,\n",
      " train_loss: 839.3145,\n",
      " train_mae: 25.3529,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1822/10000,\n",
      " train_loss: 839.3134,\n",
      " train_mae: 25.3528,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1823/10000,\n",
      " train_loss: 839.3127,\n",
      " train_mae: 25.3528,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1824/10000,\n",
      " train_loss: 839.3118,\n",
      " train_mae: 25.3527,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1825/10000,\n",
      " train_loss: 839.3110,\n",
      " train_mae: 25.3527,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1826/10000,\n",
      " train_loss: 839.3100,\n",
      " train_mae: 25.3526,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1827/10000,\n",
      " train_loss: 839.3093,\n",
      " train_mae: 25.3526,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 1828/10000,\n",
      " train_loss: 839.3082,\n",
      " train_mae: 25.3525,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 1829/10000,\n",
      " train_loss: 839.3075,\n",
      " train_mae: 25.3525,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1830/10000,\n",
      " train_loss: 839.3066,\n",
      " train_mae: 25.3524,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 1831/10000,\n",
      " train_loss: 839.3057,\n",
      " train_mae: 25.3524,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1832/10000,\n",
      " train_loss: 839.3049,\n",
      " train_mae: 25.3523,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "epoch: 1833/10000,\n",
      " train_loss: 839.3041,\n",
      " train_mae: 25.3523,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1834/10000,\n",
      " train_loss: 839.3033,\n",
      " train_mae: 25.3522,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1835/10000,\n",
      " train_loss: 839.3022,\n",
      " train_mae: 25.3522,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1836/10000,\n",
      " train_loss: 839.3015,\n",
      " train_mae: 25.3521,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1837/10000,\n",
      " train_loss: 839.3008,\n",
      " train_mae: 25.3521,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1838/10000,\n",
      " train_loss: 839.2998,\n",
      " train_mae: 25.3520,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 1839/10000,\n",
      " train_loss: 839.2991,\n",
      " train_mae: 25.3520,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 1840/10000,\n",
      " train_loss: 839.2980,\n",
      " train_mae: 25.3520,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 1841/10000,\n",
      " train_loss: 839.2972,\n",
      " train_mae: 25.3519,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1842/10000,\n",
      " train_loss: 839.2964,\n",
      " train_mae: 25.3519,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1843/10000,\n",
      " train_loss: 839.2956,\n",
      " train_mae: 25.3518,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1844/10000,\n",
      " train_loss: 839.2949,\n",
      " train_mae: 25.3518,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1845/10000,\n",
      " train_loss: 839.2941,\n",
      " train_mae: 25.3517,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1846/10000,\n",
      " train_loss: 839.2931,\n",
      " train_mae: 25.3517,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1847/10000,\n",
      " train_loss: 839.2923,\n",
      " train_mae: 25.3516,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1848/10000,\n",
      " train_loss: 839.2914,\n",
      " train_mae: 25.3516,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1849/10000,\n",
      " train_loss: 839.2906,\n",
      " train_mae: 25.3515,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1850/10000,\n",
      " train_loss: 839.2900,\n",
      " train_mae: 25.3515,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1851/10000,\n",
      " train_loss: 839.2890,\n",
      " train_mae: 25.3514,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1852/10000,\n",
      " train_loss: 839.2883,\n",
      " train_mae: 25.3514,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1853/10000,\n",
      " train_loss: 839.2874,\n",
      " train_mae: 25.3513,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1854/10000,\n",
      " train_loss: 839.2866,\n",
      " train_mae: 25.3513,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1855/10000,\n",
      " train_loss: 839.2857,\n",
      " train_mae: 25.3512,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1856/10000,\n",
      " train_loss: 839.2849,\n",
      " train_mae: 25.3512,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1857/10000,\n",
      " train_loss: 839.2842,\n",
      " train_mae: 25.3512,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1858/10000,\n",
      " train_loss: 839.2834,\n",
      " train_mae: 25.3511,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1859/10000,\n",
      " train_loss: 839.2826,\n",
      " train_mae: 25.3511,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1860/10000,\n",
      " train_loss: 839.2818,\n",
      " train_mae: 25.3510,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 1861/10000,\n",
      " train_loss: 839.2809,\n",
      " train_mae: 25.3510,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 1862/10000,\n",
      " train_loss: 839.2802,\n",
      " train_mae: 25.3509,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1863/10000,\n",
      " train_loss: 839.2795,\n",
      " train_mae: 25.3509,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1864/10000,\n",
      " train_loss: 839.2785,\n",
      " train_mae: 25.3508,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1865/10000,\n",
      " train_loss: 839.2778,\n",
      " train_mae: 25.3508,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "epoch: 1866/10000,\n",
      " train_loss: 839.2770,\n",
      " train_mae: 25.3508,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1867/10000,\n",
      " train_loss: 839.2763,\n",
      " train_mae: 25.3507,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1868/10000,\n",
      " train_loss: 839.2755,\n",
      " train_mae: 25.3507,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1869/10000,\n",
      " train_loss: 839.2746,\n",
      " train_mae: 25.3506,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1870/10000,\n",
      " train_loss: 839.2740,\n",
      " train_mae: 25.3506,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1871/10000,\n",
      " train_loss: 839.2732,\n",
      " train_mae: 25.3505,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1872/10000,\n",
      " train_loss: 839.2723,\n",
      " train_mae: 25.3505,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1873/10000,\n",
      " train_loss: 839.2716,\n",
      " train_mae: 25.3504,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1874/10000,\n",
      " train_loss: 839.2709,\n",
      " train_mae: 25.3504,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1875/10000,\n",
      " train_loss: 839.2701,\n",
      " train_mae: 25.3504,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1876/10000,\n",
      " train_loss: 839.2693,\n",
      " train_mae: 25.3503,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1877/10000,\n",
      " train_loss: 839.2687,\n",
      " train_mae: 25.3503,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1878/10000,\n",
      " train_loss: 839.2678,\n",
      " train_mae: 25.3502,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1879/10000,\n",
      " train_loss: 839.2670,\n",
      " train_mae: 25.3502,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 1880/10000,\n",
      " train_loss: 839.2662,\n",
      " train_mae: 25.3501,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1881/10000,\n",
      " train_loss: 839.2656,\n",
      " train_mae: 25.3501,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1882/10000,\n",
      " train_loss: 839.2648,\n",
      " train_mae: 25.3500,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1883/10000,\n",
      " train_loss: 839.2641,\n",
      " train_mae: 25.3500,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1884/10000,\n",
      " train_loss: 839.2633,\n",
      " train_mae: 25.3500,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1885/10000,\n",
      " train_loss: 839.2626,\n",
      " train_mae: 25.3499,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1886/10000,\n",
      " train_loss: 839.2618,\n",
      " train_mae: 25.3499,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1887/10000,\n",
      " train_loss: 839.2610,\n",
      " train_mae: 25.3498,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1888/10000,\n",
      " train_loss: 839.2602,\n",
      " train_mae: 25.3498,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1889/10000,\n",
      " train_loss: 839.2595,\n",
      " train_mae: 25.3498,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1890/10000,\n",
      " train_loss: 839.2589,\n",
      " train_mae: 25.3497,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1891/10000,\n",
      " train_loss: 839.2581,\n",
      " train_mae: 25.3497,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1892/10000,\n",
      " train_loss: 839.2573,\n",
      " train_mae: 25.3496,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1893/10000,\n",
      " train_loss: 839.2566,\n",
      " train_mae: 25.3496,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 1894/10000,\n",
      " train_loss: 839.2560,\n",
      " train_mae: 25.3496,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1895/10000,\n",
      " train_loss: 839.2552,\n",
      " train_mae: 25.3495,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1896/10000,\n",
      " train_loss: 839.2546,\n",
      " train_mae: 25.3495,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 1897/10000,\n",
      " train_loss: 839.2537,\n",
      " train_mae: 25.3494,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1898/10000,\n",
      " train_loss: 839.2531,\n",
      " train_mae: 25.3494,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1899/10000,\n",
      " train_loss: 839.2524,\n",
      " train_mae: 25.3493,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1900/10000,\n",
      " train_loss: 839.2516,\n",
      " train_mae: 25.3493,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1901/10000,\n",
      " train_loss: 839.2509,\n",
      " train_mae: 25.3493,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1902/10000,\n",
      " train_loss: 839.2502,\n",
      " train_mae: 25.3492,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 1903/10000,\n",
      " train_loss: 839.2494,\n",
      " train_mae: 25.3492,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1904/10000,\n",
      " train_loss: 839.2487,\n",
      " train_mae: 25.3491,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 1905/10000,\n",
      " train_loss: 839.2481,\n",
      " train_mae: 25.3491,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 1906/10000,\n",
      " train_loss: 839.2473,\n",
      " train_mae: 25.3491,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 1907/10000,\n",
      " train_loss: 839.2466,\n",
      " train_mae: 25.3490,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1908/10000,\n",
      " train_loss: 839.2460,\n",
      " train_mae: 25.3490,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1909/10000,\n",
      " train_loss: 839.2451,\n",
      " train_mae: 25.3489,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1910/10000,\n",
      " train_loss: 839.2444,\n",
      " train_mae: 25.3489,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1911/10000,\n",
      " train_loss: 839.2438,\n",
      " train_mae: 25.3489,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1912/10000,\n",
      " train_loss: 839.2432,\n",
      " train_mae: 25.3488,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1913/10000,\n",
      " train_loss: 839.2424,\n",
      " train_mae: 25.3488,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1914/10000,\n",
      " train_loss: 839.2418,\n",
      " train_mae: 25.3487,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1915/10000,\n",
      " train_loss: 839.2411,\n",
      " train_mae: 25.3487,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1916/10000,\n",
      " train_loss: 839.2403,\n",
      " train_mae: 25.3487,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1917/10000,\n",
      " train_loss: 839.2397,\n",
      " train_mae: 25.3486,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1918/10000,\n",
      " train_loss: 839.2390,\n",
      " train_mae: 25.3486,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1919/10000,\n",
      " train_loss: 839.2383,\n",
      " train_mae: 25.3485,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 1920/10000,\n",
      " train_loss: 839.2376,\n",
      " train_mae: 25.3485,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1921/10000,\n",
      " train_loss: 839.2369,\n",
      " train_mae: 25.3485,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1922/10000,\n",
      " train_loss: 839.2362,\n",
      " train_mae: 25.3484,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1923/10000,\n",
      " train_loss: 839.2356,\n",
      " train_mae: 25.3484,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 1924/10000,\n",
      " train_loss: 839.2348,\n",
      " train_mae: 25.3483,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1925/10000,\n",
      " train_loss: 839.2343,\n",
      " train_mae: 25.3483,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1926/10000,\n",
      " train_loss: 839.2335,\n",
      " train_mae: 25.3483,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1927/10000,\n",
      " train_loss: 839.2328,\n",
      " train_mae: 25.3482,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1928/10000,\n",
      " train_loss: 839.2321,\n",
      " train_mae: 25.3482,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 1929/10000,\n",
      " train_loss: 839.2314,\n",
      " train_mae: 25.3482,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1930/10000,\n",
      " train_loss: 839.2307,\n",
      " train_mae: 25.3481,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1931/10000,\n",
      " train_loss: 839.2300,\n",
      " train_mae: 25.3481,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1932/10000,\n",
      " train_loss: 839.2295,\n",
      " train_mae: 25.3480,\n",
      " epoch_time_duration: 0.0087\n",
      "\n",
      "epoch: 1933/10000,\n",
      " train_loss: 839.2288,\n",
      " train_mae: 25.3480,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1934/10000,\n",
      " train_loss: 839.2281,\n",
      " train_mae: 25.3479,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 1935/10000,\n",
      " train_loss: 839.2273,\n",
      " train_mae: 25.3479,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1936/10000,\n",
      " train_loss: 839.2267,\n",
      " train_mae: 25.3479,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 1937/10000,\n",
      " train_loss: 839.2260,\n",
      " train_mae: 25.3478,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1938/10000,\n",
      " train_loss: 839.2255,\n",
      " train_mae: 25.3478,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1939/10000,\n",
      " train_loss: 839.2247,\n",
      " train_mae: 25.3478,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1940/10000,\n",
      " train_loss: 839.2240,\n",
      " train_mae: 25.3477,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1941/10000,\n",
      " train_loss: 839.2234,\n",
      " train_mae: 25.3477,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1942/10000,\n",
      " train_loss: 839.2228,\n",
      " train_mae: 25.3477,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1943/10000,\n",
      " train_loss: 839.2221,\n",
      " train_mae: 25.3476,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1944/10000,\n",
      " train_loss: 839.2216,\n",
      " train_mae: 25.3476,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1945/10000,\n",
      " train_loss: 839.2209,\n",
      " train_mae: 25.3475,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1946/10000,\n",
      " train_loss: 839.2202,\n",
      " train_mae: 25.3475,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 1947/10000,\n",
      " train_loss: 839.2197,\n",
      " train_mae: 25.3475,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1948/10000,\n",
      " train_loss: 839.2189,\n",
      " train_mae: 25.3474,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1949/10000,\n",
      " train_loss: 839.2183,\n",
      " train_mae: 25.3474,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1950/10000,\n",
      " train_loss: 839.2177,\n",
      " train_mae: 25.3474,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 1951/10000,\n",
      " train_loss: 839.2169,\n",
      " train_mae: 25.3473,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 1952/10000,\n",
      " train_loss: 839.2164,\n",
      " train_mae: 25.3473,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1953/10000,\n",
      " train_loss: 839.2157,\n",
      " train_mae: 25.3473,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 1954/10000,\n",
      " train_loss: 839.2151,\n",
      " train_mae: 25.3472,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1955/10000,\n",
      " train_loss: 839.2145,\n",
      " train_mae: 25.3472,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 1956/10000,\n",
      " train_loss: 839.2138,\n",
      " train_mae: 25.3471,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1957/10000,\n",
      " train_loss: 839.2132,\n",
      " train_mae: 25.3471,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1958/10000,\n",
      " train_loss: 839.2125,\n",
      " train_mae: 25.3471,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1959/10000,\n",
      " train_loss: 839.2120,\n",
      " train_mae: 25.3470,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1960/10000,\n",
      " train_loss: 839.2113,\n",
      " train_mae: 25.3470,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1961/10000,\n",
      " train_loss: 839.2107,\n",
      " train_mae: 25.3470,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 1962/10000,\n",
      " train_loss: 839.2101,\n",
      " train_mae: 25.3469,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1963/10000,\n",
      " train_loss: 839.2094,\n",
      " train_mae: 25.3469,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 1964/10000,\n",
      " train_loss: 839.2089,\n",
      " train_mae: 25.3469,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1965/10000,\n",
      " train_loss: 839.2083,\n",
      " train_mae: 25.3468,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1966/10000,\n",
      " train_loss: 839.2076,\n",
      " train_mae: 25.3468,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1967/10000,\n",
      " train_loss: 839.2069,\n",
      " train_mae: 25.3468,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1968/10000,\n",
      " train_loss: 839.2064,\n",
      " train_mae: 25.3467,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 1969/10000,\n",
      " train_loss: 839.2057,\n",
      " train_mae: 25.3467,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 1970/10000,\n",
      " train_loss: 839.2052,\n",
      " train_mae: 25.3466,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 1971/10000,\n",
      " train_loss: 839.2045,\n",
      " train_mae: 25.3466,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 1972/10000,\n",
      " train_loss: 839.2040,\n",
      " train_mae: 25.3466,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 1973/10000,\n",
      " train_loss: 839.2034,\n",
      " train_mae: 25.3465,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 1974/10000,\n",
      " train_loss: 839.2026,\n",
      " train_mae: 25.3465,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1975/10000,\n",
      " train_loss: 839.2021,\n",
      " train_mae: 25.3465,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 1976/10000,\n",
      " train_loss: 839.2015,\n",
      " train_mae: 25.3464,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 1977/10000,\n",
      " train_loss: 839.2009,\n",
      " train_mae: 25.3464,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1978/10000,\n",
      " train_loss: 839.2003,\n",
      " train_mae: 25.3464,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1979/10000,\n",
      " train_loss: 839.1998,\n",
      " train_mae: 25.3463,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1980/10000,\n",
      " train_loss: 839.1992,\n",
      " train_mae: 25.3463,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1981/10000,\n",
      " train_loss: 839.1986,\n",
      " train_mae: 25.3463,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 1982/10000,\n",
      " train_loss: 839.1980,\n",
      " train_mae: 25.3462,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1983/10000,\n",
      " train_loss: 839.1973,\n",
      " train_mae: 25.3462,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1984/10000,\n",
      " train_loss: 839.1967,\n",
      " train_mae: 25.3462,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 1985/10000,\n",
      " train_loss: 839.1962,\n",
      " train_mae: 25.3461,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 1986/10000,\n",
      " train_loss: 839.1955,\n",
      " train_mae: 25.3461,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 1987/10000,\n",
      " train_loss: 839.1951,\n",
      " train_mae: 25.3461,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 1988/10000,\n",
      " train_loss: 839.1945,\n",
      " train_mae: 25.3460,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 1989/10000,\n",
      " train_loss: 839.1938,\n",
      " train_mae: 25.3460,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 1990/10000,\n",
      " train_loss: 839.1934,\n",
      " train_mae: 25.3460,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1991/10000,\n",
      " train_loss: 839.1927,\n",
      " train_mae: 25.3459,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 1992/10000,\n",
      " train_loss: 839.1921,\n",
      " train_mae: 25.3459,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 1993/10000,\n",
      " train_loss: 839.1915,\n",
      " train_mae: 25.3459,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 1994/10000,\n",
      " train_loss: 839.1909,\n",
      " train_mae: 25.3458,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 1995/10000,\n",
      " train_loss: 839.1903,\n",
      " train_mae: 25.3458,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 1996/10000,\n",
      " train_loss: 839.1898,\n",
      " train_mae: 25.3458,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 1997/10000,\n",
      " train_loss: 839.1892,\n",
      " train_mae: 25.3457,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 1998/10000,\n",
      " train_loss: 839.1887,\n",
      " train_mae: 25.3457,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 1999/10000,\n",
      " train_loss: 839.1880,\n",
      " train_mae: 25.3457,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2000/10000,\n",
      " train_loss: 839.1876,\n",
      " train_mae: 25.3456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2001/10000,\n",
      " train_loss: 839.1870,\n",
      " train_mae: 25.3456,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2002/10000,\n",
      " train_loss: 839.1864,\n",
      " train_mae: 25.3456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2003/10000,\n",
      " train_loss: 839.1857,\n",
      " train_mae: 25.3456,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2004/10000,\n",
      " train_loss: 839.1852,\n",
      " train_mae: 25.3455,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2005/10000,\n",
      " train_loss: 839.1847,\n",
      " train_mae: 25.3455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2006/10000,\n",
      " train_loss: 839.1841,\n",
      " train_mae: 25.3455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2007/10000,\n",
      " train_loss: 839.1836,\n",
      " train_mae: 25.3454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2008/10000,\n",
      " train_loss: 839.1830,\n",
      " train_mae: 25.3454,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2009/10000,\n",
      " train_loss: 839.1823,\n",
      " train_mae: 25.3454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2010/10000,\n",
      " train_loss: 839.1818,\n",
      " train_mae: 25.3453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2011/10000,\n",
      " train_loss: 839.1813,\n",
      " train_mae: 25.3453,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2012/10000,\n",
      " train_loss: 839.1808,\n",
      " train_mae: 25.3453,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2013/10000,\n",
      " train_loss: 839.1802,\n",
      " train_mae: 25.3452,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2014/10000,\n",
      " train_loss: 839.1797,\n",
      " train_mae: 25.3452,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2015/10000,\n",
      " train_loss: 839.1791,\n",
      " train_mae: 25.3452,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2016/10000,\n",
      " train_loss: 839.1786,\n",
      " train_mae: 25.3451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2017/10000,\n",
      " train_loss: 839.1780,\n",
      " train_mae: 25.3451,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2018/10000,\n",
      " train_loss: 839.1775,\n",
      " train_mae: 25.3451,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2019/10000,\n",
      " train_loss: 839.1771,\n",
      " train_mae: 25.3450,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2020/10000,\n",
      " train_loss: 839.1765,\n",
      " train_mae: 25.3450,\n",
      " epoch_time_duration: 0.0025\n",
      "\n",
      "epoch: 2021/10000,\n",
      " train_loss: 839.1759,\n",
      " train_mae: 25.3450,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2022/10000,\n",
      " train_loss: 839.1752,\n",
      " train_mae: 25.3450,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2023/10000,\n",
      " train_loss: 839.1749,\n",
      " train_mae: 25.3449,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2024/10000,\n",
      " train_loss: 839.1744,\n",
      " train_mae: 25.3449,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2025/10000,\n",
      " train_loss: 839.1738,\n",
      " train_mae: 25.3449,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2026/10000,\n",
      " train_loss: 839.1732,\n",
      " train_mae: 25.3448,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2027/10000,\n",
      " train_loss: 839.1726,\n",
      " train_mae: 25.3448,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2028/10000,\n",
      " train_loss: 839.1722,\n",
      " train_mae: 25.3448,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 2029/10000,\n",
      " train_loss: 839.1716,\n",
      " train_mae: 25.3447,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2030/10000,\n",
      " train_loss: 839.1712,\n",
      " train_mae: 25.3447,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2031/10000,\n",
      " train_loss: 839.1706,\n",
      " train_mae: 25.3447,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 2032/10000,\n",
      " train_loss: 839.1701,\n",
      " train_mae: 25.3447,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2033/10000,\n",
      " train_loss: 839.1694,\n",
      " train_mae: 25.3446,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2034/10000,\n",
      " train_loss: 839.1691,\n",
      " train_mae: 25.3446,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 2035/10000,\n",
      " train_loss: 839.1684,\n",
      " train_mae: 25.3446,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2036/10000,\n",
      " train_loss: 839.1680,\n",
      " train_mae: 25.3445,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2037/10000,\n",
      " train_loss: 839.1674,\n",
      " train_mae: 25.3445,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2038/10000,\n",
      " train_loss: 839.1670,\n",
      " train_mae: 25.3445,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2039/10000,\n",
      " train_loss: 839.1666,\n",
      " train_mae: 25.3445,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2040/10000,\n",
      " train_loss: 839.1659,\n",
      " train_mae: 25.3444,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2041/10000,\n",
      " train_loss: 839.1654,\n",
      " train_mae: 25.3444,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2042/10000,\n",
      " train_loss: 839.1649,\n",
      " train_mae: 25.3444,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2043/10000,\n",
      " train_loss: 839.1644,\n",
      " train_mae: 25.3443,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2044/10000,\n",
      " train_loss: 839.1639,\n",
      " train_mae: 25.3443,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2045/10000,\n",
      " train_loss: 839.1633,\n",
      " train_mae: 25.3443,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2046/10000,\n",
      " train_loss: 839.1628,\n",
      " train_mae: 25.3442,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2047/10000,\n",
      " train_loss: 839.1624,\n",
      " train_mae: 25.3442,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2048/10000,\n",
      " train_loss: 839.1618,\n",
      " train_mae: 25.3442,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2049/10000,\n",
      " train_loss: 839.1614,\n",
      " train_mae: 25.3442,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2050/10000,\n",
      " train_loss: 839.1608,\n",
      " train_mae: 25.3441,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2051/10000,\n",
      " train_loss: 839.1603,\n",
      " train_mae: 25.3441,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2052/10000,\n",
      " train_loss: 839.1598,\n",
      " train_mae: 25.3441,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2053/10000,\n",
      " train_loss: 839.1593,\n",
      " train_mae: 25.3440,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2054/10000,\n",
      " train_loss: 839.1588,\n",
      " train_mae: 25.3440,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2055/10000,\n",
      " train_loss: 839.1583,\n",
      " train_mae: 25.3440,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2056/10000,\n",
      " train_loss: 839.1578,\n",
      " train_mae: 25.3440,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2057/10000,\n",
      " train_loss: 839.1573,\n",
      " train_mae: 25.3439,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2058/10000,\n",
      " train_loss: 839.1569,\n",
      " train_mae: 25.3439,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "epoch: 2059/10000,\n",
      " train_loss: 839.1563,\n",
      " train_mae: 25.3439,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2060/10000,\n",
      " train_loss: 839.1557,\n",
      " train_mae: 25.3439,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2061/10000,\n",
      " train_loss: 839.1553,\n",
      " train_mae: 25.3438,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2062/10000,\n",
      " train_loss: 839.1548,\n",
      " train_mae: 25.3438,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2063/10000,\n",
      " train_loss: 839.1544,\n",
      " train_mae: 25.3438,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2064/10000,\n",
      " train_loss: 839.1539,\n",
      " train_mae: 25.3437,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2065/10000,\n",
      " train_loss: 839.1534,\n",
      " train_mae: 25.3437,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2066/10000,\n",
      " train_loss: 839.1529,\n",
      " train_mae: 25.3437,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2067/10000,\n",
      " train_loss: 839.1525,\n",
      " train_mae: 25.3437,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2068/10000,\n",
      " train_loss: 839.1519,\n",
      " train_mae: 25.3436,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2069/10000,\n",
      " train_loss: 839.1515,\n",
      " train_mae: 25.3436,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2070/10000,\n",
      " train_loss: 839.1510,\n",
      " train_mae: 25.3436,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2071/10000,\n",
      " train_loss: 839.1505,\n",
      " train_mae: 25.3435,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2072/10000,\n",
      " train_loss: 839.1500,\n",
      " train_mae: 25.3435,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2073/10000,\n",
      " train_loss: 839.1497,\n",
      " train_mae: 25.3435,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2074/10000,\n",
      " train_loss: 839.1491,\n",
      " train_mae: 25.3435,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2075/10000,\n",
      " train_loss: 839.1487,\n",
      " train_mae: 25.3434,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2076/10000,\n",
      " train_loss: 839.1481,\n",
      " train_mae: 25.3434,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2077/10000,\n",
      " train_loss: 839.1477,\n",
      " train_mae: 25.3434,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2078/10000,\n",
      " train_loss: 839.1472,\n",
      " train_mae: 25.3434,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2079/10000,\n",
      " train_loss: 839.1467,\n",
      " train_mae: 25.3433,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2080/10000,\n",
      " train_loss: 839.1462,\n",
      " train_mae: 25.3433,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2081/10000,\n",
      " train_loss: 839.1458,\n",
      " train_mae: 25.3433,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2082/10000,\n",
      " train_loss: 839.1454,\n",
      " train_mae: 25.3433,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2083/10000,\n",
      " train_loss: 839.1448,\n",
      " train_mae: 25.3432,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2084/10000,\n",
      " train_loss: 839.1443,\n",
      " train_mae: 25.3432,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2085/10000,\n",
      " train_loss: 839.1439,\n",
      " train_mae: 25.3432,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2086/10000,\n",
      " train_loss: 839.1436,\n",
      " train_mae: 25.3432,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2087/10000,\n",
      " train_loss: 839.1431,\n",
      " train_mae: 25.3431,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2088/10000,\n",
      " train_loss: 839.1425,\n",
      " train_mae: 25.3431,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2089/10000,\n",
      " train_loss: 839.1420,\n",
      " train_mae: 25.3431,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2090/10000,\n",
      " train_loss: 839.1416,\n",
      " train_mae: 25.3430,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2091/10000,\n",
      " train_loss: 839.1412,\n",
      " train_mae: 25.3430,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2092/10000,\n",
      " train_loss: 839.1407,\n",
      " train_mae: 25.3430,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2093/10000,\n",
      " train_loss: 839.1403,\n",
      " train_mae: 25.3430,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2094/10000,\n",
      " train_loss: 839.1398,\n",
      " train_mae: 25.3429,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "epoch: 2095/10000,\n",
      " train_loss: 839.1393,\n",
      " train_mae: 25.3429,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2096/10000,\n",
      " train_loss: 839.1389,\n",
      " train_mae: 25.3429,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2097/10000,\n",
      " train_loss: 839.1384,\n",
      " train_mae: 25.3429,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2098/10000,\n",
      " train_loss: 839.1381,\n",
      " train_mae: 25.3428,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2099/10000,\n",
      " train_loss: 839.1376,\n",
      " train_mae: 25.3428,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2100/10000,\n",
      " train_loss: 839.1371,\n",
      " train_mae: 25.3428,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2101/10000,\n",
      " train_loss: 839.1367,\n",
      " train_mae: 25.3428,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2102/10000,\n",
      " train_loss: 839.1362,\n",
      " train_mae: 25.3427,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2103/10000,\n",
      " train_loss: 839.1358,\n",
      " train_mae: 25.3427,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2104/10000,\n",
      " train_loss: 839.1353,\n",
      " train_mae: 25.3427,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2105/10000,\n",
      " train_loss: 839.1348,\n",
      " train_mae: 25.3427,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2106/10000,\n",
      " train_loss: 839.1344,\n",
      " train_mae: 25.3427,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2107/10000,\n",
      " train_loss: 839.1340,\n",
      " train_mae: 25.3426,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2108/10000,\n",
      " train_loss: 839.1337,\n",
      " train_mae: 25.3426,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2109/10000,\n",
      " train_loss: 839.1331,\n",
      " train_mae: 25.3426,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2110/10000,\n",
      " train_loss: 839.1328,\n",
      " train_mae: 25.3426,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2111/10000,\n",
      " train_loss: 839.1322,\n",
      " train_mae: 25.3425,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2112/10000,\n",
      " train_loss: 839.1318,\n",
      " train_mae: 25.3425,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2113/10000,\n",
      " train_loss: 839.1313,\n",
      " train_mae: 25.3425,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2114/10000,\n",
      " train_loss: 839.1310,\n",
      " train_mae: 25.3425,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2115/10000,\n",
      " train_loss: 839.1305,\n",
      " train_mae: 25.3424,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2116/10000,\n",
      " train_loss: 839.1300,\n",
      " train_mae: 25.3424,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2117/10000,\n",
      " train_loss: 839.1295,\n",
      " train_mae: 25.3424,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2118/10000,\n",
      " train_loss: 839.1292,\n",
      " train_mae: 25.3424,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2119/10000,\n",
      " train_loss: 839.1287,\n",
      " train_mae: 25.3423,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2120/10000,\n",
      " train_loss: 839.1283,\n",
      " train_mae: 25.3423,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2121/10000,\n",
      " train_loss: 839.1279,\n",
      " train_mae: 25.3423,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2122/10000,\n",
      " train_loss: 839.1275,\n",
      " train_mae: 25.3423,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2123/10000,\n",
      " train_loss: 839.1270,\n",
      " train_mae: 25.3422,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2124/10000,\n",
      " train_loss: 839.1266,\n",
      " train_mae: 25.3422,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2125/10000,\n",
      " train_loss: 839.1262,\n",
      " train_mae: 25.3422,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2126/10000,\n",
      " train_loss: 839.1257,\n",
      " train_mae: 25.3422,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2127/10000,\n",
      " train_loss: 839.1254,\n",
      " train_mae: 25.3421,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 2128/10000,\n",
      " train_loss: 839.1249,\n",
      " train_mae: 25.3421,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 2129/10000,\n",
      " train_loss: 839.1245,\n",
      " train_mae: 25.3421,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2130/10000,\n",
      " train_loss: 839.1241,\n",
      " train_mae: 25.3421,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2131/10000,\n",
      " train_loss: 839.1237,\n",
      " train_mae: 25.3420,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2132/10000,\n",
      " train_loss: 839.1233,\n",
      " train_mae: 25.3420,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2133/10000,\n",
      " train_loss: 839.1228,\n",
      " train_mae: 25.3420,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2134/10000,\n",
      " train_loss: 839.1224,\n",
      " train_mae: 25.3420,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2135/10000,\n",
      " train_loss: 839.1221,\n",
      " train_mae: 25.3420,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2136/10000,\n",
      " train_loss: 839.1216,\n",
      " train_mae: 25.3419,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2137/10000,\n",
      " train_loss: 839.1212,\n",
      " train_mae: 25.3419,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2138/10000,\n",
      " train_loss: 839.1207,\n",
      " train_mae: 25.3419,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2139/10000,\n",
      " train_loss: 839.1204,\n",
      " train_mae: 25.3419,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2140/10000,\n",
      " train_loss: 839.1200,\n",
      " train_mae: 25.3419,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2141/10000,\n",
      " train_loss: 839.1197,\n",
      " train_mae: 25.3418,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2142/10000,\n",
      " train_loss: 839.1192,\n",
      " train_mae: 25.3418,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2143/10000,\n",
      " train_loss: 839.1188,\n",
      " train_mae: 25.3418,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2144/10000,\n",
      " train_loss: 839.1183,\n",
      " train_mae: 25.3418,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2145/10000,\n",
      " train_loss: 839.1180,\n",
      " train_mae: 25.3417,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2146/10000,\n",
      " train_loss: 839.1176,\n",
      " train_mae: 25.3417,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2147/10000,\n",
      " train_loss: 839.1171,\n",
      " train_mae: 25.3417,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2148/10000,\n",
      " train_loss: 839.1166,\n",
      " train_mae: 25.3417,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2149/10000,\n",
      " train_loss: 839.1163,\n",
      " train_mae: 25.3417,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2150/10000,\n",
      " train_loss: 839.1159,\n",
      " train_mae: 25.3416,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2151/10000,\n",
      " train_loss: 839.1155,\n",
      " train_mae: 25.3416,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2152/10000,\n",
      " train_loss: 839.1152,\n",
      " train_mae: 25.3416,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2153/10000,\n",
      " train_loss: 839.1147,\n",
      " train_mae: 25.3416,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2154/10000,\n",
      " train_loss: 839.1144,\n",
      " train_mae: 25.3415,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 2155/10000,\n",
      " train_loss: 839.1139,\n",
      " train_mae: 25.3415,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2156/10000,\n",
      " train_loss: 839.1136,\n",
      " train_mae: 25.3415,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 2157/10000,\n",
      " train_loss: 839.1132,\n",
      " train_mae: 25.3415,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2158/10000,\n",
      " train_loss: 839.1127,\n",
      " train_mae: 25.3414,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2159/10000,\n",
      " train_loss: 839.1124,\n",
      " train_mae: 25.3414,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2160/10000,\n",
      " train_loss: 839.1121,\n",
      " train_mae: 25.3414,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2161/10000,\n",
      " train_loss: 839.1116,\n",
      " train_mae: 25.3414,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2162/10000,\n",
      " train_loss: 839.1112,\n",
      " train_mae: 25.3414,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 2163/10000,\n",
      " train_loss: 839.1108,\n",
      " train_mae: 25.3413,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2164/10000,\n",
      " train_loss: 839.1104,\n",
      " train_mae: 25.3413,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2165/10000,\n",
      " train_loss: 839.1099,\n",
      " train_mae: 25.3413,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2166/10000,\n",
      " train_loss: 839.1097,\n",
      " train_mae: 25.3413,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2167/10000,\n",
      " train_loss: 839.1093,\n",
      " train_mae: 25.3413,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2168/10000,\n",
      " train_loss: 839.1088,\n",
      " train_mae: 25.3412,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2169/10000,\n",
      " train_loss: 839.1085,\n",
      " train_mae: 25.3412,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2170/10000,\n",
      " train_loss: 839.1081,\n",
      " train_mae: 25.3412,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2171/10000,\n",
      " train_loss: 839.1077,\n",
      " train_mae: 25.3412,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2172/10000,\n",
      " train_loss: 839.1073,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2173/10000,\n",
      " train_loss: 839.1069,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2174/10000,\n",
      " train_loss: 839.1066,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2175/10000,\n",
      " train_loss: 839.1061,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2176/10000,\n",
      " train_loss: 839.1060,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2177/10000,\n",
      " train_loss: 839.1055,\n",
      " train_mae: 25.3411,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 2178/10000,\n",
      " train_loss: 839.1049,\n",
      " train_mae: 25.3410,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2179/10000,\n",
      " train_loss: 839.1047,\n",
      " train_mae: 25.3410,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2180/10000,\n",
      " train_loss: 839.1044,\n",
      " train_mae: 25.3410,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2181/10000,\n",
      " train_loss: 839.1039,\n",
      " train_mae: 25.3410,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2182/10000,\n",
      " train_loss: 839.1036,\n",
      " train_mae: 25.3409,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2183/10000,\n",
      " train_loss: 839.1031,\n",
      " train_mae: 25.3409,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2184/10000,\n",
      " train_loss: 839.1028,\n",
      " train_mae: 25.3409,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2185/10000,\n",
      " train_loss: 839.1024,\n",
      " train_mae: 25.3409,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 2186/10000,\n",
      " train_loss: 839.1021,\n",
      " train_mae: 25.3409,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 2187/10000,\n",
      " train_loss: 839.1017,\n",
      " train_mae: 25.3408,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2188/10000,\n",
      " train_loss: 839.1013,\n",
      " train_mae: 25.3408,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 2189/10000,\n",
      " train_loss: 839.1010,\n",
      " train_mae: 25.3408,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2190/10000,\n",
      " train_loss: 839.1006,\n",
      " train_mae: 25.3408,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2191/10000,\n",
      " train_loss: 839.1002,\n",
      " train_mae: 25.3408,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2192/10000,\n",
      " train_loss: 839.0999,\n",
      " train_mae: 25.3407,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2193/10000,\n",
      " train_loss: 839.0995,\n",
      " train_mae: 25.3407,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2194/10000,\n",
      " train_loss: 839.0991,\n",
      " train_mae: 25.3407,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2195/10000,\n",
      " train_loss: 839.0988,\n",
      " train_mae: 25.3407,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2196/10000,\n",
      " train_loss: 839.0983,\n",
      " train_mae: 25.3407,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2197/10000,\n",
      " train_loss: 839.0980,\n",
      " train_mae: 25.3406,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2198/10000,\n",
      " train_loss: 839.0977,\n",
      " train_mae: 25.3406,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 2199/10000,\n",
      " train_loss: 839.0972,\n",
      " train_mae: 25.3406,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2200/10000,\n",
      " train_loss: 839.0969,\n",
      " train_mae: 25.3406,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2201/10000,\n",
      " train_loss: 839.0966,\n",
      " train_mae: 25.3406,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2202/10000,\n",
      " train_loss: 839.0963,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2203/10000,\n",
      " train_loss: 839.0958,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2204/10000,\n",
      " train_loss: 839.0955,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2205/10000,\n",
      " train_loss: 839.0951,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2206/10000,\n",
      " train_loss: 839.0948,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 2207/10000,\n",
      " train_loss: 839.0944,\n",
      " train_mae: 25.3405,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2208/10000,\n",
      " train_loss: 839.0941,\n",
      " train_mae: 25.3404,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2209/10000,\n",
      " train_loss: 839.0938,\n",
      " train_mae: 25.3404,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2210/10000,\n",
      " train_loss: 839.0934,\n",
      " train_mae: 25.3404,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2211/10000,\n",
      " train_loss: 839.0930,\n",
      " train_mae: 25.3404,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2212/10000,\n",
      " train_loss: 839.0928,\n",
      " train_mae: 25.3404,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2213/10000,\n",
      " train_loss: 839.0923,\n",
      " train_mae: 25.3403,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2214/10000,\n",
      " train_loss: 839.0920,\n",
      " train_mae: 25.3403,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2215/10000,\n",
      " train_loss: 839.0917,\n",
      " train_mae: 25.3403,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2216/10000,\n",
      " train_loss: 839.0912,\n",
      " train_mae: 25.3403,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2217/10000,\n",
      " train_loss: 839.0909,\n",
      " train_mae: 25.3403,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2218/10000,\n",
      " train_loss: 839.0907,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2219/10000,\n",
      " train_loss: 839.0902,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2220/10000,\n",
      " train_loss: 839.0900,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2221/10000,\n",
      " train_loss: 839.0895,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "epoch: 2222/10000,\n",
      " train_loss: 839.0892,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0142\n",
      "\n",
      "epoch: 2223/10000,\n",
      " train_loss: 839.0889,\n",
      " train_mae: 25.3402,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2224/10000,\n",
      " train_loss: 839.0885,\n",
      " train_mae: 25.3401,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2225/10000,\n",
      " train_loss: 839.0882,\n",
      " train_mae: 25.3401,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 2226/10000,\n",
      " train_loss: 839.0878,\n",
      " train_mae: 25.3401,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2227/10000,\n",
      " train_loss: 839.0875,\n",
      " train_mae: 25.3401,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2228/10000,\n",
      " train_loss: 839.0872,\n",
      " train_mae: 25.3401,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2229/10000,\n",
      " train_loss: 839.0869,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2230/10000,\n",
      " train_loss: 839.0865,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2231/10000,\n",
      " train_loss: 839.0862,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2232/10000,\n",
      " train_loss: 839.0859,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2233/10000,\n",
      " train_loss: 839.0855,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2234/10000,\n",
      " train_loss: 839.0851,\n",
      " train_mae: 25.3400,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2235/10000,\n",
      " train_loss: 839.0848,\n",
      " train_mae: 25.3399,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2236/10000,\n",
      " train_loss: 839.0845,\n",
      " train_mae: 25.3399,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2237/10000,\n",
      " train_loss: 839.0842,\n",
      " train_mae: 25.3399,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2238/10000,\n",
      " train_loss: 839.0837,\n",
      " train_mae: 25.3399,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2239/10000,\n",
      " train_loss: 839.0834,\n",
      " train_mae: 25.3399,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2240/10000,\n",
      " train_loss: 839.0831,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2241/10000,\n",
      " train_loss: 839.0829,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2242/10000,\n",
      " train_loss: 839.0825,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2243/10000,\n",
      " train_loss: 839.0822,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2244/10000,\n",
      " train_loss: 839.0819,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2245/10000,\n",
      " train_loss: 839.0815,\n",
      " train_mae: 25.3398,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2246/10000,\n",
      " train_loss: 839.0812,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2247/10000,\n",
      " train_loss: 839.0809,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2248/10000,\n",
      " train_loss: 839.0805,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2249/10000,\n",
      " train_loss: 839.0802,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2250/10000,\n",
      " train_loss: 839.0798,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2251/10000,\n",
      " train_loss: 839.0795,\n",
      " train_mae: 25.3397,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2252/10000,\n",
      " train_loss: 839.0792,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2253/10000,\n",
      " train_loss: 839.0788,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0122\n",
      "\n",
      "epoch: 2254/10000,\n",
      " train_loss: 839.0787,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2255/10000,\n",
      " train_loss: 839.0783,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2256/10000,\n",
      " train_loss: 839.0779,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2257/10000,\n",
      " train_loss: 839.0776,\n",
      " train_mae: 25.3396,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2258/10000,\n",
      " train_loss: 839.0773,\n",
      " train_mae: 25.3395,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2259/10000,\n",
      " train_loss: 839.0770,\n",
      " train_mae: 25.3395,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2260/10000,\n",
      " train_loss: 839.0767,\n",
      " train_mae: 25.3395,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2261/10000,\n",
      " train_loss: 839.0764,\n",
      " train_mae: 25.3395,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2262/10000,\n",
      " train_loss: 839.0761,\n",
      " train_mae: 25.3395,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2263/10000,\n",
      " train_loss: 839.0756,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2264/10000,\n",
      " train_loss: 839.0754,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2265/10000,\n",
      " train_loss: 839.0751,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2266/10000,\n",
      " train_loss: 839.0748,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2267/10000,\n",
      " train_loss: 839.0745,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2268/10000,\n",
      " train_loss: 839.0742,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2269/10000,\n",
      " train_loss: 839.0739,\n",
      " train_mae: 25.3394,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2270/10000,\n",
      " train_loss: 839.0735,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2271/10000,\n",
      " train_loss: 839.0732,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2272/10000,\n",
      " train_loss: 839.0729,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2273/10000,\n",
      " train_loss: 839.0726,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2274/10000,\n",
      " train_loss: 839.0723,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2275/10000,\n",
      " train_loss: 839.0720,\n",
      " train_mae: 25.3393,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2276/10000,\n",
      " train_loss: 839.0717,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2277/10000,\n",
      " train_loss: 839.0714,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2278/10000,\n",
      " train_loss: 839.0710,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2279/10000,\n",
      " train_loss: 839.0707,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2280/10000,\n",
      " train_loss: 839.0704,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2281/10000,\n",
      " train_loss: 839.0703,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2282/10000,\n",
      " train_loss: 839.0698,\n",
      " train_mae: 25.3392,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2283/10000,\n",
      " train_loss: 839.0696,\n",
      " train_mae: 25.3391,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2284/10000,\n",
      " train_loss: 839.0693,\n",
      " train_mae: 25.3391,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 2285/10000,\n",
      " train_loss: 839.0689,\n",
      " train_mae: 25.3391,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2286/10000,\n",
      " train_loss: 839.0687,\n",
      " train_mae: 25.3391,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2287/10000,\n",
      " train_loss: 839.0684,\n",
      " train_mae: 25.3391,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2288/10000,\n",
      " train_loss: 839.0681,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2289/10000,\n",
      " train_loss: 839.0677,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2290/10000,\n",
      " train_loss: 839.0674,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2291/10000,\n",
      " train_loss: 839.0671,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2292/10000,\n",
      " train_loss: 839.0668,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2293/10000,\n",
      " train_loss: 839.0666,\n",
      " train_mae: 25.3390,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2294/10000,\n",
      " train_loss: 839.0663,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2295/10000,\n",
      " train_loss: 839.0660,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2296/10000,\n",
      " train_loss: 839.0657,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2297/10000,\n",
      " train_loss: 839.0654,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2298/10000,\n",
      " train_loss: 839.0651,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2299/10000,\n",
      " train_loss: 839.0649,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2300/10000,\n",
      " train_loss: 839.0645,\n",
      " train_mae: 25.3389,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2301/10000,\n",
      " train_loss: 839.0641,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2302/10000,\n",
      " train_loss: 839.0639,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2303/10000,\n",
      " train_loss: 839.0637,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2304/10000,\n",
      " train_loss: 839.0634,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0025\n",
      "\n",
      "epoch: 2305/10000,\n",
      " train_loss: 839.0630,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2306/10000,\n",
      " train_loss: 839.0628,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2307/10000,\n",
      " train_loss: 839.0626,\n",
      " train_mae: 25.3388,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2308/10000,\n",
      " train_loss: 839.0621,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2309/10000,\n",
      " train_loss: 839.0619,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2310/10000,\n",
      " train_loss: 839.0616,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2311/10000,\n",
      " train_loss: 839.0614,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2312/10000,\n",
      " train_loss: 839.0611,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2313/10000,\n",
      " train_loss: 839.0607,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2314/10000,\n",
      " train_loss: 839.0605,\n",
      " train_mae: 25.3387,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 2315/10000,\n",
      " train_loss: 839.0601,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2316/10000,\n",
      " train_loss: 839.0599,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2317/10000,\n",
      " train_loss: 839.0597,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2318/10000,\n",
      " train_loss: 839.0593,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2319/10000,\n",
      " train_loss: 839.0590,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2320/10000,\n",
      " train_loss: 839.0588,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2321/10000,\n",
      " train_loss: 839.0585,\n",
      " train_mae: 25.3386,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2322/10000,\n",
      " train_loss: 839.0582,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2323/10000,\n",
      " train_loss: 839.0580,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2324/10000,\n",
      " train_loss: 839.0577,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2325/10000,\n",
      " train_loss: 839.0573,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2326/10000,\n",
      " train_loss: 839.0571,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2327/10000,\n",
      " train_loss: 839.0568,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2328/10000,\n",
      " train_loss: 839.0566,\n",
      " train_mae: 25.3385,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2329/10000,\n",
      " train_loss: 839.0563,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2330/10000,\n",
      " train_loss: 839.0560,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2331/10000,\n",
      " train_loss: 839.0557,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2332/10000,\n",
      " train_loss: 839.0555,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2333/10000,\n",
      " train_loss: 839.0552,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2334/10000,\n",
      " train_loss: 839.0549,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2335/10000,\n",
      " train_loss: 839.0547,\n",
      " train_mae: 25.3384,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2336/10000,\n",
      " train_loss: 839.0543,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2337/10000,\n",
      " train_loss: 839.0541,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2338/10000,\n",
      " train_loss: 839.0538,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2339/10000,\n",
      " train_loss: 839.0536,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2340/10000,\n",
      " train_loss: 839.0533,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 2341/10000,\n",
      " train_loss: 839.0530,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2342/10000,\n",
      " train_loss: 839.0528,\n",
      " train_mae: 25.3383,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2343/10000,\n",
      " train_loss: 839.0525,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2344/10000,\n",
      " train_loss: 839.0522,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2345/10000,\n",
      " train_loss: 839.0520,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2346/10000,\n",
      " train_loss: 839.0517,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 2347/10000,\n",
      " train_loss: 839.0515,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2348/10000,\n",
      " train_loss: 839.0511,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2349/10000,\n",
      " train_loss: 839.0509,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2350/10000,\n",
      " train_loss: 839.0507,\n",
      " train_mae: 25.3382,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2351/10000,\n",
      " train_loss: 839.0504,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2352/10000,\n",
      " train_loss: 839.0501,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2353/10000,\n",
      " train_loss: 839.0499,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2354/10000,\n",
      " train_loss: 839.0496,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2355/10000,\n",
      " train_loss: 839.0493,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2356/10000,\n",
      " train_loss: 839.0491,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2357/10000,\n",
      " train_loss: 839.0488,\n",
      " train_mae: 25.3381,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2358/10000,\n",
      " train_loss: 839.0485,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2359/10000,\n",
      " train_loss: 839.0482,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2360/10000,\n",
      " train_loss: 839.0480,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2361/10000,\n",
      " train_loss: 839.0478,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2362/10000,\n",
      " train_loss: 839.0475,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2363/10000,\n",
      " train_loss: 839.0472,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2364/10000,\n",
      " train_loss: 839.0470,\n",
      " train_mae: 25.3380,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2365/10000,\n",
      " train_loss: 839.0468,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2366/10000,\n",
      " train_loss: 839.0463,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2367/10000,\n",
      " train_loss: 839.0462,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2368/10000,\n",
      " train_loss: 839.0460,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2369/10000,\n",
      " train_loss: 839.0458,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2370/10000,\n",
      " train_loss: 839.0455,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2371/10000,\n",
      " train_loss: 839.0452,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2372/10000,\n",
      " train_loss: 839.0449,\n",
      " train_mae: 25.3379,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 2373/10000,\n",
      " train_loss: 839.0447,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0138\n",
      "\n",
      "epoch: 2374/10000,\n",
      " train_loss: 839.0444,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2375/10000,\n",
      " train_loss: 839.0442,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2376/10000,\n",
      " train_loss: 839.0439,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2377/10000,\n",
      " train_loss: 839.0436,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2378/10000,\n",
      " train_loss: 839.0434,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2379/10000,\n",
      " train_loss: 839.0432,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2380/10000,\n",
      " train_loss: 839.0429,\n",
      " train_mae: 25.3378,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2381/10000,\n",
      " train_loss: 839.0426,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2382/10000,\n",
      " train_loss: 839.0424,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2383/10000,\n",
      " train_loss: 839.0422,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2384/10000,\n",
      " train_loss: 839.0419,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2385/10000,\n",
      " train_loss: 839.0416,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2386/10000,\n",
      " train_loss: 839.0414,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2387/10000,\n",
      " train_loss: 839.0412,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2388/10000,\n",
      " train_loss: 839.0410,\n",
      " train_mae: 25.3377,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2389/10000,\n",
      " train_loss: 839.0406,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2390/10000,\n",
      " train_loss: 839.0405,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2391/10000,\n",
      " train_loss: 839.0402,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2392/10000,\n",
      " train_loss: 839.0399,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2393/10000,\n",
      " train_loss: 839.0397,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2394/10000,\n",
      " train_loss: 839.0394,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2395/10000,\n",
      " train_loss: 839.0392,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2396/10000,\n",
      " train_loss: 839.0388,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2397/10000,\n",
      " train_loss: 839.0387,\n",
      " train_mae: 25.3376,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2398/10000,\n",
      " train_loss: 839.0384,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2399/10000,\n",
      " train_loss: 839.0382,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2400/10000,\n",
      " train_loss: 839.0380,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 2401/10000,\n",
      " train_loss: 839.0378,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 2402/10000,\n",
      " train_loss: 839.0375,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2403/10000,\n",
      " train_loss: 839.0373,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2404/10000,\n",
      " train_loss: 839.0370,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2405/10000,\n",
      " train_loss: 839.0367,\n",
      " train_mae: 25.3375,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2406/10000,\n",
      " train_loss: 839.0366,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2407/10000,\n",
      " train_loss: 839.0364,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2408/10000,\n",
      " train_loss: 839.0361,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2409/10000,\n",
      " train_loss: 839.0358,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2410/10000,\n",
      " train_loss: 839.0356,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2411/10000,\n",
      " train_loss: 839.0354,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2412/10000,\n",
      " train_loss: 839.0351,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2413/10000,\n",
      " train_loss: 839.0349,\n",
      " train_mae: 25.3374,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2414/10000,\n",
      " train_loss: 839.0346,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2415/10000,\n",
      " train_loss: 839.0344,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2416/10000,\n",
      " train_loss: 839.0342,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2417/10000,\n",
      " train_loss: 839.0339,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2418/10000,\n",
      " train_loss: 839.0338,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2419/10000,\n",
      " train_loss: 839.0336,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2420/10000,\n",
      " train_loss: 839.0333,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2421/10000,\n",
      " train_loss: 839.0330,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2422/10000,\n",
      " train_loss: 839.0328,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2423/10000,\n",
      " train_loss: 839.0326,\n",
      " train_mae: 25.3373,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2424/10000,\n",
      " train_loss: 839.0323,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2425/10000,\n",
      " train_loss: 839.0322,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2426/10000,\n",
      " train_loss: 839.0319,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2427/10000,\n",
      " train_loss: 839.0316,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2428/10000,\n",
      " train_loss: 839.0314,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2429/10000,\n",
      " train_loss: 839.0312,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2430/10000,\n",
      " train_loss: 839.0309,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2431/10000,\n",
      " train_loss: 839.0307,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2432/10000,\n",
      " train_loss: 839.0305,\n",
      " train_mae: 25.3372,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2433/10000,\n",
      " train_loss: 839.0303,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2434/10000,\n",
      " train_loss: 839.0302,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2435/10000,\n",
      " train_loss: 839.0298,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2436/10000,\n",
      " train_loss: 839.0297,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2437/10000,\n",
      " train_loss: 839.0295,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2438/10000,\n",
      " train_loss: 839.0292,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2439/10000,\n",
      " train_loss: 839.0289,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "epoch: 2440/10000,\n",
      " train_loss: 839.0287,\n",
      " train_mae: 25.3371,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2441/10000,\n",
      " train_loss: 839.0286,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2442/10000,\n",
      " train_loss: 839.0282,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2443/10000,\n",
      " train_loss: 839.0281,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 2444/10000,\n",
      " train_loss: 839.0278,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2445/10000,\n",
      " train_loss: 839.0276,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 2446/10000,\n",
      " train_loss: 839.0274,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2447/10000,\n",
      " train_loss: 839.0272,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2448/10000,\n",
      " train_loss: 839.0270,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2449/10000,\n",
      " train_loss: 839.0267,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2450/10000,\n",
      " train_loss: 839.0265,\n",
      " train_mae: 25.3370,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2451/10000,\n",
      " train_loss: 839.0262,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2452/10000,\n",
      " train_loss: 839.0260,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2453/10000,\n",
      " train_loss: 839.0258,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2454/10000,\n",
      " train_loss: 839.0256,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2455/10000,\n",
      " train_loss: 839.0255,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2456/10000,\n",
      " train_loss: 839.0251,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2457/10000,\n",
      " train_loss: 839.0250,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2458/10000,\n",
      " train_loss: 839.0248,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2459/10000,\n",
      " train_loss: 839.0246,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2460/10000,\n",
      " train_loss: 839.0244,\n",
      " train_mae: 25.3369,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2461/10000,\n",
      " train_loss: 839.0241,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2462/10000,\n",
      " train_loss: 839.0240,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2463/10000,\n",
      " train_loss: 839.0237,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2464/10000,\n",
      " train_loss: 839.0235,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2465/10000,\n",
      " train_loss: 839.0232,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2466/10000,\n",
      " train_loss: 839.0231,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2467/10000,\n",
      " train_loss: 839.0228,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2468/10000,\n",
      " train_loss: 839.0227,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2469/10000,\n",
      " train_loss: 839.0225,\n",
      " train_mae: 25.3368,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2470/10000,\n",
      " train_loss: 839.0222,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2471/10000,\n",
      " train_loss: 839.0220,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "epoch: 2472/10000,\n",
      " train_loss: 839.0218,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 2473/10000,\n",
      " train_loss: 839.0215,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2474/10000,\n",
      " train_loss: 839.0214,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2475/10000,\n",
      " train_loss: 839.0212,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2476/10000,\n",
      " train_loss: 839.0209,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2477/10000,\n",
      " train_loss: 839.0208,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2478/10000,\n",
      " train_loss: 839.0206,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2479/10000,\n",
      " train_loss: 839.0204,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2480/10000,\n",
      " train_loss: 839.0201,\n",
      " train_mae: 25.3367,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2481/10000,\n",
      " train_loss: 839.0199,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2482/10000,\n",
      " train_loss: 839.0197,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2483/10000,\n",
      " train_loss: 839.0195,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2484/10000,\n",
      " train_loss: 839.0193,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2485/10000,\n",
      " train_loss: 839.0190,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2486/10000,\n",
      " train_loss: 839.0189,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2487/10000,\n",
      " train_loss: 839.0187,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2488/10000,\n",
      " train_loss: 839.0184,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2489/10000,\n",
      " train_loss: 839.0182,\n",
      " train_mae: 25.3366,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2490/10000,\n",
      " train_loss: 839.0180,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2491/10000,\n",
      " train_loss: 839.0179,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2492/10000,\n",
      " train_loss: 839.0176,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2493/10000,\n",
      " train_loss: 839.0175,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2494/10000,\n",
      " train_loss: 839.0172,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2495/10000,\n",
      " train_loss: 839.0170,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 2496/10000,\n",
      " train_loss: 839.0168,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2497/10000,\n",
      " train_loss: 839.0167,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0154\n",
      "\n",
      "epoch: 2498/10000,\n",
      " train_loss: 839.0164,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2499/10000,\n",
      " train_loss: 839.0162,\n",
      " train_mae: 25.3365,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 2500/10000,\n",
      " train_loss: 839.0161,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2501/10000,\n",
      " train_loss: 839.0158,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2502/10000,\n",
      " train_loss: 839.0157,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2503/10000,\n",
      " train_loss: 839.0155,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2504/10000,\n",
      " train_loss: 839.0153,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2505/10000,\n",
      " train_loss: 839.0150,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2506/10000,\n",
      " train_loss: 839.0149,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2507/10000,\n",
      " train_loss: 839.0146,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2508/10000,\n",
      " train_loss: 839.0145,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2509/10000,\n",
      " train_loss: 839.0143,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2510/10000,\n",
      " train_loss: 839.0141,\n",
      " train_mae: 25.3364,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2511/10000,\n",
      " train_loss: 839.0139,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2512/10000,\n",
      " train_loss: 839.0137,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2513/10000,\n",
      " train_loss: 839.0134,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2514/10000,\n",
      " train_loss: 839.0132,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2515/10000,\n",
      " train_loss: 839.0131,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2516/10000,\n",
      " train_loss: 839.0129,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2517/10000,\n",
      " train_loss: 839.0128,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2518/10000,\n",
      " train_loss: 839.0126,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2519/10000,\n",
      " train_loss: 839.0123,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2520/10000,\n",
      " train_loss: 839.0121,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2521/10000,\n",
      " train_loss: 839.0119,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2522/10000,\n",
      " train_loss: 839.0118,\n",
      " train_mae: 25.3363,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2523/10000,\n",
      " train_loss: 839.0115,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2524/10000,\n",
      " train_loss: 839.0114,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2525/10000,\n",
      " train_loss: 839.0112,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2526/10000,\n",
      " train_loss: 839.0110,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2527/10000,\n",
      " train_loss: 839.0108,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2528/10000,\n",
      " train_loss: 839.0106,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2529/10000,\n",
      " train_loss: 839.0104,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2530/10000,\n",
      " train_loss: 839.0102,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2531/10000,\n",
      " train_loss: 839.0100,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2532/10000,\n",
      " train_loss: 839.0098,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2533/10000,\n",
      " train_loss: 839.0097,\n",
      " train_mae: 25.3362,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2534/10000,\n",
      " train_loss: 839.0095,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "epoch: 2535/10000,\n",
      " train_loss: 839.0092,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2536/10000,\n",
      " train_loss: 839.0091,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2537/10000,\n",
      " train_loss: 839.0089,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2538/10000,\n",
      " train_loss: 839.0087,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2539/10000,\n",
      " train_loss: 839.0085,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2540/10000,\n",
      " train_loss: 839.0084,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2541/10000,\n",
      " train_loss: 839.0081,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2542/10000,\n",
      " train_loss: 839.0079,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2543/10000,\n",
      " train_loss: 839.0078,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2544/10000,\n",
      " train_loss: 839.0076,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2545/10000,\n",
      " train_loss: 839.0074,\n",
      " train_mae: 25.3361,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2546/10000,\n",
      " train_loss: 839.0072,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2547/10000,\n",
      " train_loss: 839.0071,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2548/10000,\n",
      " train_loss: 839.0068,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 2549/10000,\n",
      " train_loss: 839.0066,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2550/10000,\n",
      " train_loss: 839.0065,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2551/10000,\n",
      " train_loss: 839.0063,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2552/10000,\n",
      " train_loss: 839.0060,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2553/10000,\n",
      " train_loss: 839.0059,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2554/10000,\n",
      " train_loss: 839.0057,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2555/10000,\n",
      " train_loss: 839.0055,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2556/10000,\n",
      " train_loss: 839.0054,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2557/10000,\n",
      " train_loss: 839.0052,\n",
      " train_mae: 25.3360,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2558/10000,\n",
      " train_loss: 839.0051,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2559/10000,\n",
      " train_loss: 839.0048,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2560/10000,\n",
      " train_loss: 839.0046,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2561/10000,\n",
      " train_loss: 839.0045,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2562/10000,\n",
      " train_loss: 839.0043,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2563/10000,\n",
      " train_loss: 839.0042,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2564/10000,\n",
      " train_loss: 839.0040,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2565/10000,\n",
      " train_loss: 839.0038,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2566/10000,\n",
      " train_loss: 839.0035,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2567/10000,\n",
      " train_loss: 839.0035,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2568/10000,\n",
      " train_loss: 839.0032,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2569/10000,\n",
      " train_loss: 839.0031,\n",
      " train_mae: 25.3359,\n",
      " epoch_time_duration: 0.0101\n",
      "\n",
      "epoch: 2570/10000,\n",
      " train_loss: 839.0029,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2571/10000,\n",
      " train_loss: 839.0027,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2572/10000,\n",
      " train_loss: 839.0025,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2573/10000,\n",
      " train_loss: 839.0023,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2574/10000,\n",
      " train_loss: 839.0022,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2575/10000,\n",
      " train_loss: 839.0020,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2576/10000,\n",
      " train_loss: 839.0019,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2577/10000,\n",
      " train_loss: 839.0016,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2578/10000,\n",
      " train_loss: 839.0014,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2579/10000,\n",
      " train_loss: 839.0013,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2580/10000,\n",
      " train_loss: 839.0012,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2581/10000,\n",
      " train_loss: 839.0010,\n",
      " train_mae: 25.3358,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2582/10000,\n",
      " train_loss: 839.0009,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2583/10000,\n",
      " train_loss: 839.0006,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2584/10000,\n",
      " train_loss: 839.0005,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2585/10000,\n",
      " train_loss: 839.0002,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2586/10000,\n",
      " train_loss: 839.0001,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2587/10000,\n",
      " train_loss: 838.9999,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2588/10000,\n",
      " train_loss: 838.9998,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2589/10000,\n",
      " train_loss: 838.9996,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2590/10000,\n",
      " train_loss: 838.9994,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2591/10000,\n",
      " train_loss: 838.9993,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 2592/10000,\n",
      " train_loss: 838.9991,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2593/10000,\n",
      " train_loss: 838.9989,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 2594/10000,\n",
      " train_loss: 838.9987,\n",
      " train_mae: 25.3357,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2595/10000,\n",
      " train_loss: 838.9986,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2596/10000,\n",
      " train_loss: 838.9984,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2597/10000,\n",
      " train_loss: 838.9982,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2598/10000,\n",
      " train_loss: 838.9980,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2599/10000,\n",
      " train_loss: 838.9979,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2600/10000,\n",
      " train_loss: 838.9977,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2601/10000,\n",
      " train_loss: 838.9975,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2602/10000,\n",
      " train_loss: 838.9974,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2603/10000,\n",
      " train_loss: 838.9972,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 2604/10000,\n",
      " train_loss: 838.9971,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2605/10000,\n",
      " train_loss: 838.9969,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2606/10000,\n",
      " train_loss: 838.9966,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2607/10000,\n",
      " train_loss: 838.9965,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2608/10000,\n",
      " train_loss: 838.9964,\n",
      " train_mae: 25.3356,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2609/10000,\n",
      " train_loss: 838.9963,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2610/10000,\n",
      " train_loss: 838.9960,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2611/10000,\n",
      " train_loss: 838.9958,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2612/10000,\n",
      " train_loss: 838.9957,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2613/10000,\n",
      " train_loss: 838.9955,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2614/10000,\n",
      " train_loss: 838.9954,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2615/10000,\n",
      " train_loss: 838.9952,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2616/10000,\n",
      " train_loss: 838.9951,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2617/10000,\n",
      " train_loss: 838.9950,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2618/10000,\n",
      " train_loss: 838.9948,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2619/10000,\n",
      " train_loss: 838.9946,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2620/10000,\n",
      " train_loss: 838.9944,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2621/10000,\n",
      " train_loss: 838.9943,\n",
      " train_mae: 25.3355,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2622/10000,\n",
      " train_loss: 838.9941,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2623/10000,\n",
      " train_loss: 838.9940,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2624/10000,\n",
      " train_loss: 838.9938,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2625/10000,\n",
      " train_loss: 838.9936,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2626/10000,\n",
      " train_loss: 838.9935,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 2627/10000,\n",
      " train_loss: 838.9933,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "epoch: 2628/10000,\n",
      " train_loss: 838.9932,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2629/10000,\n",
      " train_loss: 838.9930,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2630/10000,\n",
      " train_loss: 838.9928,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2631/10000,\n",
      " train_loss: 838.9926,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2632/10000,\n",
      " train_loss: 838.9925,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2633/10000,\n",
      " train_loss: 838.9924,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2634/10000,\n",
      " train_loss: 838.9922,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2635/10000,\n",
      " train_loss: 838.9921,\n",
      " train_mae: 25.3354,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2636/10000,\n",
      " train_loss: 838.9919,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2637/10000,\n",
      " train_loss: 838.9916,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2638/10000,\n",
      " train_loss: 838.9916,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2639/10000,\n",
      " train_loss: 838.9914,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2640/10000,\n",
      " train_loss: 838.9913,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2641/10000,\n",
      " train_loss: 838.9911,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2642/10000,\n",
      " train_loss: 838.9909,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2643/10000,\n",
      " train_loss: 838.9908,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2644/10000,\n",
      " train_loss: 838.9906,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2645/10000,\n",
      " train_loss: 838.9905,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2646/10000,\n",
      " train_loss: 838.9903,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2647/10000,\n",
      " train_loss: 838.9902,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 2648/10000,\n",
      " train_loss: 838.9899,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2649/10000,\n",
      " train_loss: 838.9898,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2650/10000,\n",
      " train_loss: 838.9897,\n",
      " train_mae: 25.3353,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2651/10000,\n",
      " train_loss: 838.9895,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 2652/10000,\n",
      " train_loss: 838.9894,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 2653/10000,\n",
      " train_loss: 838.9893,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 2654/10000,\n",
      " train_loss: 838.9891,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2655/10000,\n",
      " train_loss: 838.9890,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2656/10000,\n",
      " train_loss: 838.9888,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2657/10000,\n",
      " train_loss: 838.9886,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2658/10000,\n",
      " train_loss: 838.9885,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2659/10000,\n",
      " train_loss: 838.9884,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2660/10000,\n",
      " train_loss: 838.9882,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 2661/10000,\n",
      " train_loss: 838.9880,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2662/10000,\n",
      " train_loss: 838.9879,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2663/10000,\n",
      " train_loss: 838.9877,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2664/10000,\n",
      " train_loss: 838.9875,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2665/10000,\n",
      " train_loss: 838.9874,\n",
      " train_mae: 25.3352,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2666/10000,\n",
      " train_loss: 838.9873,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2667/10000,\n",
      " train_loss: 838.9871,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2668/10000,\n",
      " train_loss: 838.9869,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2669/10000,\n",
      " train_loss: 838.9868,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2670/10000,\n",
      " train_loss: 838.9867,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2671/10000,\n",
      " train_loss: 838.9865,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2672/10000,\n",
      " train_loss: 838.9863,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2673/10000,\n",
      " train_loss: 838.9863,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2674/10000,\n",
      " train_loss: 838.9860,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2675/10000,\n",
      " train_loss: 838.9859,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2676/10000,\n",
      " train_loss: 838.9858,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2677/10000,\n",
      " train_loss: 838.9856,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2678/10000,\n",
      " train_loss: 838.9855,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2679/10000,\n",
      " train_loss: 838.9853,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0116\n",
      "\n",
      "epoch: 2680/10000,\n",
      " train_loss: 838.9852,\n",
      " train_mae: 25.3351,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2681/10000,\n",
      " train_loss: 838.9850,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 2682/10000,\n",
      " train_loss: 838.9849,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2683/10000,\n",
      " train_loss: 838.9847,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2684/10000,\n",
      " train_loss: 838.9846,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2685/10000,\n",
      " train_loss: 838.9844,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2686/10000,\n",
      " train_loss: 838.9843,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2687/10000,\n",
      " train_loss: 838.9841,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2688/10000,\n",
      " train_loss: 838.9840,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2689/10000,\n",
      " train_loss: 838.9838,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2690/10000,\n",
      " train_loss: 838.9838,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2691/10000,\n",
      " train_loss: 838.9835,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2692/10000,\n",
      " train_loss: 838.9835,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2693/10000,\n",
      " train_loss: 838.9833,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2694/10000,\n",
      " train_loss: 838.9832,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2695/10000,\n",
      " train_loss: 838.9830,\n",
      " train_mae: 25.3350,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2696/10000,\n",
      " train_loss: 838.9828,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2697/10000,\n",
      " train_loss: 838.9827,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2698/10000,\n",
      " train_loss: 838.9826,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2699/10000,\n",
      " train_loss: 838.9824,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2700/10000,\n",
      " train_loss: 838.9823,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2701/10000,\n",
      " train_loss: 838.9821,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2702/10000,\n",
      " train_loss: 838.9819,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 2703/10000,\n",
      " train_loss: 838.9818,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2704/10000,\n",
      " train_loss: 838.9817,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0167\n",
      "\n",
      "epoch: 2705/10000,\n",
      " train_loss: 838.9816,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0116\n",
      "\n",
      "epoch: 2706/10000,\n",
      " train_loss: 838.9814,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2707/10000,\n",
      " train_loss: 838.9813,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2708/10000,\n",
      " train_loss: 838.9811,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2709/10000,\n",
      " train_loss: 838.9810,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 2710/10000,\n",
      " train_loss: 838.9808,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2711/10000,\n",
      " train_loss: 838.9807,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2712/10000,\n",
      " train_loss: 838.9805,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2713/10000,\n",
      " train_loss: 838.9804,\n",
      " train_mae: 25.3349,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2714/10000,\n",
      " train_loss: 838.9802,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2715/10000,\n",
      " train_loss: 838.9801,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2716/10000,\n",
      " train_loss: 838.9799,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2717/10000,\n",
      " train_loss: 838.9798,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2718/10000,\n",
      " train_loss: 838.9797,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2719/10000,\n",
      " train_loss: 838.9796,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2720/10000,\n",
      " train_loss: 838.9795,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2721/10000,\n",
      " train_loss: 838.9792,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2722/10000,\n",
      " train_loss: 838.9791,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2723/10000,\n",
      " train_loss: 838.9791,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2724/10000,\n",
      " train_loss: 838.9788,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2725/10000,\n",
      " train_loss: 838.9787,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2726/10000,\n",
      " train_loss: 838.9786,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2727/10000,\n",
      " train_loss: 838.9785,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2728/10000,\n",
      " train_loss: 838.9783,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2729/10000,\n",
      " train_loss: 838.9781,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2730/10000,\n",
      " train_loss: 838.9780,\n",
      " train_mae: 25.3348,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2731/10000,\n",
      " train_loss: 838.9779,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2732/10000,\n",
      " train_loss: 838.9778,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2733/10000,\n",
      " train_loss: 838.9777,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2734/10000,\n",
      " train_loss: 838.9775,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2735/10000,\n",
      " train_loss: 838.9774,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 2736/10000,\n",
      " train_loss: 838.9772,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0121\n",
      "\n",
      "epoch: 2737/10000,\n",
      " train_loss: 838.9771,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2738/10000,\n",
      " train_loss: 838.9769,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2739/10000,\n",
      " train_loss: 838.9768,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2740/10000,\n",
      " train_loss: 838.9767,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2741/10000,\n",
      " train_loss: 838.9766,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2742/10000,\n",
      " train_loss: 838.9764,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2743/10000,\n",
      " train_loss: 838.9763,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2744/10000,\n",
      " train_loss: 838.9762,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2745/10000,\n",
      " train_loss: 838.9760,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2746/10000,\n",
      " train_loss: 838.9759,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2747/10000,\n",
      " train_loss: 838.9758,\n",
      " train_mae: 25.3347,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2748/10000,\n",
      " train_loss: 838.9757,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2749/10000,\n",
      " train_loss: 838.9755,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2750/10000,\n",
      " train_loss: 838.9755,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2751/10000,\n",
      " train_loss: 838.9752,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2752/10000,\n",
      " train_loss: 838.9750,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2753/10000,\n",
      " train_loss: 838.9750,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2754/10000,\n",
      " train_loss: 838.9748,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2755/10000,\n",
      " train_loss: 838.9747,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2756/10000,\n",
      " train_loss: 838.9745,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2757/10000,\n",
      " train_loss: 838.9744,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2758/10000,\n",
      " train_loss: 838.9743,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2759/10000,\n",
      " train_loss: 838.9741,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2760/10000,\n",
      " train_loss: 838.9741,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2761/10000,\n",
      " train_loss: 838.9740,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2762/10000,\n",
      " train_loss: 838.9738,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2763/10000,\n",
      " train_loss: 838.9737,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2764/10000,\n",
      " train_loss: 838.9735,\n",
      " train_mae: 25.3346,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2765/10000,\n",
      " train_loss: 838.9734,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0129\n",
      "\n",
      "epoch: 2766/10000,\n",
      " train_loss: 838.9733,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2767/10000,\n",
      " train_loss: 838.9731,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2768/10000,\n",
      " train_loss: 838.9731,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2769/10000,\n",
      " train_loss: 838.9729,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2770/10000,\n",
      " train_loss: 838.9728,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2771/10000,\n",
      " train_loss: 838.9727,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2772/10000,\n",
      " train_loss: 838.9724,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2773/10000,\n",
      " train_loss: 838.9724,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2774/10000,\n",
      " train_loss: 838.9723,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2775/10000,\n",
      " train_loss: 838.9721,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2776/10000,\n",
      " train_loss: 838.9720,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2777/10000,\n",
      " train_loss: 838.9719,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2778/10000,\n",
      " train_loss: 838.9717,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2779/10000,\n",
      " train_loss: 838.9717,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2780/10000,\n",
      " train_loss: 838.9716,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2781/10000,\n",
      " train_loss: 838.9714,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2782/10000,\n",
      " train_loss: 838.9713,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2783/10000,\n",
      " train_loss: 838.9711,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2784/10000,\n",
      " train_loss: 838.9710,\n",
      " train_mae: 25.3345,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2785/10000,\n",
      " train_loss: 838.9709,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2786/10000,\n",
      " train_loss: 838.9708,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2787/10000,\n",
      " train_loss: 838.9706,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2788/10000,\n",
      " train_loss: 838.9705,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2789/10000,\n",
      " train_loss: 838.9703,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2790/10000,\n",
      " train_loss: 838.9702,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 2791/10000,\n",
      " train_loss: 838.9701,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 2792/10000,\n",
      " train_loss: 838.9700,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2793/10000,\n",
      " train_loss: 838.9699,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2794/10000,\n",
      " train_loss: 838.9698,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2795/10000,\n",
      " train_loss: 838.9697,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2796/10000,\n",
      " train_loss: 838.9694,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2797/10000,\n",
      " train_loss: 838.9694,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2798/10000,\n",
      " train_loss: 838.9694,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2799/10000,\n",
      " train_loss: 838.9691,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2800/10000,\n",
      " train_loss: 838.9691,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2801/10000,\n",
      " train_loss: 838.9689,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2802/10000,\n",
      " train_loss: 838.9688,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2803/10000,\n",
      " train_loss: 838.9688,\n",
      " train_mae: 25.3344,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2804/10000,\n",
      " train_loss: 838.9685,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2805/10000,\n",
      " train_loss: 838.9684,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2806/10000,\n",
      " train_loss: 838.9682,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 2807/10000,\n",
      " train_loss: 838.9682,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2808/10000,\n",
      " train_loss: 838.9680,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 2809/10000,\n",
      " train_loss: 838.9680,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 2810/10000,\n",
      " train_loss: 838.9678,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2811/10000,\n",
      " train_loss: 838.9677,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2812/10000,\n",
      " train_loss: 838.9675,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 2813/10000,\n",
      " train_loss: 838.9675,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2814/10000,\n",
      " train_loss: 838.9673,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2815/10000,\n",
      " train_loss: 838.9672,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2816/10000,\n",
      " train_loss: 838.9671,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 2817/10000,\n",
      " train_loss: 838.9670,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 2818/10000,\n",
      " train_loss: 838.9669,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2819/10000,\n",
      " train_loss: 838.9668,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2820/10000,\n",
      " train_loss: 838.9667,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2821/10000,\n",
      " train_loss: 838.9665,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2822/10000,\n",
      " train_loss: 838.9662,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2823/10000,\n",
      " train_loss: 838.9662,\n",
      " train_mae: 25.3343,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2824/10000,\n",
      " train_loss: 838.9661,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2825/10000,\n",
      " train_loss: 838.9661,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2826/10000,\n",
      " train_loss: 838.9659,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2827/10000,\n",
      " train_loss: 838.9659,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2828/10000,\n",
      " train_loss: 838.9657,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2829/10000,\n",
      " train_loss: 838.9657,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2830/10000,\n",
      " train_loss: 838.9655,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2831/10000,\n",
      " train_loss: 838.9654,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2832/10000,\n",
      " train_loss: 838.9653,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2833/10000,\n",
      " train_loss: 838.9651,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2834/10000,\n",
      " train_loss: 838.9650,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2835/10000,\n",
      " train_loss: 838.9649,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2836/10000,\n",
      " train_loss: 838.9648,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2837/10000,\n",
      " train_loss: 838.9646,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2838/10000,\n",
      " train_loss: 838.9645,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2839/10000,\n",
      " train_loss: 838.9644,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2840/10000,\n",
      " train_loss: 838.9643,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2841/10000,\n",
      " train_loss: 838.9642,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2842/10000,\n",
      " train_loss: 838.9641,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2843/10000,\n",
      " train_loss: 838.9640,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2844/10000,\n",
      " train_loss: 838.9639,\n",
      " train_mae: 25.3342,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2845/10000,\n",
      " train_loss: 838.9637,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2846/10000,\n",
      " train_loss: 838.9636,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2847/10000,\n",
      " train_loss: 838.9634,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 2848/10000,\n",
      " train_loss: 838.9634,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "epoch: 2849/10000,\n",
      " train_loss: 838.9633,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2850/10000,\n",
      " train_loss: 838.9632,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2851/10000,\n",
      " train_loss: 838.9630,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2852/10000,\n",
      " train_loss: 838.9630,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2853/10000,\n",
      " train_loss: 838.9628,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2854/10000,\n",
      " train_loss: 838.9626,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2855/10000,\n",
      " train_loss: 838.9626,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2856/10000,\n",
      " train_loss: 838.9625,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2857/10000,\n",
      " train_loss: 838.9623,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2858/10000,\n",
      " train_loss: 838.9623,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2859/10000,\n",
      " train_loss: 838.9622,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2860/10000,\n",
      " train_loss: 838.9620,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2861/10000,\n",
      " train_loss: 838.9619,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2862/10000,\n",
      " train_loss: 838.9618,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2863/10000,\n",
      " train_loss: 838.9617,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2864/10000,\n",
      " train_loss: 838.9616,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2865/10000,\n",
      " train_loss: 838.9615,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2866/10000,\n",
      " train_loss: 838.9614,\n",
      " train_mae: 25.3341,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2867/10000,\n",
      " train_loss: 838.9612,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2868/10000,\n",
      " train_loss: 838.9612,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2869/10000,\n",
      " train_loss: 838.9611,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2870/10000,\n",
      " train_loss: 838.9609,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2871/10000,\n",
      " train_loss: 838.9609,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2872/10000,\n",
      " train_loss: 838.9607,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2873/10000,\n",
      " train_loss: 838.9606,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2874/10000,\n",
      " train_loss: 838.9604,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0149\n",
      "\n",
      "epoch: 2875/10000,\n",
      " train_loss: 838.9604,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 2876/10000,\n",
      " train_loss: 838.9603,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2877/10000,\n",
      " train_loss: 838.9601,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2878/10000,\n",
      " train_loss: 838.9601,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 2879/10000,\n",
      " train_loss: 838.9600,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2880/10000,\n",
      " train_loss: 838.9598,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2881/10000,\n",
      " train_loss: 838.9597,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2882/10000,\n",
      " train_loss: 838.9596,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2883/10000,\n",
      " train_loss: 838.9595,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2884/10000,\n",
      " train_loss: 838.9594,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2885/10000,\n",
      " train_loss: 838.9593,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2886/10000,\n",
      " train_loss: 838.9592,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2887/10000,\n",
      " train_loss: 838.9590,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2888/10000,\n",
      " train_loss: 838.9590,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2889/10000,\n",
      " train_loss: 838.9589,\n",
      " train_mae: 25.3340,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 2890/10000,\n",
      " train_loss: 838.9587,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2891/10000,\n",
      " train_loss: 838.9586,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2892/10000,\n",
      " train_loss: 838.9586,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2893/10000,\n",
      " train_loss: 838.9584,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2894/10000,\n",
      " train_loss: 838.9584,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2895/10000,\n",
      " train_loss: 838.9583,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2896/10000,\n",
      " train_loss: 838.9582,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2897/10000,\n",
      " train_loss: 838.9580,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2898/10000,\n",
      " train_loss: 838.9580,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2899/10000,\n",
      " train_loss: 838.9579,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2900/10000,\n",
      " train_loss: 838.9577,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2901/10000,\n",
      " train_loss: 838.9576,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 2902/10000,\n",
      " train_loss: 838.9575,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 2903/10000,\n",
      " train_loss: 838.9575,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 2904/10000,\n",
      " train_loss: 838.9573,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2905/10000,\n",
      " train_loss: 838.9572,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2906/10000,\n",
      " train_loss: 838.9572,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2907/10000,\n",
      " train_loss: 838.9571,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 2908/10000,\n",
      " train_loss: 838.9569,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 2909/10000,\n",
      " train_loss: 838.9568,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2910/10000,\n",
      " train_loss: 838.9567,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2911/10000,\n",
      " train_loss: 838.9565,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2912/10000,\n",
      " train_loss: 838.9564,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2913/10000,\n",
      " train_loss: 838.9564,\n",
      " train_mae: 25.3339,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 2914/10000,\n",
      " train_loss: 838.9563,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2915/10000,\n",
      " train_loss: 838.9562,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2916/10000,\n",
      " train_loss: 838.9561,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2917/10000,\n",
      " train_loss: 838.9561,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2918/10000,\n",
      " train_loss: 838.9559,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2919/10000,\n",
      " train_loss: 838.9557,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2920/10000,\n",
      " train_loss: 838.9556,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2921/10000,\n",
      " train_loss: 838.9556,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2922/10000,\n",
      " train_loss: 838.9554,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 2923/10000,\n",
      " train_loss: 838.9554,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2924/10000,\n",
      " train_loss: 838.9553,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2925/10000,\n",
      " train_loss: 838.9552,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2926/10000,\n",
      " train_loss: 838.9551,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 2927/10000,\n",
      " train_loss: 838.9550,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 2928/10000,\n",
      " train_loss: 838.9548,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2929/10000,\n",
      " train_loss: 838.9547,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2930/10000,\n",
      " train_loss: 838.9547,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2931/10000,\n",
      " train_loss: 838.9545,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2932/10000,\n",
      " train_loss: 838.9545,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 2933/10000,\n",
      " train_loss: 838.9543,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 2934/10000,\n",
      " train_loss: 838.9543,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 2935/10000,\n",
      " train_loss: 838.9542,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2936/10000,\n",
      " train_loss: 838.9541,\n",
      " train_mae: 25.3338,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2937/10000,\n",
      " train_loss: 838.9540,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2938/10000,\n",
      " train_loss: 838.9538,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2939/10000,\n",
      " train_loss: 838.9537,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2940/10000,\n",
      " train_loss: 838.9537,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2941/10000,\n",
      " train_loss: 838.9536,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2942/10000,\n",
      " train_loss: 838.9535,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 2943/10000,\n",
      " train_loss: 838.9534,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2944/10000,\n",
      " train_loss: 838.9533,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 2945/10000,\n",
      " train_loss: 838.9532,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 2946/10000,\n",
      " train_loss: 838.9531,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2947/10000,\n",
      " train_loss: 838.9530,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 2948/10000,\n",
      " train_loss: 838.9529,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2949/10000,\n",
      " train_loss: 838.9527,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 2950/10000,\n",
      " train_loss: 838.9528,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 2951/10000,\n",
      " train_loss: 838.9526,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 2952/10000,\n",
      " train_loss: 838.9525,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0116\n",
      "\n",
      "epoch: 2953/10000,\n",
      " train_loss: 838.9524,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2954/10000,\n",
      " train_loss: 838.9523,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2955/10000,\n",
      " train_loss: 838.9523,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2956/10000,\n",
      " train_loss: 838.9521,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2957/10000,\n",
      " train_loss: 838.9520,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2958/10000,\n",
      " train_loss: 838.9519,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2959/10000,\n",
      " train_loss: 838.9518,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2960/10000,\n",
      " train_loss: 838.9517,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 2961/10000,\n",
      " train_loss: 838.9516,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 2962/10000,\n",
      " train_loss: 838.9515,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 2963/10000,\n",
      " train_loss: 838.9514,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 2964/10000,\n",
      " train_loss: 838.9514,\n",
      " train_mae: 25.3337,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2965/10000,\n",
      " train_loss: 838.9513,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2966/10000,\n",
      " train_loss: 838.9512,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 2967/10000,\n",
      " train_loss: 838.9511,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 2968/10000,\n",
      " train_loss: 838.9509,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 2969/10000,\n",
      " train_loss: 838.9509,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2970/10000,\n",
      " train_loss: 838.9507,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2971/10000,\n",
      " train_loss: 838.9506,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2972/10000,\n",
      " train_loss: 838.9506,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2973/10000,\n",
      " train_loss: 838.9505,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2974/10000,\n",
      " train_loss: 838.9504,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2975/10000,\n",
      " train_loss: 838.9503,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2976/10000,\n",
      " train_loss: 838.9502,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2977/10000,\n",
      " train_loss: 838.9502,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 2978/10000,\n",
      " train_loss: 838.9501,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 2979/10000,\n",
      " train_loss: 838.9500,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 2980/10000,\n",
      " train_loss: 838.9499,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 2981/10000,\n",
      " train_loss: 838.9498,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 2982/10000,\n",
      " train_loss: 838.9496,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 2983/10000,\n",
      " train_loss: 838.9495,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 2984/10000,\n",
      " train_loss: 838.9495,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 2985/10000,\n",
      " train_loss: 838.9494,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2986/10000,\n",
      " train_loss: 838.9493,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2987/10000,\n",
      " train_loss: 838.9492,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2988/10000,\n",
      " train_loss: 838.9491,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 2989/10000,\n",
      " train_loss: 838.9490,\n",
      " train_mae: 25.3336,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2990/10000,\n",
      " train_loss: 838.9489,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 2991/10000,\n",
      " train_loss: 838.9489,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2992/10000,\n",
      " train_loss: 838.9487,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2993/10000,\n",
      " train_loss: 838.9486,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2994/10000,\n",
      " train_loss: 838.9485,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 2995/10000,\n",
      " train_loss: 838.9485,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2996/10000,\n",
      " train_loss: 838.9484,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 2997/10000,\n",
      " train_loss: 838.9484,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 2998/10000,\n",
      " train_loss: 838.9482,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 2999/10000,\n",
      " train_loss: 838.9481,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3000/10000,\n",
      " train_loss: 838.9480,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3001/10000,\n",
      " train_loss: 838.9479,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3002/10000,\n",
      " train_loss: 838.9478,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3003/10000,\n",
      " train_loss: 838.9477,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3004/10000,\n",
      " train_loss: 838.9476,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0146\n",
      "\n",
      "epoch: 3005/10000,\n",
      " train_loss: 838.9476,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "epoch: 3006/10000,\n",
      " train_loss: 838.9474,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3007/10000,\n",
      " train_loss: 838.9473,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3008/10000,\n",
      " train_loss: 838.9473,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 3009/10000,\n",
      " train_loss: 838.9472,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 3010/10000,\n",
      " train_loss: 838.9471,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3011/10000,\n",
      " train_loss: 838.9470,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3012/10000,\n",
      " train_loss: 838.9469,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3013/10000,\n",
      " train_loss: 838.9468,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3014/10000,\n",
      " train_loss: 838.9467,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3015/10000,\n",
      " train_loss: 838.9467,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3016/10000,\n",
      " train_loss: 838.9465,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3017/10000,\n",
      " train_loss: 838.9464,\n",
      " train_mae: 25.3335,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3018/10000,\n",
      " train_loss: 838.9464,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3019/10000,\n",
      " train_loss: 838.9464,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3020/10000,\n",
      " train_loss: 838.9463,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3021/10000,\n",
      " train_loss: 838.9462,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3022/10000,\n",
      " train_loss: 838.9460,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3023/10000,\n",
      " train_loss: 838.9459,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0134\n",
      "\n",
      "epoch: 3024/10000,\n",
      " train_loss: 838.9459,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3025/10000,\n",
      " train_loss: 838.9457,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3026/10000,\n",
      " train_loss: 838.9456,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3027/10000,\n",
      " train_loss: 838.9456,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3028/10000,\n",
      " train_loss: 838.9455,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3029/10000,\n",
      " train_loss: 838.9455,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3030/10000,\n",
      " train_loss: 838.9454,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3031/10000,\n",
      " train_loss: 838.9453,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3032/10000,\n",
      " train_loss: 838.9452,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3033/10000,\n",
      " train_loss: 838.9451,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3034/10000,\n",
      " train_loss: 838.9449,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3035/10000,\n",
      " train_loss: 838.9449,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3036/10000,\n",
      " train_loss: 838.9448,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3037/10000,\n",
      " train_loss: 838.9447,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3038/10000,\n",
      " train_loss: 838.9446,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3039/10000,\n",
      " train_loss: 838.9446,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3040/10000,\n",
      " train_loss: 838.9445,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3041/10000,\n",
      " train_loss: 838.9444,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3042/10000,\n",
      " train_loss: 838.9443,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3043/10000,\n",
      " train_loss: 838.9442,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3044/10000,\n",
      " train_loss: 838.9441,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3045/10000,\n",
      " train_loss: 838.9441,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3046/10000,\n",
      " train_loss: 838.9440,\n",
      " train_mae: 25.3334,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3047/10000,\n",
      " train_loss: 838.9439,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3048/10000,\n",
      " train_loss: 838.9438,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0122\n",
      "\n",
      "epoch: 3049/10000,\n",
      " train_loss: 838.9437,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3050/10000,\n",
      " train_loss: 838.9436,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "epoch: 3051/10000,\n",
      " train_loss: 838.9435,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3052/10000,\n",
      " train_loss: 838.9435,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3053/10000,\n",
      " train_loss: 838.9434,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3054/10000,\n",
      " train_loss: 838.9434,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3055/10000,\n",
      " train_loss: 838.9431,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3056/10000,\n",
      " train_loss: 838.9431,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3057/10000,\n",
      " train_loss: 838.9430,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3058/10000,\n",
      " train_loss: 838.9429,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3059/10000,\n",
      " train_loss: 838.9429,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3060/10000,\n",
      " train_loss: 838.9427,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3061/10000,\n",
      " train_loss: 838.9427,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3062/10000,\n",
      " train_loss: 838.9426,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3063/10000,\n",
      " train_loss: 838.9425,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3064/10000,\n",
      " train_loss: 838.9424,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3065/10000,\n",
      " train_loss: 838.9424,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3066/10000,\n",
      " train_loss: 838.9423,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3067/10000,\n",
      " train_loss: 838.9423,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3068/10000,\n",
      " train_loss: 838.9421,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3069/10000,\n",
      " train_loss: 838.9420,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3070/10000,\n",
      " train_loss: 838.9420,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3071/10000,\n",
      " train_loss: 838.9418,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3072/10000,\n",
      " train_loss: 838.9418,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3073/10000,\n",
      " train_loss: 838.9417,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3074/10000,\n",
      " train_loss: 838.9416,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3075/10000,\n",
      " train_loss: 838.9416,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3076/10000,\n",
      " train_loss: 838.9415,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3077/10000,\n",
      " train_loss: 838.9413,\n",
      " train_mae: 25.3333,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3078/10000,\n",
      " train_loss: 838.9413,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3079/10000,\n",
      " train_loss: 838.9412,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3080/10000,\n",
      " train_loss: 838.9412,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3081/10000,\n",
      " train_loss: 838.9410,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3082/10000,\n",
      " train_loss: 838.9409,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3083/10000,\n",
      " train_loss: 838.9409,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0111\n",
      "\n",
      "epoch: 3084/10000,\n",
      " train_loss: 838.9408,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3085/10000,\n",
      " train_loss: 838.9407,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3086/10000,\n",
      " train_loss: 838.9407,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3087/10000,\n",
      " train_loss: 838.9406,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3088/10000,\n",
      " train_loss: 838.9406,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3089/10000,\n",
      " train_loss: 838.9404,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 3090/10000,\n",
      " train_loss: 838.9404,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 3091/10000,\n",
      " train_loss: 838.9402,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 3092/10000,\n",
      " train_loss: 838.9401,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 3093/10000,\n",
      " train_loss: 838.9401,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3094/10000,\n",
      " train_loss: 838.9400,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3095/10000,\n",
      " train_loss: 838.9399,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3096/10000,\n",
      " train_loss: 838.9398,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3097/10000,\n",
      " train_loss: 838.9398,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3098/10000,\n",
      " train_loss: 838.9397,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3099/10000,\n",
      " train_loss: 838.9396,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3100/10000,\n",
      " train_loss: 838.9395,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3101/10000,\n",
      " train_loss: 838.9395,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3102/10000,\n",
      " train_loss: 838.9394,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3103/10000,\n",
      " train_loss: 838.9393,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3104/10000,\n",
      " train_loss: 838.9392,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3105/10000,\n",
      " train_loss: 838.9391,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3106/10000,\n",
      " train_loss: 838.9391,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 3107/10000,\n",
      " train_loss: 838.9389,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3108/10000,\n",
      " train_loss: 838.9388,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3109/10000,\n",
      " train_loss: 838.9388,\n",
      " train_mae: 25.3332,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3110/10000,\n",
      " train_loss: 838.9388,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3111/10000,\n",
      " train_loss: 838.9387,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3112/10000,\n",
      " train_loss: 838.9386,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3113/10000,\n",
      " train_loss: 838.9386,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3114/10000,\n",
      " train_loss: 838.9385,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3115/10000,\n",
      " train_loss: 838.9384,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3116/10000,\n",
      " train_loss: 838.9382,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3117/10000,\n",
      " train_loss: 838.9382,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0129\n",
      "\n",
      "epoch: 3118/10000,\n",
      " train_loss: 838.9382,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 3119/10000,\n",
      " train_loss: 838.9380,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 3120/10000,\n",
      " train_loss: 838.9379,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3121/10000,\n",
      " train_loss: 838.9379,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3122/10000,\n",
      " train_loss: 838.9379,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3123/10000,\n",
      " train_loss: 838.9378,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3124/10000,\n",
      " train_loss: 838.9377,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3125/10000,\n",
      " train_loss: 838.9376,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3126/10000,\n",
      " train_loss: 838.9376,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3127/10000,\n",
      " train_loss: 838.9374,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3128/10000,\n",
      " train_loss: 838.9374,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3129/10000,\n",
      " train_loss: 838.9374,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3130/10000,\n",
      " train_loss: 838.9373,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3131/10000,\n",
      " train_loss: 838.9371,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3132/10000,\n",
      " train_loss: 838.9371,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3133/10000,\n",
      " train_loss: 838.9370,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3134/10000,\n",
      " train_loss: 838.9370,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3135/10000,\n",
      " train_loss: 838.9368,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3136/10000,\n",
      " train_loss: 838.9368,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3137/10000,\n",
      " train_loss: 838.9367,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3138/10000,\n",
      " train_loss: 838.9366,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 3139/10000,\n",
      " train_loss: 838.9366,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3140/10000,\n",
      " train_loss: 838.9365,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3141/10000,\n",
      " train_loss: 838.9365,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3142/10000,\n",
      " train_loss: 838.9364,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3143/10000,\n",
      " train_loss: 838.9363,\n",
      " train_mae: 25.3331,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3144/10000,\n",
      " train_loss: 838.9362,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3145/10000,\n",
      " train_loss: 838.9362,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3146/10000,\n",
      " train_loss: 838.9361,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3147/10000,\n",
      " train_loss: 838.9360,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3148/10000,\n",
      " train_loss: 838.9359,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3149/10000,\n",
      " train_loss: 838.9359,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3150/10000,\n",
      " train_loss: 838.9357,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 3151/10000,\n",
      " train_loss: 838.9357,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3152/10000,\n",
      " train_loss: 838.9356,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3153/10000,\n",
      " train_loss: 838.9355,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3154/10000,\n",
      " train_loss: 838.9355,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3155/10000,\n",
      " train_loss: 838.9353,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3156/10000,\n",
      " train_loss: 838.9352,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3157/10000,\n",
      " train_loss: 838.9352,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3158/10000,\n",
      " train_loss: 838.9352,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3159/10000,\n",
      " train_loss: 838.9350,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3160/10000,\n",
      " train_loss: 838.9350,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3161/10000,\n",
      " train_loss: 838.9349,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3162/10000,\n",
      " train_loss: 838.9349,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3163/10000,\n",
      " train_loss: 838.9348,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3164/10000,\n",
      " train_loss: 838.9348,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3165/10000,\n",
      " train_loss: 838.9347,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3166/10000,\n",
      " train_loss: 838.9346,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 3167/10000,\n",
      " train_loss: 838.9346,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3168/10000,\n",
      " train_loss: 838.9344,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 3169/10000,\n",
      " train_loss: 838.9344,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0025\n",
      "\n",
      "epoch: 3170/10000,\n",
      " train_loss: 838.9343,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3171/10000,\n",
      " train_loss: 838.9343,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3172/10000,\n",
      " train_loss: 838.9341,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3173/10000,\n",
      " train_loss: 838.9341,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3174/10000,\n",
      " train_loss: 838.9340,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3175/10000,\n",
      " train_loss: 838.9340,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3176/10000,\n",
      " train_loss: 838.9339,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3177/10000,\n",
      " train_loss: 838.9338,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 3178/10000,\n",
      " train_loss: 838.9338,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 3179/10000,\n",
      " train_loss: 838.9337,\n",
      " train_mae: 25.3330,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3180/10000,\n",
      " train_loss: 838.9335,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3181/10000,\n",
      " train_loss: 838.9336,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3182/10000,\n",
      " train_loss: 838.9335,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3183/10000,\n",
      " train_loss: 838.9335,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "epoch: 3184/10000,\n",
      " train_loss: 838.9333,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3185/10000,\n",
      " train_loss: 838.9332,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3186/10000,\n",
      " train_loss: 838.9332,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3187/10000,\n",
      " train_loss: 838.9330,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3188/10000,\n",
      " train_loss: 838.9330,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3189/10000,\n",
      " train_loss: 838.9330,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3190/10000,\n",
      " train_loss: 838.9329,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3191/10000,\n",
      " train_loss: 838.9329,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3192/10000,\n",
      " train_loss: 838.9329,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3193/10000,\n",
      " train_loss: 838.9327,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3194/10000,\n",
      " train_loss: 838.9327,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3195/10000,\n",
      " train_loss: 838.9326,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3196/10000,\n",
      " train_loss: 838.9325,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3197/10000,\n",
      " train_loss: 838.9325,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3198/10000,\n",
      " train_loss: 838.9324,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3199/10000,\n",
      " train_loss: 838.9323,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3200/10000,\n",
      " train_loss: 838.9322,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3201/10000,\n",
      " train_loss: 838.9322,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3202/10000,\n",
      " train_loss: 838.9321,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3203/10000,\n",
      " train_loss: 838.9320,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3204/10000,\n",
      " train_loss: 838.9319,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3205/10000,\n",
      " train_loss: 838.9319,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3206/10000,\n",
      " train_loss: 838.9318,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3207/10000,\n",
      " train_loss: 838.9318,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3208/10000,\n",
      " train_loss: 838.9317,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3209/10000,\n",
      " train_loss: 838.9316,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3210/10000,\n",
      " train_loss: 838.9316,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3211/10000,\n",
      " train_loss: 838.9315,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3212/10000,\n",
      " train_loss: 838.9314,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3213/10000,\n",
      " train_loss: 838.9313,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3214/10000,\n",
      " train_loss: 838.9313,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3215/10000,\n",
      " train_loss: 838.9311,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3216/10000,\n",
      " train_loss: 838.9311,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3217/10000,\n",
      " train_loss: 838.9311,\n",
      " train_mae: 25.3329,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3218/10000,\n",
      " train_loss: 838.9310,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3219/10000,\n",
      " train_loss: 838.9310,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3220/10000,\n",
      " train_loss: 838.9309,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3221/10000,\n",
      " train_loss: 838.9308,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3222/10000,\n",
      " train_loss: 838.9308,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 3223/10000,\n",
      " train_loss: 838.9307,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3224/10000,\n",
      " train_loss: 838.9307,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3225/10000,\n",
      " train_loss: 838.9305,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3226/10000,\n",
      " train_loss: 838.9305,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3227/10000,\n",
      " train_loss: 838.9304,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 3228/10000,\n",
      " train_loss: 838.9304,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3229/10000,\n",
      " train_loss: 838.9302,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 3230/10000,\n",
      " train_loss: 838.9302,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3231/10000,\n",
      " train_loss: 838.9301,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3232/10000,\n",
      " train_loss: 838.9301,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3233/10000,\n",
      " train_loss: 838.9300,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3234/10000,\n",
      " train_loss: 838.9300,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3235/10000,\n",
      " train_loss: 838.9299,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3236/10000,\n",
      " train_loss: 838.9299,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3237/10000,\n",
      " train_loss: 838.9297,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3238/10000,\n",
      " train_loss: 838.9297,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3239/10000,\n",
      " train_loss: 838.9296,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3240/10000,\n",
      " train_loss: 838.9296,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3241/10000,\n",
      " train_loss: 838.9294,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3242/10000,\n",
      " train_loss: 838.9294,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3243/10000,\n",
      " train_loss: 838.9294,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3244/10000,\n",
      " train_loss: 838.9293,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3245/10000,\n",
      " train_loss: 838.9291,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3246/10000,\n",
      " train_loss: 838.9291,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3247/10000,\n",
      " train_loss: 838.9291,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3248/10000,\n",
      " train_loss: 838.9290,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3249/10000,\n",
      " train_loss: 838.9290,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3250/10000,\n",
      " train_loss: 838.9290,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 3251/10000,\n",
      " train_loss: 838.9288,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3252/10000,\n",
      " train_loss: 838.9288,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3253/10000,\n",
      " train_loss: 838.9287,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3254/10000,\n",
      " train_loss: 838.9286,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3255/10000,\n",
      " train_loss: 838.9286,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3256/10000,\n",
      " train_loss: 838.9286,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3257/10000,\n",
      " train_loss: 838.9284,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3258/10000,\n",
      " train_loss: 838.9284,\n",
      " train_mae: 25.3328,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3259/10000,\n",
      " train_loss: 838.9283,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3260/10000,\n",
      " train_loss: 838.9283,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3261/10000,\n",
      " train_loss: 838.9283,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3262/10000,\n",
      " train_loss: 838.9282,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3263/10000,\n",
      " train_loss: 838.9281,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3264/10000,\n",
      " train_loss: 838.9280,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3265/10000,\n",
      " train_loss: 838.9280,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3266/10000,\n",
      " train_loss: 838.9279,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3267/10000,\n",
      " train_loss: 838.9279,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3268/10000,\n",
      " train_loss: 838.9278,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 3269/10000,\n",
      " train_loss: 838.9277,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3270/10000,\n",
      " train_loss: 838.9276,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3271/10000,\n",
      " train_loss: 838.9275,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3272/10000,\n",
      " train_loss: 838.9275,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3273/10000,\n",
      " train_loss: 838.9275,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3274/10000,\n",
      " train_loss: 838.9274,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3275/10000,\n",
      " train_loss: 838.9273,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3276/10000,\n",
      " train_loss: 838.9273,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3277/10000,\n",
      " train_loss: 838.9272,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3278/10000,\n",
      " train_loss: 838.9271,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3279/10000,\n",
      " train_loss: 838.9271,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3280/10000,\n",
      " train_loss: 838.9271,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3281/10000,\n",
      " train_loss: 838.9270,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3282/10000,\n",
      " train_loss: 838.9269,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3283/10000,\n",
      " train_loss: 838.9268,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3284/10000,\n",
      " train_loss: 838.9268,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3285/10000,\n",
      " train_loss: 838.9268,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3286/10000,\n",
      " train_loss: 838.9267,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3287/10000,\n",
      " train_loss: 838.9266,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3288/10000,\n",
      " train_loss: 838.9265,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 3289/10000,\n",
      " train_loss: 838.9265,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3290/10000,\n",
      " train_loss: 838.9265,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3291/10000,\n",
      " train_loss: 838.9263,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3292/10000,\n",
      " train_loss: 838.9263,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3293/10000,\n",
      " train_loss: 838.9262,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3294/10000,\n",
      " train_loss: 838.9261,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3295/10000,\n",
      " train_loss: 838.9261,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3296/10000,\n",
      " train_loss: 838.9261,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 3297/10000,\n",
      " train_loss: 838.9260,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3298/10000,\n",
      " train_loss: 838.9260,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 3299/10000,\n",
      " train_loss: 838.9258,\n",
      " train_mae: 25.3327,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3300/10000,\n",
      " train_loss: 838.9258,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3301/10000,\n",
      " train_loss: 838.9258,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3302/10000,\n",
      " train_loss: 838.9257,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3303/10000,\n",
      " train_loss: 838.9257,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3304/10000,\n",
      " train_loss: 838.9255,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3305/10000,\n",
      " train_loss: 838.9255,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3306/10000,\n",
      " train_loss: 838.9255,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3307/10000,\n",
      " train_loss: 838.9254,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3308/10000,\n",
      " train_loss: 838.9252,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3309/10000,\n",
      " train_loss: 838.9252,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3310/10000,\n",
      " train_loss: 838.9252,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3311/10000,\n",
      " train_loss: 838.9252,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3312/10000,\n",
      " train_loss: 838.9252,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3313/10000,\n",
      " train_loss: 838.9250,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3314/10000,\n",
      " train_loss: 838.9250,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3315/10000,\n",
      " train_loss: 838.9249,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3316/10000,\n",
      " train_loss: 838.9249,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3317/10000,\n",
      " train_loss: 838.9248,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3318/10000,\n",
      " train_loss: 838.9247,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 3319/10000,\n",
      " train_loss: 838.9247,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3320/10000,\n",
      " train_loss: 838.9246,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3321/10000,\n",
      " train_loss: 838.9245,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3322/10000,\n",
      " train_loss: 838.9245,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3323/10000,\n",
      " train_loss: 838.9244,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 3324/10000,\n",
      " train_loss: 838.9244,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 3325/10000,\n",
      " train_loss: 838.9243,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3326/10000,\n",
      " train_loss: 838.9243,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3327/10000,\n",
      " train_loss: 838.9242,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3328/10000,\n",
      " train_loss: 838.9241,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3329/10000,\n",
      " train_loss: 838.9241,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3330/10000,\n",
      " train_loss: 838.9240,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3331/10000,\n",
      " train_loss: 838.9240,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3332/10000,\n",
      " train_loss: 838.9239,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3333/10000,\n",
      " train_loss: 838.9239,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3334/10000,\n",
      " train_loss: 838.9238,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3335/10000,\n",
      " train_loss: 838.9237,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3336/10000,\n",
      " train_loss: 838.9237,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3337/10000,\n",
      " train_loss: 838.9236,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3338/10000,\n",
      " train_loss: 838.9235,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3339/10000,\n",
      " train_loss: 838.9235,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3340/10000,\n",
      " train_loss: 838.9235,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3341/10000,\n",
      " train_loss: 838.9233,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3342/10000,\n",
      " train_loss: 838.9233,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3343/10000,\n",
      " train_loss: 838.9233,\n",
      " train_mae: 25.3326,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3344/10000,\n",
      " train_loss: 838.9232,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3345/10000,\n",
      " train_loss: 838.9232,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3346/10000,\n",
      " train_loss: 838.9231,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3347/10000,\n",
      " train_loss: 838.9230,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3348/10000,\n",
      " train_loss: 838.9230,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3349/10000,\n",
      " train_loss: 838.9229,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3350/10000,\n",
      " train_loss: 838.9229,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3351/10000,\n",
      " train_loss: 838.9229,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3352/10000,\n",
      " train_loss: 838.9228,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 3353/10000,\n",
      " train_loss: 838.9227,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 3354/10000,\n",
      " train_loss: 838.9227,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3355/10000,\n",
      " train_loss: 838.9226,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3356/10000,\n",
      " train_loss: 838.9225,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3357/10000,\n",
      " train_loss: 838.9224,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3358/10000,\n",
      " train_loss: 838.9224,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3359/10000,\n",
      " train_loss: 838.9223,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3360/10000,\n",
      " train_loss: 838.9223,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3361/10000,\n",
      " train_loss: 838.9223,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3362/10000,\n",
      " train_loss: 838.9222,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0139\n",
      "\n",
      "epoch: 3363/10000,\n",
      " train_loss: 838.9222,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3364/10000,\n",
      " train_loss: 838.9221,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3365/10000,\n",
      " train_loss: 838.9221,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3366/10000,\n",
      " train_loss: 838.9220,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3367/10000,\n",
      " train_loss: 838.9219,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3368/10000,\n",
      " train_loss: 838.9218,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3369/10000,\n",
      " train_loss: 838.9218,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3370/10000,\n",
      " train_loss: 838.9218,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3371/10000,\n",
      " train_loss: 838.9218,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3372/10000,\n",
      " train_loss: 838.9216,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3373/10000,\n",
      " train_loss: 838.9216,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3374/10000,\n",
      " train_loss: 838.9215,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3375/10000,\n",
      " train_loss: 838.9215,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3376/10000,\n",
      " train_loss: 838.9213,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3377/10000,\n",
      " train_loss: 838.9213,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3378/10000,\n",
      " train_loss: 838.9213,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3379/10000,\n",
      " train_loss: 838.9213,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3380/10000,\n",
      " train_loss: 838.9213,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3381/10000,\n",
      " train_loss: 838.9211,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3382/10000,\n",
      " train_loss: 838.9211,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3383/10000,\n",
      " train_loss: 838.9211,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3384/10000,\n",
      " train_loss: 838.9210,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3385/10000,\n",
      " train_loss: 838.9210,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3386/10000,\n",
      " train_loss: 838.9209,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 3387/10000,\n",
      " train_loss: 838.9208,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 3388/10000,\n",
      " train_loss: 838.9208,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3389/10000,\n",
      " train_loss: 838.9208,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3390/10000,\n",
      " train_loss: 838.9208,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3391/10000,\n",
      " train_loss: 838.9206,\n",
      " train_mae: 25.3325,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3392/10000,\n",
      " train_loss: 838.9205,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3393/10000,\n",
      " train_loss: 838.9205,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3394/10000,\n",
      " train_loss: 838.9205,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3395/10000,\n",
      " train_loss: 838.9205,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3396/10000,\n",
      " train_loss: 838.9203,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3397/10000,\n",
      " train_loss: 838.9203,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3398/10000,\n",
      " train_loss: 838.9203,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3399/10000,\n",
      " train_loss: 838.9202,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3400/10000,\n",
      " train_loss: 838.9202,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3401/10000,\n",
      " train_loss: 838.9201,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3402/10000,\n",
      " train_loss: 838.9200,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3403/10000,\n",
      " train_loss: 838.9200,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3404/10000,\n",
      " train_loss: 838.9200,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3405/10000,\n",
      " train_loss: 838.9199,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3406/10000,\n",
      " train_loss: 838.9199,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3407/10000,\n",
      " train_loss: 838.9199,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3408/10000,\n",
      " train_loss: 838.9197,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3409/10000,\n",
      " train_loss: 838.9197,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3410/10000,\n",
      " train_loss: 838.9196,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3411/10000,\n",
      " train_loss: 838.9196,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3412/10000,\n",
      " train_loss: 838.9195,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3413/10000,\n",
      " train_loss: 838.9194,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3414/10000,\n",
      " train_loss: 838.9194,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3415/10000,\n",
      " train_loss: 838.9193,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3416/10000,\n",
      " train_loss: 838.9193,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3417/10000,\n",
      " train_loss: 838.9193,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3418/10000,\n",
      " train_loss: 838.9192,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3419/10000,\n",
      " train_loss: 838.9192,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 3420/10000,\n",
      " train_loss: 838.9191,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 3421/10000,\n",
      " train_loss: 838.9191,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3422/10000,\n",
      " train_loss: 838.9190,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3423/10000,\n",
      " train_loss: 838.9189,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3424/10000,\n",
      " train_loss: 838.9189,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3425/10000,\n",
      " train_loss: 838.9188,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3426/10000,\n",
      " train_loss: 838.9188,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3427/10000,\n",
      " train_loss: 838.9187,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3428/10000,\n",
      " train_loss: 838.9186,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3429/10000,\n",
      " train_loss: 838.9186,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3430/10000,\n",
      " train_loss: 838.9186,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3431/10000,\n",
      " train_loss: 838.9185,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3432/10000,\n",
      " train_loss: 838.9185,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3433/10000,\n",
      " train_loss: 838.9184,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3434/10000,\n",
      " train_loss: 838.9184,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3435/10000,\n",
      " train_loss: 838.9183,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3436/10000,\n",
      " train_loss: 838.9183,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3437/10000,\n",
      " train_loss: 838.9182,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3438/10000,\n",
      " train_loss: 838.9182,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3439/10000,\n",
      " train_loss: 838.9182,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3440/10000,\n",
      " train_loss: 838.9181,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3441/10000,\n",
      " train_loss: 838.9180,\n",
      " train_mae: 25.3324,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3442/10000,\n",
      " train_loss: 838.9180,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3443/10000,\n",
      " train_loss: 838.9179,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3444/10000,\n",
      " train_loss: 838.9179,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3445/10000,\n",
      " train_loss: 838.9177,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3446/10000,\n",
      " train_loss: 838.9177,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3447/10000,\n",
      " train_loss: 838.9177,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3448/10000,\n",
      " train_loss: 838.9176,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3449/10000,\n",
      " train_loss: 838.9176,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3450/10000,\n",
      " train_loss: 838.9175,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3451/10000,\n",
      " train_loss: 838.9174,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0125\n",
      "\n",
      "epoch: 3452/10000,\n",
      " train_loss: 838.9174,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3453/10000,\n",
      " train_loss: 838.9174,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3454/10000,\n",
      " train_loss: 838.9174,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 3455/10000,\n",
      " train_loss: 838.9174,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3456/10000,\n",
      " train_loss: 838.9172,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3457/10000,\n",
      " train_loss: 838.9172,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3458/10000,\n",
      " train_loss: 838.9172,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3459/10000,\n",
      " train_loss: 838.9171,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3460/10000,\n",
      " train_loss: 838.9170,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3461/10000,\n",
      " train_loss: 838.9171,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3462/10000,\n",
      " train_loss: 838.9169,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3463/10000,\n",
      " train_loss: 838.9169,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3464/10000,\n",
      " train_loss: 838.9169,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3465/10000,\n",
      " train_loss: 838.9167,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3466/10000,\n",
      " train_loss: 838.9167,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3467/10000,\n",
      " train_loss: 838.9166,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3468/10000,\n",
      " train_loss: 838.9166,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3469/10000,\n",
      " train_loss: 838.9166,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3470/10000,\n",
      " train_loss: 838.9166,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3471/10000,\n",
      " train_loss: 838.9166,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3472/10000,\n",
      " train_loss: 838.9164,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3473/10000,\n",
      " train_loss: 838.9164,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3474/10000,\n",
      " train_loss: 838.9164,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3475/10000,\n",
      " train_loss: 838.9163,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 3476/10000,\n",
      " train_loss: 838.9163,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3477/10000,\n",
      " train_loss: 838.9162,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3478/10000,\n",
      " train_loss: 838.9162,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 3479/10000,\n",
      " train_loss: 838.9161,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0121\n",
      "\n",
      "epoch: 3480/10000,\n",
      " train_loss: 838.9161,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3481/10000,\n",
      " train_loss: 838.9160,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3482/10000,\n",
      " train_loss: 838.9160,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3483/10000,\n",
      " train_loss: 838.9160,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3484/10000,\n",
      " train_loss: 838.9160,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3485/10000,\n",
      " train_loss: 838.9158,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3486/10000,\n",
      " train_loss: 838.9157,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3487/10000,\n",
      " train_loss: 838.9156,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3488/10000,\n",
      " train_loss: 838.9156,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3489/10000,\n",
      " train_loss: 838.9156,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3490/10000,\n",
      " train_loss: 838.9156,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3491/10000,\n",
      " train_loss: 838.9155,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3492/10000,\n",
      " train_loss: 838.9155,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3493/10000,\n",
      " train_loss: 838.9154,\n",
      " train_mae: 25.3323,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3494/10000,\n",
      " train_loss: 838.9154,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 3495/10000,\n",
      " train_loss: 838.9153,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3496/10000,\n",
      " train_loss: 838.9153,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3497/10000,\n",
      " train_loss: 838.9153,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3498/10000,\n",
      " train_loss: 838.9152,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3499/10000,\n",
      " train_loss: 838.9152,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3500/10000,\n",
      " train_loss: 838.9151,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3501/10000,\n",
      " train_loss: 838.9150,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3502/10000,\n",
      " train_loss: 838.9150,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3503/10000,\n",
      " train_loss: 838.9150,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3504/10000,\n",
      " train_loss: 838.9149,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3505/10000,\n",
      " train_loss: 838.9149,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3506/10000,\n",
      " train_loss: 838.9148,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3507/10000,\n",
      " train_loss: 838.9147,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3508/10000,\n",
      " train_loss: 838.9147,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3509/10000,\n",
      " train_loss: 838.9146,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3510/10000,\n",
      " train_loss: 838.9146,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3511/10000,\n",
      " train_loss: 838.9146,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3512/10000,\n",
      " train_loss: 838.9145,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3513/10000,\n",
      " train_loss: 838.9145,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3514/10000,\n",
      " train_loss: 838.9145,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3515/10000,\n",
      " train_loss: 838.9144,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3516/10000,\n",
      " train_loss: 838.9144,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3517/10000,\n",
      " train_loss: 838.9142,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 3518/10000,\n",
      " train_loss: 838.9142,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 3519/10000,\n",
      " train_loss: 838.9142,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3520/10000,\n",
      " train_loss: 838.9141,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3521/10000,\n",
      " train_loss: 838.9141,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 3522/10000,\n",
      " train_loss: 838.9140,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3523/10000,\n",
      " train_loss: 838.9141,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 3524/10000,\n",
      " train_loss: 838.9140,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3525/10000,\n",
      " train_loss: 838.9139,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3526/10000,\n",
      " train_loss: 838.9138,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3527/10000,\n",
      " train_loss: 838.9138,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3528/10000,\n",
      " train_loss: 838.9138,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3529/10000,\n",
      " train_loss: 838.9137,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3530/10000,\n",
      " train_loss: 838.9136,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3531/10000,\n",
      " train_loss: 838.9136,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3532/10000,\n",
      " train_loss: 838.9135,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3533/10000,\n",
      " train_loss: 838.9135,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3534/10000,\n",
      " train_loss: 838.9135,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3535/10000,\n",
      " train_loss: 838.9135,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3536/10000,\n",
      " train_loss: 838.9134,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3537/10000,\n",
      " train_loss: 838.9133,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3538/10000,\n",
      " train_loss: 838.9133,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3539/10000,\n",
      " train_loss: 838.9133,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3540/10000,\n",
      " train_loss: 838.9132,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3541/10000,\n",
      " train_loss: 838.9132,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3542/10000,\n",
      " train_loss: 838.9131,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3543/10000,\n",
      " train_loss: 838.9131,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3544/10000,\n",
      " train_loss: 838.9131,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3545/10000,\n",
      " train_loss: 838.9130,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3546/10000,\n",
      " train_loss: 838.9130,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3547/10000,\n",
      " train_loss: 838.9130,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3548/10000,\n",
      " train_loss: 838.9128,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3549/10000,\n",
      " train_loss: 838.9128,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3550/10000,\n",
      " train_loss: 838.9127,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3551/10000,\n",
      " train_loss: 838.9127,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3552/10000,\n",
      " train_loss: 838.9127,\n",
      " train_mae: 25.3322,\n",
      " epoch_time_duration: 0.0157\n",
      "\n",
      "epoch: 3553/10000,\n",
      " train_loss: 838.9127,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3554/10000,\n",
      " train_loss: 838.9127,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3555/10000,\n",
      " train_loss: 838.9125,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3556/10000,\n",
      " train_loss: 838.9125,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3557/10000,\n",
      " train_loss: 838.9124,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3558/10000,\n",
      " train_loss: 838.9125,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3559/10000,\n",
      " train_loss: 838.9124,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3560/10000,\n",
      " train_loss: 838.9124,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3561/10000,\n",
      " train_loss: 838.9123,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3562/10000,\n",
      " train_loss: 838.9123,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3563/10000,\n",
      " train_loss: 838.9122,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3564/10000,\n",
      " train_loss: 838.9122,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3565/10000,\n",
      " train_loss: 838.9122,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3566/10000,\n",
      " train_loss: 838.9120,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3567/10000,\n",
      " train_loss: 838.9120,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3568/10000,\n",
      " train_loss: 838.9120,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3569/10000,\n",
      " train_loss: 838.9119,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3570/10000,\n",
      " train_loss: 838.9119,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3571/10000,\n",
      " train_loss: 838.9119,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3572/10000,\n",
      " train_loss: 838.9118,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3573/10000,\n",
      " train_loss: 838.9117,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3574/10000,\n",
      " train_loss: 838.9117,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3575/10000,\n",
      " train_loss: 838.9117,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3576/10000,\n",
      " train_loss: 838.9116,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3577/10000,\n",
      " train_loss: 838.9116,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3578/10000,\n",
      " train_loss: 838.9116,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 3579/10000,\n",
      " train_loss: 838.9115,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3580/10000,\n",
      " train_loss: 838.9115,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 3581/10000,\n",
      " train_loss: 838.9114,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3582/10000,\n",
      " train_loss: 838.9114,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3583/10000,\n",
      " train_loss: 838.9113,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3584/10000,\n",
      " train_loss: 838.9113,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3585/10000,\n",
      " train_loss: 838.9113,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3586/10000,\n",
      " train_loss: 838.9113,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0112\n",
      "\n",
      "epoch: 3587/10000,\n",
      " train_loss: 838.9112,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3588/10000,\n",
      " train_loss: 838.9111,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3589/10000,\n",
      " train_loss: 838.9111,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3590/10000,\n",
      " train_loss: 838.9111,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3591/10000,\n",
      " train_loss: 838.9110,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3592/10000,\n",
      " train_loss: 838.9110,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3593/10000,\n",
      " train_loss: 838.9110,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3594/10000,\n",
      " train_loss: 838.9108,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3595/10000,\n",
      " train_loss: 838.9108,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3596/10000,\n",
      " train_loss: 838.9107,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3597/10000,\n",
      " train_loss: 838.9108,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3598/10000,\n",
      " train_loss: 838.9107,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3599/10000,\n",
      " train_loss: 838.9107,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3600/10000,\n",
      " train_loss: 838.9107,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3601/10000,\n",
      " train_loss: 838.9105,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3602/10000,\n",
      " train_loss: 838.9106,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3603/10000,\n",
      " train_loss: 838.9105,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3604/10000,\n",
      " train_loss: 838.9105,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3605/10000,\n",
      " train_loss: 838.9104,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3606/10000,\n",
      " train_loss: 838.9103,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3607/10000,\n",
      " train_loss: 838.9103,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3608/10000,\n",
      " train_loss: 838.9103,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3609/10000,\n",
      " train_loss: 838.9102,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3610/10000,\n",
      " train_loss: 838.9102,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3611/10000,\n",
      " train_loss: 838.9102,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3612/10000,\n",
      " train_loss: 838.9101,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3613/10000,\n",
      " train_loss: 838.9101,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3614/10000,\n",
      " train_loss: 838.9101,\n",
      " train_mae: 25.3321,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3615/10000,\n",
      " train_loss: 838.9101,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3616/10000,\n",
      " train_loss: 838.9099,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3617/10000,\n",
      " train_loss: 838.9099,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3618/10000,\n",
      " train_loss: 838.9099,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3619/10000,\n",
      " train_loss: 838.9099,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3620/10000,\n",
      " train_loss: 838.9098,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3621/10000,\n",
      " train_loss: 838.9097,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3622/10000,\n",
      " train_loss: 838.9096,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3623/10000,\n",
      " train_loss: 838.9096,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0166\n",
      "\n",
      "epoch: 3624/10000,\n",
      " train_loss: 838.9096,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 3625/10000,\n",
      " train_loss: 838.9095,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 3626/10000,\n",
      " train_loss: 838.9095,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 3627/10000,\n",
      " train_loss: 838.9095,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 3628/10000,\n",
      " train_loss: 838.9094,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3629/10000,\n",
      " train_loss: 838.9094,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 3630/10000,\n",
      " train_loss: 838.9094,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3631/10000,\n",
      " train_loss: 838.9094,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 3632/10000,\n",
      " train_loss: 838.9093,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3633/10000,\n",
      " train_loss: 838.9093,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3634/10000,\n",
      " train_loss: 838.9092,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3635/10000,\n",
      " train_loss: 838.9092,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3636/10000,\n",
      " train_loss: 838.9092,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3637/10000,\n",
      " train_loss: 838.9091,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3638/10000,\n",
      " train_loss: 838.9092,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3639/10000,\n",
      " train_loss: 838.9091,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3640/10000,\n",
      " train_loss: 838.9091,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3641/10000,\n",
      " train_loss: 838.9089,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3642/10000,\n",
      " train_loss: 838.9089,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3643/10000,\n",
      " train_loss: 838.9089,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3644/10000,\n",
      " train_loss: 838.9088,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3645/10000,\n",
      " train_loss: 838.9088,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3646/10000,\n",
      " train_loss: 838.9088,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3647/10000,\n",
      " train_loss: 838.9086,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3648/10000,\n",
      " train_loss: 838.9086,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3649/10000,\n",
      " train_loss: 838.9086,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 3650/10000,\n",
      " train_loss: 838.9085,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "epoch: 3651/10000,\n",
      " train_loss: 838.9085,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3652/10000,\n",
      " train_loss: 838.9085,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3653/10000,\n",
      " train_loss: 838.9085,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3654/10000,\n",
      " train_loss: 838.9084,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3655/10000,\n",
      " train_loss: 838.9084,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3656/10000,\n",
      " train_loss: 838.9084,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3657/10000,\n",
      " train_loss: 838.9083,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3658/10000,\n",
      " train_loss: 838.9083,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3659/10000,\n",
      " train_loss: 838.9082,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3660/10000,\n",
      " train_loss: 838.9082,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3661/10000,\n",
      " train_loss: 838.9081,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3662/10000,\n",
      " train_loss: 838.9081,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3663/10000,\n",
      " train_loss: 838.9081,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3664/10000,\n",
      " train_loss: 838.9080,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3665/10000,\n",
      " train_loss: 838.9080,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3666/10000,\n",
      " train_loss: 838.9080,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3667/10000,\n",
      " train_loss: 838.9078,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3668/10000,\n",
      " train_loss: 838.9078,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3669/10000,\n",
      " train_loss: 838.9078,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3670/10000,\n",
      " train_loss: 838.9077,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3671/10000,\n",
      " train_loss: 838.9077,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3672/10000,\n",
      " train_loss: 838.9077,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3673/10000,\n",
      " train_loss: 838.9077,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3674/10000,\n",
      " train_loss: 838.9076,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3675/10000,\n",
      " train_loss: 838.9076,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3676/10000,\n",
      " train_loss: 838.9075,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3677/10000,\n",
      " train_loss: 838.9075,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3678/10000,\n",
      " train_loss: 838.9075,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3679/10000,\n",
      " train_loss: 838.9075,\n",
      " train_mae: 25.3320,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3680/10000,\n",
      " train_loss: 838.9074,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3681/10000,\n",
      " train_loss: 838.9073,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "epoch: 3682/10000,\n",
      " train_loss: 838.9073,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3683/10000,\n",
      " train_loss: 838.9072,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3684/10000,\n",
      " train_loss: 838.9072,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3685/10000,\n",
      " train_loss: 838.9072,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3686/10000,\n",
      " train_loss: 838.9072,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3687/10000,\n",
      " train_loss: 838.9071,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3688/10000,\n",
      " train_loss: 838.9071,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3689/10000,\n",
      " train_loss: 838.9071,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3690/10000,\n",
      " train_loss: 838.9070,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3691/10000,\n",
      " train_loss: 838.9069,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3692/10000,\n",
      " train_loss: 838.9069,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3693/10000,\n",
      " train_loss: 838.9069,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3694/10000,\n",
      " train_loss: 838.9068,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3695/10000,\n",
      " train_loss: 838.9068,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3696/10000,\n",
      " train_loss: 838.9068,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3697/10000,\n",
      " train_loss: 838.9067,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3698/10000,\n",
      " train_loss: 838.9068,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3699/10000,\n",
      " train_loss: 838.9067,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3700/10000,\n",
      " train_loss: 838.9067,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3701/10000,\n",
      " train_loss: 838.9066,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3702/10000,\n",
      " train_loss: 838.9066,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3703/10000,\n",
      " train_loss: 838.9066,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3704/10000,\n",
      " train_loss: 838.9065,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3705/10000,\n",
      " train_loss: 838.9065,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3706/10000,\n",
      " train_loss: 838.9064,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3707/10000,\n",
      " train_loss: 838.9064,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3708/10000,\n",
      " train_loss: 838.9063,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3709/10000,\n",
      " train_loss: 838.9063,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3710/10000,\n",
      " train_loss: 838.9062,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3711/10000,\n",
      " train_loss: 838.9062,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3712/10000,\n",
      " train_loss: 838.9062,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3713/10000,\n",
      " train_loss: 838.9062,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3714/10000,\n",
      " train_loss: 838.9062,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "epoch: 3715/10000,\n",
      " train_loss: 838.9061,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 3716/10000,\n",
      " train_loss: 838.9060,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3717/10000,\n",
      " train_loss: 838.9060,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3718/10000,\n",
      " train_loss: 838.9060,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3719/10000,\n",
      " train_loss: 838.9060,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 3720/10000,\n",
      " train_loss: 838.9059,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3721/10000,\n",
      " train_loss: 838.9059,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3722/10000,\n",
      " train_loss: 838.9058,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3723/10000,\n",
      " train_loss: 838.9057,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3724/10000,\n",
      " train_loss: 838.9057,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3725/10000,\n",
      " train_loss: 838.9057,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3726/10000,\n",
      " train_loss: 838.9057,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3727/10000,\n",
      " train_loss: 838.9057,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3728/10000,\n",
      " train_loss: 838.9056,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3729/10000,\n",
      " train_loss: 838.9056,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3730/10000,\n",
      " train_loss: 838.9056,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3731/10000,\n",
      " train_loss: 838.9055,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3732/10000,\n",
      " train_loss: 838.9055,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3733/10000,\n",
      " train_loss: 838.9055,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3734/10000,\n",
      " train_loss: 838.9055,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3735/10000,\n",
      " train_loss: 838.9054,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3736/10000,\n",
      " train_loss: 838.9053,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3737/10000,\n",
      " train_loss: 838.9054,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3738/10000,\n",
      " train_loss: 838.9053,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3739/10000,\n",
      " train_loss: 838.9053,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3740/10000,\n",
      " train_loss: 838.9052,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3741/10000,\n",
      " train_loss: 838.9052,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3742/10000,\n",
      " train_loss: 838.9052,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3743/10000,\n",
      " train_loss: 838.9052,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3744/10000,\n",
      " train_loss: 838.9050,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3745/10000,\n",
      " train_loss: 838.9050,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 3746/10000,\n",
      " train_loss: 838.9050,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3747/10000,\n",
      " train_loss: 838.9050,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 3748/10000,\n",
      " train_loss: 838.9049,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 3749/10000,\n",
      " train_loss: 838.9049,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 3750/10000,\n",
      " train_loss: 838.9048,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3751/10000,\n",
      " train_loss: 838.9048,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3752/10000,\n",
      " train_loss: 838.9048,\n",
      " train_mae: 25.3319,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3753/10000,\n",
      " train_loss: 838.9047,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3754/10000,\n",
      " train_loss: 838.9047,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3755/10000,\n",
      " train_loss: 838.9047,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3756/10000,\n",
      " train_loss: 838.9047,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3757/10000,\n",
      " train_loss: 838.9046,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3758/10000,\n",
      " train_loss: 838.9046,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3759/10000,\n",
      " train_loss: 838.9046,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3760/10000,\n",
      " train_loss: 838.9045,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3761/10000,\n",
      " train_loss: 838.9045,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3762/10000,\n",
      " train_loss: 838.9045,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3763/10000,\n",
      " train_loss: 838.9045,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3764/10000,\n",
      " train_loss: 838.9045,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3765/10000,\n",
      " train_loss: 838.9044,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3766/10000,\n",
      " train_loss: 838.9044,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3767/10000,\n",
      " train_loss: 838.9043,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3768/10000,\n",
      " train_loss: 838.9043,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3769/10000,\n",
      " train_loss: 838.9042,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3770/10000,\n",
      " train_loss: 838.9042,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3771/10000,\n",
      " train_loss: 838.9042,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3772/10000,\n",
      " train_loss: 838.9041,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3773/10000,\n",
      " train_loss: 838.9041,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3774/10000,\n",
      " train_loss: 838.9041,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3775/10000,\n",
      " train_loss: 838.9040,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3776/10000,\n",
      " train_loss: 838.9039,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3777/10000,\n",
      " train_loss: 838.9039,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3778/10000,\n",
      " train_loss: 838.9039,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "epoch: 3779/10000,\n",
      " train_loss: 838.9039,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3780/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3781/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3782/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3783/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3784/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3785/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3786/10000,\n",
      " train_loss: 838.9037,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3787/10000,\n",
      " train_loss: 838.9036,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3788/10000,\n",
      " train_loss: 838.9036,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3789/10000,\n",
      " train_loss: 838.9036,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3790/10000,\n",
      " train_loss: 838.9035,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3791/10000,\n",
      " train_loss: 838.9034,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3792/10000,\n",
      " train_loss: 838.9034,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3793/10000,\n",
      " train_loss: 838.9034,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3794/10000,\n",
      " train_loss: 838.9033,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3795/10000,\n",
      " train_loss: 838.9033,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3796/10000,\n",
      " train_loss: 838.9033,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3797/10000,\n",
      " train_loss: 838.9033,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 3798/10000,\n",
      " train_loss: 838.9032,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3799/10000,\n",
      " train_loss: 838.9032,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 3800/10000,\n",
      " train_loss: 838.9032,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 3801/10000,\n",
      " train_loss: 838.9031,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 3802/10000,\n",
      " train_loss: 838.9031,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 3803/10000,\n",
      " train_loss: 838.9030,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3804/10000,\n",
      " train_loss: 838.9030,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3805/10000,\n",
      " train_loss: 838.9030,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3806/10000,\n",
      " train_loss: 838.9029,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 3807/10000,\n",
      " train_loss: 838.9029,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3808/10000,\n",
      " train_loss: 838.9029,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3809/10000,\n",
      " train_loss: 838.9029,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 3810/10000,\n",
      " train_loss: 838.9029,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3811/10000,\n",
      " train_loss: 838.9028,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3812/10000,\n",
      " train_loss: 838.9028,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3813/10000,\n",
      " train_loss: 838.9026,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3814/10000,\n",
      " train_loss: 838.9027,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3815/10000,\n",
      " train_loss: 838.9026,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3816/10000,\n",
      " train_loss: 838.9026,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3817/10000,\n",
      " train_loss: 838.9026,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3818/10000,\n",
      " train_loss: 838.9025,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3819/10000,\n",
      " train_loss: 838.9025,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3820/10000,\n",
      " train_loss: 838.9025,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3821/10000,\n",
      " train_loss: 838.9025,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3822/10000,\n",
      " train_loss: 838.9025,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3823/10000,\n",
      " train_loss: 838.9024,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 3824/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3825/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3826/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3827/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3828/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3829/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3830/10000,\n",
      " train_loss: 838.9023,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3831/10000,\n",
      " train_loss: 838.9022,\n",
      " train_mae: 25.3318,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3832/10000,\n",
      " train_loss: 838.9021,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3833/10000,\n",
      " train_loss: 838.9020,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3834/10000,\n",
      " train_loss: 838.9020,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3835/10000,\n",
      " train_loss: 838.9020,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3836/10000,\n",
      " train_loss: 838.9020,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3837/10000,\n",
      " train_loss: 838.9019,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3838/10000,\n",
      " train_loss: 838.9020,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3839/10000,\n",
      " train_loss: 838.9018,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3840/10000,\n",
      " train_loss: 838.9018,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 3841/10000,\n",
      " train_loss: 838.9018,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3842/10000,\n",
      " train_loss: 838.9018,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3843/10000,\n",
      " train_loss: 838.9018,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3844/10000,\n",
      " train_loss: 838.9017,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3845/10000,\n",
      " train_loss: 838.9017,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 3846/10000,\n",
      " train_loss: 838.9017,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3847/10000,\n",
      " train_loss: 838.9016,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 3848/10000,\n",
      " train_loss: 838.9016,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 3849/10000,\n",
      " train_loss: 838.9016,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3850/10000,\n",
      " train_loss: 838.9016,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3851/10000,\n",
      " train_loss: 838.9015,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 3852/10000,\n",
      " train_loss: 838.9015,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3853/10000,\n",
      " train_loss: 838.9014,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 3854/10000,\n",
      " train_loss: 838.9015,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3855/10000,\n",
      " train_loss: 838.9014,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3856/10000,\n",
      " train_loss: 838.9014,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3857/10000,\n",
      " train_loss: 838.9014,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3858/10000,\n",
      " train_loss: 838.9013,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3859/10000,\n",
      " train_loss: 838.9014,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3860/10000,\n",
      " train_loss: 838.9012,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3861/10000,\n",
      " train_loss: 838.9012,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3862/10000,\n",
      " train_loss: 838.9011,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3863/10000,\n",
      " train_loss: 838.9011,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3864/10000,\n",
      " train_loss: 838.9011,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3865/10000,\n",
      " train_loss: 838.9011,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 3866/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0087\n",
      "\n",
      "epoch: 3867/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3868/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3869/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 3870/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3871/10000,\n",
      " train_loss: 838.9008,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3872/10000,\n",
      " train_loss: 838.9009,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3873/10000,\n",
      " train_loss: 838.9008,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3874/10000,\n",
      " train_loss: 838.9008,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3875/10000,\n",
      " train_loss: 838.9007,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3876/10000,\n",
      " train_loss: 838.9007,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3877/10000,\n",
      " train_loss: 838.9007,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3878/10000,\n",
      " train_loss: 838.9006,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3879/10000,\n",
      " train_loss: 838.9006,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3880/10000,\n",
      " train_loss: 838.9006,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3881/10000,\n",
      " train_loss: 838.9006,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3882/10000,\n",
      " train_loss: 838.9006,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 3883/10000,\n",
      " train_loss: 838.9005,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3884/10000,\n",
      " train_loss: 838.9005,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 3885/10000,\n",
      " train_loss: 838.9005,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3886/10000,\n",
      " train_loss: 838.9004,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3887/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 3888/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3889/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3890/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3891/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 3892/10000,\n",
      " train_loss: 838.9003,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0134\n",
      "\n",
      "epoch: 3893/10000,\n",
      " train_loss: 838.9001,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3894/10000,\n",
      " train_loss: 838.9001,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3895/10000,\n",
      " train_loss: 838.9001,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3896/10000,\n",
      " train_loss: 838.9001,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 3897/10000,\n",
      " train_loss: 838.9000,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3898/10000,\n",
      " train_loss: 838.9000,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3899/10000,\n",
      " train_loss: 838.9000,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3900/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 3901/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3902/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3903/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3904/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3905/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3906/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3907/10000,\n",
      " train_loss: 838.8998,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3908/10000,\n",
      " train_loss: 838.8997,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3909/10000,\n",
      " train_loss: 838.8997,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3910/10000,\n",
      " train_loss: 838.8997,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3911/10000,\n",
      " train_loss: 838.8997,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3912/10000,\n",
      " train_loss: 838.8995,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3913/10000,\n",
      " train_loss: 838.8996,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3914/10000,\n",
      " train_loss: 838.8995,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3915/10000,\n",
      " train_loss: 838.8995,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3916/10000,\n",
      " train_loss: 838.8995,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3917/10000,\n",
      " train_loss: 838.8995,\n",
      " train_mae: 25.3317,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3918/10000,\n",
      " train_loss: 838.8994,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 3919/10000,\n",
      " train_loss: 838.8994,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3920/10000,\n",
      " train_loss: 838.8994,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3921/10000,\n",
      " train_loss: 838.8994,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 3922/10000,\n",
      " train_loss: 838.8993,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 3923/10000,\n",
      " train_loss: 838.8993,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3924/10000,\n",
      " train_loss: 838.8993,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3925/10000,\n",
      " train_loss: 838.8993,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3926/10000,\n",
      " train_loss: 838.8992,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3927/10000,\n",
      " train_loss: 838.8991,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3928/10000,\n",
      " train_loss: 838.8991,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3929/10000,\n",
      " train_loss: 838.8991,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3930/10000,\n",
      " train_loss: 838.8990,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3931/10000,\n",
      " train_loss: 838.8990,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 3932/10000,\n",
      " train_loss: 838.8990,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 3933/10000,\n",
      " train_loss: 838.8990,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 3934/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 3935/10000,\n",
      " train_loss: 838.8990,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3936/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3937/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3938/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3939/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3940/10000,\n",
      " train_loss: 838.8989,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3941/10000,\n",
      " train_loss: 838.8987,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3942/10000,\n",
      " train_loss: 838.8987,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3943/10000,\n",
      " train_loss: 838.8987,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 3944/10000,\n",
      " train_loss: 838.8987,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3945/10000,\n",
      " train_loss: 838.8987,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 3946/10000,\n",
      " train_loss: 838.8986,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3947/10000,\n",
      " train_loss: 838.8986,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3948/10000,\n",
      " train_loss: 838.8986,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3949/10000,\n",
      " train_loss: 838.8985,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3950/10000,\n",
      " train_loss: 838.8985,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3951/10000,\n",
      " train_loss: 838.8985,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 3952/10000,\n",
      " train_loss: 838.8985,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3953/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3954/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3955/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 3956/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "epoch: 3957/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 3958/10000,\n",
      " train_loss: 838.8984,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3959/10000,\n",
      " train_loss: 838.8982,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 3960/10000,\n",
      " train_loss: 838.8982,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3961/10000,\n",
      " train_loss: 838.8982,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3962/10000,\n",
      " train_loss: 838.8982,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 3963/10000,\n",
      " train_loss: 838.8981,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 3964/10000,\n",
      " train_loss: 838.8981,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3965/10000,\n",
      " train_loss: 838.8981,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3966/10000,\n",
      " train_loss: 838.8981,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3967/10000,\n",
      " train_loss: 838.8979,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3968/10000,\n",
      " train_loss: 838.8980,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3969/10000,\n",
      " train_loss: 838.8979,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3970/10000,\n",
      " train_loss: 838.8979,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 3971/10000,\n",
      " train_loss: 838.8979,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 3972/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 3973/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 3974/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 3975/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 3976/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 3977/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3978/10000,\n",
      " train_loss: 838.8978,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 3979/10000,\n",
      " train_loss: 838.8977,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 3980/10000,\n",
      " train_loss: 838.8977,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 3981/10000,\n",
      " train_loss: 838.8976,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3982/10000,\n",
      " train_loss: 838.8976,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 3983/10000,\n",
      " train_loss: 838.8976,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 3984/10000,\n",
      " train_loss: 838.8976,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3985/10000,\n",
      " train_loss: 838.8976,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3986/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 3987/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 3988/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 3989/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 3990/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 3991/10000,\n",
      " train_loss: 838.8975,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3992/10000,\n",
      " train_loss: 838.8974,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3993/10000,\n",
      " train_loss: 838.8973,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 3994/10000,\n",
      " train_loss: 838.8974,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 3995/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 3996/10000,\n",
      " train_loss: 838.8973,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 3997/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3998/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 3999/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4000/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4001/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4002/10000,\n",
      " train_loss: 838.8972,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4003/10000,\n",
      " train_loss: 838.8971,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4004/10000,\n",
      " train_loss: 838.8970,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4005/10000,\n",
      " train_loss: 838.8970,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4006/10000,\n",
      " train_loss: 838.8970,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4007/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4008/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4009/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4010/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4011/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4012/10000,\n",
      " train_loss: 838.8969,\n",
      " train_mae: 25.3316,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4013/10000,\n",
      " train_loss: 838.8968,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4014/10000,\n",
      " train_loss: 838.8968,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4015/10000,\n",
      " train_loss: 838.8968,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4016/10000,\n",
      " train_loss: 838.8967,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4017/10000,\n",
      " train_loss: 838.8967,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4018/10000,\n",
      " train_loss: 838.8967,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4019/10000,\n",
      " train_loss: 838.8967,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4020/10000,\n",
      " train_loss: 838.8967,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4021/10000,\n",
      " train_loss: 838.8966,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4022/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4023/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4024/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4025/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4026/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 4027/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4028/10000,\n",
      " train_loss: 838.8965,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4029/10000,\n",
      " train_loss: 838.8964,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4030/10000,\n",
      " train_loss: 838.8964,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4031/10000,\n",
      " train_loss: 838.8964,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4032/10000,\n",
      " train_loss: 838.8962,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4033/10000,\n",
      " train_loss: 838.8962,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4034/10000,\n",
      " train_loss: 838.8962,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4035/10000,\n",
      " train_loss: 838.8962,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4036/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4037/10000,\n",
      " train_loss: 838.8962,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4038/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4039/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4040/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4041/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4042/10000,\n",
      " train_loss: 838.8961,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4043/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4044/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4045/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4046/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4047/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4048/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4049/10000,\n",
      " train_loss: 838.8959,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4050/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4051/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4052/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4053/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4054/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4055/10000,\n",
      " train_loss: 838.8957,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4056/10000,\n",
      " train_loss: 838.8958,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4057/10000,\n",
      " train_loss: 838.8956,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 4058/10000,\n",
      " train_loss: 838.8956,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0138\n",
      "\n",
      "epoch: 4059/10000,\n",
      " train_loss: 838.8956,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4060/10000,\n",
      " train_loss: 838.8956,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4061/10000,\n",
      " train_loss: 838.8956,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4062/10000,\n",
      " train_loss: 838.8955,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4063/10000,\n",
      " train_loss: 838.8955,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4064/10000,\n",
      " train_loss: 838.8955,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4065/10000,\n",
      " train_loss: 838.8955,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4066/10000,\n",
      " train_loss: 838.8954,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4067/10000,\n",
      " train_loss: 838.8954,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4068/10000,\n",
      " train_loss: 838.8954,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4069/10000,\n",
      " train_loss: 838.8954,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4070/10000,\n",
      " train_loss: 838.8954,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4071/10000,\n",
      " train_loss: 838.8953,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4072/10000,\n",
      " train_loss: 838.8952,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4073/10000,\n",
      " train_loss: 838.8952,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4074/10000,\n",
      " train_loss: 838.8952,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4075/10000,\n",
      " train_loss: 838.8952,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4076/10000,\n",
      " train_loss: 838.8952,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4077/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4078/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4079/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4080/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4081/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4082/10000,\n",
      " train_loss: 838.8951,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4083/10000,\n",
      " train_loss: 838.8950,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4084/10000,\n",
      " train_loss: 838.8950,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4085/10000,\n",
      " train_loss: 838.8950,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4086/10000,\n",
      " train_loss: 838.8950,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4087/10000,\n",
      " train_loss: 838.8949,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4088/10000,\n",
      " train_loss: 838.8948,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4089/10000,\n",
      " train_loss: 838.8948,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 4090/10000,\n",
      " train_loss: 838.8948,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 4091/10000,\n",
      " train_loss: 838.8948,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4092/10000,\n",
      " train_loss: 838.8948,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4093/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4094/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0119\n",
      "\n",
      "epoch: 4095/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4096/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4097/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4098/10000,\n",
      " train_loss: 838.8947,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4099/10000,\n",
      " train_loss: 838.8946,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4100/10000,\n",
      " train_loss: 838.8946,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4101/10000,\n",
      " train_loss: 838.8946,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4102/10000,\n",
      " train_loss: 838.8946,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4103/10000,\n",
      " train_loss: 838.8945,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4104/10000,\n",
      " train_loss: 838.8945,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4105/10000,\n",
      " train_loss: 838.8945,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4106/10000,\n",
      " train_loss: 838.8945,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4107/10000,\n",
      " train_loss: 838.8945,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4108/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4109/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4110/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4111/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4112/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4113/10000,\n",
      " train_loss: 838.8943,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4114/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4115/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4116/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4117/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4118/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 4119/10000,\n",
      " train_loss: 838.8942,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4120/10000,\n",
      " train_loss: 838.8941,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4121/10000,\n",
      " train_loss: 838.8941,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4122/10000,\n",
      " train_loss: 838.8940,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4123/10000,\n",
      " train_loss: 838.8940,\n",
      " train_mae: 25.3315,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4124/10000,\n",
      " train_loss: 838.8940,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4125/10000,\n",
      " train_loss: 838.8940,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4126/10000,\n",
      " train_loss: 838.8940,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4127/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4128/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4129/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4130/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4131/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4132/10000,\n",
      " train_loss: 838.8939,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4133/10000,\n",
      " train_loss: 838.8938,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4134/10000,\n",
      " train_loss: 838.8938,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4135/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4136/10000,\n",
      " train_loss: 838.8938,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4137/10000,\n",
      " train_loss: 838.8938,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4138/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4139/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4140/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4141/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4142/10000,\n",
      " train_loss: 838.8937,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4143/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4144/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4145/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4146/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4147/10000,\n",
      " train_loss: 838.8935,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4148/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4149/10000,\n",
      " train_loss: 838.8936,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 4150/10000,\n",
      " train_loss: 838.8935,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0106\n",
      "\n",
      "epoch: 4151/10000,\n",
      " train_loss: 838.8934,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4152/10000,\n",
      " train_loss: 838.8934,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4153/10000,\n",
      " train_loss: 838.8934,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4154/10000,\n",
      " train_loss: 838.8933,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4155/10000,\n",
      " train_loss: 838.8934,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4156/10000,\n",
      " train_loss: 838.8932,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4157/10000,\n",
      " train_loss: 838.8932,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4158/10000,\n",
      " train_loss: 838.8932,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4159/10000,\n",
      " train_loss: 838.8932,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4160/10000,\n",
      " train_loss: 838.8932,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4161/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4162/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4163/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4164/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4165/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4166/10000,\n",
      " train_loss: 838.8931,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4167/10000,\n",
      " train_loss: 838.8930,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4168/10000,\n",
      " train_loss: 838.8930,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4169/10000,\n",
      " train_loss: 838.8930,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4170/10000,\n",
      " train_loss: 838.8930,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4171/10000,\n",
      " train_loss: 838.8929,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4172/10000,\n",
      " train_loss: 838.8929,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4173/10000,\n",
      " train_loss: 838.8929,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4174/10000,\n",
      " train_loss: 838.8929,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4175/10000,\n",
      " train_loss: 838.8929,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4176/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4177/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "epoch: 4178/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4179/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4180/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4181/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4182/10000,\n",
      " train_loss: 838.8928,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4183/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4184/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4185/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4186/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4187/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4188/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4189/10000,\n",
      " train_loss: 838.8926,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4190/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4191/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4192/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4193/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4194/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4195/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4196/10000,\n",
      " train_loss: 838.8925,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4197/10000,\n",
      " train_loss: 838.8923,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4198/10000,\n",
      " train_loss: 838.8923,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4199/10000,\n",
      " train_loss: 838.8923,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4200/10000,\n",
      " train_loss: 838.8923,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4201/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4202/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4203/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4204/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 4205/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4206/10000,\n",
      " train_loss: 838.8922,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 4207/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4208/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 4209/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4210/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 4211/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4212/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4213/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4214/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4215/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4216/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4217/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4218/10000,\n",
      " train_loss: 838.8920,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4219/10000,\n",
      " train_loss: 838.8919,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4220/10000,\n",
      " train_loss: 838.8918,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4221/10000,\n",
      " train_loss: 838.8918,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4222/10000,\n",
      " train_loss: 838.8918,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4223/10000,\n",
      " train_loss: 838.8918,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4224/10000,\n",
      " train_loss: 838.8918,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4225/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4226/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4227/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4228/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 4229/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4230/10000,\n",
      " train_loss: 838.8917,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4231/10000,\n",
      " train_loss: 838.8916,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4232/10000,\n",
      " train_loss: 838.8916,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4233/10000,\n",
      " train_loss: 838.8916,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 4234/10000,\n",
      " train_loss: 838.8916,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4235/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4236/10000,\n",
      " train_loss: 838.8916,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4237/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4238/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 4239/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4240/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3314,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4241/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4242/10000,\n",
      " train_loss: 838.8914,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 4243/10000,\n",
      " train_loss: 838.8915,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4244/10000,\n",
      " train_loss: 838.8914,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4245/10000,\n",
      " train_loss: 838.8913,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4246/10000,\n",
      " train_loss: 838.8913,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0137\n",
      "\n",
      "epoch: 4247/10000,\n",
      " train_loss: 838.8913,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4248/10000,\n",
      " train_loss: 838.8913,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4249/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4250/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4251/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4252/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4253/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4254/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4255/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4256/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4257/10000,\n",
      " train_loss: 838.8912,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4258/10000,\n",
      " train_loss: 838.8911,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4259/10000,\n",
      " train_loss: 838.8911,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4260/10000,\n",
      " train_loss: 838.8911,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4261/10000,\n",
      " train_loss: 838.8911,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4262/10000,\n",
      " train_loss: 838.8910,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4263/10000,\n",
      " train_loss: 838.8910,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4264/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4265/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4266/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4267/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4268/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4269/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0144\n",
      "\n",
      "epoch: 4270/10000,\n",
      " train_loss: 838.8908,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4271/10000,\n",
      " train_loss: 838.8908,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4272/10000,\n",
      " train_loss: 838.8909,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4273/10000,\n",
      " train_loss: 838.8908,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4274/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4275/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4276/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4277/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4278/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4279/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4280/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 4281/10000,\n",
      " train_loss: 838.8907,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4282/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4283/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4284/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4285/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4286/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4287/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4288/10000,\n",
      " train_loss: 838.8906,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4289/10000,\n",
      " train_loss: 838.8904,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4290/10000,\n",
      " train_loss: 838.8904,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4291/10000,\n",
      " train_loss: 838.8904,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4292/10000,\n",
      " train_loss: 838.8904,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4293/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4294/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4295/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4296/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4297/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4298/10000,\n",
      " train_loss: 838.8903,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4299/10000,\n",
      " train_loss: 838.8902,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4300/10000,\n",
      " train_loss: 838.8902,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 4301/10000,\n",
      " train_loss: 838.8902,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "epoch: 4302/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4303/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4304/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4305/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4306/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4307/10000,\n",
      " train_loss: 838.8901,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4308/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4309/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4310/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4311/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4312/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4313/10000,\n",
      " train_loss: 838.8900,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4314/10000,\n",
      " train_loss: 838.8899,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4315/10000,\n",
      " train_loss: 838.8899,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4316/10000,\n",
      " train_loss: 838.8899,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4317/10000,\n",
      " train_loss: 838.8899,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4318/10000,\n",
      " train_loss: 838.8899,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4319/10000,\n",
      " train_loss: 838.8898,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4320/10000,\n",
      " train_loss: 838.8898,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4321/10000,\n",
      " train_loss: 838.8898,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4322/10000,\n",
      " train_loss: 838.8898,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4323/10000,\n",
      " train_loss: 838.8898,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4324/10000,\n",
      " train_loss: 838.8897,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4325/10000,\n",
      " train_loss: 838.8897,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4326/10000,\n",
      " train_loss: 838.8897,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 4327/10000,\n",
      " train_loss: 838.8897,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4328/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4329/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4330/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4331/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4332/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4333/10000,\n",
      " train_loss: 838.8896,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4334/10000,\n",
      " train_loss: 838.8895,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 4335/10000,\n",
      " train_loss: 838.8895,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "epoch: 4336/10000,\n",
      " train_loss: 838.8895,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4337/10000,\n",
      " train_loss: 838.8895,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4338/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4339/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4340/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4341/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4342/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4343/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4344/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4345/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4346/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4347/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4348/10000,\n",
      " train_loss: 838.8893,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4349/10000,\n",
      " train_loss: 838.8892,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4350/10000,\n",
      " train_loss: 838.8892,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4351/10000,\n",
      " train_loss: 838.8892,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4352/10000,\n",
      " train_loss: 838.8892,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4353/10000,\n",
      " train_loss: 838.8892,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4354/10000,\n",
      " train_loss: 838.8891,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4355/10000,\n",
      " train_loss: 838.8891,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4356/10000,\n",
      " train_loss: 838.8891,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 4357/10000,\n",
      " train_loss: 838.8891,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4358/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4359/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4360/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4361/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4362/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4363/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4364/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4365/10000,\n",
      " train_loss: 838.8890,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4366/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "epoch: 4367/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4368/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4369/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4370/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4371/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4372/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4373/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4374/10000,\n",
      " train_loss: 838.8889,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4375/10000,\n",
      " train_loss: 838.8888,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4376/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3313,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4377/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4378/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4379/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4380/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4381/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4382/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4383/10000,\n",
      " train_loss: 838.8887,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4384/10000,\n",
      " train_loss: 838.8886,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4385/10000,\n",
      " train_loss: 838.8886,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4386/10000,\n",
      " train_loss: 838.8886,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4387/10000,\n",
      " train_loss: 838.8886,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4388/10000,\n",
      " train_loss: 838.8885,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 4389/10000,\n",
      " train_loss: 838.8886,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 4390/10000,\n",
      " train_loss: 838.8885,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4391/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4392/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4393/10000,\n",
      " train_loss: 838.8885,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4394/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4395/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4396/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4397/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4398/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0133\n",
      "\n",
      "epoch: 4399/10000,\n",
      " train_loss: 838.8884,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0134\n",
      "\n",
      "epoch: 4400/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4401/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 4402/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "epoch: 4403/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0086\n",
      "\n",
      "epoch: 4404/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4405/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 4406/10000,\n",
      " train_loss: 838.8883,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4407/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4408/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4409/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4410/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4411/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4412/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4413/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4414/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4415/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4416/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4417/10000,\n",
      " train_loss: 838.8881,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4418/10000,\n",
      " train_loss: 838.8880,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4419/10000,\n",
      " train_loss: 838.8880,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4420/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4421/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4422/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "epoch: 4423/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0094\n",
      "\n",
      "epoch: 4424/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4425/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4426/10000,\n",
      " train_loss: 838.8879,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4427/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4428/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4429/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4430/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4431/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4432/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4433/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4434/10000,\n",
      " train_loss: 838.8878,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4435/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4436/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4437/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4438/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4439/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4440/10000,\n",
      " train_loss: 838.8877,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4441/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4442/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4443/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4444/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4445/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4446/10000,\n",
      " train_loss: 838.8875,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4447/10000,\n",
      " train_loss: 838.8875,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4448/10000,\n",
      " train_loss: 838.8876,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4449/10000,\n",
      " train_loss: 838.8875,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "epoch: 4450/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4451/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4452/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0087\n",
      "\n",
      "epoch: 4453/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 4454/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4455/10000,\n",
      " train_loss: 838.8874,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4456/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4457/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4458/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4459/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4460/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4461/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4462/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4463/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4464/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4465/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4466/10000,\n",
      " train_loss: 838.8873,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4467/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4468/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4469/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4470/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4471/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4472/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4473/10000,\n",
      " train_loss: 838.8871,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4474/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4475/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4476/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4477/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4478/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4479/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4480/10000,\n",
      " train_loss: 838.8870,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4481/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4482/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4483/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4484/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4485/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4486/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0118\n",
      "\n",
      "epoch: 4487/10000,\n",
      " train_loss: 838.8869,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0149\n",
      "\n",
      "epoch: 4488/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4489/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4490/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4491/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4492/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4493/10000,\n",
      " train_loss: 838.8868,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4494/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4495/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4496/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4497/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4498/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4499/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4500/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4501/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4502/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4503/10000,\n",
      " train_loss: 838.8867,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4504/10000,\n",
      " train_loss: 838.8866,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4505/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4506/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4507/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4508/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4509/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4510/10000,\n",
      " train_loss: 838.8865,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4511/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4512/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4513/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4514/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4515/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4516/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4517/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0102\n",
      "\n",
      "epoch: 4518/10000,\n",
      " train_loss: 838.8864,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0120\n",
      "\n",
      "epoch: 4519/10000,\n",
      " train_loss: 838.8863,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4520/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4521/10000,\n",
      " train_loss: 838.8863,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4522/10000,\n",
      " train_loss: 838.8863,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4523/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4524/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4525/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4526/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4527/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4528/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4529/10000,\n",
      " train_loss: 838.8862,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4530/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4531/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3312,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4532/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4533/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4534/10000,\n",
      " train_loss: 838.8861,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4535/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4536/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4537/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4538/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4539/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4540/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 4541/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4542/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4543/10000,\n",
      " train_loss: 838.8860,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4544/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4545/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4546/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4547/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "epoch: 4548/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4549/10000,\n",
      " train_loss: 838.8858,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4550/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4551/10000,\n",
      " train_loss: 838.8859,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4552/10000,\n",
      " train_loss: 838.8858,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4553/10000,\n",
      " train_loss: 838.8858,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4554/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4555/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4556/10000,\n",
      " train_loss: 838.8858,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4557/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4558/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4559/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4560/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4561/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4562/10000,\n",
      " train_loss: 838.8856,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4563/10000,\n",
      " train_loss: 838.8856,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4564/10000,\n",
      " train_loss: 838.8857,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4565/10000,\n",
      " train_loss: 838.8856,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4566/10000,\n",
      " train_loss: 838.8856,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4567/10000,\n",
      " train_loss: 838.8855,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4568/10000,\n",
      " train_loss: 838.8856,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4569/10000,\n",
      " train_loss: 838.8855,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4570/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4571/10000,\n",
      " train_loss: 838.8855,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0116\n",
      "\n",
      "epoch: 4572/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4573/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4574/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4575/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4576/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4577/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4578/10000,\n",
      " train_loss: 838.8854,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4579/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4580/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4581/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4582/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4583/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 4584/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4585/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 4586/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4587/10000,\n",
      " train_loss: 838.8852,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4588/10000,\n",
      " train_loss: 838.8853,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4589/10000,\n",
      " train_loss: 838.8852,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4590/10000,\n",
      " train_loss: 838.8852,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4591/10000,\n",
      " train_loss: 838.8852,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4592/10000,\n",
      " train_loss: 838.8852,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4593/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4594/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4595/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4596/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4597/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4598/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4599/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4600/10000,\n",
      " train_loss: 838.8851,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4601/10000,\n",
      " train_loss: 838.8850,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4602/10000,\n",
      " train_loss: 838.8850,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4603/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4604/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 4605/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4606/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4607/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4608/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4609/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4610/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4611/10000,\n",
      " train_loss: 838.8849,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4612/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4613/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4614/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4615/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4616/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4617/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4618/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4619/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4620/10000,\n",
      " train_loss: 838.8848,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4621/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4622/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4623/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4624/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4625/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4626/10000,\n",
      " train_loss: 838.8847,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4627/10000,\n",
      " train_loss: 838.8846,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4628/10000,\n",
      " train_loss: 838.8846,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4629/10000,\n",
      " train_loss: 838.8846,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4630/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4631/10000,\n",
      " train_loss: 838.8846,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4632/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4633/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4634/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4635/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 4636/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4637/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 4638/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4639/10000,\n",
      " train_loss: 838.8845,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4640/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4641/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 4642/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4643/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 4644/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4645/10000,\n",
      " train_loss: 838.8843,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4646/10000,\n",
      " train_loss: 838.8843,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4647/10000,\n",
      " train_loss: 838.8844,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4648/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4649/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4650/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4651/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4652/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4653/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4654/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4655/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4656/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4657/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4658/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4659/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4660/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4661/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4662/10000,\n",
      " train_loss: 838.8841,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4663/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 4664/10000,\n",
      " train_loss: 838.8842,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4665/10000,\n",
      " train_loss: 838.8841,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 4666/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4667/10000,\n",
      " train_loss: 838.8841,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4668/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4669/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4670/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4671/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4672/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4673/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4674/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4675/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4676/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4677/10000,\n",
      " train_loss: 838.8840,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4678/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4679/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4680/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4681/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4682/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4683/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4684/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4685/10000,\n",
      " train_loss: 838.8839,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4686/10000,\n",
      " train_loss: 838.8838,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4687/10000,\n",
      " train_loss: 838.8838,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4688/10000,\n",
      " train_loss: 838.8838,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4689/10000,\n",
      " train_loss: 838.8838,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4690/10000,\n",
      " train_loss: 838.8838,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4691/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 4692/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4693/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4694/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4695/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4696/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4697/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4698/10000,\n",
      " train_loss: 838.8837,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4699/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4700/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4701/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4702/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4703/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4704/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 4705/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 4706/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4707/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4708/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4709/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4710/10000,\n",
      " train_loss: 838.8835,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4711/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4712/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3311,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4713/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4714/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4715/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4716/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4717/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4718/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 4719/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4720/10000,\n",
      " train_loss: 838.8834,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4721/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4722/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4723/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4724/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4725/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 4726/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4727/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4728/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4729/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4730/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4731/10000,\n",
      " train_loss: 838.8832,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4732/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4733/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 4734/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 4735/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4736/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4737/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4738/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4739/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4740/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4741/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4742/10000,\n",
      " train_loss: 838.8831,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4743/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4744/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4745/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4746/10000,\n",
      " train_loss: 838.8830,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4747/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4748/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4749/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 4750/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4751/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4752/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4753/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4754/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4755/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4756/10000,\n",
      " train_loss: 838.8829,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4757/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4758/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4759/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4760/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4761/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4762/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4763/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4764/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4765/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4766/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4767/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4768/10000,\n",
      " train_loss: 838.8828,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4769/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4770/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4771/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4772/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4773/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4774/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4775/10000,\n",
      " train_loss: 838.8826,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4776/10000,\n",
      " train_loss: 838.8825,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4777/10000,\n",
      " train_loss: 838.8825,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4778/10000,\n",
      " train_loss: 838.8825,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4779/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4780/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4781/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 4782/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0183\n",
      "\n",
      "epoch: 4783/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 4784/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4785/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4786/10000,\n",
      " train_loss: 838.8824,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 4787/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4788/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 4789/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4790/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 4791/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0082\n",
      "\n",
      "epoch: 4792/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4793/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4794/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4795/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4796/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4797/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4798/10000,\n",
      " train_loss: 838.8823,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4799/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4800/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4801/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4802/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4803/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4804/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4805/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4806/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4807/10000,\n",
      " train_loss: 838.8822,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4808/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 4809/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0107\n",
      "\n",
      "epoch: 4810/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4811/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 4812/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "epoch: 4813/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 4814/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0216\n",
      "\n",
      "epoch: 4815/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "epoch: 4816/10000,\n",
      " train_loss: 838.8821,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4817/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4818/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0088\n",
      "\n",
      "epoch: 4819/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 4820/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4821/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4822/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4823/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4824/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4825/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4826/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4827/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4828/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0091\n",
      "\n",
      "epoch: 4829/10000,\n",
      " train_loss: 838.8819,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 4830/10000,\n",
      " train_loss: 838.8819,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4831/10000,\n",
      " train_loss: 838.8820,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 4832/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4833/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4834/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4835/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4836/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4837/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4838/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4839/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 4840/10000,\n",
      " train_loss: 838.8818,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4841/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4842/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4843/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 4844/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4845/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 4846/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4847/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4848/10000,\n",
      " train_loss: 838.8817,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4849/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 4850/10000,\n",
      " train_loss: 838.8816,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4851/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 4852/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4853/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4854/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4855/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4856/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4857/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0147\n",
      "\n",
      "epoch: 4858/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4859/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4860/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4861/10000,\n",
      " train_loss: 838.8815,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4862/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4863/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4864/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4865/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4866/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4867/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4868/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4869/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4870/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4871/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4872/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4873/10000,\n",
      " train_loss: 838.8814,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4874/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4875/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4876/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4877/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4878/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4879/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4880/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4881/10000,\n",
      " train_loss: 838.8813,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4882/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0096\n",
      "\n",
      "epoch: 4883/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0101\n",
      "\n",
      "epoch: 4884/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 4885/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4886/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4887/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4888/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4889/10000,\n",
      " train_loss: 838.8812,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4890/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4891/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4892/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4893/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4894/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4895/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4896/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4897/10000,\n",
      " train_loss: 838.8811,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4898/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4899/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4900/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 4901/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4902/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4903/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4904/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4905/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4906/10000,\n",
      " train_loss: 838.8810,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4907/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4908/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4909/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4910/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4911/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 4912/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4913/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4914/10000,\n",
      " train_loss: 838.8809,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 4915/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 4916/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4917/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 4918/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4919/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4920/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4921/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4922/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4923/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4924/10000,\n",
      " train_loss: 838.8807,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4925/10000,\n",
      " train_loss: 838.8808,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4926/10000,\n",
      " train_loss: 838.8807,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4927/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4928/10000,\n",
      " train_loss: 838.8807,\n",
      " train_mae: 25.3310,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4929/10000,\n",
      " train_loss: 838.8807,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4930/10000,\n",
      " train_loss: 838.8807,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4931/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4932/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 4933/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4934/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4935/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 4936/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4937/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 4938/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4939/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 4940/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0117\n",
      "\n",
      "epoch: 4941/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0142\n",
      "\n",
      "epoch: 4942/10000,\n",
      " train_loss: 838.8806,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 4943/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 4944/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0092\n",
      "\n",
      "epoch: 4945/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0115\n",
      "\n",
      "epoch: 4946/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 4947/10000,\n",
      " train_loss: 838.8805,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "epoch: 4948/10000,\n",
      " train_loss: 838.8804,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 4949/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 4950/10000,\n",
      " train_loss: 838.8804,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4951/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4952/10000,\n",
      " train_loss: 838.8804,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 4953/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4954/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4955/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4956/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4957/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 4958/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4959/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4960/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 4961/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4962/10000,\n",
      " train_loss: 838.8803,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4963/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4964/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4965/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4966/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4967/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 4968/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 4969/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 4970/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 4971/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 4972/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4973/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 4974/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 4975/10000,\n",
      " train_loss: 838.8802,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 4976/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 4977/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4978/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 4979/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 4980/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 4981/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 4982/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4983/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4984/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4985/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 4986/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 4987/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 4988/10000,\n",
      " train_loss: 838.8801,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 4989/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 4990/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4991/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4992/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 4993/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 4994/10000,\n",
      " train_loss: 838.8800,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4995/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 4996/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4997/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 4998/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 4999/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5000/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5001/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5002/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5003/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 5004/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5005/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5006/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5007/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5008/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5009/10000,\n",
      " train_loss: 838.8799,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5010/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5011/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "epoch: 5012/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5013/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5014/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5015/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5016/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5017/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5018/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5019/10000,\n",
      " train_loss: 838.8798,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5020/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5021/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5022/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5023/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5024/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5025/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5026/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5027/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5028/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5029/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5030/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5031/10000,\n",
      " train_loss: 838.8796,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5032/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5033/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5034/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5035/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0127\n",
      "\n",
      "epoch: 5036/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5037/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5038/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5039/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5040/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5041/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5042/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5043/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5044/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5045/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5046/10000,\n",
      " train_loss: 838.8795,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5047/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5048/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5049/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5050/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5051/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5052/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5053/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5054/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5055/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5056/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5057/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5058/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5059/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5060/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5061/10000,\n",
      " train_loss: 838.8793,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0110\n",
      "\n",
      "epoch: 5062/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 5063/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5064/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5065/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5066/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5067/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5068/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5069/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5070/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5071/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5072/10000,\n",
      " train_loss: 838.8792,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5073/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5074/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5075/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5076/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5077/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5078/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5079/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5080/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5081/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5082/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5083/10000,\n",
      " train_loss: 838.8791,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5084/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5085/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5086/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5087/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5088/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5089/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5090/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5091/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5092/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5093/10000,\n",
      " train_loss: 838.8790,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 5094/10000,\n",
      " train_loss: 838.8789,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5095/10000,\n",
      " train_loss: 838.8789,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5096/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5097/10000,\n",
      " train_loss: 838.8789,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5098/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5099/10000,\n",
      " train_loss: 838.8789,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5100/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5101/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5102/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5103/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5104/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5105/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5106/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5107/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5108/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5109/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5110/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5111/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5112/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5113/10000,\n",
      " train_loss: 838.8788,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5114/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 5115/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5116/10000,\n",
      " train_loss: 838.8786,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5117/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0108\n",
      "\n",
      "epoch: 5118/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0125\n",
      "\n",
      "epoch: 5119/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5120/10000,\n",
      " train_loss: 838.8787,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5121/10000,\n",
      " train_loss: 838.8786,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5122/10000,\n",
      " train_loss: 838.8786,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5123/10000,\n",
      " train_loss: 838.8786,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5124/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5125/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5126/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5127/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5128/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5129/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5130/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5131/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5132/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5133/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5134/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5135/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5136/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5137/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5138/10000,\n",
      " train_loss: 838.8785,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5139/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5140/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5141/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5142/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5143/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5144/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5145/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5146/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5147/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "epoch: 5148/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 5149/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0143\n",
      "\n",
      "epoch: 5150/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5151/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5152/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5153/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5154/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5155/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5156/10000,\n",
      " train_loss: 838.8784,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5157/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5158/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5159/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5160/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5161/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5162/10000,\n",
      " train_loss: 838.8783,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5163/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5164/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5165/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5166/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5167/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5168/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5169/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5170/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5171/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5172/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5173/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5174/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5175/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5176/10000,\n",
      " train_loss: 838.8782,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5177/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5178/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5179/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5180/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0164\n",
      "\n",
      "epoch: 5181/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5182/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5183/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3309,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5184/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0109\n",
      "\n",
      "epoch: 5185/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5186/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 5187/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5188/10000,\n",
      " train_loss: 838.8781,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5189/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5190/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5191/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5192/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5193/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5194/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5195/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5196/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5197/10000,\n",
      " train_loss: 838.8780,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5198/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5199/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5200/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5201/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5202/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5203/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5204/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5205/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5206/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5207/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5208/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0113\n",
      "\n",
      "epoch: 5209/10000,\n",
      " train_loss: 838.8779,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5210/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5211/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5212/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5213/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5214/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5215/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5216/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5217/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5218/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5219/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5220/10000,\n",
      " train_loss: 838.8777,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5221/10000,\n",
      " train_loss: 838.8777,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5222/10000,\n",
      " train_loss: 838.8778,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5223/10000,\n",
      " train_loss: 838.8777,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5224/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 5225/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5226/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5227/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5228/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5229/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5230/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5231/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0133\n",
      "\n",
      "epoch: 5232/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5233/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5234/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5235/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5236/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5237/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5238/10000,\n",
      " train_loss: 838.8776,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5239/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5240/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5241/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5242/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5243/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5244/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5245/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5246/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5247/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5248/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5249/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5250/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5251/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5252/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5253/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5254/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5255/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5256/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5257/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5258/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5259/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5260/10000,\n",
      " train_loss: 838.8775,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5261/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5262/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5263/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5264/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5265/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5266/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5267/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5268/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5269/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5270/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5271/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5272/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5273/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5274/10000,\n",
      " train_loss: 838.8774,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5275/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5276/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5277/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5278/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5279/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5280/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5281/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5282/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5283/10000,\n",
      " train_loss: 838.8772,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5284/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5285/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5286/10000,\n",
      " train_loss: 838.8773,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5287/10000,\n",
      " train_loss: 838.8772,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5288/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5289/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 5290/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5291/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 5292/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5293/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5294/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 5295/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "epoch: 5296/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 5297/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5298/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5299/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5300/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5301/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5302/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5303/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5304/10000,\n",
      " train_loss: 838.8771,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5305/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5306/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5307/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5308/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5309/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5310/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5311/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5312/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5313/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5314/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5315/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5316/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5317/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5318/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5319/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5320/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5321/10000,\n",
      " train_loss: 838.8770,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5322/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5323/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5324/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5325/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5326/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5327/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5328/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5329/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5330/10000,\n",
      " train_loss: 838.8769,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 5331/10000,\n",
      " train_loss: 838.8768,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5332/10000,\n",
      " train_loss: 838.8768,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5333/10000,\n",
      " train_loss: 838.8768,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5334/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5335/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5336/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 5337/10000,\n",
      " train_loss: 838.8768,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5338/10000,\n",
      " train_loss: 838.8768,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5339/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5340/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5341/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5342/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5343/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5344/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5345/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5346/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5347/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5348/10000,\n",
      " train_loss: 838.8767,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5349/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5350/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5351/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5352/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5353/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5354/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5355/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5356/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5357/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5358/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5359/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 5360/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5361/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5362/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5363/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5364/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5365/10000,\n",
      " train_loss: 838.8766,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5366/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 5367/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5368/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5369/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5370/10000,\n",
      " train_loss: 838.8765,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5371/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5372/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5373/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5374/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5375/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5376/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5377/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5378/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5379/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5380/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5381/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5382/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5383/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5384/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5385/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5386/10000,\n",
      " train_loss: 838.8764,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5387/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5388/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5389/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5390/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5391/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5392/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5393/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5394/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5395/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5396/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5397/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5398/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0083\n",
      "\n",
      "epoch: 5399/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0080\n",
      "\n",
      "epoch: 5400/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5401/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5402/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5403/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5404/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5405/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5406/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5407/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5408/10000,\n",
      " train_loss: 838.8763,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5409/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5410/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5411/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5412/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5413/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5414/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5415/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5416/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5417/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5418/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5419/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5420/10000,\n",
      " train_loss: 838.8762,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5421/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5422/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5423/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5424/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0130\n",
      "\n",
      "epoch: 5425/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 5426/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5427/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5428/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5429/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5430/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5431/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5432/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5433/10000,\n",
      " train_loss: 838.8761,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5434/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5435/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5436/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5437/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5438/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5439/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5440/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5441/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5442/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5443/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5444/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5445/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5446/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5447/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5448/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5449/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5450/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5451/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5452/10000,\n",
      " train_loss: 838.8760,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5453/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0131\n",
      "\n",
      "epoch: 5454/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0119\n",
      "\n",
      "epoch: 5455/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0122\n",
      "\n",
      "epoch: 5456/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5457/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5458/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5459/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5460/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5461/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5462/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5463/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5464/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5465/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5466/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5467/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5468/10000,\n",
      " train_loss: 838.8759,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5469/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5470/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5471/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5472/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5473/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5474/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5475/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5476/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5477/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5478/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5479/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5480/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5481/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5482/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5483/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 5484/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 5485/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5486/10000,\n",
      " train_loss: 838.8757,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5487/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5488/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5489/10000,\n",
      " train_loss: 838.8756,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5490/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5491/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5492/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5493/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5494/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5495/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5496/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5497/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5498/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5499/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5500/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5501/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5502/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5503/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5504/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5505/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5506/10000,\n",
      " train_loss: 838.8755,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5507/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 5508/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5509/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5510/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5511/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5512/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5513/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5514/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5515/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5516/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5517/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5518/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5519/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5520/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5521/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5522/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5523/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3308,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5524/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5525/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5526/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5527/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5528/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5529/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 5530/10000,\n",
      " train_loss: 838.8754,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 5531/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5532/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5533/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5534/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5535/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 5536/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 5537/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5538/10000,\n",
      " train_loss: 838.8753,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5539/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5540/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5541/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5542/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5543/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5544/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5545/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5546/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5547/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5548/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5549/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5550/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5551/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5552/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5553/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5554/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5555/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5556/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5557/10000,\n",
      " train_loss: 838.8752,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5558/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5559/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5560/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5561/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5562/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5563/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5564/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5565/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 5566/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0099\n",
      "\n",
      "epoch: 5567/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5568/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5569/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5570/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5571/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5572/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5573/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5574/10000,\n",
      " train_loss: 838.8750,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5575/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5576/10000,\n",
      " train_loss: 838.8750,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5577/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5578/10000,\n",
      " train_loss: 838.8750,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5579/10000,\n",
      " train_loss: 838.8750,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5580/10000,\n",
      " train_loss: 838.8750,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5581/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5582/10000,\n",
      " train_loss: 838.8751,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5583/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5584/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5585/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5586/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5587/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5588/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5589/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5590/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5591/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5592/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5593/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5594/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5595/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 5596/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0078\n",
      "\n",
      "epoch: 5597/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5598/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0187\n",
      "\n",
      "epoch: 5599/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5600/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5601/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5602/10000,\n",
      " train_loss: 838.8749,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5603/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5604/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5605/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 5606/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5607/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5608/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5609/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5610/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5611/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5612/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5613/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5614/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5615/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5616/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5617/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5618/10000,\n",
      " train_loss: 838.8748,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5619/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5620/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5621/10000,\n",
      " train_loss: 838.8747,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5622/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5623/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0100\n",
      "\n",
      "epoch: 5624/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5625/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 5626/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5627/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5628/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5629/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5630/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5631/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5632/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5633/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5634/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5635/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5636/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5637/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5638/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5639/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5640/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5641/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5642/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5643/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5644/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5645/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5646/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5647/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5648/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5649/10000,\n",
      " train_loss: 838.8746,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 5650/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5651/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5652/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5653/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5654/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5655/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5656/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5657/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5658/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5659/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5660/10000,\n",
      " train_loss: 838.8745,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5661/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5662/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5663/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5664/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5665/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5666/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5667/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5668/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5669/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5670/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5671/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5672/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5673/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5674/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5675/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5676/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5677/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5678/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5679/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5680/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5681/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5682/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5683/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 5684/10000,\n",
      " train_loss: 838.8744,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0097\n",
      "\n",
      "epoch: 5685/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5686/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5687/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5688/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5689/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5690/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5691/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5692/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5693/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5694/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5695/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5696/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5697/10000,\n",
      " train_loss: 838.8743,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5698/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5699/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5700/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5701/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5702/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5703/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5704/10000,\n",
      " train_loss: 838.8742,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5705/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5706/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5707/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5708/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5709/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5710/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5711/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5712/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0123\n",
      "\n",
      "epoch: 5713/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5714/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5715/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5716/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5717/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5718/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5719/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5720/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5721/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5722/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5723/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5724/10000,\n",
      " train_loss: 838.8741,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5725/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5726/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5727/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5728/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5729/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5730/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5731/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5732/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5733/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5734/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5735/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5736/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5737/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5738/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5739/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5740/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 5741/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5742/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5743/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5744/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5745/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5746/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5747/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5748/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5749/10000,\n",
      " train_loss: 838.8740,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5750/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5751/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5752/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5753/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5754/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5755/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5756/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5757/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5758/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5759/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5760/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5761/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5762/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5763/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5764/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 5765/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 5766/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5767/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5768/10000,\n",
      " train_loss: 838.8739,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5769/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5770/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5771/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0085\n",
      "\n",
      "epoch: 5772/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5773/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5774/10000,\n",
      " train_loss: 838.8738,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5775/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5776/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5777/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5778/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5779/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5780/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5781/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5782/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5783/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5784/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5785/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5786/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5787/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5788/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5789/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5790/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5791/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5792/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0093\n",
      "\n",
      "epoch: 5793/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5794/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5795/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5796/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5797/10000,\n",
      " train_loss: 838.8737,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 5798/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5799/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5800/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5801/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5802/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5803/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5804/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5805/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5806/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5807/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5808/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5809/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5810/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5811/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5812/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5813/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5814/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5815/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5816/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0124\n",
      "\n",
      "epoch: 5817/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 5818/10000,\n",
      " train_loss: 838.8736,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5819/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5820/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5821/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5822/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5823/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5824/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5825/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5826/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5827/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5828/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5829/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 5830/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5831/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5832/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5833/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 5834/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5835/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5836/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 5837/10000,\n",
      " train_loss: 838.8735,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0189\n",
      "\n",
      "epoch: 5838/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5839/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5840/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5841/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5842/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5843/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5844/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5845/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5846/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5847/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5848/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5849/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5850/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5851/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5852/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5853/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5854/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5855/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5856/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5857/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5858/10000,\n",
      " train_loss: 838.8734,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5859/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5860/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5861/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5862/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5863/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5864/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5865/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5866/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5867/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 5868/10000,\n",
      " train_loss: 838.8733,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0128\n",
      "\n",
      "epoch: 5869/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 5870/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 5871/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5872/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5873/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 5874/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5875/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5876/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5877/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 5878/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5879/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5880/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5881/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5882/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5883/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5884/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5885/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5886/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5887/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5888/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5889/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5890/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5891/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5892/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5893/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5894/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5895/10000,\n",
      " train_loss: 838.8732,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5896/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 5897/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 5898/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5899/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0104\n",
      "\n",
      "epoch: 5900/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5901/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5902/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5903/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0084\n",
      "\n",
      "epoch: 5904/10000,\n",
      " train_loss: 838.8731,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5905/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 5906/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5907/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5908/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5909/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5910/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5911/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5912/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5913/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0060\n",
      "\n",
      "epoch: 5914/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5915/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 5916/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5917/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5918/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5919/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5920/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5921/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5922/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5923/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 5924/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5925/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5926/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5927/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 5928/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0105\n",
      "\n",
      "epoch: 5929/10000,\n",
      " train_loss: 838.8730,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5930/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5931/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5932/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5933/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5934/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 5935/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5936/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5937/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5938/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5939/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5940/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5941/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5942/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5943/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5944/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 5945/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5946/10000,\n",
      " train_loss: 838.8729,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 5947/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5948/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5949/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 5950/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5951/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 5952/10000,\n",
      " train_loss: 838.8728,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0074\n",
      "\n",
      "epoch: 5953/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0066\n",
      "\n",
      "epoch: 5954/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5955/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5956/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5957/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 5958/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 5959/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 5960/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 5961/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 5962/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5963/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5964/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5965/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5966/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5967/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 5968/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 5969/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5970/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 5971/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 5972/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 5973/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 5974/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5975/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5976/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5977/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5978/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 5979/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5980/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5981/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5982/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 5983/10000,\n",
      " train_loss: 838.8727,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5984/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 5985/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0089\n",
      "\n",
      "epoch: 5986/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0073\n",
      "\n",
      "epoch: 5987/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5988/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0075\n",
      "\n",
      "epoch: 5989/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 5990/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 5991/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 5992/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 5993/10000,\n",
      " train_loss: 838.8726,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 5994/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 5995/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5996/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 5997/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 5998/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 5999/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 6000/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 6001/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3307,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 6002/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 6003/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 6004/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 6005/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6006/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6007/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6008/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6009/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6010/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 6011/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 6012/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6013/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 6014/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6015/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6016/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 6017/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 6018/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0131\n",
      "\n",
      "epoch: 6019/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 6020/10000,\n",
      " train_loss: 838.8725,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 6021/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 6022/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 6023/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 6024/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6025/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6026/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6027/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 6028/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6029/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6030/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6031/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6032/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6033/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6034/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 6035/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 6036/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 6037/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 6038/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 6039/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 6040/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 6041/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 6042/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 6043/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 6044/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 6045/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0201\n",
      "\n",
      "epoch: 6046/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0103\n",
      "\n",
      "epoch: 6047/10000,\n",
      " train_loss: 838.8724,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 6048/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0062\n",
      "\n",
      "epoch: 6049/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 6050/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 6051/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 6052/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 6053/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 6054/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 6055/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 6056/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 6057/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6058/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6059/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6060/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 6061/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6062/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6063/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 6064/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6065/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 6066/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0026\n",
      "\n",
      "epoch: 6067/10000,\n",
      " train_loss: 838.8723,\n",
      " train_mae: 25.3306,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6068/10000,\n",
      " train_loss: 838.8688,\n",
      " train_mae: 25.3305,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6069/10000,\n",
      " train_loss: 838.8673,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 6070/10000,\n",
      " train_loss: 838.8661,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6071/10000,\n",
      " train_loss: 838.8655,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 6072/10000,\n",
      " train_loss: 838.8653,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 6073/10000,\n",
      " train_loss: 838.8653,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 6074/10000,\n",
      " train_loss: 838.8652,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 6075/10000,\n",
      " train_loss: 838.8652,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 6076/10000,\n",
      " train_loss: 838.8654,\n",
      " train_mae: 25.3304,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 6077/10000,\n",
      " train_loss: 838.8666,\n",
      " train_mae: 25.3437,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 6078/10000,\n",
      " train_loss: 839.5973,\n",
      " train_mae: 26.0474,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "early stopping activated\n",
      "== end training ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(5378.2949),\n",
       "  tensor(4373.0112),\n",
       "  tensor(3608.8101),\n",
       "  tensor(2933.8242),\n",
       "  tensor(2374.7063),\n",
       "  tensor(1913.9542),\n",
       "  tensor(1548.0836),\n",
       "  tensor(1272.1437),\n",
       "  tensor(1079.2406),\n",
       "  tensor(960.4120),\n",
       "  tensor(904.7333),\n",
       "  tensor(899.6686),\n",
       "  tensor(931.6901),\n",
       "  tensor(987.1213),\n",
       "  tensor(1053.0928),\n",
       "  tensor(1118.4487),\n",
       "  tensor(1174.4438),\n",
       "  tensor(1215.1248),\n",
       "  tensor(1237.3660),\n",
       "  tensor(1240.6007),\n",
       "  tensor(1226.3479),\n",
       "  tensor(1197.6333),\n",
       "  tensor(1158.4042),\n",
       "  tensor(1112.9894),\n",
       "  tensor(1065.6417),\n",
       "  tensor(1020.1714),\n",
       "  tensor(979.6805),\n",
       "  tensor(946.3939),\n",
       "  tensor(921.5851),\n",
       "  tensor(905.5898),\n",
       "  tensor(897.8991),\n",
       "  tensor(897.3178),\n",
       "  tensor(902.1699),\n",
       "  tensor(910.5287),\n",
       "  tensor(920.4459),\n",
       "  tensor(930.1548),\n",
       "  tensor(938.2309),\n",
       "  tensor(943.6913),\n",
       "  tensor(946.0344),\n",
       "  tensor(945.2186),\n",
       "  tensor(941.5944),\n",
       "  tensor(935.8018),\n",
       "  tensor(928.6495),\n",
       "  tensor(920.9962),\n",
       "  tensor(913.6401),\n",
       "  tensor(907.2347),\n",
       "  tensor(902.2318),\n",
       "  tensor(898.8561),\n",
       "  tensor(897.1130),\n",
       "  tensor(896.8178),\n",
       "  tensor(897.6477),\n",
       "  tensor(899.2006),\n",
       "  tensor(901.0580),\n",
       "  tensor(902.8398),\n",
       "  tensor(904.2454),\n",
       "  tensor(905.0812),\n",
       "  tensor(905.2675),\n",
       "  tensor(904.8304),\n",
       "  tensor(903.8821),\n",
       "  tensor(902.5900),\n",
       "  tensor(901.1459),\n",
       "  tensor(899.7350),\n",
       "  tensor(898.5111),\n",
       "  tensor(897.5797),\n",
       "  tensor(896.9905),\n",
       "  tensor(896.7395),\n",
       "  tensor(896.7774),\n",
       "  tensor(897.0237),\n",
       "  tensor(897.3837),\n",
       "  tensor(897.7636),\n",
       "  tensor(898.0848),\n",
       "  tensor(898.2922),\n",
       "  tensor(898.3590),\n",
       "  tensor(898.2855),\n",
       "  tensor(898.0945),\n",
       "  tensor(897.8248),\n",
       "  tensor(897.5209),\n",
       "  tensor(897.2268),\n",
       "  tensor(896.9779),\n",
       "  tensor(896.7975),\n",
       "  tensor(896.6945),\n",
       "  tensor(896.6647),\n",
       "  tensor(896.6934),\n",
       "  tensor(896.7594),\n",
       "  tensor(896.8398),\n",
       "  tensor(896.9133),\n",
       "  tensor(896.9642),\n",
       "  tensor(896.9833),\n",
       "  tensor(896.9687),\n",
       "  tensor(896.9245),\n",
       "  tensor(896.8597),\n",
       "  tensor(896.7845),\n",
       "  tensor(896.7097),\n",
       "  tensor(896.6436),\n",
       "  tensor(896.5905),\n",
       "  tensor(896.5512),\n",
       "  tensor(896.5206),\n",
       "  tensor(896.4871),\n",
       "  tensor(896.4255),\n",
       "  tensor(896.2666),\n",
       "  tensor(895.7122),\n",
       "  tensor(893.1200),\n",
       "  tensor(885.1932),\n",
       "  tensor(873.7490),\n",
       "  tensor(870.0516),\n",
       "  tensor(870.5014),\n",
       "  tensor(867.5229),\n",
       "  tensor(861.7965),\n",
       "  tensor(864.7092),\n",
       "  tensor(864.0833),\n",
       "  tensor(854.4782),\n",
       "  tensor(856.5946),\n",
       "  tensor(859.1998),\n",
       "  tensor(859.7930),\n",
       "  tensor(857.7511),\n",
       "  tensor(853.3597),\n",
       "  tensor(856.7487),\n",
       "  tensor(858.5410),\n",
       "  tensor(854.1005),\n",
       "  tensor(854.8033),\n",
       "  tensor(856.6354),\n",
       "  tensor(854.5654),\n",
       "  tensor(852.1403),\n",
       "  tensor(853.4782),\n",
       "  tensor(853.5333),\n",
       "  tensor(851.4791),\n",
       "  tensor(851.7664),\n",
       "  tensor(852.8923),\n",
       "  tensor(852.1617),\n",
       "  tensor(851.4123),\n",
       "  tensor(852.1057),\n",
       "  tensor(852.4152),\n",
       "  tensor(851.5861),\n",
       "  tensor(851.1813),\n",
       "  tensor(851.5658),\n",
       "  tensor(851.4209),\n",
       "  tensor(850.7806),\n",
       "  tensor(850.7025),\n",
       "  tensor(850.9678),\n",
       "  tensor(850.8686),\n",
       "  tensor(850.5676),\n",
       "  tensor(850.5908),\n",
       "  tensor(850.7903),\n",
       "  tensor(850.7383),\n",
       "  tensor(850.5205),\n",
       "  tensor(850.4570),\n",
       "  tensor(850.5292),\n",
       "  tensor(850.4819),\n",
       "  tensor(850.3145),\n",
       "  tensor(850.2391),\n",
       "  tensor(850.2735),\n",
       "  tensor(850.2885),\n",
       "  tensor(850.2267),\n",
       "  tensor(850.1678),\n",
       "  tensor(850.1709),\n",
       "  tensor(850.1974),\n",
       "  tensor(850.1793),\n",
       "  tensor(850.1208),\n",
       "  tensor(850.0800),\n",
       "  tensor(850.0727),\n",
       "  tensor(850.0664),\n",
       "  tensor(850.0370),\n",
       "  tensor(849.9974),\n",
       "  tensor(849.9750),\n",
       "  tensor(849.9756),\n",
       "  tensor(849.9736),\n",
       "  tensor(849.9525),\n",
       "  tensor(849.9280),\n",
       "  tensor(849.9171),\n",
       "  tensor(849.9117),\n",
       "  tensor(849.8975),\n",
       "  tensor(849.8740),\n",
       "  tensor(849.8530),\n",
       "  tensor(849.8417),\n",
       "  tensor(849.8331),\n",
       "  tensor(849.8188),\n",
       "  tensor(849.8013),\n",
       "  tensor(849.7888),\n",
       "  tensor(849.7803),\n",
       "  tensor(849.7695),\n",
       "  tensor(849.7550),\n",
       "  tensor(849.7389),\n",
       "  tensor(849.7258),\n",
       "  tensor(849.7150),\n",
       "  tensor(849.7018),\n",
       "  tensor(849.6865),\n",
       "  tensor(849.6728),\n",
       "  tensor(849.6615),\n",
       "  tensor(849.6494),\n",
       "  tensor(849.6364),\n",
       "  tensor(849.6221),\n",
       "  tensor(849.6096),\n",
       "  tensor(849.5977),\n",
       "  tensor(849.5837),\n",
       "  tensor(849.5697),\n",
       "  tensor(849.5560),\n",
       "  tensor(849.5429),\n",
       "  tensor(849.5292),\n",
       "  tensor(849.5147),\n",
       "  tensor(849.5012),\n",
       "  tensor(849.4873),\n",
       "  tensor(849.4738),\n",
       "  tensor(849.4594),\n",
       "  tensor(849.4448),\n",
       "  tensor(849.4305),\n",
       "  tensor(849.4160),\n",
       "  tensor(849.4007),\n",
       "  tensor(849.3856),\n",
       "  tensor(849.3711),\n",
       "  tensor(849.3560),\n",
       "  tensor(849.3405),\n",
       "  tensor(849.3253),\n",
       "  tensor(849.3098),\n",
       "  tensor(849.2939),\n",
       "  tensor(849.2778),\n",
       "  tensor(849.2621),\n",
       "  tensor(849.2457),\n",
       "  tensor(849.2291),\n",
       "  tensor(849.2126),\n",
       "  tensor(849.1959),\n",
       "  tensor(849.1791),\n",
       "  tensor(849.1620),\n",
       "  tensor(849.1448),\n",
       "  tensor(849.1271),\n",
       "  tensor(849.1099),\n",
       "  tensor(849.0915),\n",
       "  tensor(849.0737),\n",
       "  tensor(849.0557),\n",
       "  tensor(849.0374),\n",
       "  tensor(849.0189),\n",
       "  tensor(849.0002),\n",
       "  tensor(848.9812),\n",
       "  tensor(848.9623),\n",
       "  tensor(848.9433),\n",
       "  tensor(848.9235),\n",
       "  tensor(848.9047),\n",
       "  tensor(848.8844),\n",
       "  tensor(848.8645),\n",
       "  tensor(848.8450),\n",
       "  tensor(848.8243),\n",
       "  tensor(848.8040),\n",
       "  tensor(848.7834),\n",
       "  tensor(848.7628),\n",
       "  tensor(848.7416),\n",
       "  tensor(848.7206),\n",
       "  tensor(848.6993),\n",
       "  tensor(848.6780),\n",
       "  tensor(848.6562),\n",
       "  tensor(848.6345),\n",
       "  tensor(848.6125),\n",
       "  tensor(848.5901),\n",
       "  tensor(848.5680),\n",
       "  tensor(848.5456),\n",
       "  tensor(848.5232),\n",
       "  tensor(848.5009),\n",
       "  tensor(848.4779),\n",
       "  tensor(848.4548),\n",
       "  tensor(848.4319),\n",
       "  tensor(848.4088),\n",
       "  tensor(848.3853),\n",
       "  tensor(848.3620),\n",
       "  tensor(848.3382),\n",
       "  tensor(848.3146),\n",
       "  tensor(848.2905),\n",
       "  tensor(848.2667),\n",
       "  tensor(848.2430),\n",
       "  tensor(848.2187),\n",
       "  tensor(848.1947),\n",
       "  tensor(848.1706),\n",
       "  tensor(848.1458),\n",
       "  tensor(848.1213),\n",
       "  tensor(848.0968),\n",
       "  tensor(848.0722),\n",
       "  tensor(848.0474),\n",
       "  tensor(848.0225),\n",
       "  tensor(847.9977),\n",
       "  tensor(847.9730),\n",
       "  tensor(847.9478),\n",
       "  tensor(847.9231),\n",
       "  tensor(847.8984),\n",
       "  tensor(847.8730),\n",
       "  tensor(847.8479),\n",
       "  tensor(847.8229),\n",
       "  tensor(847.7980),\n",
       "  tensor(847.7729),\n",
       "  tensor(847.7477),\n",
       "  tensor(847.7221),\n",
       "  tensor(847.6971),\n",
       "  tensor(847.6721),\n",
       "  tensor(847.6474),\n",
       "  tensor(847.6217),\n",
       "  tensor(847.5967),\n",
       "  tensor(847.5717),\n",
       "  tensor(847.5466),\n",
       "  tensor(847.5217),\n",
       "  tensor(847.4965),\n",
       "  tensor(847.4718),\n",
       "  tensor(847.4467),\n",
       "  tensor(847.4221),\n",
       "  tensor(847.3972),\n",
       "  tensor(847.3725),\n",
       "  tensor(847.3481),\n",
       "  tensor(847.3234),\n",
       "  tensor(847.2991),\n",
       "  tensor(847.2745),\n",
       "  tensor(847.2503),\n",
       "  tensor(847.2260),\n",
       "  tensor(847.2019),\n",
       "  tensor(847.1777),\n",
       "  tensor(847.1537),\n",
       "  tensor(847.1301),\n",
       "  tensor(847.1063),\n",
       "  tensor(847.0827),\n",
       "  tensor(847.0591),\n",
       "  tensor(847.0358),\n",
       "  tensor(847.0121),\n",
       "  tensor(846.9893),\n",
       "  tensor(846.9661),\n",
       "  tensor(846.9434),\n",
       "  tensor(846.9203),\n",
       "  tensor(846.8975),\n",
       "  tensor(846.8755),\n",
       "  tensor(846.8527),\n",
       "  tensor(846.8305),\n",
       "  tensor(846.8087),\n",
       "  tensor(846.7864),\n",
       "  tensor(846.7649),\n",
       "  tensor(846.7433),\n",
       "  tensor(846.7213),\n",
       "  tensor(846.6998),\n",
       "  tensor(846.6787),\n",
       "  tensor(846.6575),\n",
       "  tensor(846.6367),\n",
       "  tensor(846.6158),\n",
       "  tensor(846.5952),\n",
       "  tensor(846.5748),\n",
       "  tensor(846.5546),\n",
       "  tensor(846.5342),\n",
       "  tensor(846.5142),\n",
       "  tensor(846.4944),\n",
       "  tensor(846.4744),\n",
       "  tensor(846.4550),\n",
       "  tensor(846.4356),\n",
       "  tensor(846.4166),\n",
       "  tensor(846.3973),\n",
       "  tensor(846.3783),\n",
       "  tensor(846.3595),\n",
       "  tensor(846.3411),\n",
       "  tensor(846.3226),\n",
       "  tensor(846.3040),\n",
       "  tensor(846.2860),\n",
       "  tensor(846.2680),\n",
       "  tensor(846.2498),\n",
       "  tensor(846.2322),\n",
       "  tensor(846.2148),\n",
       "  tensor(846.1975),\n",
       "  tensor(846.1801),\n",
       "  tensor(846.1632),\n",
       "  tensor(846.1462),\n",
       "  tensor(846.1292),\n",
       "  tensor(846.1125),\n",
       "  tensor(846.0961),\n",
       "  tensor(846.0801),\n",
       "  tensor(846.0638),\n",
       "  tensor(846.0476),\n",
       "  tensor(846.0317),\n",
       "  tensor(846.0159),\n",
       "  tensor(846.0002),\n",
       "  tensor(845.9847),\n",
       "  tensor(845.9694),\n",
       "  tensor(845.9543),\n",
       "  tensor(845.9391),\n",
       "  tensor(845.9244),\n",
       "  tensor(845.9094),\n",
       "  tensor(845.8948),\n",
       "  tensor(845.8801),\n",
       "  tensor(845.8657),\n",
       "  tensor(845.8515),\n",
       "  tensor(845.8375),\n",
       "  tensor(845.8232),\n",
       "  tensor(845.8095),\n",
       "  tensor(845.7958),\n",
       "  tensor(845.7821),\n",
       "  tensor(845.7686),\n",
       "  tensor(845.7548),\n",
       "  tensor(845.7418),\n",
       "  tensor(845.7286),\n",
       "  tensor(845.7157),\n",
       "  tensor(845.7026),\n",
       "  tensor(845.6900),\n",
       "  tensor(845.6771),\n",
       "  tensor(845.6645),\n",
       "  tensor(845.6523),\n",
       "  tensor(845.6398),\n",
       "  tensor(845.6275),\n",
       "  tensor(845.6154),\n",
       "  tensor(845.6035),\n",
       "  tensor(845.5912),\n",
       "  tensor(845.5795),\n",
       "  tensor(845.5676),\n",
       "  tensor(845.5561),\n",
       "  tensor(845.5446),\n",
       "  tensor(845.5331),\n",
       "  tensor(845.5217),\n",
       "  tensor(845.5108),\n",
       "  tensor(845.4991),\n",
       "  tensor(845.4882),\n",
       "  tensor(845.4772),\n",
       "  tensor(845.4664),\n",
       "  tensor(845.4556),\n",
       "  tensor(845.4450),\n",
       "  tensor(845.4344),\n",
       "  tensor(845.4238),\n",
       "  tensor(845.4133),\n",
       "  tensor(845.4030),\n",
       "  tensor(845.3928),\n",
       "  tensor(845.3825),\n",
       "  tensor(845.3725),\n",
       "  tensor(845.3625),\n",
       "  tensor(845.3524),\n",
       "  tensor(845.3423),\n",
       "  tensor(845.3329),\n",
       "  tensor(845.3228),\n",
       "  tensor(845.3135),\n",
       "  tensor(845.3037),\n",
       "  tensor(845.2943),\n",
       "  tensor(845.2850),\n",
       "  tensor(845.2755),\n",
       "  tensor(845.2661),\n",
       "  tensor(845.2569),\n",
       "  tensor(845.2477),\n",
       "  tensor(845.2386),\n",
       "  tensor(845.2296),\n",
       "  tensor(845.2205),\n",
       "  tensor(845.2115),\n",
       "  tensor(845.2030),\n",
       "  tensor(845.1940),\n",
       "  tensor(845.1850),\n",
       "  tensor(845.1765),\n",
       "  tensor(845.1682),\n",
       "  tensor(845.1594),\n",
       "  tensor(845.1511),\n",
       "  tensor(845.1426),\n",
       "  tensor(845.1342),\n",
       "  tensor(845.1260),\n",
       "  tensor(845.1175),\n",
       "  tensor(845.1094),\n",
       "  tensor(845.1010),\n",
       "  tensor(845.0928),\n",
       "  tensor(845.0848),\n",
       "  tensor(845.0769),\n",
       "  tensor(845.0688),\n",
       "  tensor(845.0611),\n",
       "  tensor(845.0529),\n",
       "  tensor(845.0451),\n",
       "  tensor(845.0374),\n",
       "  tensor(845.0295),\n",
       "  tensor(845.0218),\n",
       "  tensor(845.0142),\n",
       "  tensor(845.0065),\n",
       "  tensor(844.9990),\n",
       "  tensor(844.9916),\n",
       "  tensor(844.9840),\n",
       "  tensor(844.9766),\n",
       "  tensor(844.9692),\n",
       "  tensor(844.9620),\n",
       "  tensor(844.9543),\n",
       "  tensor(844.9473),\n",
       "  tensor(844.9399),\n",
       "  tensor(844.9326),\n",
       "  tensor(844.9254),\n",
       "  tensor(844.9183),\n",
       "  tensor(844.9111),\n",
       "  tensor(844.9042),\n",
       "  tensor(844.8971),\n",
       "  tensor(844.8901),\n",
       "  tensor(844.8831),\n",
       "  tensor(844.8762),\n",
       "  tensor(844.8692),\n",
       "  tensor(844.8623),\n",
       "  tensor(844.8552),\n",
       "  tensor(844.8486),\n",
       "  tensor(844.8419),\n",
       "  tensor(844.8350),\n",
       "  tensor(844.8283),\n",
       "  tensor(844.8217),\n",
       "  tensor(844.8149),\n",
       "  tensor(844.8082),\n",
       "  tensor(844.8015),\n",
       "  tensor(844.7952),\n",
       "  tensor(844.7885),\n",
       "  tensor(844.7819),\n",
       "  tensor(844.7753),\n",
       "  tensor(844.7689),\n",
       "  tensor(844.7623),\n",
       "  tensor(844.7559),\n",
       "  tensor(844.7494),\n",
       "  tensor(844.7432),\n",
       "  tensor(844.7366),\n",
       "  tensor(844.7305),\n",
       "  tensor(844.7238),\n",
       "  tensor(844.7175),\n",
       "  tensor(844.7111),\n",
       "  tensor(844.7051),\n",
       "  tensor(844.6986),\n",
       "  tensor(844.6924),\n",
       "  tensor(844.6861),\n",
       "  tensor(844.6799),\n",
       "  tensor(844.6738),\n",
       "  tensor(844.6675),\n",
       "  tensor(844.6615),\n",
       "  tensor(844.6553),\n",
       "  tensor(844.6494),\n",
       "  tensor(844.6431),\n",
       "  tensor(844.6369),\n",
       "  tensor(844.6310),\n",
       "  tensor(844.6248),\n",
       "  tensor(844.6190),\n",
       "  tensor(844.6127),\n",
       "  tensor(844.6067),\n",
       "  tensor(844.6008),\n",
       "  tensor(844.5947),\n",
       "  tensor(844.5888),\n",
       "  tensor(844.5828),\n",
       "  tensor(844.5770),\n",
       "  tensor(844.5709),\n",
       "  tensor(844.5650),\n",
       "  tensor(844.5590),\n",
       "  tensor(844.5530),\n",
       "  tensor(844.5472),\n",
       "  tensor(844.5413),\n",
       "  tensor(844.5355),\n",
       "  tensor(844.5295),\n",
       "  tensor(844.5238),\n",
       "  tensor(844.5180),\n",
       "  tensor(844.5121),\n",
       "  tensor(844.5061),\n",
       "  tensor(844.5003),\n",
       "  tensor(844.4946),\n",
       "  tensor(844.4888),\n",
       "  tensor(844.4830),\n",
       "  tensor(844.4771),\n",
       "  tensor(844.4713),\n",
       "  tensor(844.4653),\n",
       "  tensor(844.4598),\n",
       "  tensor(844.4541),\n",
       "  tensor(844.4484),\n",
       "  tensor(844.4427),\n",
       "  tensor(844.4370),\n",
       "  tensor(844.4310),\n",
       "  tensor(844.4254),\n",
       "  tensor(844.4197),\n",
       "  tensor(844.4138),\n",
       "  tensor(844.4083),\n",
       "  tensor(844.4025),\n",
       "  tensor(844.3969),\n",
       "  tensor(844.3912),\n",
       "  tensor(844.3852),\n",
       "  tensor(844.3798),\n",
       "  tensor(844.3741),\n",
       "  tensor(844.3684),\n",
       "  tensor(844.3625),\n",
       "  tensor(844.3569),\n",
       "  tensor(844.3513),\n",
       "  tensor(844.3453),\n",
       "  tensor(844.3400),\n",
       "  tensor(844.3343),\n",
       "  tensor(844.3286),\n",
       "  tensor(844.3231),\n",
       "  tensor(844.3174),\n",
       "  tensor(844.3119),\n",
       "  tensor(844.3062),\n",
       "  tensor(844.3007),\n",
       "  tensor(844.2948),\n",
       "  tensor(844.2892),\n",
       "  tensor(844.2838),\n",
       "  tensor(844.2779),\n",
       "  tensor(844.2725),\n",
       "  tensor(844.2665),\n",
       "  tensor(844.2609),\n",
       "  tensor(844.2554),\n",
       "  tensor(844.2499),\n",
       "  tensor(844.2443),\n",
       "  tensor(844.2387),\n",
       "  tensor(844.2327),\n",
       "  tensor(844.2271),\n",
       "  tensor(844.2217),\n",
       "  tensor(844.2160),\n",
       "  tensor(844.2103),\n",
       "  tensor(844.2050),\n",
       "  tensor(844.1992),\n",
       "  tensor(844.1933),\n",
       "  tensor(844.1880),\n",
       "  tensor(844.1822),\n",
       "  tensor(844.1766),\n",
       "  tensor(844.1708),\n",
       "  tensor(844.1653),\n",
       "  tensor(844.1596),\n",
       "  tensor(844.1542),\n",
       "  tensor(844.1483),\n",
       "  tensor(844.1430),\n",
       "  tensor(844.1371),\n",
       "  tensor(844.1317),\n",
       "  tensor(844.1260),\n",
       "  tensor(844.1205),\n",
       "  tensor(844.1148),\n",
       "  tensor(844.1090),\n",
       "  tensor(844.1033),\n",
       "  tensor(844.0978),\n",
       "  tensor(844.0922),\n",
       "  tensor(844.0866),\n",
       "  tensor(844.0806),\n",
       "  tensor(844.0753),\n",
       "  tensor(844.0697),\n",
       "  tensor(844.0638),\n",
       "  tensor(844.0583),\n",
       "  tensor(844.0527),\n",
       "  tensor(844.0471),\n",
       "  tensor(844.0414),\n",
       "  tensor(844.0360),\n",
       "  tensor(844.0300),\n",
       "  tensor(844.0245),\n",
       "  tensor(844.0189),\n",
       "  tensor(844.0131),\n",
       "  tensor(844.0073),\n",
       "  tensor(844.0014),\n",
       "  tensor(843.9962),\n",
       "  tensor(843.9904),\n",
       "  tensor(843.9848),\n",
       "  tensor(843.9791),\n",
       "  tensor(843.9735),\n",
       "  tensor(843.9677),\n",
       "  tensor(843.9621),\n",
       "  tensor(843.9563),\n",
       "  tensor(843.9508),\n",
       "  tensor(843.9449),\n",
       "  tensor(843.9396),\n",
       "  tensor(843.9335),\n",
       "  tensor(843.9279),\n",
       "  tensor(843.9227),\n",
       "  tensor(843.9163),\n",
       "  tensor(843.9108),\n",
       "  tensor(843.9052),\n",
       "  tensor(843.8996),\n",
       "  tensor(843.8941),\n",
       "  tensor(843.8882),\n",
       "  tensor(843.8823),\n",
       "  tensor(843.8768),\n",
       "  tensor(843.8707),\n",
       "  tensor(843.8654),\n",
       "  tensor(843.8595),\n",
       "  tensor(843.8539),\n",
       "  tensor(843.8481),\n",
       "  tensor(843.8424),\n",
       "  tensor(843.8368),\n",
       "  tensor(843.8307),\n",
       "  tensor(843.8254),\n",
       "  tensor(843.8195),\n",
       "  tensor(843.8137),\n",
       "  tensor(843.8077),\n",
       "  tensor(843.8020),\n",
       "  tensor(843.7963),\n",
       "  tensor(843.7905),\n",
       "  tensor(843.7851),\n",
       "  tensor(843.7794),\n",
       "  tensor(843.7734),\n",
       "  tensor(843.7677),\n",
       "  tensor(843.7618),\n",
       "  tensor(843.7562),\n",
       "  tensor(843.7505),\n",
       "  tensor(843.7443),\n",
       "  tensor(843.7389),\n",
       "  tensor(843.7330),\n",
       "  tensor(843.7271),\n",
       "  tensor(843.7211),\n",
       "  tensor(843.7158),\n",
       "  tensor(843.7098),\n",
       "  tensor(843.7038),\n",
       "  tensor(843.6984),\n",
       "  tensor(843.6921),\n",
       "  tensor(843.6862),\n",
       "  tensor(843.6807),\n",
       "  tensor(843.6747),\n",
       "  tensor(843.6691),\n",
       "  tensor(843.6633),\n",
       "  tensor(843.6572),\n",
       "  tensor(843.6516),\n",
       "  tensor(843.6456),\n",
       "  tensor(843.6400),\n",
       "  tensor(843.6340),\n",
       "  tensor(843.6282),\n",
       "  tensor(843.6225),\n",
       "  tensor(843.6164),\n",
       "  tensor(843.6104),\n",
       "  tensor(843.6045),\n",
       "  tensor(843.5991),\n",
       "  tensor(843.5929),\n",
       "  tensor(843.5873),\n",
       "  tensor(843.5815),\n",
       "  tensor(843.5756),\n",
       "  tensor(843.5697),\n",
       "  tensor(843.5638),\n",
       "  tensor(843.5579),\n",
       "  tensor(843.5519),\n",
       "  tensor(843.5459),\n",
       "  tensor(843.5403),\n",
       "  tensor(843.5342),\n",
       "  tensor(843.5287),\n",
       "  tensor(843.5229),\n",
       "  tensor(843.5166),\n",
       "  tensor(843.5104),\n",
       "  tensor(843.5049),\n",
       "  tensor(843.4990),\n",
       "  tensor(843.4929),\n",
       "  tensor(843.4872),\n",
       "  tensor(843.4811),\n",
       "  tensor(843.4752),\n",
       "  tensor(843.4694),\n",
       "  tensor(843.4640),\n",
       "  tensor(843.4576),\n",
       "  tensor(843.4520),\n",
       "  tensor(843.4457),\n",
       "  tensor(843.4403),\n",
       "  tensor(843.4339),\n",
       "  tensor(843.4280),\n",
       "  tensor(843.4223),\n",
       "  tensor(843.4161),\n",
       "  tensor(843.4103),\n",
       "  tensor(843.4043),\n",
       "  tensor(843.3984),\n",
       "  tensor(843.3925),\n",
       "  tensor(843.3864),\n",
       "  tensor(843.3804),\n",
       "  tensor(843.3746),\n",
       "  tensor(843.3684),\n",
       "  tensor(843.3625),\n",
       "  tensor(843.3564),\n",
       "  tensor(843.3506),\n",
       "  tensor(843.3448),\n",
       "  tensor(843.3386),\n",
       "  tensor(843.3327),\n",
       "  tensor(843.3270),\n",
       "  tensor(843.3206),\n",
       "  tensor(843.3150),\n",
       "  tensor(843.3089),\n",
       "  tensor(843.3030),\n",
       "  tensor(843.2968),\n",
       "  tensor(843.2911),\n",
       "  tensor(843.2848),\n",
       "  tensor(843.2787),\n",
       "  tensor(843.2731),\n",
       "  tensor(843.2668),\n",
       "  tensor(843.2607),\n",
       "  tensor(843.2549),\n",
       "  tensor(843.2491),\n",
       "  tensor(843.2431),\n",
       "  tensor(843.2369),\n",
       "  tensor(843.2310),\n",
       "  tensor(843.2250),\n",
       "  tensor(843.2188),\n",
       "  tensor(843.2128),\n",
       "  tensor(843.2070),\n",
       "  tensor(843.2009),\n",
       "  tensor(843.1947),\n",
       "  tensor(843.1888),\n",
       "  tensor(843.1826),\n",
       "  tensor(843.1768),\n",
       "  tensor(843.1710),\n",
       "  tensor(843.1649),\n",
       "  tensor(843.1586),\n",
       "  tensor(843.1529),\n",
       "  tensor(843.1469),\n",
       "  tensor(843.1409),\n",
       "  tensor(843.1348),\n",
       "  tensor(843.1289),\n",
       "  tensor(843.1227),\n",
       "  tensor(843.1166),\n",
       "  tensor(843.1105),\n",
       "  tensor(843.1044),\n",
       "  tensor(843.0990),\n",
       "  tensor(843.0923),\n",
       "  tensor(843.0865),\n",
       "  tensor(843.0805),\n",
       "  tensor(843.0744),\n",
       "  tensor(843.0684),\n",
       "  tensor(843.0626),\n",
       "  tensor(843.0561),\n",
       "  tensor(843.0505),\n",
       "  tensor(843.0442),\n",
       "  tensor(843.0381),\n",
       "  tensor(843.0319),\n",
       "  tensor(843.0262),\n",
       "  tensor(843.0200),\n",
       "  tensor(843.0141),\n",
       "  tensor(843.0079),\n",
       "  tensor(843.0018),\n",
       "  tensor(842.9957),\n",
       "  tensor(842.9897),\n",
       "  tensor(842.9836),\n",
       "  tensor(842.9779),\n",
       "  tensor(842.9713),\n",
       "  tensor(842.9654),\n",
       "  tensor(842.9591),\n",
       "  tensor(842.9534),\n",
       "  tensor(842.9476),\n",
       "  tensor(842.9413),\n",
       "  tensor(842.9352),\n",
       "  tensor(842.9291),\n",
       "  tensor(842.9230),\n",
       "  tensor(842.9172),\n",
       "  tensor(842.9111),\n",
       "  tensor(842.9052),\n",
       "  tensor(842.8990),\n",
       "  tensor(842.8928),\n",
       "  tensor(842.8867),\n",
       "  tensor(842.8805),\n",
       "  tensor(842.8748),\n",
       "  tensor(842.8685),\n",
       "  tensor(842.8624),\n",
       "  tensor(842.8564),\n",
       "  tensor(842.8506),\n",
       "  tensor(842.8443),\n",
       "  tensor(842.8385),\n",
       "  tensor(842.8323),\n",
       "  tensor(842.8262),\n",
       "  tensor(842.8201),\n",
       "  tensor(842.8139),\n",
       "  tensor(842.8079),\n",
       "  tensor(842.8018),\n",
       "  tensor(842.7959),\n",
       "  tensor(842.7899),\n",
       "  tensor(842.7836),\n",
       "  tensor(842.7775),\n",
       "  tensor(842.7714),\n",
       "  tensor(842.7653),\n",
       "  tensor(842.7594),\n",
       "  tensor(842.7535),\n",
       "  tensor(842.7469),\n",
       "  tensor(842.7412),\n",
       "  tensor(842.7348),\n",
       "  tensor(842.7289),\n",
       "  tensor(842.7230),\n",
       "  tensor(842.7167),\n",
       "  tensor(842.7110),\n",
       "  tensor(842.7048),\n",
       "  tensor(842.6989),\n",
       "  tensor(842.6926),\n",
       "  tensor(842.6864),\n",
       "  tensor(842.6802),\n",
       "  tensor(842.6739),\n",
       "  tensor(842.6684),\n",
       "  tensor(842.6622),\n",
       "  tensor(842.6564),\n",
       "  tensor(842.6504),\n",
       "  tensor(842.6442),\n",
       "  tensor(842.6379),\n",
       "  tensor(842.6319),\n",
       "  tensor(842.6261),\n",
       "  tensor(842.6200),\n",
       "  tensor(842.6139),\n",
       "  tensor(842.6080),\n",
       "  tensor(842.6017),\n",
       "  tensor(842.5956),\n",
       "  tensor(842.5894),\n",
       "  tensor(842.5834),\n",
       "  tensor(842.5771),\n",
       "  tensor(842.5713),\n",
       "  tensor(842.5654),\n",
       "  tensor(842.5591),\n",
       "  tensor(842.5532),\n",
       "  tensor(842.5471),\n",
       "  tensor(842.5411),\n",
       "  tensor(842.5349),\n",
       "  tensor(842.5289),\n",
       "  tensor(842.5231),\n",
       "  tensor(842.5170),\n",
       "  tensor(842.5107),\n",
       "  tensor(842.5051),\n",
       "  tensor(842.4991),\n",
       "  tensor(842.4927),\n",
       "  tensor(842.4869),\n",
       "  tensor(842.4809),\n",
       "  tensor(842.4745),\n",
       "  tensor(842.4688),\n",
       "  tensor(842.4625),\n",
       "  tensor(842.4564),\n",
       "  tensor(842.4503),\n",
       "  tensor(842.4446),\n",
       "  tensor(842.4384),\n",
       "  tensor(842.4322),\n",
       "  tensor(842.4265),\n",
       "  tensor(842.4201),\n",
       "  tensor(842.4140),\n",
       "  tensor(842.4081),\n",
       "  tensor(842.4023),\n",
       "  tensor(842.3964),\n",
       "  tensor(842.3898),\n",
       "  tensor(842.3839),\n",
       "  tensor(842.3779),\n",
       "  tensor(842.3717),\n",
       "  tensor(842.3658),\n",
       "  tensor(842.3599),\n",
       "  tensor(842.3542),\n",
       "  tensor(842.3482),\n",
       "  tensor(842.3420),\n",
       "  tensor(842.3359),\n",
       "  tensor(842.3302),\n",
       "  tensor(842.3236),\n",
       "  tensor(842.3181),\n",
       "  tensor(842.3120),\n",
       "  tensor(842.3058),\n",
       "  tensor(842.2998),\n",
       "  tensor(842.2935),\n",
       "  tensor(842.2878),\n",
       "  tensor(842.2819),\n",
       "  tensor(842.2759),\n",
       "  tensor(842.2701),\n",
       "  tensor(842.2641),\n",
       "  tensor(842.2576),\n",
       "  tensor(842.2521),\n",
       "  tensor(842.2457),\n",
       "  tensor(842.2399),\n",
       "  tensor(842.2338),\n",
       "  tensor(842.2278),\n",
       "  tensor(842.2219),\n",
       "  tensor(842.2162),\n",
       "  tensor(842.2101),\n",
       "  tensor(842.2042),\n",
       "  tensor(842.1984),\n",
       "  tensor(842.1924),\n",
       "  tensor(842.1862),\n",
       "  tensor(842.1802),\n",
       "  tensor(842.1742),\n",
       "  tensor(842.1680),\n",
       "  tensor(842.1627),\n",
       "  tensor(842.1563),\n",
       "  tensor(842.1500),\n",
       "  tensor(842.1443),\n",
       "  tensor(842.1384),\n",
       "  tensor(842.1328),\n",
       "  tensor(842.1264),\n",
       "  tensor(842.1205),\n",
       "  tensor(842.1146),\n",
       "  tensor(842.1086),\n",
       "  tensor(842.1027),\n",
       "  tensor(842.0971),\n",
       "  tensor(842.0911),\n",
       "  tensor(842.0850),\n",
       "  tensor(842.0788),\n",
       "  tensor(842.0734),\n",
       "  tensor(842.0675),\n",
       "  tensor(842.0615),\n",
       "  tensor(842.0552),\n",
       "  tensor(842.0494),\n",
       "  tensor(842.0438),\n",
       "  tensor(842.0375),\n",
       "  tensor(842.0320),\n",
       "  tensor(842.0261),\n",
       "  tensor(842.0201),\n",
       "  tensor(842.0141),\n",
       "  tensor(842.0085),\n",
       "  tensor(842.0026),\n",
       "  tensor(841.9966),\n",
       "  tensor(841.9905),\n",
       "  tensor(841.9852),\n",
       "  tensor(841.9786),\n",
       "  tensor(841.9732),\n",
       "  tensor(841.9673),\n",
       "  tensor(841.9614),\n",
       "  tensor(841.9554),\n",
       "  tensor(841.9498),\n",
       "  tensor(841.9437),\n",
       "  tensor(841.9378),\n",
       "  tensor(841.9321),\n",
       "  tensor(841.9262),\n",
       "  tensor(841.9207),\n",
       "  tensor(841.9152),\n",
       "  tensor(841.9088),\n",
       "  tensor(841.9030),\n",
       "  tensor(841.8976),\n",
       "  tensor(841.8915),\n",
       "  tensor(841.8856),\n",
       "  tensor(841.8798),\n",
       "  tensor(841.8741),\n",
       "  tensor(841.8682),\n",
       "  tensor(841.8625),\n",
       "  tensor(841.8566),\n",
       "  tensor(841.8510),\n",
       "  tensor(841.8450),\n",
       "  tensor(841.8392),\n",
       "  tensor(841.8339),\n",
       "  tensor(841.8278),\n",
       "  tensor(841.8220),\n",
       "  tensor(841.8163),\n",
       "  tensor(841.8104),\n",
       "  tensor(841.8050),\n",
       "  tensor(841.7991),\n",
       "  tensor(841.7930),\n",
       "  tensor(841.7874),\n",
       "  tensor(841.7816),\n",
       "  ...],\n",
       " 'train_mae': [tensor(59.1030),\n",
       "  tensor(52.4354),\n",
       "  tensor(46.4671),\n",
       "  tensor(41.5882),\n",
       "  tensor(37.6855),\n",
       "  tensor(34.3410),\n",
       "  tensor(31.4919),\n",
       "  tensor(29.1906),\n",
       "  tensor(27.6272),\n",
       "  tensor(26.8701),\n",
       "  tensor(26.4361),\n",
       "  tensor(26.1699),\n",
       "  tensor(25.9395),\n",
       "  tensor(25.8003),\n",
       "  tensor(25.8521),\n",
       "  tensor(26.0728),\n",
       "  tensor(26.3219),\n",
       "  tensor(26.4862),\n",
       "  tensor(26.5097),\n",
       "  tensor(26.4055),\n",
       "  tensor(26.2112),\n",
       "  tensor(25.9928),\n",
       "  tensor(25.8440),\n",
       "  tensor(25.8067),\n",
       "  tensor(25.8414),\n",
       "  tensor(25.9701),\n",
       "  tensor(26.1025),\n",
       "  tensor(26.2349),\n",
       "  tensor(26.3641),\n",
       "  tensor(26.4870),\n",
       "  tensor(26.6469),\n",
       "  tensor(26.8023),\n",
       "  tensor(26.9827),\n",
       "  tensor(27.1339),\n",
       "  tensor(27.2673),\n",
       "  tensor(27.3756),\n",
       "  tensor(27.4430),\n",
       "  tensor(27.4707),\n",
       "  tensor(27.4611),\n",
       "  tensor(27.4176),\n",
       "  tensor(27.3443),\n",
       "  tensor(27.2457),\n",
       "  tensor(27.1413),\n",
       "  tensor(27.0349),\n",
       "  tensor(26.9209),\n",
       "  tensor(26.8038),\n",
       "  tensor(26.7168),\n",
       "  tensor(26.6331),\n",
       "  tensor(26.5551),\n",
       "  tensor(26.4941),\n",
       "  tensor(26.4541),\n",
       "  tensor(26.4213),\n",
       "  tensor(26.3960),\n",
       "  tensor(26.3786),\n",
       "  tensor(26.3690),\n",
       "  tensor(26.3669),\n",
       "  tensor(26.3717),\n",
       "  tensor(26.3827),\n",
       "  tensor(26.3989),\n",
       "  tensor(26.4194),\n",
       "  tensor(26.4429),\n",
       "  tensor(26.4684),\n",
       "  tensor(26.4948),\n",
       "  tensor(26.5260),\n",
       "  tensor(26.5640),\n",
       "  tensor(26.5989),\n",
       "  tensor(26.6297),\n",
       "  tensor(26.6555),\n",
       "  tensor(26.6757),\n",
       "  tensor(26.6900),\n",
       "  tensor(26.6984),\n",
       "  tensor(26.7011),\n",
       "  tensor(26.6984),\n",
       "  tensor(26.6909),\n",
       "  tensor(26.6793),\n",
       "  tensor(26.6645),\n",
       "  tensor(26.6474),\n",
       "  tensor(26.6288),\n",
       "  tensor(26.6098),\n",
       "  tensor(26.5910),\n",
       "  tensor(26.5733),\n",
       "  tensor(26.5574),\n",
       "  tensor(26.5437),\n",
       "  tensor(26.5327),\n",
       "  tensor(26.5246),\n",
       "  tensor(26.5195),\n",
       "  tensor(26.5174),\n",
       "  tensor(26.5180),\n",
       "  tensor(26.5211),\n",
       "  tensor(26.5263),\n",
       "  tensor(26.5332),\n",
       "  tensor(26.5414),\n",
       "  tensor(26.5502),\n",
       "  tensor(26.5593),\n",
       "  tensor(26.5681),\n",
       "  tensor(26.5762),\n",
       "  tensor(26.5831),\n",
       "  tensor(26.5882),\n",
       "  tensor(26.5903),\n",
       "  tensor(26.5845),\n",
       "  tensor(26.5432),\n",
       "  tensor(26.4135),\n",
       "  tensor(26.2009),\n",
       "  tensor(25.9632),\n",
       "  tensor(25.8510),\n",
       "  tensor(25.7739),\n",
       "  tensor(25.6307),\n",
       "  tensor(25.5927),\n",
       "  tensor(25.6561),\n",
       "  tensor(25.5727),\n",
       "  tensor(25.8484),\n",
       "  tensor(25.9758),\n",
       "  tensor(26.0241),\n",
       "  tensor(25.9942),\n",
       "  tensor(25.8220),\n",
       "  tensor(25.8322),\n",
       "  tensor(25.8709),\n",
       "  tensor(25.7909),\n",
       "  tensor(25.9063),\n",
       "  tensor(25.9781),\n",
       "  tensor(25.9019),\n",
       "  tensor(25.7416),\n",
       "  tensor(25.7391),\n",
       "  tensor(25.7251),\n",
       "  tensor(25.6410),\n",
       "  tensor(25.7086),\n",
       "  tensor(25.7579),\n",
       "  tensor(25.6961),\n",
       "  tensor(25.5788),\n",
       "  tensor(25.6017),\n",
       "  tensor(25.6118),\n",
       "  tensor(25.5874),\n",
       "  tensor(25.5914),\n",
       "  tensor(25.6651),\n",
       "  tensor(25.6731),\n",
       "  tensor(25.6224),\n",
       "  tensor(25.6233),\n",
       "  tensor(25.6531),\n",
       "  tensor(25.6601),\n",
       "  tensor(25.6491),\n",
       "  tensor(25.6560),\n",
       "  tensor(25.6860),\n",
       "  tensor(25.6815),\n",
       "  tensor(25.6509),\n",
       "  tensor(25.6593),\n",
       "  tensor(25.6671),\n",
       "  tensor(25.6630),\n",
       "  tensor(25.6491),\n",
       "  tensor(25.6305),\n",
       "  tensor(25.6143),\n",
       "  tensor(25.6134),\n",
       "  tensor(25.6055),\n",
       "  tensor(25.6128),\n",
       "  tensor(25.6198),\n",
       "  tensor(25.6237),\n",
       "  tensor(25.6238),\n",
       "  tensor(25.6209),\n",
       "  tensor(25.6169),\n",
       "  tensor(25.6141),\n",
       "  tensor(25.6150),\n",
       "  tensor(25.6203),\n",
       "  tensor(25.6283),\n",
       "  tensor(25.6365),\n",
       "  tensor(25.6428),\n",
       "  tensor(25.6463),\n",
       "  tensor(25.6468),\n",
       "  tensor(25.6451),\n",
       "  tensor(25.6426),\n",
       "  tensor(25.6407),\n",
       "  tensor(25.6400),\n",
       "  tensor(25.6405),\n",
       "  tensor(25.6414),\n",
       "  tensor(25.6419),\n",
       "  tensor(25.6414),\n",
       "  tensor(25.6398),\n",
       "  tensor(25.6375),\n",
       "  tensor(25.6352),\n",
       "  tensor(25.6336),\n",
       "  tensor(25.6332),\n",
       "  tensor(25.6339),\n",
       "  tensor(25.6355),\n",
       "  tensor(25.6373),\n",
       "  tensor(25.6389),\n",
       "  tensor(25.6399),\n",
       "  tensor(25.6404),\n",
       "  tensor(25.6407),\n",
       "  tensor(25.6410),\n",
       "  tensor(25.6415),\n",
       "  tensor(25.6423),\n",
       "  tensor(25.6432),\n",
       "  tensor(25.6439),\n",
       "  tensor(25.6441),\n",
       "  tensor(25.6438),\n",
       "  tensor(25.6431),\n",
       "  tensor(25.6423),\n",
       "  tensor(25.6415),\n",
       "  tensor(25.6410),\n",
       "  tensor(25.6407),\n",
       "  tensor(25.6406),\n",
       "  tensor(25.6405),\n",
       "  tensor(25.6403),\n",
       "  tensor(25.6401),\n",
       "  tensor(25.6398),\n",
       "  tensor(25.6397),\n",
       "  tensor(25.6397),\n",
       "  tensor(25.6400),\n",
       "  tensor(25.6403),\n",
       "  tensor(25.6406),\n",
       "  tensor(25.6408),\n",
       "  tensor(25.6408),\n",
       "  tensor(25.6407),\n",
       "  tensor(25.6405),\n",
       "  tensor(25.6404),\n",
       "  tensor(25.6402),\n",
       "  tensor(25.6401),\n",
       "  tensor(25.6398),\n",
       "  tensor(25.6394),\n",
       "  tensor(25.6390),\n",
       "  tensor(25.6385),\n",
       "  tensor(25.6381),\n",
       "  tensor(25.6378),\n",
       "  tensor(25.6375),\n",
       "  tensor(25.6372),\n",
       "  tensor(25.6370),\n",
       "  tensor(25.6367),\n",
       "  tensor(25.6364),\n",
       "  tensor(25.6361),\n",
       "  tensor(25.6359),\n",
       "  tensor(25.6357),\n",
       "  tensor(25.6355),\n",
       "  tensor(25.6353),\n",
       "  tensor(25.6350),\n",
       "  tensor(25.6347),\n",
       "  tensor(25.6344),\n",
       "  tensor(25.6340),\n",
       "  tensor(25.6337),\n",
       "  tensor(25.6333),\n",
       "  tensor(25.6329),\n",
       "  tensor(25.6324),\n",
       "  tensor(25.6320),\n",
       "  tensor(25.6315),\n",
       "  tensor(25.6311),\n",
       "  tensor(25.6307),\n",
       "  tensor(25.6303),\n",
       "  tensor(25.6299),\n",
       "  tensor(25.6295),\n",
       "  tensor(25.6290),\n",
       "  tensor(25.6286),\n",
       "  tensor(25.6283),\n",
       "  tensor(25.6279),\n",
       "  tensor(25.6275),\n",
       "  tensor(25.6270),\n",
       "  tensor(25.6266),\n",
       "  tensor(25.6262),\n",
       "  tensor(25.6257),\n",
       "  tensor(25.6253),\n",
       "  tensor(25.6248),\n",
       "  tensor(25.6244),\n",
       "  tensor(25.6239),\n",
       "  tensor(25.6234),\n",
       "  tensor(25.6229),\n",
       "  tensor(25.6224),\n",
       "  tensor(25.6219),\n",
       "  tensor(25.6214),\n",
       "  tensor(25.6210),\n",
       "  tensor(25.6205),\n",
       "  tensor(25.6200),\n",
       "  tensor(25.6195),\n",
       "  tensor(25.6191),\n",
       "  tensor(25.6186),\n",
       "  tensor(25.6181),\n",
       "  tensor(25.6176),\n",
       "  tensor(25.6171),\n",
       "  tensor(25.6167),\n",
       "  tensor(25.6162),\n",
       "  tensor(25.6157),\n",
       "  tensor(25.6152),\n",
       "  tensor(25.6147),\n",
       "  tensor(25.6142),\n",
       "  tensor(25.6137),\n",
       "  tensor(25.6132),\n",
       "  tensor(25.6127),\n",
       "  tensor(25.6122),\n",
       "  tensor(25.6117),\n",
       "  tensor(25.6112),\n",
       "  tensor(25.6107),\n",
       "  tensor(25.6103),\n",
       "  tensor(25.6098),\n",
       "  tensor(25.6093),\n",
       "  tensor(25.6088),\n",
       "  tensor(25.6083),\n",
       "  tensor(25.6079),\n",
       "  tensor(25.6074),\n",
       "  tensor(25.6069),\n",
       "  tensor(25.6064),\n",
       "  tensor(25.6059),\n",
       "  tensor(25.6055),\n",
       "  tensor(25.6050),\n",
       "  tensor(25.6045),\n",
       "  tensor(25.6040),\n",
       "  tensor(25.6036),\n",
       "  tensor(25.6031),\n",
       "  tensor(25.6026),\n",
       "  tensor(25.6022),\n",
       "  tensor(25.6017),\n",
       "  tensor(25.6013),\n",
       "  tensor(25.6008),\n",
       "  tensor(25.6004),\n",
       "  tensor(25.5999),\n",
       "  tensor(25.5995),\n",
       "  tensor(25.5990),\n",
       "  tensor(25.5986),\n",
       "  tensor(25.5982),\n",
       "  tensor(25.5977),\n",
       "  tensor(25.5973),\n",
       "  tensor(25.5969),\n",
       "  tensor(25.5964),\n",
       "  tensor(25.5960),\n",
       "  tensor(25.5956),\n",
       "  tensor(25.5952),\n",
       "  tensor(25.5948),\n",
       "  tensor(25.5944),\n",
       "  tensor(25.5940),\n",
       "  tensor(25.5936),\n",
       "  tensor(25.5932),\n",
       "  tensor(25.5928),\n",
       "  tensor(25.5924),\n",
       "  tensor(25.5920),\n",
       "  tensor(25.5916),\n",
       "  tensor(25.5912),\n",
       "  tensor(25.5908),\n",
       "  tensor(25.5904),\n",
       "  tensor(25.5901),\n",
       "  tensor(25.5897),\n",
       "  tensor(25.5893),\n",
       "  tensor(25.5890),\n",
       "  tensor(25.5886),\n",
       "  tensor(25.5882),\n",
       "  tensor(25.5879),\n",
       "  tensor(25.5875),\n",
       "  tensor(25.5872),\n",
       "  tensor(25.5868),\n",
       "  tensor(25.5865),\n",
       "  tensor(25.5861),\n",
       "  tensor(25.5858),\n",
       "  tensor(25.5855),\n",
       "  tensor(25.5851),\n",
       "  tensor(25.5848),\n",
       "  tensor(25.5845),\n",
       "  tensor(25.5842),\n",
       "  tensor(25.5838),\n",
       "  tensor(25.5835),\n",
       "  tensor(25.5832),\n",
       "  tensor(25.5829),\n",
       "  tensor(25.5826),\n",
       "  tensor(25.5823),\n",
       "  tensor(25.5820),\n",
       "  tensor(25.5817),\n",
       "  tensor(25.5814),\n",
       "  tensor(25.5811),\n",
       "  tensor(25.5808),\n",
       "  tensor(25.5805),\n",
       "  tensor(25.5802),\n",
       "  tensor(25.5799),\n",
       "  tensor(25.5796),\n",
       "  tensor(25.5794),\n",
       "  tensor(25.5791),\n",
       "  tensor(25.5788),\n",
       "  tensor(25.5785),\n",
       "  tensor(25.5783),\n",
       "  tensor(25.5780),\n",
       "  tensor(25.5777),\n",
       "  tensor(25.5775),\n",
       "  tensor(25.5772),\n",
       "  tensor(25.5769),\n",
       "  tensor(25.5767),\n",
       "  tensor(25.5764),\n",
       "  tensor(25.5762),\n",
       "  tensor(25.5759),\n",
       "  tensor(25.5757),\n",
       "  tensor(25.5754),\n",
       "  tensor(25.5752),\n",
       "  tensor(25.5749),\n",
       "  tensor(25.5747),\n",
       "  tensor(25.5745),\n",
       "  tensor(25.5742),\n",
       "  tensor(25.5740),\n",
       "  tensor(25.5738),\n",
       "  tensor(25.5735),\n",
       "  tensor(25.5733),\n",
       "  tensor(25.5731),\n",
       "  tensor(25.5729),\n",
       "  tensor(25.5726),\n",
       "  tensor(25.5724),\n",
       "  tensor(25.5722),\n",
       "  tensor(25.5720),\n",
       "  tensor(25.5718),\n",
       "  tensor(25.5715),\n",
       "  tensor(25.5713),\n",
       "  tensor(25.5711),\n",
       "  tensor(25.5709),\n",
       "  tensor(25.5707),\n",
       "  tensor(25.5705),\n",
       "  tensor(25.5703),\n",
       "  tensor(25.5701),\n",
       "  tensor(25.5698),\n",
       "  tensor(25.5696),\n",
       "  tensor(25.5694),\n",
       "  tensor(25.5692),\n",
       "  tensor(25.5690),\n",
       "  tensor(25.5689),\n",
       "  tensor(25.5687),\n",
       "  tensor(25.5685),\n",
       "  tensor(25.5683),\n",
       "  tensor(25.5681),\n",
       "  tensor(25.5679),\n",
       "  tensor(25.5677),\n",
       "  tensor(25.5675),\n",
       "  tensor(25.5673),\n",
       "  tensor(25.5671),\n",
       "  tensor(25.5669),\n",
       "  tensor(25.5667),\n",
       "  tensor(25.5665),\n",
       "  tensor(25.5664),\n",
       "  tensor(25.5662),\n",
       "  tensor(25.5660),\n",
       "  tensor(25.5658),\n",
       "  tensor(25.5656),\n",
       "  tensor(25.5655),\n",
       "  tensor(25.5653),\n",
       "  tensor(25.5651),\n",
       "  tensor(25.5649),\n",
       "  tensor(25.5647),\n",
       "  tensor(25.5646),\n",
       "  tensor(25.5644),\n",
       "  tensor(25.5642),\n",
       "  tensor(25.5640),\n",
       "  tensor(25.5639),\n",
       "  tensor(25.5637),\n",
       "  tensor(25.5635),\n",
       "  tensor(25.5633),\n",
       "  tensor(25.5632),\n",
       "  tensor(25.5630),\n",
       "  tensor(25.5628),\n",
       "  tensor(25.5627),\n",
       "  tensor(25.5625),\n",
       "  tensor(25.5623),\n",
       "  tensor(25.5621),\n",
       "  tensor(25.5620),\n",
       "  tensor(25.5618),\n",
       "  tensor(25.5616),\n",
       "  tensor(25.5615),\n",
       "  tensor(25.5613),\n",
       "  tensor(25.5611),\n",
       "  tensor(25.5610),\n",
       "  tensor(25.5608),\n",
       "  tensor(25.5606),\n",
       "  tensor(25.5605),\n",
       "  tensor(25.5603),\n",
       "  tensor(25.5601),\n",
       "  tensor(25.5600),\n",
       "  tensor(25.5598),\n",
       "  tensor(25.5597),\n",
       "  tensor(25.5595),\n",
       "  tensor(25.5593),\n",
       "  tensor(25.5592),\n",
       "  tensor(25.5590),\n",
       "  tensor(25.5588),\n",
       "  tensor(25.5587),\n",
       "  tensor(25.5585),\n",
       "  tensor(25.5584),\n",
       "  tensor(25.5582),\n",
       "  tensor(25.5580),\n",
       "  tensor(25.5579),\n",
       "  tensor(25.5577),\n",
       "  tensor(25.5576),\n",
       "  tensor(25.5574),\n",
       "  tensor(25.5572),\n",
       "  tensor(25.5571),\n",
       "  tensor(25.5569),\n",
       "  tensor(25.5567),\n",
       "  tensor(25.5566),\n",
       "  tensor(25.5564),\n",
       "  tensor(25.5563),\n",
       "  tensor(25.5561),\n",
       "  tensor(25.5559),\n",
       "  tensor(25.5558),\n",
       "  tensor(25.5556),\n",
       "  tensor(25.5555),\n",
       "  tensor(25.5553),\n",
       "  tensor(25.5551),\n",
       "  tensor(25.5550),\n",
       "  tensor(25.5548),\n",
       "  tensor(25.5547),\n",
       "  tensor(25.5545),\n",
       "  tensor(25.5543),\n",
       "  tensor(25.5542),\n",
       "  tensor(25.5540),\n",
       "  tensor(25.5539),\n",
       "  tensor(25.5537),\n",
       "  tensor(25.5536),\n",
       "  tensor(25.5534),\n",
       "  tensor(25.5532),\n",
       "  tensor(25.5531),\n",
       "  tensor(25.5529),\n",
       "  tensor(25.5527),\n",
       "  tensor(25.5526),\n",
       "  tensor(25.5524),\n",
       "  tensor(25.5523),\n",
       "  tensor(25.5521),\n",
       "  tensor(25.5520),\n",
       "  tensor(25.5518),\n",
       "  tensor(25.5516),\n",
       "  tensor(25.5515),\n",
       "  tensor(25.5513),\n",
       "  tensor(25.5511),\n",
       "  tensor(25.5510),\n",
       "  tensor(25.5508),\n",
       "  tensor(25.5507),\n",
       "  tensor(25.5505),\n",
       "  tensor(25.5503),\n",
       "  tensor(25.5502),\n",
       "  tensor(25.5500),\n",
       "  tensor(25.5498),\n",
       "  tensor(25.5497),\n",
       "  tensor(25.5495),\n",
       "  tensor(25.5493),\n",
       "  tensor(25.5492),\n",
       "  tensor(25.5490),\n",
       "  tensor(25.5489),\n",
       "  tensor(25.5487),\n",
       "  tensor(25.5485),\n",
       "  tensor(25.5484),\n",
       "  tensor(25.5482),\n",
       "  tensor(25.5480),\n",
       "  tensor(25.5479),\n",
       "  tensor(25.5477),\n",
       "  tensor(25.5475),\n",
       "  tensor(25.5474),\n",
       "  tensor(25.5472),\n",
       "  tensor(25.5470),\n",
       "  tensor(25.5469),\n",
       "  tensor(25.5467),\n",
       "  tensor(25.5465),\n",
       "  tensor(25.5464),\n",
       "  tensor(25.5462),\n",
       "  tensor(25.5460),\n",
       "  tensor(25.5459),\n",
       "  tensor(25.5457),\n",
       "  tensor(25.5455),\n",
       "  tensor(25.5454),\n",
       "  tensor(25.5452),\n",
       "  tensor(25.5450),\n",
       "  tensor(25.5449),\n",
       "  tensor(25.5447),\n",
       "  tensor(25.5445),\n",
       "  tensor(25.5443),\n",
       "  tensor(25.5442),\n",
       "  tensor(25.5440),\n",
       "  tensor(25.5438),\n",
       "  tensor(25.5437),\n",
       "  tensor(25.5435),\n",
       "  tensor(25.5433),\n",
       "  tensor(25.5432),\n",
       "  tensor(25.5430),\n",
       "  tensor(25.5428),\n",
       "  tensor(25.5426),\n",
       "  tensor(25.5425),\n",
       "  tensor(25.5423),\n",
       "  tensor(25.5421),\n",
       "  tensor(25.5420),\n",
       "  tensor(25.5418),\n",
       "  tensor(25.5416),\n",
       "  tensor(25.5414),\n",
       "  tensor(25.5413),\n",
       "  tensor(25.5411),\n",
       "  tensor(25.5409),\n",
       "  tensor(25.5407),\n",
       "  tensor(25.5406),\n",
       "  tensor(25.5404),\n",
       "  tensor(25.5402),\n",
       "  tensor(25.5400),\n",
       "  tensor(25.5399),\n",
       "  tensor(25.5397),\n",
       "  tensor(25.5395),\n",
       "  tensor(25.5393),\n",
       "  tensor(25.5391),\n",
       "  tensor(25.5390),\n",
       "  tensor(25.5388),\n",
       "  tensor(25.5386),\n",
       "  tensor(25.5384),\n",
       "  tensor(25.5383),\n",
       "  tensor(25.5381),\n",
       "  tensor(25.5379),\n",
       "  tensor(25.5377),\n",
       "  tensor(25.5375),\n",
       "  tensor(25.5374),\n",
       "  tensor(25.5372),\n",
       "  tensor(25.5370),\n",
       "  tensor(25.5369),\n",
       "  tensor(25.5367),\n",
       "  tensor(25.5365),\n",
       "  tensor(25.5363),\n",
       "  tensor(25.5361),\n",
       "  tensor(25.5359),\n",
       "  tensor(25.5358),\n",
       "  tensor(25.5356),\n",
       "  tensor(25.5354),\n",
       "  tensor(25.5352),\n",
       "  tensor(25.5350),\n",
       "  tensor(25.5348),\n",
       "  tensor(25.5347),\n",
       "  tensor(25.5345),\n",
       "  tensor(25.5343),\n",
       "  tensor(25.5341),\n",
       "  tensor(25.5340),\n",
       "  tensor(25.5338),\n",
       "  tensor(25.5336),\n",
       "  tensor(25.5334),\n",
       "  tensor(25.5332),\n",
       "  tensor(25.5331),\n",
       "  tensor(25.5329),\n",
       "  tensor(25.5327),\n",
       "  tensor(25.5325),\n",
       "  tensor(25.5323),\n",
       "  tensor(25.5321),\n",
       "  tensor(25.5319),\n",
       "  tensor(25.5318),\n",
       "  tensor(25.5316),\n",
       "  tensor(25.5314),\n",
       "  tensor(25.5312),\n",
       "  tensor(25.5310),\n",
       "  tensor(25.5308),\n",
       "  tensor(25.5306),\n",
       "  tensor(25.5305),\n",
       "  tensor(25.5303),\n",
       "  tensor(25.5301),\n",
       "  tensor(25.5299),\n",
       "  tensor(25.5297),\n",
       "  tensor(25.5295),\n",
       "  tensor(25.5293),\n",
       "  tensor(25.5292),\n",
       "  tensor(25.5290),\n",
       "  tensor(25.5288),\n",
       "  tensor(25.5286),\n",
       "  tensor(25.5284),\n",
       "  tensor(25.5282),\n",
       "  tensor(25.5280),\n",
       "  tensor(25.5279),\n",
       "  tensor(25.5277),\n",
       "  tensor(25.5275),\n",
       "  tensor(25.5273),\n",
       "  tensor(25.5271),\n",
       "  tensor(25.5269),\n",
       "  tensor(25.5267),\n",
       "  tensor(25.5265),\n",
       "  tensor(25.5264),\n",
       "  tensor(25.5262),\n",
       "  tensor(25.5260),\n",
       "  tensor(25.5258),\n",
       "  tensor(25.5256),\n",
       "  tensor(25.5254),\n",
       "  tensor(25.5252),\n",
       "  tensor(25.5250),\n",
       "  tensor(25.5248),\n",
       "  tensor(25.5247),\n",
       "  tensor(25.5244),\n",
       "  tensor(25.5242),\n",
       "  tensor(25.5241),\n",
       "  tensor(25.5239),\n",
       "  tensor(25.5237),\n",
       "  tensor(25.5235),\n",
       "  tensor(25.5233),\n",
       "  tensor(25.5231),\n",
       "  tensor(25.5229),\n",
       "  tensor(25.5227),\n",
       "  tensor(25.5225),\n",
       "  tensor(25.5224),\n",
       "  tensor(25.5222),\n",
       "  tensor(25.5219),\n",
       "  tensor(25.5217),\n",
       "  tensor(25.5216),\n",
       "  tensor(25.5214),\n",
       "  tensor(25.5212),\n",
       "  tensor(25.5210),\n",
       "  tensor(25.5208),\n",
       "  tensor(25.5206),\n",
       "  tensor(25.5204),\n",
       "  tensor(25.5202),\n",
       "  tensor(25.5200),\n",
       "  tensor(25.5198),\n",
       "  tensor(25.5196),\n",
       "  tensor(25.5194),\n",
       "  tensor(25.5192),\n",
       "  tensor(25.5190),\n",
       "  tensor(25.5189),\n",
       "  tensor(25.5187),\n",
       "  tensor(25.5185),\n",
       "  tensor(25.5183),\n",
       "  tensor(25.5181),\n",
       "  tensor(25.5179),\n",
       "  tensor(25.5177),\n",
       "  tensor(25.5175),\n",
       "  tensor(25.5173),\n",
       "  tensor(25.5171),\n",
       "  tensor(25.5169),\n",
       "  tensor(25.5167),\n",
       "  tensor(25.5165),\n",
       "  tensor(25.5163),\n",
       "  tensor(25.5161),\n",
       "  tensor(25.5159),\n",
       "  tensor(25.5157),\n",
       "  tensor(25.5155),\n",
       "  tensor(25.5153),\n",
       "  tensor(25.5151),\n",
       "  tensor(25.5149),\n",
       "  tensor(25.5147),\n",
       "  tensor(25.5146),\n",
       "  tensor(25.5144),\n",
       "  tensor(25.5142),\n",
       "  tensor(25.5140),\n",
       "  tensor(25.5138),\n",
       "  tensor(25.5136),\n",
       "  tensor(25.5134),\n",
       "  tensor(25.5132),\n",
       "  tensor(25.5130),\n",
       "  tensor(25.5128),\n",
       "  tensor(25.5126),\n",
       "  tensor(25.5124),\n",
       "  tensor(25.5122),\n",
       "  tensor(25.5120),\n",
       "  tensor(25.5118),\n",
       "  tensor(25.5116),\n",
       "  tensor(25.5114),\n",
       "  tensor(25.5112),\n",
       "  tensor(25.5110),\n",
       "  tensor(25.5108),\n",
       "  tensor(25.5106),\n",
       "  tensor(25.5104),\n",
       "  tensor(25.5102),\n",
       "  tensor(25.5100),\n",
       "  tensor(25.5098),\n",
       "  tensor(25.5096),\n",
       "  tensor(25.5094),\n",
       "  tensor(25.5092),\n",
       "  tensor(25.5090),\n",
       "  tensor(25.5088),\n",
       "  tensor(25.5086),\n",
       "  tensor(25.5084),\n",
       "  tensor(25.5082),\n",
       "  tensor(25.5080),\n",
       "  tensor(25.5078),\n",
       "  tensor(25.5076),\n",
       "  tensor(25.5074),\n",
       "  tensor(25.5072),\n",
       "  tensor(25.5070),\n",
       "  tensor(25.5068),\n",
       "  tensor(25.5066),\n",
       "  tensor(25.5064),\n",
       "  tensor(25.5062),\n",
       "  tensor(25.5060),\n",
       "  tensor(25.5058),\n",
       "  tensor(25.5056),\n",
       "  tensor(25.5054),\n",
       "  tensor(25.5052),\n",
       "  tensor(25.5050),\n",
       "  tensor(25.5048),\n",
       "  tensor(25.5046),\n",
       "  tensor(25.5044),\n",
       "  tensor(25.5042),\n",
       "  tensor(25.5040),\n",
       "  tensor(25.5038),\n",
       "  tensor(25.5036),\n",
       "  tensor(25.5034),\n",
       "  tensor(25.5032),\n",
       "  tensor(25.5030),\n",
       "  tensor(25.5027),\n",
       "  tensor(25.5025),\n",
       "  tensor(25.5024),\n",
       "  tensor(25.5022),\n",
       "  tensor(25.5019),\n",
       "  tensor(25.5017),\n",
       "  tensor(25.5015),\n",
       "  tensor(25.5013),\n",
       "  tensor(25.5011),\n",
       "  tensor(25.5009),\n",
       "  tensor(25.5007),\n",
       "  tensor(25.5005),\n",
       "  tensor(25.5003),\n",
       "  tensor(25.5001),\n",
       "  tensor(25.4999),\n",
       "  tensor(25.4997),\n",
       "  tensor(25.4995),\n",
       "  tensor(25.4993),\n",
       "  tensor(25.4991),\n",
       "  tensor(25.4989),\n",
       "  tensor(25.4987),\n",
       "  tensor(25.4985),\n",
       "  tensor(25.4983),\n",
       "  tensor(25.4981),\n",
       "  tensor(25.4979),\n",
       "  tensor(25.4977),\n",
       "  tensor(25.4975),\n",
       "  tensor(25.4973),\n",
       "  tensor(25.4971),\n",
       "  tensor(25.4969),\n",
       "  tensor(25.4967),\n",
       "  tensor(25.4964),\n",
       "  tensor(25.4962),\n",
       "  tensor(25.4960),\n",
       "  tensor(25.4958),\n",
       "  tensor(25.4956),\n",
       "  tensor(25.4954),\n",
       "  tensor(25.4952),\n",
       "  tensor(25.4950),\n",
       "  tensor(25.4948),\n",
       "  tensor(25.4946),\n",
       "  tensor(25.4944),\n",
       "  tensor(25.4942),\n",
       "  tensor(25.4940),\n",
       "  tensor(25.4938),\n",
       "  tensor(25.4936),\n",
       "  tensor(25.4934),\n",
       "  tensor(25.4932),\n",
       "  tensor(25.4930),\n",
       "  tensor(25.4928),\n",
       "  tensor(25.4926),\n",
       "  tensor(25.4923),\n",
       "  tensor(25.4921),\n",
       "  tensor(25.4919),\n",
       "  tensor(25.4918),\n",
       "  tensor(25.4915),\n",
       "  tensor(25.4913),\n",
       "  tensor(25.4911),\n",
       "  tensor(25.4909),\n",
       "  tensor(25.4907),\n",
       "  tensor(25.4905),\n",
       "  tensor(25.4903),\n",
       "  tensor(25.4901),\n",
       "  tensor(25.4899),\n",
       "  tensor(25.4897),\n",
       "  tensor(25.4895),\n",
       "  tensor(25.4893),\n",
       "  tensor(25.4891),\n",
       "  tensor(25.4889),\n",
       "  tensor(25.4887),\n",
       "  tensor(25.4884),\n",
       "  tensor(25.4882),\n",
       "  tensor(25.4880),\n",
       "  tensor(25.4878),\n",
       "  tensor(25.4876),\n",
       "  tensor(25.4874),\n",
       "  tensor(25.4872),\n",
       "  tensor(25.4870),\n",
       "  tensor(25.4868),\n",
       "  tensor(25.4866),\n",
       "  tensor(25.4864),\n",
       "  tensor(25.4862),\n",
       "  tensor(25.4860),\n",
       "  tensor(25.4858),\n",
       "  tensor(25.4856),\n",
       "  tensor(25.4854),\n",
       "  tensor(25.4851),\n",
       "  tensor(25.4849),\n",
       "  tensor(25.4847),\n",
       "  tensor(25.4845),\n",
       "  tensor(25.4843),\n",
       "  tensor(25.4841),\n",
       "  tensor(25.4839),\n",
       "  tensor(25.4837),\n",
       "  tensor(25.4835),\n",
       "  tensor(25.4833),\n",
       "  tensor(25.4831),\n",
       "  tensor(25.4829),\n",
       "  tensor(25.4827),\n",
       "  tensor(25.4825),\n",
       "  tensor(25.4823),\n",
       "  tensor(25.4821),\n",
       "  tensor(25.4818),\n",
       "  tensor(25.4816),\n",
       "  tensor(25.4814),\n",
       "  tensor(25.4812),\n",
       "  tensor(25.4810),\n",
       "  tensor(25.4808),\n",
       "  tensor(25.4806),\n",
       "  tensor(25.4804),\n",
       "  tensor(25.4802),\n",
       "  tensor(25.4800),\n",
       "  tensor(25.4798),\n",
       "  tensor(25.4796),\n",
       "  tensor(25.4794),\n",
       "  tensor(25.4791),\n",
       "  tensor(25.4789),\n",
       "  tensor(25.4787),\n",
       "  tensor(25.4785),\n",
       "  tensor(25.4783),\n",
       "  tensor(25.4781),\n",
       "  tensor(25.4779),\n",
       "  tensor(25.4777),\n",
       "  tensor(25.4775),\n",
       "  tensor(25.4773),\n",
       "  tensor(25.4771),\n",
       "  tensor(25.4769),\n",
       "  tensor(25.4767),\n",
       "  tensor(25.4765),\n",
       "  tensor(25.4762),\n",
       "  tensor(25.4760),\n",
       "  tensor(25.4758),\n",
       "  tensor(25.4756),\n",
       "  tensor(25.4754),\n",
       "  tensor(25.4752),\n",
       "  tensor(25.4750),\n",
       "  tensor(25.4748),\n",
       "  tensor(25.4746),\n",
       "  tensor(25.4744),\n",
       "  tensor(25.4742),\n",
       "  tensor(25.4740),\n",
       "  tensor(25.4738),\n",
       "  tensor(25.4736),\n",
       "  tensor(25.4734),\n",
       "  tensor(25.4731),\n",
       "  tensor(25.4729),\n",
       "  tensor(25.4727),\n",
       "  tensor(25.4725),\n",
       "  tensor(25.4723),\n",
       "  tensor(25.4721),\n",
       "  tensor(25.4719),\n",
       "  tensor(25.4717),\n",
       "  tensor(25.4715),\n",
       "  tensor(25.4713),\n",
       "  tensor(25.4711),\n",
       "  tensor(25.4709),\n",
       "  tensor(25.4707),\n",
       "  tensor(25.4704),\n",
       "  tensor(25.4702),\n",
       "  tensor(25.4700),\n",
       "  tensor(25.4698),\n",
       "  tensor(25.4696),\n",
       "  tensor(25.4694),\n",
       "  tensor(25.4692),\n",
       "  tensor(25.4690),\n",
       "  tensor(25.4688),\n",
       "  tensor(25.4686),\n",
       "  tensor(25.4684),\n",
       "  tensor(25.4682),\n",
       "  tensor(25.4680),\n",
       "  tensor(25.4678),\n",
       "  tensor(25.4675),\n",
       "  tensor(25.4674),\n",
       "  tensor(25.4672),\n",
       "  tensor(25.4669),\n",
       "  tensor(25.4667),\n",
       "  tensor(25.4665),\n",
       "  tensor(25.4663),\n",
       "  tensor(25.4661),\n",
       "  tensor(25.4659),\n",
       "  tensor(25.4657),\n",
       "  tensor(25.4655),\n",
       "  tensor(25.4653),\n",
       "  tensor(25.4651),\n",
       "  tensor(25.4649),\n",
       "  tensor(25.4647),\n",
       "  tensor(25.4645),\n",
       "  tensor(25.4643),\n",
       "  tensor(25.4641),\n",
       "  tensor(25.4639),\n",
       "  tensor(25.4636),\n",
       "  tensor(25.4634),\n",
       "  tensor(25.4632),\n",
       "  tensor(25.4630),\n",
       "  tensor(25.4628),\n",
       "  tensor(25.4626),\n",
       "  tensor(25.4624),\n",
       "  tensor(25.4622),\n",
       "  tensor(25.4620),\n",
       "  tensor(25.4618),\n",
       "  tensor(25.4616),\n",
       "  tensor(25.4614),\n",
       "  tensor(25.4612),\n",
       "  tensor(25.4610),\n",
       "  tensor(25.4608),\n",
       "  tensor(25.4606),\n",
       "  tensor(25.4604),\n",
       "  tensor(25.4602),\n",
       "  tensor(25.4599),\n",
       "  tensor(25.4598),\n",
       "  tensor(25.4596),\n",
       "  tensor(25.4593),\n",
       "  tensor(25.4591),\n",
       "  tensor(25.4589),\n",
       "  tensor(25.4587),\n",
       "  tensor(25.4585),\n",
       "  tensor(25.4583),\n",
       "  tensor(25.4581),\n",
       "  tensor(25.4579),\n",
       "  tensor(25.4577),\n",
       "  tensor(25.4575),\n",
       "  tensor(25.4573),\n",
       "  tensor(25.4571),\n",
       "  tensor(25.4569),\n",
       "  ...],\n",
       " 'val_loss': [],\n",
       " 'val_mae': []}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from examples.introduction.my_GAT_implem import myGATConv\n",
    "\n",
    "my_module = myGATConv(\n",
    "    in_channels=(1,1),\n",
    "    out_channels=1,\n",
    "    heads=1,\n",
    "    negative_slope=0.2,\n",
    "    add_self_loops=False,\n",
    "    edge_dim=1)\n",
    "# my_module(x=participant_graph.x,edge_index=participant_graph.edge_index,edge_attr=participant_graph.edge_attr)\n",
    "\n",
    "complete_model = GNN_naive_framework(my_module,device)\n",
    "opt = complete_model.configure_optimizer(lr=1)\n",
    "scheduler = complete_model.configure_scheduler(opt,1,1,10)\n",
    "\n",
    "complete_model.train([participant_graph],10000,1,opt,scheduler,\"train_loss\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           6.430633544921875,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375,
           62.5609130859375
          ]
         },
         "mode": "markers",
         "type": "scatter",
         "x": [
          21,
          21,
          80,
          78,
          59,
          75,
          88,
          90,
          88,
          85,
          7,
          29,
          77,
          53,
          89,
          53,
          77,
          38,
          50,
          87,
          83,
          84,
          100,
          100,
          94,
          50,
          20,
          94,
          13,
          90,
          17,
          77,
          53,
          83,
          76,
          100,
          83,
          35,
          56,
          24,
          22,
          90,
          29,
          79,
          100,
          6,
          62,
          46,
          17,
          92,
          46,
          40,
          9,
          79,
          13,
          73,
          45,
          73,
          100,
          100
         ],
         "y": [
          41.5609130859375,
          41.5609130859375,
          17.4390869140625,
          15.4390869140625,
          3.5609130859375,
          12.4390869140625,
          25.4390869140625,
          27.4390869140625,
          25.4390869140625,
          22.4390869140625,
          55.5609130859375,
          33.5609130859375,
          14.4390869140625,
          9.5609130859375,
          26.4390869140625,
          9.5609130859375,
          14.4390869140625,
          24.5609130859375,
          12.5609130859375,
          24.4390869140625,
          20.4390869140625,
          21.4390869140625,
          37.4390869140625,
          37.4390869140625,
          31.4390869140625,
          12.5609130859375,
          42.5609130859375,
          31.4390869140625,
          49.5609130859375,
          27.4390869140625,
          45.5609130859375,
          14.4390869140625,
          9.5609130859375,
          20.4390869140625,
          13.4390869140625,
          37.4390869140625,
          20.4390869140625,
          27.5609130859375,
          6.5609130859375,
          38.5609130859375,
          40.5609130859375,
          27.4390869140625,
          33.5609130859375,
          16.4390869140625,
          37.4390869140625,
          0.430633544921875,
          0.5609130859375,
          16.5609130859375,
          45.5609130859375,
          29.4390869140625,
          16.5609130859375,
          22.5609130859375,
          53.5609130859375,
          16.4390869140625,
          49.5609130859375,
          10.4390869140625,
          17.5609130859375,
          10.4390869140625,
          37.4390869140625,
          37.4390869140625
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Residual depending on label value"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Residual"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "type": "histogram",
         "x": [
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          6.430633544921875,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375,
          62.5609130859375
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Residual depending on label value"
        },
        "xaxis": {
         "title": {
          "text": "Label"
         }
        },
        "yaxis": {
         "title": {
          "text": "Residual"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "preds, (adj, alpha) = complete_model.predict(participant_graph.x,\n",
    "                               participant_graph.edge_index,\n",
    "                               participant_graph.edge_attr,\n",
    "                               return_attention_weights=True)\n",
    "preds = np.array(preds.detach().to(\"cpu\"))\n",
    "preds = np.squeeze(preds)\n",
    "labels = np.array(participant_graph.y)\n",
    "labels = np.squeeze(labels)\n",
    "\n",
    "errors = np.abs(labels-preds)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x = labels,\n",
    "    y = errors,\n",
    "    mode = \"markers\",\n",
    "    marker=dict(color=preds)\n",
    "))\n",
    "fig.update_layout(\n",
    "    title=\"Residual depending on label value\",\n",
    "    xaxis_title=\"Label\",\n",
    "    yaxis_title=\"Residual\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(\n",
    "    x = preds)\n",
    ")\n",
    "fig.update_layout(\n",
    "    title=\"Residual depending on label value\",\n",
    "    xaxis_title=\"Label\",\n",
    "    yaxis_title=\"Residual\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "x: %{x}<br>y: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           2.6359491546001705e-20,
           2.6343235443636992e-18,
           3.6446187673229444e-21,
           4.5553459949928917e-20,
           1.057254798568867e-22,
           2.8849697777459854e-20,
           2.6405473175316207e-21,
           7.348664181062841e-22,
           1.062055652355316e-17,
           2.2300876152238073e-21,
           0,
           6.470853606628799e-18,
           1.148573884742264e-19,
           1.433403188917242e-20,
           9.434594592111382e-18,
           6.916179524286522e-17,
           8.478936512998816e-22,
           7.706455318714132e-20,
           1.6674750950745648e-15,
           6.765686419541687e-18,
           1.7447037267223376e-20,
           7.349761467649341e-21,
           1.9630601829494436e-20,
           4.908429877191516e-22,
           3.494410926798341e-20,
           3.2296111032226923e-18,
           2.0133507608646217e-19,
           2.5733334401551103e-22,
           8.668303519930207e-20,
           2.665556404415887e-20,
           2.4548762488967584e-20,
           1.312281753111227e-21,
           1.0721579704023349e-19,
           4.044306510103786e-19,
           4.56159088550024e-19,
           2.298882656742266e-17,
           2.9305609099567025e-18,
           8.711263920524972e-20,
           1.2220204145535836e-20,
           8.750221865554232e-22,
           1.100967986128612e-18,
           8.682600173595449e-20,
           2.9556486048485553e-21,
           2.2645301469373088e-23,
           3.092099357420958e-20,
           1,
           5.807362628120548e-19,
           3.0837228612491516e-21,
           1.5990334242219848e-21,
           8.5213648619763e-18,
           1.3073079210962657e-17,
           1.385275494433434e-19,
           1.8869287411920504e-19,
           1.314401625574125e-20,
           1.463231838793787e-19,
           5.746170598138442e-18,
           3.73753191040732e-20,
           1.1033453288516884e-15,
           6.543043326376121e-23,
           9.187710130585742e-19
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           0,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1,
           1
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1.4690909298474317e-37,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "#0d0887"
          ],
          [
           0.1111111111111111,
           "#46039f"
          ],
          [
           0.2222222222222222,
           "#7201a8"
          ],
          [
           0.3333333333333333,
           "#9c179e"
          ],
          [
           0.4444444444444444,
           "#bd3786"
          ],
          [
           0.5555555555555556,
           "#d8576b"
          ],
          [
           0.6666666666666666,
           "#ed7953"
          ],
          [
           0.7777777777777778,
           "#fb9f3a"
          ],
          [
           0.8888888888888888,
           "#fdca26"
          ],
          [
           1,
           "#f0f921"
          ]
         ]
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Alpha: the message passing strength between nodes"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_geometric.utils import (\n",
    "    add_self_loops,\n",
    "    is_torch_sparse_tensor,\n",
    "    remove_self_loops,\n",
    "    softmax,\n",
    "    to_dense_adj\n",
    ")\n",
    "\n",
    "matrix_alpha = to_dense_adj(adj, edge_attr = alpha).cpu().detach()\n",
    "matrix_alpha = matrix_alpha.squeeze()\n",
    "fig = px.imshow(matrix_alpha)\n",
    "fig.update_layout(\n",
    "    title=\"Alpha: the message passing strength between nodes\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_x_src, param_x_dst = -42.656185150146484 5.747586250305176\n",
      "lin_content_src_params, lin_content_src_params = 6.158009052276611 -1.351555585861206\n",
      "params_edge tensor(-26.7681, device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "tensor(399.3427, device='cuda:0', grad_fn=<UnbindBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin_src_params = [param for param in complete_model.update_node_module.lin_src.parameters()][0]\n",
    "lin_dst_params = [param for param in complete_model.update_node_module.lin_dst.parameters()][0]\n",
    "\n",
    "src_att_lin_params = lin_src_params * complete_model.update_node_module.att_src\n",
    "dst_att_lin_params = lin_dst_params * complete_model.update_node_module.att_dst\n",
    "#lin_params.squeeze()\n",
    "print(\"param_x_src, param_x_dst =\", float(src_att_lin_params), float(dst_att_lin_params))\n",
    "\n",
    "\n",
    "lin_content_src_params = [param for param in complete_model.update_node_module.lin_src.parameters()][0]\n",
    "lin_content_dst_params = [param for param in complete_model.update_node_module.lin_dst.parameters()][0]\n",
    "\n",
    "#lin_params.squeeze()\n",
    "print(\"lin_content_src_params, lin_content_src_params =\", float(lin_content_src_params), float(lin_content_dst_params))\n",
    "\n",
    "lin_edge_params = [param for param in complete_model.update_node_module.lin_edge.parameters()][0]\n",
    "att_lin_edge_params = lin_edge_params * complete_model.update_node_module.att_edge\n",
    "print(\"params_edge\", att_lin_edge_params.squeeze())\n",
    "\n",
    "bias = [param for param in complete_model.update_node_module.bias][0]\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_graph.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "loader = NeighborLoader(\n",
    "    participant_graph,\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[60],\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=1,\n",
    "    input_nodes=participant_graph.train_mask,\n",
    ")\n",
    "\n",
    "sampled_data = next(iter(loader))\n",
    "print(sampled_data.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in complete_model.update_node_module.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(\"1\")\n",
    "print([param for param in complete_model.update_node_module.lin.parameters()])\n",
    "\n",
    "print(\"att_src\",complete_model.update_node_module.att_src)\n",
    "print(\"att_dst\",complete_model.update_node_module.att_dst)\n",
    "print(\"lin\",[param for param in complete_model.update_node_module.lin.parameters()])\n",
    "print(\"lin_edge\",[param for param in complete_model.update_node_module.lin_edge.parameters()])\n",
    "print(\"att_edge\",complete_model.update_node_module.att_edge[0])\n",
    "print(\"bias\",complete_model.update_node_module.bias)\n",
    "\n",
    "lin_params = [param for param in complete_model.update_node_module.lin.parameters()][0]\n",
    "src_att_lin_params = lin_params * complete_model.update_node_module.att_src\n",
    "dst_att_lin_params = lin_params * complete_model.update_node_module.att_dst\n",
    "#lin_params.squeeze()\n",
    "print(\"param_x_src, param_x_dst =\", float(src_att_lin_params), float(dst_att_lin_params))\n",
    "\n",
    "\n",
    "lin_edge_params = [param for param in complete_model.update_node_module.lin_edge.parameters()][0]\n",
    "att_lin_edge_params = lin_edge_params * complete_model.update_node_module.att_edge\n",
    "print(\"params_edge\", att_lin_edge_params.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_semantic_to_liking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
