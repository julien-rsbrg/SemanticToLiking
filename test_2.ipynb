{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader, DataLoader\n",
    "\n",
    "from src.models.nn_layers import MLPModel\n",
    "from src.models.gnn_layers import MyGATConv\n",
    "from src.models.ML_frameworks import GNNFramework\n",
    "import src.loading as loading\n",
    "import src.processing.raw_data_cleaning as raw_data_cleaning\n",
    "\n",
    "from src.visualization.analyse_model import plot_errors_labels_comparison, get_prediction_table\n",
    "\n",
    "from src.pipeline import GeneralizerRun \n",
    "import src.processing.preprocessing as preprocessing\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Load Data: start ==\n",
      "== Load Data: end ==\n"
     ]
    }
   ],
   "source": [
    "data = loading.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start participant_id/n_participants-1:10/112\n",
      "Test function convert_table_to_graph\n",
      "Data(x=[60, 2], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], x_names=[2], edge_attr_names=[1], y_names=[1], train_mask=[60], val_mask=[60])\n",
      "validate: True\n",
      "is undirected: True\n",
      "has_self_loop: tensor(False)\n",
      "end Test function convert_table_to_graph\n",
      "Preprocessing 1\n",
      "Number of Edges before transform: 3540\n",
      "Number of Edges after transform: 2929\n",
      "Preprocessing 2\n",
      "Preprocessing 3\n",
      "Model\n",
      "my_module.bias None\n",
      "== start training ==\n",
      "epoch: 1/10000,\n",
      " train_loss: 0.8794,\n",
      " train_mae: 0.8015,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 2/10000,\n",
      " train_loss: 0.8672,\n",
      " train_mae: 0.7811,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 3/10000,\n",
      " train_loss: 0.8683,\n",
      " train_mae: 0.7831,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 4/10000,\n",
      " train_loss: 0.8616,\n",
      " train_mae: 0.7937,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 5/10000,\n",
      " train_loss: 0.8528,\n",
      " train_mae: 0.8062,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 6/10000,\n",
      " train_loss: 0.8466,\n",
      " train_mae: 0.8153,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 7/10000,\n",
      " train_loss: 0.8430,\n",
      " train_mae: 0.8173,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 8/10000,\n",
      " train_loss: 0.8389,\n",
      " train_mae: 0.8122,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 9/10000,\n",
      " train_loss: 0.8328,\n",
      " train_mae: 0.8024,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 10/10000,\n",
      " train_loss: 0.8262,\n",
      " train_mae: 0.7910,\n",
      " epoch_time_duration: 0.0063\n",
      "\n",
      "epoch: 11/10000,\n",
      " train_loss: 0.8205,\n",
      " train_mae: 0.7811,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 12/10000,\n",
      " train_loss: 0.8162,\n",
      " train_mae: 0.7750,\n",
      " epoch_time_duration: 0.0095\n",
      "\n",
      "epoch: 13/10000,\n",
      " train_loss: 0.8118,\n",
      " train_mae: 0.7734,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 14/10000,\n",
      " train_loss: 0.8066,\n",
      " train_mae: 0.7757,\n",
      " epoch_time_duration: 0.0081\n",
      "\n",
      "epoch: 15/10000,\n",
      " train_loss: 0.8006,\n",
      " train_mae: 0.7802,\n",
      " epoch_time_duration: 0.0061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6940/2740522246.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdata[\"test_sim\"] = subdata[\"senenceBERT_mpnet_similarity\"]\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word1_index\"] = complete_data_table[\"word1\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word2_index\"] = complete_data_table[\"word2\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16/10000,\n",
      " train_loss: 0.7948,\n",
      " train_mae: 0.7851,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 17/10000,\n",
      " train_loss: 0.7897,\n",
      " train_mae: 0.7884,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 18/10000,\n",
      " train_loss: 0.7851,\n",
      " train_mae: 0.7887,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 19/10000,\n",
      " train_loss: 0.7803,\n",
      " train_mae: 0.7858,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 20/10000,\n",
      " train_loss: 0.7751,\n",
      " train_mae: 0.7803,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 21/10000,\n",
      " train_loss: 0.7698,\n",
      " train_mae: 0.7737,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 22/10000,\n",
      " train_loss: 0.7648,\n",
      " train_mae: 0.7676,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 23/10000,\n",
      " train_loss: 0.7602,\n",
      " train_mae: 0.7634,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 24/10000,\n",
      " train_loss: 0.7558,\n",
      " train_mae: 0.7617,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 25/10000,\n",
      " train_loss: 0.7513,\n",
      " train_mae: 0.7625,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 26/10000,\n",
      " train_loss: 0.7467,\n",
      " train_mae: 0.7650,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 27/10000,\n",
      " train_loss: 0.7421,\n",
      " train_mae: 0.7678,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 28/10000,\n",
      " train_loss: 0.7380,\n",
      " train_mae: 0.7698,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 29/10000,\n",
      " train_loss: 0.7341,\n",
      " train_mae: 0.7700,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 30/10000,\n",
      " train_loss: 0.7304,\n",
      " train_mae: 0.7682,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 31/10000,\n",
      " train_loss: 0.7266,\n",
      " train_mae: 0.7647,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 32/10000,\n",
      " train_loss: 0.7230,\n",
      " train_mae: 0.7607,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 33/10000,\n",
      " train_loss: 0.7196,\n",
      " train_mae: 0.7571,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 34/10000,\n",
      " train_loss: 0.7166,\n",
      " train_mae: 0.7549,\n",
      " epoch_time_duration: 0.0028\n",
      "\n",
      "epoch: 35/10000,\n",
      " train_loss: 0.7137,\n",
      " train_mae: 0.7545,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 36/10000,\n",
      " train_loss: 0.7110,\n",
      " train_mae: 0.7557,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 37/10000,\n",
      " train_loss: 0.7084,\n",
      " train_mae: 0.7576,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 38/10000,\n",
      " train_loss: 0.7060,\n",
      " train_mae: 0.7593,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 39/10000,\n",
      " train_loss: 0.7039,\n",
      " train_mae: 0.7601,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 40/10000,\n",
      " train_loss: 0.7020,\n",
      " train_mae: 0.7595,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 41/10000,\n",
      " train_loss: 0.7002,\n",
      " train_mae: 0.7576,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 42/10000,\n",
      " train_loss: 0.6984,\n",
      " train_mae: 0.7551,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 43/10000,\n",
      " train_loss: 0.6967,\n",
      " train_mae: 0.7527,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 44/10000,\n",
      " train_loss: 0.6952,\n",
      " train_mae: 0.7511,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 45/10000,\n",
      " train_loss: 0.6937,\n",
      " train_mae: 0.7508,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 46/10000,\n",
      " train_loss: 0.6922,\n",
      " train_mae: 0.7514,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 47/10000,\n",
      " train_loss: 0.6907,\n",
      " train_mae: 0.7524,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 48/10000,\n",
      " train_loss: 0.6891,\n",
      " train_mae: 0.7533,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 49/10000,\n",
      " train_loss: 0.6874,\n",
      " train_mae: 0.7534,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 50/10000,\n",
      " train_loss: 0.6857,\n",
      " train_mae: 0.7524,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 51/10000,\n",
      " train_loss: 0.6838,\n",
      " train_mae: 0.7506,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 52/10000,\n",
      " train_loss: 0.6818,\n",
      " train_mae: 0.7484,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 53/10000,\n",
      " train_loss: 0.6797,\n",
      " train_mae: 0.7465,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 54/10000,\n",
      " train_loss: 0.6775,\n",
      " train_mae: 0.7452,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 55/10000,\n",
      " train_loss: 0.6751,\n",
      " train_mae: 0.7445,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 56/10000,\n",
      " train_loss: 0.6726,\n",
      " train_mae: 0.7443,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 57/10000,\n",
      " train_loss: 0.6699,\n",
      " train_mae: 0.7441,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 58/10000,\n",
      " train_loss: 0.6671,\n",
      " train_mae: 0.7435,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 59/10000,\n",
      " train_loss: 0.6642,\n",
      " train_mae: 0.7422,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 60/10000,\n",
      " train_loss: 0.6612,\n",
      " train_mae: 0.7402,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 61/10000,\n",
      " train_loss: 0.6581,\n",
      " train_mae: 0.7378,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 62/10000,\n",
      " train_loss: 0.6549,\n",
      " train_mae: 0.7354,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 63/10000,\n",
      " train_loss: 0.6515,\n",
      " train_mae: 0.7333,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 64/10000,\n",
      " train_loss: 0.6481,\n",
      " train_mae: 0.7317,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 65/10000,\n",
      " train_loss: 0.6446,\n",
      " train_mae: 0.7304,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 66/10000,\n",
      " train_loss: 0.6411,\n",
      " train_mae: 0.7290,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 67/10000,\n",
      " train_loss: 0.6374,\n",
      " train_mae: 0.7274,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 68/10000,\n",
      " train_loss: 0.6338,\n",
      " train_mae: 0.7254,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 69/10000,\n",
      " train_loss: 0.6300,\n",
      " train_mae: 0.7228,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 70/10000,\n",
      " train_loss: 0.6262,\n",
      " train_mae: 0.7200,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 71/10000,\n",
      " train_loss: 0.6224,\n",
      " train_mae: 0.7172,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 72/10000,\n",
      " train_loss: 0.6186,\n",
      " train_mae: 0.7147,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 73/10000,\n",
      " train_loss: 0.6147,\n",
      " train_mae: 0.7124,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 74/10000,\n",
      " train_loss: 0.6109,\n",
      " train_mae: 0.7104,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 75/10000,\n",
      " train_loss: 0.6070,\n",
      " train_mae: 0.7083,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 76/10000,\n",
      " train_loss: 0.6031,\n",
      " train_mae: 0.7060,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 77/10000,\n",
      " train_loss: 0.5993,\n",
      " train_mae: 0.7034,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 78/10000,\n",
      " train_loss: 0.5954,\n",
      " train_mae: 0.7005,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 79/10000,\n",
      " train_loss: 0.5916,\n",
      " train_mae: 0.6976,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 80/10000,\n",
      " train_loss: 0.5878,\n",
      " train_mae: 0.6948,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 81/10000,\n",
      " train_loss: 0.5840,\n",
      " train_mae: 0.6921,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 82/10000,\n",
      " train_loss: 0.5802,\n",
      " train_mae: 0.6897,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 83/10000,\n",
      " train_loss: 0.5765,\n",
      " train_mae: 0.6875,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 84/10000,\n",
      " train_loss: 0.5728,\n",
      " train_mae: 0.6851,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 85/10000,\n",
      " train_loss: 0.5691,\n",
      " train_mae: 0.6826,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 86/10000,\n",
      " train_loss: 0.5654,\n",
      " train_mae: 0.6800,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 87/10000,\n",
      " train_loss: 0.5617,\n",
      " train_mae: 0.6772,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 88/10000,\n",
      " train_loss: 0.5581,\n",
      " train_mae: 0.6746,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 89/10000,\n",
      " train_loss: 0.5545,\n",
      " train_mae: 0.6721,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 90/10000,\n",
      " train_loss: 0.5509,\n",
      " train_mae: 0.6698,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 91/10000,\n",
      " train_loss: 0.5473,\n",
      " train_mae: 0.6676,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 92/10000,\n",
      " train_loss: 0.5437,\n",
      " train_mae: 0.6655,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 93/10000,\n",
      " train_loss: 0.5401,\n",
      " train_mae: 0.6633,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 94/10000,\n",
      " train_loss: 0.5365,\n",
      " train_mae: 0.6610,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 95/10000,\n",
      " train_loss: 0.5329,\n",
      " train_mae: 0.6587,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 96/10000,\n",
      " train_loss: 0.5294,\n",
      " train_mae: 0.6564,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 97/10000,\n",
      " train_loss: 0.5258,\n",
      " train_mae: 0.6543,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 98/10000,\n",
      " train_loss: 0.5223,\n",
      " train_mae: 0.6523,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 99/10000,\n",
      " train_loss: 0.5187,\n",
      " train_mae: 0.6504,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 100/10000,\n",
      " train_loss: 0.5152,\n",
      " train_mae: 0.6486,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 101/10000,\n",
      " train_loss: 0.5117,\n",
      " train_mae: 0.6467,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 102/10000,\n",
      " train_loss: 0.5082,\n",
      " train_mae: 0.6447,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 103/10000,\n",
      " train_loss: 0.5047,\n",
      " train_mae: 0.6427,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 104/10000,\n",
      " train_loss: 0.5012,\n",
      " train_mae: 0.6408,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 105/10000,\n",
      " train_loss: 0.4978,\n",
      " train_mae: 0.6389,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 106/10000,\n",
      " train_loss: 0.4944,\n",
      " train_mae: 0.6372,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 107/10000,\n",
      " train_loss: 0.4910,\n",
      " train_mae: 0.6355,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 108/10000,\n",
      " train_loss: 0.4877,\n",
      " train_mae: 0.6337,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 109/10000,\n",
      " train_loss: 0.4843,\n",
      " train_mae: 0.6319,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 110/10000,\n",
      " train_loss: 0.4810,\n",
      " train_mae: 0.6301,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 111/10000,\n",
      " train_loss: 0.4778,\n",
      " train_mae: 0.6282,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 112/10000,\n",
      " train_loss: 0.4745,\n",
      " train_mae: 0.6263,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 113/10000,\n",
      " train_loss: 0.4713,\n",
      " train_mae: 0.6245,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 114/10000,\n",
      " train_loss: 0.4681,\n",
      " train_mae: 0.6226,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 115/10000,\n",
      " train_loss: 0.4650,\n",
      " train_mae: 0.6208,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 116/10000,\n",
      " train_loss: 0.4618,\n",
      " train_mae: 0.6189,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 117/10000,\n",
      " train_loss: 0.4587,\n",
      " train_mae: 0.6170,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 118/10000,\n",
      " train_loss: 0.4556,\n",
      " train_mae: 0.6150,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 119/10000,\n",
      " train_loss: 0.4525,\n",
      " train_mae: 0.6130,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 120/10000,\n",
      " train_loss: 0.4495,\n",
      " train_mae: 0.6109,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 121/10000,\n",
      " train_loss: 0.4464,\n",
      " train_mae: 0.6089,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 122/10000,\n",
      " train_loss: 0.4434,\n",
      " train_mae: 0.6069,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 123/10000,\n",
      " train_loss: 0.4404,\n",
      " train_mae: 0.6049,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 124/10000,\n",
      " train_loss: 0.4375,\n",
      " train_mae: 0.6028,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 125/10000,\n",
      " train_loss: 0.4345,\n",
      " train_mae: 0.6008,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 126/10000,\n",
      " train_loss: 0.4316,\n",
      " train_mae: 0.5987,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 127/10000,\n",
      " train_loss: 0.4287,\n",
      " train_mae: 0.5966,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 128/10000,\n",
      " train_loss: 0.4258,\n",
      " train_mae: 0.5945,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 129/10000,\n",
      " train_loss: 0.4230,\n",
      " train_mae: 0.5925,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 130/10000,\n",
      " train_loss: 0.4201,\n",
      " train_mae: 0.5906,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 131/10000,\n",
      " train_loss: 0.4173,\n",
      " train_mae: 0.5886,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 132/10000,\n",
      " train_loss: 0.4146,\n",
      " train_mae: 0.5866,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 133/10000,\n",
      " train_loss: 0.4118,\n",
      " train_mae: 0.5847,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 134/10000,\n",
      " train_loss: 0.4091,\n",
      " train_mae: 0.5827,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 135/10000,\n",
      " train_loss: 0.4063,\n",
      " train_mae: 0.5809,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 136/10000,\n",
      " train_loss: 0.4035,\n",
      " train_mae: 0.5791,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 137/10000,\n",
      " train_loss: 0.4008,\n",
      " train_mae: 0.5773,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 138/10000,\n",
      " train_loss: 0.3980,\n",
      " train_mae: 0.5754,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 139/10000,\n",
      " train_loss: 0.3952,\n",
      " train_mae: 0.5735,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 140/10000,\n",
      " train_loss: 0.3924,\n",
      " train_mae: 0.5716,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 141/10000,\n",
      " train_loss: 0.3896,\n",
      " train_mae: 0.5696,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 142/10000,\n",
      " train_loss: 0.3867,\n",
      " train_mae: 0.5676,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 143/10000,\n",
      " train_loss: 0.3839,\n",
      " train_mae: 0.5656,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 144/10000,\n",
      " train_loss: 0.3811,\n",
      " train_mae: 0.5637,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 145/10000,\n",
      " train_loss: 0.3783,\n",
      " train_mae: 0.5618,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 146/10000,\n",
      " train_loss: 0.3755,\n",
      " train_mae: 0.5598,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 147/10000,\n",
      " train_loss: 0.3727,\n",
      " train_mae: 0.5578,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 148/10000,\n",
      " train_loss: 0.3699,\n",
      " train_mae: 0.5557,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 149/10000,\n",
      " train_loss: 0.3671,\n",
      " train_mae: 0.5537,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 150/10000,\n",
      " train_loss: 0.3644,\n",
      " train_mae: 0.5517,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 151/10000,\n",
      " train_loss: 0.3616,\n",
      " train_mae: 0.5497,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 152/10000,\n",
      " train_loss: 0.3588,\n",
      " train_mae: 0.5477,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 153/10000,\n",
      " train_loss: 0.3561,\n",
      " train_mae: 0.5457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 154/10000,\n",
      " train_loss: 0.3534,\n",
      " train_mae: 0.5436,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 155/10000,\n",
      " train_loss: 0.3507,\n",
      " train_mae: 0.5415,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 156/10000,\n",
      " train_loss: 0.3480,\n",
      " train_mae: 0.5394,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 157/10000,\n",
      " train_loss: 0.3453,\n",
      " train_mae: 0.5374,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 158/10000,\n",
      " train_loss: 0.3426,\n",
      " train_mae: 0.5353,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 159/10000,\n",
      " train_loss: 0.3399,\n",
      " train_mae: 0.5333,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 160/10000,\n",
      " train_loss: 0.3373,\n",
      " train_mae: 0.5312,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 161/10000,\n",
      " train_loss: 0.3347,\n",
      " train_mae: 0.5291,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 162/10000,\n",
      " train_loss: 0.3321,\n",
      " train_mae: 0.5270,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 163/10000,\n",
      " train_loss: 0.3295,\n",
      " train_mae: 0.5249,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 164/10000,\n",
      " train_loss: 0.3270,\n",
      " train_mae: 0.5228,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 165/10000,\n",
      " train_loss: 0.3244,\n",
      " train_mae: 0.5207,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 166/10000,\n",
      " train_loss: 0.3219,\n",
      " train_mae: 0.5186,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 167/10000,\n",
      " train_loss: 0.3194,\n",
      " train_mae: 0.5165,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 168/10000,\n",
      " train_loss: 0.3170,\n",
      " train_mae: 0.5144,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 169/10000,\n",
      " train_loss: 0.3145,\n",
      " train_mae: 0.5123,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 170/10000,\n",
      " train_loss: 0.3121,\n",
      " train_mae: 0.5102,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 171/10000,\n",
      " train_loss: 0.3097,\n",
      " train_mae: 0.5081,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 172/10000,\n",
      " train_loss: 0.3074,\n",
      " train_mae: 0.5060,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 173/10000,\n",
      " train_loss: 0.3051,\n",
      " train_mae: 0.5039,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 174/10000,\n",
      " train_loss: 0.3028,\n",
      " train_mae: 0.5018,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 175/10000,\n",
      " train_loss: 0.3005,\n",
      " train_mae: 0.4997,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 176/10000,\n",
      " train_loss: 0.2982,\n",
      " train_mae: 0.4976,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 177/10000,\n",
      " train_loss: 0.2960,\n",
      " train_mae: 0.4955,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 178/10000,\n",
      " train_loss: 0.2938,\n",
      " train_mae: 0.4934,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 179/10000,\n",
      " train_loss: 0.2917,\n",
      " train_mae: 0.4913,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 180/10000,\n",
      " train_loss: 0.2896,\n",
      " train_mae: 0.4893,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 181/10000,\n",
      " train_loss: 0.2875,\n",
      " train_mae: 0.4872,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 182/10000,\n",
      " train_loss: 0.2854,\n",
      " train_mae: 0.4851,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 183/10000,\n",
      " train_loss: 0.2834,\n",
      " train_mae: 0.4831,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 184/10000,\n",
      " train_loss: 0.2814,\n",
      " train_mae: 0.4810,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 185/10000,\n",
      " train_loss: 0.2795,\n",
      " train_mae: 0.4790,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 186/10000,\n",
      " train_loss: 0.2775,\n",
      " train_mae: 0.4770,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 187/10000,\n",
      " train_loss: 0.2756,\n",
      " train_mae: 0.4750,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 188/10000,\n",
      " train_loss: 0.2738,\n",
      " train_mae: 0.4730,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 189/10000,\n",
      " train_loss: 0.2720,\n",
      " train_mae: 0.4710,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 190/10000,\n",
      " train_loss: 0.2702,\n",
      " train_mae: 0.4690,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 191/10000,\n",
      " train_loss: 0.2684,\n",
      " train_mae: 0.4670,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 192/10000,\n",
      " train_loss: 0.2667,\n",
      " train_mae: 0.4651,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 193/10000,\n",
      " train_loss: 0.2650,\n",
      " train_mae: 0.4631,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 194/10000,\n",
      " train_loss: 0.2633,\n",
      " train_mae: 0.4612,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 195/10000,\n",
      " train_loss: 0.2617,\n",
      " train_mae: 0.4593,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 196/10000,\n",
      " train_loss: 0.2600,\n",
      " train_mae: 0.4577,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 197/10000,\n",
      " train_loss: 0.2585,\n",
      " train_mae: 0.4570,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 198/10000,\n",
      " train_loss: 0.2569,\n",
      " train_mae: 0.4563,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 199/10000,\n",
      " train_loss: 0.2554,\n",
      " train_mae: 0.4556,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 200/10000,\n",
      " train_loss: 0.2539,\n",
      " train_mae: 0.4549,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 201/10000,\n",
      " train_loss: 0.2524,\n",
      " train_mae: 0.4541,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 202/10000,\n",
      " train_loss: 0.2510,\n",
      " train_mae: 0.4534,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 203/10000,\n",
      " train_loss: 0.2496,\n",
      " train_mae: 0.4526,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 204/10000,\n",
      " train_loss: 0.2482,\n",
      " train_mae: 0.4519,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 205/10000,\n",
      " train_loss: 0.2468,\n",
      " train_mae: 0.4511,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 206/10000,\n",
      " train_loss: 0.2455,\n",
      " train_mae: 0.4503,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 207/10000,\n",
      " train_loss: 0.2442,\n",
      " train_mae: 0.4495,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 208/10000,\n",
      " train_loss: 0.2429,\n",
      " train_mae: 0.4487,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 209/10000,\n",
      " train_loss: 0.2416,\n",
      " train_mae: 0.4479,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 210/10000,\n",
      " train_loss: 0.2404,\n",
      " train_mae: 0.4471,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 211/10000,\n",
      " train_loss: 0.2391,\n",
      " train_mae: 0.4462,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 212/10000,\n",
      " train_loss: 0.2379,\n",
      " train_mae: 0.4454,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 213/10000,\n",
      " train_loss: 0.2367,\n",
      " train_mae: 0.4445,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 214/10000,\n",
      " train_loss: 0.2355,\n",
      " train_mae: 0.4436,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 215/10000,\n",
      " train_loss: 0.2343,\n",
      " train_mae: 0.4427,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 216/10000,\n",
      " train_loss: 0.2332,\n",
      " train_mae: 0.4418,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 217/10000,\n",
      " train_loss: 0.2320,\n",
      " train_mae: 0.4409,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 218/10000,\n",
      " train_loss: 0.2309,\n",
      " train_mae: 0.4400,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 219/10000,\n",
      " train_loss: 0.2298,\n",
      " train_mae: 0.4390,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 220/10000,\n",
      " train_loss: 0.2287,\n",
      " train_mae: 0.4381,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 221/10000,\n",
      " train_loss: 0.2276,\n",
      " train_mae: 0.4371,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 222/10000,\n",
      " train_loss: 0.2265,\n",
      " train_mae: 0.4361,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 223/10000,\n",
      " train_loss: 0.2254,\n",
      " train_mae: 0.4351,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 224/10000,\n",
      " train_loss: 0.2244,\n",
      " train_mae: 0.4341,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 225/10000,\n",
      " train_loss: 0.2233,\n",
      " train_mae: 0.4331,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 226/10000,\n",
      " train_loss: 0.2223,\n",
      " train_mae: 0.4320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 227/10000,\n",
      " train_loss: 0.2213,\n",
      " train_mae: 0.4310,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 228/10000,\n",
      " train_loss: 0.2202,\n",
      " train_mae: 0.4300,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 229/10000,\n",
      " train_loss: 0.2192,\n",
      " train_mae: 0.4289,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 230/10000,\n",
      " train_loss: 0.2182,\n",
      " train_mae: 0.4278,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 231/10000,\n",
      " train_loss: 0.2172,\n",
      " train_mae: 0.4267,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 232/10000,\n",
      " train_loss: 0.2162,\n",
      " train_mae: 0.4257,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 233/10000,\n",
      " train_loss: 0.2152,\n",
      " train_mae: 0.4246,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 234/10000,\n",
      " train_loss: 0.2143,\n",
      " train_mae: 0.4235,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 235/10000,\n",
      " train_loss: 0.2133,\n",
      " train_mae: 0.4224,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 236/10000,\n",
      " train_loss: 0.2123,\n",
      " train_mae: 0.4213,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 237/10000,\n",
      " train_loss: 0.2114,\n",
      " train_mae: 0.4202,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 238/10000,\n",
      " train_loss: 0.2105,\n",
      " train_mae: 0.4190,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 239/10000,\n",
      " train_loss: 0.2095,\n",
      " train_mae: 0.4179,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 240/10000,\n",
      " train_loss: 0.2086,\n",
      " train_mae: 0.4168,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 241/10000,\n",
      " train_loss: 0.2077,\n",
      " train_mae: 0.4157,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 242/10000,\n",
      " train_loss: 0.2068,\n",
      " train_mae: 0.4145,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 243/10000,\n",
      " train_loss: 0.2059,\n",
      " train_mae: 0.4134,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 244/10000,\n",
      " train_loss: 0.2050,\n",
      " train_mae: 0.4123,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 245/10000,\n",
      " train_loss: 0.2041,\n",
      " train_mae: 0.4111,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 246/10000,\n",
      " train_loss: 0.2032,\n",
      " train_mae: 0.4100,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 247/10000,\n",
      " train_loss: 0.2023,\n",
      " train_mae: 0.4089,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 248/10000,\n",
      " train_loss: 0.2015,\n",
      " train_mae: 0.4077,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 249/10000,\n",
      " train_loss: 0.2006,\n",
      " train_mae: 0.4066,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 250/10000,\n",
      " train_loss: 0.1997,\n",
      " train_mae: 0.4055,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 251/10000,\n",
      " train_loss: 0.1989,\n",
      " train_mae: 0.4044,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 252/10000,\n",
      " train_loss: 0.1981,\n",
      " train_mae: 0.4032,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 253/10000,\n",
      " train_loss: 0.1972,\n",
      " train_mae: 0.4021,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 254/10000,\n",
      " train_loss: 0.1964,\n",
      " train_mae: 0.4010,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 255/10000,\n",
      " train_loss: 0.1956,\n",
      " train_mae: 0.3999,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 256/10000,\n",
      " train_loss: 0.1948,\n",
      " train_mae: 0.3988,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 257/10000,\n",
      " train_loss: 0.1940,\n",
      " train_mae: 0.3976,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 258/10000,\n",
      " train_loss: 0.1932,\n",
      " train_mae: 0.3965,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 259/10000,\n",
      " train_loss: 0.1924,\n",
      " train_mae: 0.3954,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 260/10000,\n",
      " train_loss: 0.1916,\n",
      " train_mae: 0.3943,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 261/10000,\n",
      " train_loss: 0.1908,\n",
      " train_mae: 0.3932,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 262/10000,\n",
      " train_loss: 0.1901,\n",
      " train_mae: 0.3921,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 263/10000,\n",
      " train_loss: 0.1893,\n",
      " train_mae: 0.3911,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 264/10000,\n",
      " train_loss: 0.1885,\n",
      " train_mae: 0.3900,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 265/10000,\n",
      " train_loss: 0.1878,\n",
      " train_mae: 0.3889,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 266/10000,\n",
      " train_loss: 0.1870,\n",
      " train_mae: 0.3878,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 267/10000,\n",
      " train_loss: 0.1863,\n",
      " train_mae: 0.3868,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 268/10000,\n",
      " train_loss: 0.1856,\n",
      " train_mae: 0.3857,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 269/10000,\n",
      " train_loss: 0.1849,\n",
      " train_mae: 0.3846,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 270/10000,\n",
      " train_loss: 0.1841,\n",
      " train_mae: 0.3836,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 271/10000,\n",
      " train_loss: 0.1834,\n",
      " train_mae: 0.3825,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 272/10000,\n",
      " train_loss: 0.1827,\n",
      " train_mae: 0.3815,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 273/10000,\n",
      " train_loss: 0.1820,\n",
      " train_mae: 0.3805,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 274/10000,\n",
      " train_loss: 0.1813,\n",
      " train_mae: 0.3794,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 275/10000,\n",
      " train_loss: 0.1807,\n",
      " train_mae: 0.3784,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 276/10000,\n",
      " train_loss: 0.1800,\n",
      " train_mae: 0.3774,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 277/10000,\n",
      " train_loss: 0.1793,\n",
      " train_mae: 0.3764,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 278/10000,\n",
      " train_loss: 0.1786,\n",
      " train_mae: 0.3753,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 279/10000,\n",
      " train_loss: 0.1780,\n",
      " train_mae: 0.3743,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 280/10000,\n",
      " train_loss: 0.1773,\n",
      " train_mae: 0.3733,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 281/10000,\n",
      " train_loss: 0.1767,\n",
      " train_mae: 0.3723,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 282/10000,\n",
      " train_loss: 0.1760,\n",
      " train_mae: 0.3714,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 283/10000,\n",
      " train_loss: 0.1754,\n",
      " train_mae: 0.3704,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 284/10000,\n",
      " train_loss: 0.1748,\n",
      " train_mae: 0.3694,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 285/10000,\n",
      " train_loss: 0.1742,\n",
      " train_mae: 0.3684,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 286/10000,\n",
      " train_loss: 0.1735,\n",
      " train_mae: 0.3674,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 287/10000,\n",
      " train_loss: 0.1729,\n",
      " train_mae: 0.3665,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 288/10000,\n",
      " train_loss: 0.1723,\n",
      " train_mae: 0.3655,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 289/10000,\n",
      " train_loss: 0.1717,\n",
      " train_mae: 0.3645,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 290/10000,\n",
      " train_loss: 0.1711,\n",
      " train_mae: 0.3636,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 291/10000,\n",
      " train_loss: 0.1705,\n",
      " train_mae: 0.3626,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 292/10000,\n",
      " train_loss: 0.1700,\n",
      " train_mae: 0.3617,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 293/10000,\n",
      " train_loss: 0.1694,\n",
      " train_mae: 0.3608,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 294/10000,\n",
      " train_loss: 0.1688,\n",
      " train_mae: 0.3598,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 295/10000,\n",
      " train_loss: 0.1682,\n",
      " train_mae: 0.3589,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 296/10000,\n",
      " train_loss: 0.1677,\n",
      " train_mae: 0.3580,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 297/10000,\n",
      " train_loss: 0.1671,\n",
      " train_mae: 0.3571,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 298/10000,\n",
      " train_loss: 0.1666,\n",
      " train_mae: 0.3561,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 299/10000,\n",
      " train_loss: 0.1660,\n",
      " train_mae: 0.3552,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 300/10000,\n",
      " train_loss: 0.1655,\n",
      " train_mae: 0.3543,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 301/10000,\n",
      " train_loss: 0.1650,\n",
      " train_mae: 0.3534,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 302/10000,\n",
      " train_loss: 0.1644,\n",
      " train_mae: 0.3525,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 303/10000,\n",
      " train_loss: 0.1639,\n",
      " train_mae: 0.3516,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 304/10000,\n",
      " train_loss: 0.1634,\n",
      " train_mae: 0.3507,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 305/10000,\n",
      " train_loss: 0.1629,\n",
      " train_mae: 0.3498,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 306/10000,\n",
      " train_loss: 0.1624,\n",
      " train_mae: 0.3489,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 307/10000,\n",
      " train_loss: 0.1619,\n",
      " train_mae: 0.3481,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 308/10000,\n",
      " train_loss: 0.1614,\n",
      " train_mae: 0.3472,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 309/10000,\n",
      " train_loss: 0.1609,\n",
      " train_mae: 0.3463,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 310/10000,\n",
      " train_loss: 0.1604,\n",
      " train_mae: 0.3454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 311/10000,\n",
      " train_loss: 0.1599,\n",
      " train_mae: 0.3446,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 312/10000,\n",
      " train_loss: 0.1594,\n",
      " train_mae: 0.3437,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 313/10000,\n",
      " train_loss: 0.1589,\n",
      " train_mae: 0.3429,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 314/10000,\n",
      " train_loss: 0.1585,\n",
      " train_mae: 0.3420,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 315/10000,\n",
      " train_loss: 0.1580,\n",
      " train_mae: 0.3412,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 316/10000,\n",
      " train_loss: 0.1575,\n",
      " train_mae: 0.3403,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 317/10000,\n",
      " train_loss: 0.1571,\n",
      " train_mae: 0.3395,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 318/10000,\n",
      " train_loss: 0.1566,\n",
      " train_mae: 0.3386,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 319/10000,\n",
      " train_loss: 0.1562,\n",
      " train_mae: 0.3378,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 320/10000,\n",
      " train_loss: 0.1557,\n",
      " train_mae: 0.3369,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 321/10000,\n",
      " train_loss: 0.1553,\n",
      " train_mae: 0.3361,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 322/10000,\n",
      " train_loss: 0.1549,\n",
      " train_mae: 0.3353,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 323/10000,\n",
      " train_loss: 0.1544,\n",
      " train_mae: 0.3345,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 324/10000,\n",
      " train_loss: 0.1540,\n",
      " train_mae: 0.3337,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 325/10000,\n",
      " train_loss: 0.1536,\n",
      " train_mae: 0.3328,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 326/10000,\n",
      " train_loss: 0.1532,\n",
      " train_mae: 0.3320,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 327/10000,\n",
      " train_loss: 0.1528,\n",
      " train_mae: 0.3312,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 328/10000,\n",
      " train_loss: 0.1524,\n",
      " train_mae: 0.3304,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 329/10000,\n",
      " train_loss: 0.1520,\n",
      " train_mae: 0.3296,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 330/10000,\n",
      " train_loss: 0.1516,\n",
      " train_mae: 0.3288,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 331/10000,\n",
      " train_loss: 0.1512,\n",
      " train_mae: 0.3280,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 332/10000,\n",
      " train_loss: 0.1508,\n",
      " train_mae: 0.3272,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 333/10000,\n",
      " train_loss: 0.1504,\n",
      " train_mae: 0.3264,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 334/10000,\n",
      " train_loss: 0.1500,\n",
      " train_mae: 0.3257,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 335/10000,\n",
      " train_loss: 0.1496,\n",
      " train_mae: 0.3249,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 336/10000,\n",
      " train_loss: 0.1493,\n",
      " train_mae: 0.3241,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 337/10000,\n",
      " train_loss: 0.1489,\n",
      " train_mae: 0.3233,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 338/10000,\n",
      " train_loss: 0.1485,\n",
      " train_mae: 0.3226,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 339/10000,\n",
      " train_loss: 0.1482,\n",
      " train_mae: 0.3218,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 340/10000,\n",
      " train_loss: 0.1478,\n",
      " train_mae: 0.3210,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 341/10000,\n",
      " train_loss: 0.1475,\n",
      " train_mae: 0.3203,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 342/10000,\n",
      " train_loss: 0.1471,\n",
      " train_mae: 0.3195,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 343/10000,\n",
      " train_loss: 0.1468,\n",
      " train_mae: 0.3188,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 344/10000,\n",
      " train_loss: 0.1464,\n",
      " train_mae: 0.3180,\n",
      " epoch_time_duration: 0.0155\n",
      "\n",
      "epoch: 345/10000,\n",
      " train_loss: 0.1461,\n",
      " train_mae: 0.3173,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 346/10000,\n",
      " train_loss: 0.1457,\n",
      " train_mae: 0.3165,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 347/10000,\n",
      " train_loss: 0.1454,\n",
      " train_mae: 0.3158,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 348/10000,\n",
      " train_loss: 0.1451,\n",
      " train_mae: 0.3151,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 349/10000,\n",
      " train_loss: 0.1447,\n",
      " train_mae: 0.3143,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 350/10000,\n",
      " train_loss: 0.1444,\n",
      " train_mae: 0.3136,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 351/10000,\n",
      " train_loss: 0.1441,\n",
      " train_mae: 0.3129,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 352/10000,\n",
      " train_loss: 0.1438,\n",
      " train_mae: 0.3122,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 353/10000,\n",
      " train_loss: 0.1435,\n",
      " train_mae: 0.3114,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 354/10000,\n",
      " train_loss: 0.1432,\n",
      " train_mae: 0.3107,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 355/10000,\n",
      " train_loss: 0.1429,\n",
      " train_mae: 0.3100,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 356/10000,\n",
      " train_loss: 0.1426,\n",
      " train_mae: 0.3093,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 357/10000,\n",
      " train_loss: 0.1423,\n",
      " train_mae: 0.3086,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 358/10000,\n",
      " train_loss: 0.1420,\n",
      " train_mae: 0.3079,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 359/10000,\n",
      " train_loss: 0.1417,\n",
      " train_mae: 0.3072,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 360/10000,\n",
      " train_loss: 0.1414,\n",
      " train_mae: 0.3065,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 361/10000,\n",
      " train_loss: 0.1411,\n",
      " train_mae: 0.3058,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 362/10000,\n",
      " train_loss: 0.1408,\n",
      " train_mae: 0.3051,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 363/10000,\n",
      " train_loss: 0.1405,\n",
      " train_mae: 0.3045,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 364/10000,\n",
      " train_loss: 0.1403,\n",
      " train_mae: 0.3038,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 365/10000,\n",
      " train_loss: 0.1400,\n",
      " train_mae: 0.3031,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 366/10000,\n",
      " train_loss: 0.1397,\n",
      " train_mae: 0.3024,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 367/10000,\n",
      " train_loss: 0.1395,\n",
      " train_mae: 0.3018,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 368/10000,\n",
      " train_loss: 0.1392,\n",
      " train_mae: 0.3011,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 369/10000,\n",
      " train_loss: 0.1389,\n",
      " train_mae: 0.3004,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 370/10000,\n",
      " train_loss: 0.1387,\n",
      " train_mae: 0.2998,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 371/10000,\n",
      " train_loss: 0.1384,\n",
      " train_mae: 0.2991,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 372/10000,\n",
      " train_loss: 0.1382,\n",
      " train_mae: 0.2985,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 373/10000,\n",
      " train_loss: 0.1379,\n",
      " train_mae: 0.2978,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 374/10000,\n",
      " train_loss: 0.1377,\n",
      " train_mae: 0.2972,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 375/10000,\n",
      " train_loss: 0.1374,\n",
      " train_mae: 0.2965,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 376/10000,\n",
      " train_loss: 0.1372,\n",
      " train_mae: 0.2959,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 377/10000,\n",
      " train_loss: 0.1370,\n",
      " train_mae: 0.2952,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 378/10000,\n",
      " train_loss: 0.1367,\n",
      " train_mae: 0.2946,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 379/10000,\n",
      " train_loss: 0.1365,\n",
      " train_mae: 0.2940,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 380/10000,\n",
      " train_loss: 0.1363,\n",
      " train_mae: 0.2933,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 381/10000,\n",
      " train_loss: 0.1360,\n",
      " train_mae: 0.2927,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 382/10000,\n",
      " train_loss: 0.1358,\n",
      " train_mae: 0.2921,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 383/10000,\n",
      " train_loss: 0.1356,\n",
      " train_mae: 0.2915,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 384/10000,\n",
      " train_loss: 0.1354,\n",
      " train_mae: 0.2909,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 385/10000,\n",
      " train_loss: 0.1352,\n",
      " train_mae: 0.2903,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 386/10000,\n",
      " train_loss: 0.1349,\n",
      " train_mae: 0.2897,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 387/10000,\n",
      " train_loss: 0.1347,\n",
      " train_mae: 0.2890,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 388/10000,\n",
      " train_loss: 0.1345,\n",
      " train_mae: 0.2884,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 389/10000,\n",
      " train_loss: 0.1343,\n",
      " train_mae: 0.2878,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 390/10000,\n",
      " train_loss: 0.1341,\n",
      " train_mae: 0.2873,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 391/10000,\n",
      " train_loss: 0.1339,\n",
      " train_mae: 0.2867,\n",
      " epoch_time_duration: 0.0076\n",
      "\n",
      "epoch: 392/10000,\n",
      " train_loss: 0.1337,\n",
      " train_mae: 0.2861,\n",
      " epoch_time_duration: 0.0057\n",
      "\n",
      "epoch: 393/10000,\n",
      " train_loss: 0.1335,\n",
      " train_mae: 0.2855,\n",
      " epoch_time_duration: 0.0070\n",
      "\n",
      "epoch: 394/10000,\n",
      " train_loss: 0.1333,\n",
      " train_mae: 0.2849,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 395/10000,\n",
      " train_loss: 0.1331,\n",
      " train_mae: 0.2843,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 396/10000,\n",
      " train_loss: 0.1329,\n",
      " train_mae: 0.2837,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 397/10000,\n",
      " train_loss: 0.1327,\n",
      " train_mae: 0.2832,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 398/10000,\n",
      " train_loss: 0.1326,\n",
      " train_mae: 0.2826,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 399/10000,\n",
      " train_loss: 0.1324,\n",
      " train_mae: 0.2820,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 400/10000,\n",
      " train_loss: 0.1322,\n",
      " train_mae: 0.2815,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 401/10000,\n",
      " train_loss: 0.1320,\n",
      " train_mae: 0.2809,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 402/10000,\n",
      " train_loss: 0.1318,\n",
      " train_mae: 0.2803,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 403/10000,\n",
      " train_loss: 0.1317,\n",
      " train_mae: 0.2798,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 404/10000,\n",
      " train_loss: 0.1315,\n",
      " train_mae: 0.2792,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 405/10000,\n",
      " train_loss: 0.1313,\n",
      " train_mae: 0.2787,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 406/10000,\n",
      " train_loss: 0.1312,\n",
      " train_mae: 0.2781,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 407/10000,\n",
      " train_loss: 0.1310,\n",
      " train_mae: 0.2776,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 408/10000,\n",
      " train_loss: 0.1308,\n",
      " train_mae: 0.2771,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 409/10000,\n",
      " train_loss: 0.1307,\n",
      " train_mae: 0.2765,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 410/10000,\n",
      " train_loss: 0.1305,\n",
      " train_mae: 0.2760,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 411/10000,\n",
      " train_loss: 0.1303,\n",
      " train_mae: 0.2754,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 412/10000,\n",
      " train_loss: 0.1302,\n",
      " train_mae: 0.2749,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 413/10000,\n",
      " train_loss: 0.1300,\n",
      " train_mae: 0.2744,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 414/10000,\n",
      " train_loss: 0.1299,\n",
      " train_mae: 0.2739,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 415/10000,\n",
      " train_loss: 0.1297,\n",
      " train_mae: 0.2733,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 416/10000,\n",
      " train_loss: 0.1296,\n",
      " train_mae: 0.2728,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 417/10000,\n",
      " train_loss: 0.1294,\n",
      " train_mae: 0.2723,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 418/10000,\n",
      " train_loss: 0.1293,\n",
      " train_mae: 0.2718,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 419/10000,\n",
      " train_loss: 0.1291,\n",
      " train_mae: 0.2713,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 420/10000,\n",
      " train_loss: 0.1290,\n",
      " train_mae: 0.2708,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 421/10000,\n",
      " train_loss: 0.1289,\n",
      " train_mae: 0.2703,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 422/10000,\n",
      " train_loss: 0.1287,\n",
      " train_mae: 0.2698,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 423/10000,\n",
      " train_loss: 0.1286,\n",
      " train_mae: 0.2693,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 424/10000,\n",
      " train_loss: 0.1285,\n",
      " train_mae: 0.2688,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 425/10000,\n",
      " train_loss: 0.1283,\n",
      " train_mae: 0.2683,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 426/10000,\n",
      " train_loss: 0.1282,\n",
      " train_mae: 0.2678,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 427/10000,\n",
      " train_loss: 0.1281,\n",
      " train_mae: 0.2673,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 428/10000,\n",
      " train_loss: 0.1279,\n",
      " train_mae: 0.2668,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 429/10000,\n",
      " train_loss: 0.1278,\n",
      " train_mae: 0.2664,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 430/10000,\n",
      " train_loss: 0.1277,\n",
      " train_mae: 0.2659,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 431/10000,\n",
      " train_loss: 0.1276,\n",
      " train_mae: 0.2654,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 432/10000,\n",
      " train_loss: 0.1274,\n",
      " train_mae: 0.2649,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 433/10000,\n",
      " train_loss: 0.1273,\n",
      " train_mae: 0.2645,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 434/10000,\n",
      " train_loss: 0.1272,\n",
      " train_mae: 0.2640,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 435/10000,\n",
      " train_loss: 0.1271,\n",
      " train_mae: 0.2635,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 436/10000,\n",
      " train_loss: 0.1270,\n",
      " train_mae: 0.2631,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 437/10000,\n",
      " train_loss: 0.1269,\n",
      " train_mae: 0.2626,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 438/10000,\n",
      " train_loss: 0.1267,\n",
      " train_mae: 0.2621,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 439/10000,\n",
      " train_loss: 0.1266,\n",
      " train_mae: 0.2617,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 440/10000,\n",
      " train_loss: 0.1265,\n",
      " train_mae: 0.2612,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 441/10000,\n",
      " train_loss: 0.1264,\n",
      " train_mae: 0.2608,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 442/10000,\n",
      " train_loss: 0.1263,\n",
      " train_mae: 0.2603,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 443/10000,\n",
      " train_loss: 0.1262,\n",
      " train_mae: 0.2599,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 444/10000,\n",
      " train_loss: 0.1261,\n",
      " train_mae: 0.2595,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 445/10000,\n",
      " train_loss: 0.1260,\n",
      " train_mae: 0.2590,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 446/10000,\n",
      " train_loss: 0.1259,\n",
      " train_mae: 0.2586,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 447/10000,\n",
      " train_loss: 0.1258,\n",
      " train_mae: 0.2581,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 448/10000,\n",
      " train_loss: 0.1257,\n",
      " train_mae: 0.2577,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 449/10000,\n",
      " train_loss: 0.1256,\n",
      " train_mae: 0.2573,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 450/10000,\n",
      " train_loss: 0.1255,\n",
      " train_mae: 0.2569,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 451/10000,\n",
      " train_loss: 0.1254,\n",
      " train_mae: 0.2564,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 452/10000,\n",
      " train_loss: 0.1253,\n",
      " train_mae: 0.2560,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 453/10000,\n",
      " train_loss: 0.1252,\n",
      " train_mae: 0.2556,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 454/10000,\n",
      " train_loss: 0.1251,\n",
      " train_mae: 0.2552,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 455/10000,\n",
      " train_loss: 0.1250,\n",
      " train_mae: 0.2548,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 456/10000,\n",
      " train_loss: 0.1249,\n",
      " train_mae: 0.2544,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 457/10000,\n",
      " train_loss: 0.1249,\n",
      " train_mae: 0.2540,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 458/10000,\n",
      " train_loss: 0.1248,\n",
      " train_mae: 0.2535,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 459/10000,\n",
      " train_loss: 0.1247,\n",
      " train_mae: 0.2531,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 460/10000,\n",
      " train_loss: 0.1246,\n",
      " train_mae: 0.2529,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 461/10000,\n",
      " train_loss: 0.1245,\n",
      " train_mae: 0.2527,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 462/10000,\n",
      " train_loss: 0.1244,\n",
      " train_mae: 0.2525,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 463/10000,\n",
      " train_loss: 0.1244,\n",
      " train_mae: 0.2524,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 464/10000,\n",
      " train_loss: 0.1243,\n",
      " train_mae: 0.2522,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 465/10000,\n",
      " train_loss: 0.1242,\n",
      " train_mae: 0.2520,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 466/10000,\n",
      " train_loss: 0.1241,\n",
      " train_mae: 0.2518,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 467/10000,\n",
      " train_loss: 0.1240,\n",
      " train_mae: 0.2516,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 468/10000,\n",
      " train_loss: 0.1240,\n",
      " train_mae: 0.2514,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 469/10000,\n",
      " train_loss: 0.1239,\n",
      " train_mae: 0.2512,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 470/10000,\n",
      " train_loss: 0.1238,\n",
      " train_mae: 0.2510,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 471/10000,\n",
      " train_loss: 0.1237,\n",
      " train_mae: 0.2508,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 472/10000,\n",
      " train_loss: 0.1237,\n",
      " train_mae: 0.2506,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 473/10000,\n",
      " train_loss: 0.1236,\n",
      " train_mae: 0.2505,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 474/10000,\n",
      " train_loss: 0.1235,\n",
      " train_mae: 0.2503,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 475/10000,\n",
      " train_loss: 0.1235,\n",
      " train_mae: 0.2501,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 476/10000,\n",
      " train_loss: 0.1234,\n",
      " train_mae: 0.2499,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 477/10000,\n",
      " train_loss: 0.1233,\n",
      " train_mae: 0.2497,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 478/10000,\n",
      " train_loss: 0.1233,\n",
      " train_mae: 0.2496,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 479/10000,\n",
      " train_loss: 0.1232,\n",
      " train_mae: 0.2494,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 480/10000,\n",
      " train_loss: 0.1231,\n",
      " train_mae: 0.2492,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 481/10000,\n",
      " train_loss: 0.1231,\n",
      " train_mae: 0.2490,\n",
      " epoch_time_duration: 0.0114\n",
      "\n",
      "epoch: 482/10000,\n",
      " train_loss: 0.1230,\n",
      " train_mae: 0.2489,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 483/10000,\n",
      " train_loss: 0.1230,\n",
      " train_mae: 0.2487,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 484/10000,\n",
      " train_loss: 0.1229,\n",
      " train_mae: 0.2485,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 485/10000,\n",
      " train_loss: 0.1228,\n",
      " train_mae: 0.2483,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 486/10000,\n",
      " train_loss: 0.1228,\n",
      " train_mae: 0.2482,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 487/10000,\n",
      " train_loss: 0.1227,\n",
      " train_mae: 0.2480,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 488/10000,\n",
      " train_loss: 0.1227,\n",
      " train_mae: 0.2478,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 489/10000,\n",
      " train_loss: 0.1226,\n",
      " train_mae: 0.2477,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 490/10000,\n",
      " train_loss: 0.1225,\n",
      " train_mae: 0.2475,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 491/10000,\n",
      " train_loss: 0.1225,\n",
      " train_mae: 0.2473,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 492/10000,\n",
      " train_loss: 0.1224,\n",
      " train_mae: 0.2472,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 493/10000,\n",
      " train_loss: 0.1224,\n",
      " train_mae: 0.2470,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 494/10000,\n",
      " train_loss: 0.1223,\n",
      " train_mae: 0.2469,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 495/10000,\n",
      " train_loss: 0.1223,\n",
      " train_mae: 0.2467,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 496/10000,\n",
      " train_loss: 0.1222,\n",
      " train_mae: 0.2465,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 497/10000,\n",
      " train_loss: 0.1222,\n",
      " train_mae: 0.2464,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 498/10000,\n",
      " train_loss: 0.1221,\n",
      " train_mae: 0.2462,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 499/10000,\n",
      " train_loss: 0.1221,\n",
      " train_mae: 0.2461,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 500/10000,\n",
      " train_loss: 0.1220,\n",
      " train_mae: 0.2459,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 501/10000,\n",
      " train_loss: 0.1220,\n",
      " train_mae: 0.2458,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 502/10000,\n",
      " train_loss: 0.1219,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 503/10000,\n",
      " train_loss: 0.1219,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 504/10000,\n",
      " train_loss: 0.1218,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 505/10000,\n",
      " train_loss: 0.1218,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 506/10000,\n",
      " train_loss: 0.1218,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 507/10000,\n",
      " train_loss: 0.1217,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 508/10000,\n",
      " train_loss: 0.1217,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 509/10000,\n",
      " train_loss: 0.1216,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 510/10000,\n",
      " train_loss: 0.1216,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 511/10000,\n",
      " train_loss: 0.1215,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 512/10000,\n",
      " train_loss: 0.1215,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 513/10000,\n",
      " train_loss: 0.1215,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 514/10000,\n",
      " train_loss: 0.1214,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 515/10000,\n",
      " train_loss: 0.1214,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 516/10000,\n",
      " train_loss: 0.1214,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 517/10000,\n",
      " train_loss: 0.1213,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 518/10000,\n",
      " train_loss: 0.1213,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 519/10000,\n",
      " train_loss: 0.1212,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 520/10000,\n",
      " train_loss: 0.1212,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 521/10000,\n",
      " train_loss: 0.1212,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 522/10000,\n",
      " train_loss: 0.1211,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 523/10000,\n",
      " train_loss: 0.1211,\n",
      " train_mae: 0.2450,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 524/10000,\n",
      " train_loss: 0.1211,\n",
      " train_mae: 0.2450,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 525/10000,\n",
      " train_loss: 0.1210,\n",
      " train_mae: 0.2450,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 526/10000,\n",
      " train_loss: 0.1210,\n",
      " train_mae: 0.2450,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 527/10000,\n",
      " train_loss: 0.1210,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 528/10000,\n",
      " train_loss: 0.1209,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 529/10000,\n",
      " train_loss: 0.1209,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 530/10000,\n",
      " train_loss: 0.1209,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 531/10000,\n",
      " train_loss: 0.1208,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 532/10000,\n",
      " train_loss: 0.1208,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 533/10000,\n",
      " train_loss: 0.1208,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 534/10000,\n",
      " train_loss: 0.1208,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 535/10000,\n",
      " train_loss: 0.1207,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 536/10000,\n",
      " train_loss: 0.1207,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 537/10000,\n",
      " train_loss: 0.1207,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 538/10000,\n",
      " train_loss: 0.1206,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 539/10000,\n",
      " train_loss: 0.1206,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 540/10000,\n",
      " train_loss: 0.1206,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 541/10000,\n",
      " train_loss: 0.1206,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 542/10000,\n",
      " train_loss: 0.1205,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 543/10000,\n",
      " train_loss: 0.1205,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 544/10000,\n",
      " train_loss: 0.1205,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 545/10000,\n",
      " train_loss: 0.1205,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 546/10000,\n",
      " train_loss: 0.1204,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 547/10000,\n",
      " train_loss: 0.1204,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 548/10000,\n",
      " train_loss: 0.1204,\n",
      " train_mae: 0.2451,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 549/10000,\n",
      " train_loss: 0.1204,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 550/10000,\n",
      " train_loss: 0.1203,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 551/10000,\n",
      " train_loss: 0.1203,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 552/10000,\n",
      " train_loss: 0.1203,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 553/10000,\n",
      " train_loss: 0.1203,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 554/10000,\n",
      " train_loss: 0.1203,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 555/10000,\n",
      " train_loss: 0.1202,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 556/10000,\n",
      " train_loss: 0.1202,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 557/10000,\n",
      " train_loss: 0.1202,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 558/10000,\n",
      " train_loss: 0.1202,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 559/10000,\n",
      " train_loss: 0.1202,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 560/10000,\n",
      " train_loss: 0.1201,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 561/10000,\n",
      " train_loss: 0.1201,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 562/10000,\n",
      " train_loss: 0.1201,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 563/10000,\n",
      " train_loss: 0.1201,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 564/10000,\n",
      " train_loss: 0.1201,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 565/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 566/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 567/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 568/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 569/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 570/10000,\n",
      " train_loss: 0.1200,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 571/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 572/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2452,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 573/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 574/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 575/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 576/10000,\n",
      " train_loss: 0.1199,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 577/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 578/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 579/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 580/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 581/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 582/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 583/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 584/10000,\n",
      " train_loss: 0.1198,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 585/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 586/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 587/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 588/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 589/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0051\n",
      "\n",
      "epoch: 590/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0119\n",
      "\n",
      "epoch: 591/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 592/10000,\n",
      " train_loss: 0.1197,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 593/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0061\n",
      "\n",
      "epoch: 594/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0050\n",
      "\n",
      "epoch: 595/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 596/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 597/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 598/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 599/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 600/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 601/10000,\n",
      " train_loss: 0.1196,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 602/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 603/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2453,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 604/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 605/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 606/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 607/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 608/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 609/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 610/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 611/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 612/10000,\n",
      " train_loss: 0.1195,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 613/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 614/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 615/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 616/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 617/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 618/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 619/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 620/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 621/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 622/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 623/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 624/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 625/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 626/10000,\n",
      " train_loss: 0.1194,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 627/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 628/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 629/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 630/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 631/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 632/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 633/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 634/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 635/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 636/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 637/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 638/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 639/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 640/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 641/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 642/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 643/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 644/10000,\n",
      " train_loss: 0.1193,\n",
      " train_mae: 0.2454,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 645/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 646/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 647/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 648/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 649/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 650/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 651/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 652/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 653/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 654/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 655/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 656/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 657/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 658/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 659/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 660/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 661/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 662/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 663/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 664/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 665/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 666/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 667/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 668/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 669/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0072\n",
      "\n",
      "epoch: 670/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0090\n",
      "\n",
      "epoch: 671/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 672/10000,\n",
      " train_loss: 0.1192,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 673/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 674/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 675/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0044\n",
      "\n",
      "epoch: 676/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 677/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 678/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 679/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 680/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 681/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 682/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 683/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 684/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 685/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 686/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 687/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 688/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 689/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 690/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 691/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 692/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 693/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 694/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 695/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 696/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 697/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 698/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 699/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 700/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 701/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 702/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 703/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 704/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 705/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 706/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2455,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 707/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 708/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 709/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 710/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 711/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 712/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 713/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 714/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 715/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 716/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 717/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 718/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0068\n",
      "\n",
      "epoch: 719/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0059\n",
      "\n",
      "epoch: 720/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0069\n",
      "\n",
      "epoch: 721/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 722/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 723/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 724/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 725/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 726/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 727/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 728/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 729/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 730/10000,\n",
      " train_loss: 0.1191,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 731/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 732/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 733/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 734/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 735/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 736/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 737/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 738/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0047\n",
      "\n",
      "epoch: 739/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 740/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 741/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 742/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 743/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 744/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 745/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 746/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 747/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 748/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0098\n",
      "\n",
      "epoch: 749/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 750/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 751/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 752/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 753/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 754/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 755/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 756/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 757/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 758/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 759/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 760/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 761/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 762/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 763/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 764/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 765/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 766/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 767/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 768/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 769/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 770/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 771/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 772/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 773/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 774/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 775/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 776/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 777/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 778/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 779/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 780/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 781/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 782/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 783/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 784/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 785/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 786/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 787/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 788/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 789/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 790/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 791/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 792/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 793/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 794/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 795/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 796/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 797/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 798/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 799/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 800/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 801/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 802/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 803/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 804/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 805/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 806/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 807/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 808/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 809/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 810/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 811/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 812/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 813/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 814/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 815/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 816/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 817/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 818/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 819/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 820/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 821/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 822/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 823/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 824/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 825/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 826/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 827/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0116\n",
      "\n",
      "epoch: 828/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 829/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0052\n",
      "\n",
      "epoch: 830/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 831/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 832/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 833/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 834/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 835/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 836/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 837/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 838/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 839/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 840/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 841/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 842/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 843/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 844/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 845/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 846/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 847/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0043\n",
      "\n",
      "epoch: 848/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 849/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 850/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 851/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 852/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 853/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0040\n",
      "\n",
      "epoch: 854/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 855/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 856/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 857/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 858/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 859/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 860/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 861/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 862/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 863/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 864/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 865/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 866/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 867/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 868/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 869/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 870/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 871/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 872/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 873/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 874/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 875/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 876/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 877/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 878/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 879/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 880/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2456,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 881/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 882/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 883/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 884/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 885/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 886/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 887/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 888/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 889/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 890/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 891/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 892/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 893/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 894/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 895/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 896/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0118\n",
      "\n",
      "epoch: 897/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0058\n",
      "\n",
      "epoch: 898/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0067\n",
      "\n",
      "epoch: 899/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 900/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 901/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 902/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 903/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 904/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 905/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0041\n",
      "\n",
      "epoch: 906/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 907/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 908/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 909/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 910/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 911/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 912/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 913/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 914/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 915/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0038\n",
      "\n",
      "epoch: 916/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 917/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 918/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 919/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 920/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 921/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0064\n",
      "\n",
      "epoch: 922/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0053\n",
      "\n",
      "epoch: 923/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0071\n",
      "\n",
      "epoch: 924/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 925/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0065\n",
      "\n",
      "epoch: 926/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0056\n",
      "\n",
      "epoch: 927/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 928/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0045\n",
      "\n",
      "epoch: 929/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 930/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 931/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 932/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 933/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 934/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 935/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 936/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 937/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 938/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 939/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 940/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 941/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 942/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 943/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 944/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 945/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 946/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 947/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 948/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 949/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 950/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 951/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 952/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 953/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 954/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 955/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 956/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 957/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 958/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 959/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 960/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 961/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0077\n",
      "\n",
      "epoch: 962/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0079\n",
      "\n",
      "epoch: 963/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0054\n",
      "\n",
      "epoch: 964/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0055\n",
      "\n",
      "epoch: 965/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0049\n",
      "\n",
      "epoch: 966/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0048\n",
      "\n",
      "epoch: 967/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0042\n",
      "\n",
      "epoch: 968/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0046\n",
      "\n",
      "epoch: 969/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 970/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0037\n",
      "\n",
      "epoch: 971/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 972/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 973/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 974/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 975/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 976/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 977/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 978/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0036\n",
      "\n",
      "epoch: 979/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 980/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 981/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 982/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 983/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 984/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 985/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0039\n",
      "\n",
      "epoch: 986/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 987/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0033\n",
      "\n",
      "epoch: 988/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 989/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 990/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0031\n",
      "\n",
      "epoch: 991/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0029\n",
      "\n",
      "epoch: 992/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0027\n",
      "\n",
      "epoch: 993/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 994/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0034\n",
      "\n",
      "epoch: 995/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "epoch: 996/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0035\n",
      "\n",
      "epoch: 997/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0030\n",
      "\n",
      "epoch: 998/10000,\n",
      " train_loss: 0.1190,\n",
      " train_mae: 0.2457,\n",
      " epoch_time_duration: 0.0032\n",
      "\n",
      "early stopping activated\n",
      "== end training ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end participant_id/n_participants-1:10/112\n",
      "time taken: 0.0h - 0.0m - 4.592169761657715s\n",
      "sampled_data.input_id: tensor([19])\n",
      "my_module.bias None\n"
     ]
    }
   ],
   "source": [
    "## Graph\n",
    "def prepare_graph_for_participant(data:pd.DataFrame, participant_id:any, sim_used:str) -> Data:\n",
    "    # extraction\n",
    "    subdata = data[data[\"participant\"] == participant_id]\n",
    "\n",
    "    # similarity\n",
    "    if sim_used == \"ones\":\n",
    "        subdata[\"test_sim\"] = np.ones(len(subdata))\n",
    "    elif sim_used == \"random\":\n",
    "        subdata[\"test_sim\"] = np.random.rand(len(subdata))\n",
    "    elif sim_used == \"original\":\n",
    "        subdata[\"test_sim\"] = subdata[\"senenceBERT_mpnet_similarity\"]\n",
    "    else:\n",
    "        raise NotImplementedError(\"Don't know sim_used =\", sim_used)\n",
    "\n",
    "    participant_graph,translator_word_to_index = raw_data_cleaning.convert_table_to_graph(\n",
    "        complete_data_table=subdata,\n",
    "        node_attr_names=[\"liking\",\"experience\"],\n",
    "        node_label_names=[\"liking\"],\n",
    "        edge_attr_names=[\"test_sim\"],\n",
    "        return_word_to_index=True)\n",
    "\n",
    "    # scaling only the liking\n",
    "    node_table = raw_data_cleaning.build_node_table(data,[\"liking\"],distinct_id=[\"participant\"])\n",
    "    scaler_liking = StandardScaler()\n",
    "    scaler_liking.fit(node_table.liking.to_numpy()[...,np.newaxis])\n",
    "    transformed_50 = scaler_liking.transform(np.array([[50]]))\n",
    "\n",
    "    # todo create specific scaler function\n",
    "    new_x_liking = scaler_liking.transform(participant_graph.x[:,:1])\n",
    "    new_x_liking -= np.repeat(transformed_50,repeats=participant_graph.num_nodes,axis=0)\n",
    "    participant_graph.x[:,:1] = torch.Tensor(new_x_liking)\n",
    "\n",
    "    participant_graph.y = scaler_liking.transform(participant_graph.y)\n",
    "    participant_graph.y -= np.repeat(transformed_50,repeats=participant_graph.num_nodes,axis=0)\n",
    "    participant_graph.y = torch.Tensor(participant_graph.y)\n",
    "\n",
    "    return participant_graph, translator_word_to_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run(sim_used:str = \"original\", dst_file_path:str|None = None):\n",
    "    ## Data\n",
    "    #data = data ## TODO\n",
    "\n",
    "    def nor_function(a,b):\n",
    "        return (a or b) and not(a and b)\n",
    "\n",
    "    data[\"NoExp_Exp\"] = data.apply(lambda row: nor_function(row[\"word1_experience\"]>50,row[\"word2_experience\"]>50),axis=1)\n",
    "\n",
    "\n",
    "    results = {\"participant\":[],\n",
    "               \"min_train_loss\":[],\n",
    "               \"min_train_mae\":[],\n",
    "               \"min_train_loss_epoch\":[],\n",
    "               \"min_train_mae_epoch\":[],\n",
    "               \"end_epoch\":[]}\n",
    "\n",
    "    participant_indices = data[\"participant\"].unique()\n",
    "    random.shuffle(participant_indices) #TODO: remove\n",
    "    for participant_id in participant_indices[:1]:\n",
    "        time_start_participant = time.time()\n",
    "        print(f\"start participant_id/n_participants-1:{participant_id:d}/{len(participant_indices-1):d}\")\n",
    "        \n",
    "        ## PREPROCESSING ##\n",
    "        participant_graph, translator_word_to_index = prepare_graph_for_participant(data=data, \n",
    "                                                                                    participant_id=participant_id, \n",
    "                                                                                    sim_used=sim_used)\n",
    "        \n",
    "        # preprocessing 1 - experienced to not experienced\n",
    "        print(\"Preprocessing 1\")\n",
    "        preprocessing_cut = preprocessing.CutGroupSendersToGroupReceivers(\n",
    "            group_senders_mask_fn= lambda x: x[\"experience\"] > 0,\n",
    "            group_receivers_mask_fn= lambda x: x[\"experience\"] <= 0,\n",
    "        )\n",
    "\n",
    "        new_edge_index, new_edge_attr, new_x, new_y = preprocessing_cut.fit_transform(\n",
    "            edge_index=participant_graph.edge_index.data.numpy(),\n",
    "            edge_attr=pd.DataFrame(participant_graph.edge_attr.data.numpy(),columns=[\"test_sim\"]),\n",
    "            x=pd.DataFrame(participant_graph.x.data.numpy(),columns=[\"liking\",\"experience\"]),\n",
    "            y=pd.DataFrame(participant_graph.y.data.numpy(),columns=[\"liking\"])\n",
    "        )\n",
    "\n",
    "        participant_graph.edge_index = torch.Tensor(new_edge_index).to(dtype=torch.int64)\n",
    "        participant_graph.edge_attr = torch.Tensor(new_edge_attr.values) \n",
    "        participant_graph.x = torch.Tensor(new_x.values) \n",
    "        participant_graph.y = torch.Tensor(new_y.values) \n",
    "\n",
    "        # preprocessing 2 - only not experienced predictions in training\n",
    "        print(\"Preprocessing 2\")\n",
    "        node_train_mask = torch.ones(len(participant_graph.x),dtype=torch.bool)\n",
    "        node_train_mask[participant_graph.x[:,1]>0] = False\n",
    "        participant_graph.train_mask = node_train_mask\n",
    "        participant_graph.val_mask = torch.zeros(len(participant_graph.x),dtype=torch.bool)\n",
    "        \n",
    "        # preprocessing 3 - two distinct parameters for liking positive and liking negative\n",
    "        print(\"Preprocessing 3\")\n",
    "        preprocessing_separate_features = preprocessing.SeparatePositiveNegative(verbose=True, feature_separated=\"liking\")\n",
    "        x, _ = preprocessing_separate_features.fit_transform(\n",
    "            x = pd.DataFrame(participant_graph.x.data.numpy(),columns=[\"liking\",\"experience\"])\n",
    "        )\n",
    "        participant_graph.x = torch.Tensor(x[[\"liking_pos\",\"liking_neg\"]].values)\n",
    "\n",
    "        # preprocessing 4 - neighbor loader for convergence to global minimum\n",
    "        loader = NeighborLoader(\n",
    "            participant_graph.contiguous(),\n",
    "            num_neighbors=[60],\n",
    "            batch_size=1,\n",
    "            input_nodes=participant_graph.train_mask,\n",
    "        )\n",
    "        loader = DataLoader(list(loader), shuffle=True)\n",
    "        sampled_data = next(iter(loader))\n",
    "\n",
    "        ## MODEL ##\n",
    "        print(\"Model\")\n",
    "        src_content_mask = torch.Tensor([True,True]).to(torch.bool)\n",
    "        src_edge_mask = torch.Tensor([False,False]).to(torch.bool)\n",
    "        dst_mask = torch.Tensor([False,False]).to(torch.bool)\n",
    "        my_module = MyGATConv(\n",
    "            in_channels=(2,2),\n",
    "            out_channels=1,\n",
    "            heads=1,\n",
    "            negative_slope=0.0,\n",
    "            add_self_loops=False,\n",
    "            edge_dim=1,\n",
    "            dropout=0.0,\n",
    "            bias=False,\n",
    "            src_content_mask=src_content_mask,\n",
    "            src_edge_mask=src_edge_mask,\n",
    "            dst_content_mask=dst_mask,\n",
    "            dst_edge_mask=dst_mask)\n",
    "        print(\"my_module.bias\",my_module.bias)\n",
    "        \n",
    "        \n",
    "        ## Training\n",
    "        complete_model = GNNFramework(my_module,device)\n",
    "        complete_model.predict(participant_graph.x,\n",
    "                               participant_graph.edge_index,\n",
    "                               participant_graph.edge_attr)\n",
    "\n",
    "        opt = complete_model.configure_optimizer(lr=1)\n",
    "        scheduler = complete_model.configure_scheduler(opt,0.1,0.1,10)\n",
    "\n",
    "        complete_model.predict(participant_graph.x,participant_graph.edge_index,participant_graph.edge_attr)\n",
    "        description_parameters_init = complete_model.update_node_module.get_description_parameters().copy()\n",
    "        \n",
    "        history = complete_model.train([participant_graph],\n",
    "                                       10000,\n",
    "                                       1,\n",
    "                                       opt,\n",
    "                                       scheduler,\n",
    "                                       val_dataset=None,\n",
    "                                       early_stopping_monitor=\"train_loss\",\n",
    "                                       patience=200)\n",
    "\n",
    "        plt.plot(history[\"train_mae\"])\n",
    "        plt.show()\n",
    "        complete_model.predict(participant_graph.x,participant_graph.edge_index,participant_graph.edge_attr)\n",
    "        description_parameters_trained = complete_model.update_node_module.get_description_parameters().copy()\n",
    "        \n",
    "        ## Save\n",
    "        results[\"participant\"].append(participant_id)\n",
    "        results[\"min_train_loss\"].append(np.min(history[\"train_loss\"]))\n",
    "        results[\"min_train_mae\"].append(np.min(history[\"train_mae\"]))\n",
    "        results[\"min_train_loss_epoch\"].append(np.argmin(history[\"train_loss\"]))\n",
    "        results[\"min_train_mae_epoch\"].append(np.argmin(history[\"train_mae\"]))\n",
    "        results[\"end_epoch\"].append(len(history[\"train_mae\"]))\n",
    "\n",
    "        for param_name in description_parameters_init.columns:\n",
    "            if \"init_\"+param_name in results:\n",
    "                results[\"init_\"+param_name].append(description_parameters_init[param_name][0])\n",
    "                results[\"trained_\"+param_name].append(description_parameters_trained[param_name][0])\n",
    "            else:\n",
    "                results[\"init_\"+param_name] = [description_parameters_init[param_name][0]]\n",
    "                results[\"trained_\"+param_name] = [description_parameters_trained[param_name][0]]\n",
    "\n",
    "        pd.DataFrame(results).to_csv(dst_file_path,index=False)\n",
    "            \n",
    "        print(f\"end participant_id/n_participants-1:{participant_id:d}/{len(participant_indices-1):d}\")\n",
    "        time_take_participant = (time.time()-time_start_participant)\n",
    "        print(\"time taken: {}h - {}m - {}s\".format(time_take_participant//(3600),((time_take_participant%3600)//60),((time_take_participant%3600)%60)))\n",
    "\n",
    "    print(\"sampled_data.input_id:\",sampled_data.input_id)\n",
    "    print(\"my_module.bias\",my_module.bias)\n",
    "    return results, participant_graph, complete_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results, graph, complete_model = run(sim_used=\"original\",dst_file_path=\"src/experiments/results/04-29_model_pipeline_content-liking_edge-sim_epochs-10000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0371, -0.4846]], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[param for param in complete_model.update_node_module.lin_dst_content.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'participant': [36],\n",
       " 'min_train_loss': [0.0020550874],\n",
       " 'min_train_mae': [0.031193282],\n",
       " 'min_train_loss_epoch': [454],\n",
       " 'min_train_mae_epoch': [454],\n",
       " 'end_epoch': [463],\n",
       " 'init_src_content_0': [-0.7493739724159241],\n",
       " 'trained_src_content_0': [-5.996600151062012],\n",
       " 'init_src_content_1': [0.40897414088249207],\n",
       " 'trained_src_content_1': [-4.18192720413208],\n",
       " 'init_att_src_edge_0': [1.0],\n",
       " 'trained_att_src_edge_0': [1.0],\n",
       " 'init_src_edge_0': [-0.17355701327323914],\n",
       " 'trained_src_edge_0': [-4.338362216949463],\n",
       " 'init_src_edge_1': [0.3059164881706238],\n",
       " 'trained_src_edge_1': [-0.5895199179649353],\n",
       " 'init_full_src_edge_0': [-0.17355701327323914],\n",
       " 'trained_full_src_edge_0': [-4.338362216949463],\n",
       " 'init_full_src_edge_1': [0.3059164881706238],\n",
       " 'trained_full_src_edge_1': [-0.5895199179649353],\n",
       " 'init_dst_content_0': [-0.037134911864995956],\n",
       " 'trained_dst_content_0': [-0.037134911864995956],\n",
       " 'init_dst_content_1': [-0.48461204767227173],\n",
       " 'trained_dst_content_1': [-0.48461204767227173],\n",
       " 'init_att_dst_edge_0': [1.0],\n",
       " 'trained_att_dst_edge_0': [1.0],\n",
       " 'init_dst_edge_0': [0.9285741448402405],\n",
       " 'trained_dst_edge_0': [0.527809202671051],\n",
       " 'init_dst_edge_1': [0.7875201106071472],\n",
       " 'trained_dst_edge_1': [0.384199321269989],\n",
       " 'init_full_dst_edge_0': [0.9285741448402405],\n",
       " 'trained_full_dst_edge_0': [0.527809202671051],\n",
       " 'init_full_dst_edge_1': [0.7875201106071472],\n",
       " 'trained_full_dst_edge_1': [0.384199321269989],\n",
       " 'init_att_edge_0': [1.0],\n",
       " 'trained_att_edge_0': [1.0],\n",
       " 'init_edge_0': [0.22345490753650665],\n",
       " 'trained_edge_0': [-0.34514424204826355],\n",
       " 'init_full_edge_0': [0.22345490753650665],\n",
       " 'trained_full_edge_0': [-0.34514424204826355],\n",
       " 'init_bias_0': [0.0],\n",
       " 'trained_bias_0': [-0.8822376728057861]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.1798],\n",
       "        [ 0.8773,  0.0000],\n",
       "        [ 0.0000, -0.4235],\n",
       "        [ 0.8470,  0.0000],\n",
       "        [ 0.0000, -0.2723],\n",
       "        [ 0.0000, -1.1193],\n",
       "        [ 0.0000, -0.0303],\n",
       "        [ 0.9378,  0.0000],\n",
       "        [ 0.0303,  0.0000],\n",
       "        [ 0.0000, -0.1513],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 1.3613,  0.0000],\n",
       "        [ 0.6353,  0.0000],\n",
       "        [ 0.0000, -0.8470],\n",
       "        [ 0.0000, -1.2705],\n",
       "        [ 0.5445,  0.0000],\n",
       "        [ 0.0303,  0.0000],\n",
       "        [ 0.0000, -0.7563],\n",
       "        [ 0.9983,  0.0000],\n",
       "        [ 0.0000, -0.5445],\n",
       "        [ 0.0000, -0.2723],\n",
       "        [ 0.0000, -0.3328],\n",
       "        [ 0.0000, -1.3915],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.9378,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.0000, -0.6050],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -0.3630],\n",
       "        [ 0.0000, -0.3630],\n",
       "        [ 0.5143,  0.0000],\n",
       "        [ 0.0000, -1.1495],\n",
       "        [ 0.8773,  0.0000],\n",
       "        [ 0.0000, -0.9680],\n",
       "        [ 0.8168,  0.0000],\n",
       "        [ 0.0303,  0.0000],\n",
       "        [ 1.1798,  0.0000],\n",
       "        [ 0.0000, -0.7563],\n",
       "        [ 0.0000, -0.3328],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -0.3328],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -1.2100],\n",
       "        [ 0.1513,  0.0000],\n",
       "        [ 0.0000,  0.0000],\n",
       "        [ 0.8168,  0.0000],\n",
       "        [ 0.0000, -0.3630],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -0.0303],\n",
       "        [ 0.0000, -0.4840],\n",
       "        [ 0.0000, -1.5125],\n",
       "        [ 0.0000, -0.7865],\n",
       "        [ 0.0605,  0.0000],\n",
       "        [ 0.0303,  0.0000],\n",
       "        [ 0.0000, -0.2420],\n",
       "        [ 0.0000, -0.1513],\n",
       "        [ 0.3630,  0.0000],\n",
       "        [ 0.9075,  0.0000],\n",
       "        [ 1.1798,  0.0000]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = NeighborLoader(\n",
    "    graph.contiguous(),\n",
    "    # Sample 30 neighbors for each node for 2 iterations\n",
    "    num_neighbors=[60],\n",
    "    # Use a batch size of 128 for sampling training nodes\n",
    "    batch_size=10,\n",
    "    input_nodes=graph.train_mask,\n",
    ")\n",
    "\n",
    "loader = DataLoader(list(loader), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "sampled_data = next(iter(loader))\n",
    "print(sampled_data.batch_size)\n",
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(41)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[60, 2], edge_index=[2, 488], edge_attr=[488, 1], y=[60, 1], x_names=[1], edge_attr_names=[1], y_names=[1], train_mask=[60], val_mask=[60], n_id=[60], e_id=[488], num_sampled_nodes=[1], num_sampled_edges=[1], input_id=[10], batch_size=[1], batch=[60], ptr=[2])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  4,  5,  8, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data.input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_sparse import coalesce\n",
    "\n",
    "index = torch.tensor([[1, 0, 1, 0, 2, 1],\n",
    "                      [0, 1, 1, 1, 0, 0]])\n",
    "value = torch.Tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
    "\n",
    "index, value = coalesce(index, value, m=3, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Linear.__init__() got an unexpected keyword argument 'weight_initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mweight_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglorot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Linear.__init__() got an unexpected keyword argument 'weight_initializer'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "\n",
    "\n",
    "\n",
    "torch.nn.Linear(1, 1 * 1, bias=False,weight_initializer=\"glorot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_semantic_to_liking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
