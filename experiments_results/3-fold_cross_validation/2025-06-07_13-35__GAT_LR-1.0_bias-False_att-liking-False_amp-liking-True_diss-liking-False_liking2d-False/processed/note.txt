This model is the minimal model: no intercept/bias, only the parameter for similarity. Removing that similarity parameter would make it equivalent to baseline_mean. Compare the two.

Compared to previous models, the weigths are not clipped, ie are free to vary as they wish (although a lasso regularization is applied). Also, the LeakyReLu is removed ($\lambda = 0$).

Time to train: 1 h 56 min

*Model mathematical formula:*


$$L'_i = \beta_0 + \displaystyle\sum_{j\in \mathcal{N}(i)} \alpha_{j,i} \beta_L L_j$$

$$\alpha_{j,i} = \frac{\mbox{exp}\left(\mbox{LeakyReLu}_{\lambda}(a_LL_j + a_ss_{j,i})\right)}{\displaystyle\sum_{k\in\mathcal{N}(i)}\mbox{exp}\left(\mbox{LeakyReLu}_{\lambda}(a_L L_k + a_s s_{k,i})
\right)}$$

with 

- $L_i$ the liking of activity $i$, $L_i'$ the predicted liking of i.

- $s_{i,j}$ the semantic (cosine) similarity from MPNet from activity $i$ to $j$,

- $\mathcal{N}(i)$ the neighbors of $i$,

- $\beta_0$ the bias or intercept

- $\beta_L$ the weight amplifying the liking

- $a_L$ the attentional parameter to the liking 

- $a_s$ the attentional parameter to the similarity

- $\lambda$ the negative slope of the LeakyReLu

- $\alpha_{j,i}$ the final weight for considering $j$ to compute the liking of $i$

Careful: these names currently don't match the ones used in the model itself. See documentation for that. 
        


*Hypotheses:*

- LeakyReLu can be cancelled when $\lambda = 1.0$. If better with $\lambda = 1.0$ than $\lambda = 0.0$, then the only way for the model to have equivalent attention to all neighboring activities is to put attentional parameters ($a_L$ and $a_s$) to 0.0. This parameter is meant to compare with previous results... I expect the model to be better when $\lambda = 1.0$, which allows more expressivity coming from the attentional parameters.

- Having a bias/intercept means the participant is giving a liking by default to activities. It is expected to be significantly different from 0.0 in depressed participants and negative, not necessarily for the ones in the control group.

- $a_L$ is expected to play a role... It means that the participant focuses more on some activities than others. For depressed participants, $a_L$ is expected negative, meaning that they focus on negative activities to generalize. For the control group, it is expected to be null.

- $\beta_L$ expresses the amplification applied to an activity once it is focused upon. It is expected to be positive and close to 1. It is expected to be close to 0.0 when the participant is not considering the experienced activities at all, which could be the case in depressed participants.

- Any liking activity could be separated in positive and negative and permit a different set of parameters for each ($\beta_{L^+}$ vs $\beta_{L^-}$, $a_{L^+}$ vs $a_{L^-}$). It is expected that (when applicable) $\beta_{L^+} \neq \beta_{L^-}$ and $a_{L^+} \neq a_{L^-}$ in depressed individuals only.

- The liking could be raised to the power 2. This complexify the model and should allow a better fit. It is meant to raise the possibility of more nonlinearities.

*To answer those hypotheses:*

- A factorial design should have been carried out. Compare models one on one with everything constant except the parameter of interest.

- For comparison, you may consider the performance and the relation of their trained parameters to depression. Later on, pivotal testing (not done yet) or the bayesian approach (not done yet) should more rigorously (not unvalidate or) refute the hypotheses

- Validation is better than training to see how the model perform on previously unseen data (which is the case when using the model on real patients)

For this model, $\beta_0$ learnt = 0; $\beta_L$ learnt = 1; $a_L$ learnt = 0; $\lambda = 1.0$