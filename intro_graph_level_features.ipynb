{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecdb135a",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eac8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7329ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien-rsbrg/venv/venv_semantic_to_liking/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.data_handler as data_handler\n",
    "from src.processing.raw_data_cleaning import prepare_graph_for_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b839052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Load Data: start ==\n",
      "== Load Data: end ==\n"
     ]
    }
   ],
   "source": [
    "data = data_handler.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1f75098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test function convert_table_to_graph\n",
      "Data(x=[60, 2], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], x_names=[2], edge_attr_names=[1], y_names=[1], train_mask=[60], val_mask=[60])\n",
      "validate: True\n",
      "is undirected: True\n",
      "has_self_loop: tensor(False)\n",
      "end Test function convert_table_to_graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdata[\"_sim\"] = subdata[\"senenceBERT_mpnet_similarity\"]\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word1_index\"] = complete_data_table[\"word1\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word2_index\"] = complete_data_table[\"word2\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[60, 2], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], x_names=[2], edge_attr_names=[1], y_names=[1], train_mask=[60], val_mask=[60])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_graph, _ = prepare_graph_for_participant(data=data, \n",
    "                                                     participant_id=1, \n",
    "                                                     sim_used=\"original\")\n",
    "participant_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c6ea118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['liking', 'experience'], ['_sim'], 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "participant_graph.x_names,participant_graph.edge_attr_names,participant_graph.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86640c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with random clusters (later take cs = x[:,1] > 0)\n",
    "cs = np.random.randint(0,2,size=participant_graph.num_nodes)\n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad7b05",
   "metadata": {},
   "source": [
    "assumes only 2 clusters, if there are others, they are omitted\n",
    "can use torch_geometric.datasets.InfectionDataset for validation\n",
    "\n",
    "params:\n",
    "cluster_id_start\n",
    "cluster_id_end\n",
    "\n",
    "% what if inf? no path between the two... \n",
    "\n",
    "ALGO 1\n",
    "\n",
    "distance_to_other_cluster_nodes = np.zeros((len(x),len(x))) \n",
    "weighted_distance_to_other_cluster_nodes = np.zeros((len(x),len(x)))\n",
    "\n",
    "for node_i in cluster_id_start:\n",
    "    for node_j in cluster_id_end:\n",
    "        shortest_path_ij = shortest_path(node_i,node_j,graph) # get the nodes ids [], get the weights []\n",
    "        is_cluster_end = shortest_path_ij[0] == cluster_id_end # if there is another cluster on the way before, it is omitted\n",
    "        distance_to_cluster_end = np.where(is_cluster_end)[0][0]\n",
    "        weighted_distance_to_cluster_end = sum(shortest_path_ij[:distance_to_cluster_end]\n",
    "\n",
    "        distance_to_other_cluster_nodes[node_i, node_j] = distance_to_cluster_end\n",
    "        weighted_distance_to_other_cluster_nodes[node_i, node_j] = weighted_distance_to_cluster_end\n",
    "\n",
    "distance_to_other_cluster = np.min(distance_to_other_cluster_nodes,axis=1)\n",
    "weighted_distance_to_other_cluster = np.min(weighted_distance_to_other_cluster_nodes,axis=1)\n",
    "\n",
    "mean_distance_to_other_cluster = np.mean(distance_to_other_cluster)\n",
    "mean_weighted_distance_to_other_cluster = np.mean(weighted_distance_to_other_cluster)\n",
    "\n",
    "\n",
    "ALGO 2\n",
    "\n",
    "Take random walks of length, length of the graph (or bounded in param)... and compute the average \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67fb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from typing import Iterable\n",
    "\n",
    "def shortest_path_djikstra(node_start:int,edge_index:np.array,edge_weight:Iterable,num_nodes:int|None = None):\n",
    "    assert node_start <= np.max(np.max(edge_index),num_nodes), f\"There is no edge connected to node_start or the number of nodes ({num_nodes}) given is wrong...\"\n",
    "    \n",
    "    _num_nodes = num_nodes\n",
    "    if num_nodes is None:\n",
    "        _num_nodes = np.max(edge_index)+1\n",
    "        \n",
    "    distance_from_start = np.inf * np.ones(_num_nodes)\n",
    "    distance_from_start[node_start] = 0\n",
    "\n",
    "    shortest_path_from_start = {node_id:{\"edge_index\":[],\"edge_weight\":[]} for node_id in range(_num_nodes)}\n",
    "\n",
    "    segments_to_check = [(0,node_start)]\n",
    "    while len(segments_to_check):\n",
    "        selected_segment = segments_to_check.pop(-1)\n",
    "        sending_edges_mask = edge_index[0,:] == selected_segment[1]\n",
    "\n",
    "        receiving_neighbor_nodes = edge_index[1,sending_edges_mask] \n",
    "        neighbor_distances = edge_weight[sending_edges_mask]\n",
    "\n",
    "        for edge_local_id,node_id in enumerate(receiving_neighbor_nodes):\n",
    "            current_path_distance = selected_segment[0] + neighbor_distances[edge_local_id]\n",
    "            if distance_from_start[node_id] > current_path_distance:\n",
    "                distance_from_start[node_id] =  current_path_distance\n",
    "                segments_to_check.append((distance_from_start[node_id],node_id))\n",
    "                shortest_path_from_start[node_id][\"edge_index\"] = shortest_path_from_start[selected_segment[1]][\"edge_index\"] + [[selected_segment[1],node_id]] \n",
    "                shortest_path_from_start[node_id][\"edge_weight\"] = shortest_path_from_start[selected_segment[1]][\"edge_weight\"] + [neighbor_distances[edge_local_id]] \n",
    "    return distance_from_start, shortest_path_from_start\n",
    "\n",
    "edge_index = np.array([[0,0,0,0,1,2,2,3,4],\n",
    "                       [1,2,3,4,6,3,5,5,6]])\n",
    "edge_weight = np.array([2,2,4,1,2,1,5,1,2])\n",
    "true_values = np.array([0,2,2,3,1,4,3])\n",
    "\n",
    "assert np.allclose(true_values,shortest_path_djikstra(0,edge_index,edge_weight)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc5f315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 2., 2., 3., 1., 4., 3.]),\n",
       " {0: {'edge_index': [], 'edge_weight': []},\n",
       "  1: {'edge_index': [[0, 1]], 'edge_weight': [2]},\n",
       "  2: {'edge_index': [[0, 2]], 'edge_weight': [2]},\n",
       "  3: {'edge_index': [[0, 2], [2, 3]], 'edge_weight': [2, 1]},\n",
       "  4: {'edge_index': [[0, 4]], 'edge_weight': [1]},\n",
       "  5: {'edge_index': [[0, 2], [2, 3], [3, 5]], 'edge_weight': [2, 1, 1]},\n",
       "  6: {'edge_index': [[0, 4], [4, 6]], 'edge_weight': [1, 2]}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortest_path_djikstra(0,edge_index,edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d407c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.0, {1: {'edge_index': [[0, 1]], 'edge_weight': [2]}})\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "\n",
    "def shortest_path_to_cluster_djikstra(node_start:int,edge_index:np.array,edge_weight:Iterable,cluster:Iterable[bool],num_nodes:int|None = None,exclude_itself:bool=True):\n",
    "    \"\"\"\n",
    "    shortest path from node_start to a node belonging to cluster (set to True).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    - exclude_itself: (bool)\n",
    "        If True and node_start in cluster, removes node_start from the cluster identification and computes the distance to the nodes of the same cluster\n",
    "    \"\"\"\n",
    "    _cluster = copy.copy(cluster)\n",
    "    if exclude_itself:\n",
    "        _cluster[node_start] = False\n",
    "\n",
    "    node_ids_cluster = np.where(_cluster)[0]\n",
    "    \n",
    "    if node_start in node_ids_cluster:\n",
    "        return 0, {node_start: {'edge_index': [], 'edge_weight': []}}\n",
    "    else:\n",
    "        distances_from_start, shortest_path_from_start = shortest_path_djikstra(node_start,edge_index,edge_weight,num_nodes=num_nodes)\n",
    "        closest_node_id_cluster = node_ids_cluster[np.argmin(distances_from_start[node_ids_cluster])]\n",
    "\n",
    "        shortest_path_to_cluster = {closest_node_id_cluster: shortest_path_from_start[closest_node_id_cluster]}\n",
    "        return distances_from_start[closest_node_id_cluster],shortest_path_to_cluster\n",
    "\n",
    "def mean_shortest_distance_to_cluster_djikstra(node_start:int,edge_index:np.array,edge_weight:Iterable,cluster:Iterable[bool],num_nodes:int|None = None,exclude_itself:bool=True):\n",
    "    \"\"\"\n",
    "    mean shortest distance from node_start to a node belonging to cluster (set to True).\n",
    "    \"\"\"\n",
    "    _cluster = copy.copy(cluster)\n",
    "    if exclude_itself:\n",
    "        _cluster[node_start] = False\n",
    "\n",
    "    node_ids_cluster = np.where(_cluster)[0]\n",
    "    distances_from_start, _ = shortest_path_djikstra(node_start,edge_index,edge_weight,num_nodes=num_nodes)\n",
    "    return np.mean(distances_from_start[node_ids_cluster])\n",
    "\n",
    "print(shortest_path_to_cluster_djikstra(0,edge_index,edge_weight,cluster = [True,True,False,True,False,True,True],exclude_itself=True))\n",
    "print(mean_shortest_distance_to_cluster_djikstra(0,edge_index,edge_weight,cluster = [False,True,False,True,False,True,True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant / n_participant: 1 / 112\n",
      "Test function convert_table_to_graph\n",
      "Data(x=[60, 2], edge_index=[2, 3540], edge_attr=[3540, 1], y=[60, 1], x_names=[2], edge_attr_names=[1], y_names=[1], train_mask=[60], val_mask=[60])\n",
      "validate: True\n",
      "is undirected: True\n",
      "has_self_loop: tensor(False)\n",
      "end Test function convert_table_to_graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdata[\"_sim\"] = subdata[\"senenceBERT_mpnet_similarity\"]\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word1_index\"] = complete_data_table[\"word1\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  complete_data_table[\"word2_index\"] = complete_data_table[\"word2\"].apply(lambda single_word: translater_word_to_index[single_word])\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word1.rename(columns=col_renaming,inplace=True)\n",
      "/home/julien-rsbrg/Documents/UCL/SemanticToLiking/src/processing/raw_data_cleaning.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_features_word2.rename(columns=col_renaming,inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m node_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_to_exp\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_to_not_exp\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_to_exp\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_to_not_exp\u001b[39m\u001b[38;5;124m\"\u001b[39m:[],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperienced\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(participant_graph\u001b[38;5;241m.\u001b[39mnum_nodes):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Careful: suboptimal, compute twice the shortest distance\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     min_to_exp \u001b[38;5;241m=\u001b[39m \u001b[43mshortest_path_to_cluster_djikstra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcluster_has_been_experienced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     mean_to_exp \u001b[38;5;241m=\u001b[39m mean_shortest_distance_to_cluster_djikstra(node_id,edge_index,edge_weight,cluster_has_been_experienced)\n\u001b[1;32m     19\u001b[0m     min_to_not_exp \u001b[38;5;241m=\u001b[39m shortest_path_to_cluster_djikstra(node_id,edge_index,edge_weight,\u001b[38;5;241m~\u001b[39mcluster_has_been_experienced)\n",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m, in \u001b[0;36mshortest_path_to_cluster_djikstra\u001b[0;34m(node_start, edge_index, edge_weight, cluster, num_nodes, exclude_itself)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m, {node_start: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: []}}\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     distances_from_start, shortest_path_from_start \u001b[38;5;241m=\u001b[39m \u001b[43mshortest_path_djikstra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     closest_node_id_cluster \u001b[38;5;241m=\u001b[39m node_ids_cluster[np\u001b[38;5;241m.\u001b[39margmin(distances_from_start[node_ids_cluster])]\n\u001b[1;32m     24\u001b[0m     shortest_path_to_cluster \u001b[38;5;241m=\u001b[39m {closest_node_id_cluster: shortest_path_from_start[closest_node_id_cluster]}\n",
      "Cell \u001b[0;32mIn[7], line -1\u001b[0m, in \u001b[0;36mshortest_path_djikstra\u001b[0;34m(node_start, edge_index, edge_weight, num_nodes)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "participant_ids = data[\"participant\"].unique()\n",
    "n_participants = len(participant_ids)\n",
    "for i in participant_ids:\n",
    "    print(f\"participant / n_participant: {i} / {n_participants}\")\n",
    "    participant_graph, _ = prepare_graph_for_participant(data=data, \n",
    "                                                        participant_id=1, \n",
    "                                                        sim_used=\"original\")\n",
    "    x = pd.DataFrame(participant_graph.x,columns=participant_graph.x_names)\n",
    "    cluster_has_been_experienced = (x[\"experience\"] > 0).values\n",
    "    edge_index = participant_graph.edge_index.numpy() # check to remove\n",
    "    edge_weight = participant_graph.edge_attr.numpy() # check to remove\n",
    "\n",
    "    node_data = {\"min_to_exp\":[],\"min_to_not_exp\":[],\"mean_to_exp\":[],\"mean_to_not_exp\":[],\"experienced\":[]}\n",
    "    for node_id in range(participant_graph.num_nodes):\n",
    "        print(f\"node_id + 1 / num_nodes : {node_id} / {participant_graph.num_nodes} \")\n",
    "        # Careful: suboptimal, compute twice the shortest distance\n",
    "        min_to_exp = shortest_path_to_cluster_djikstra(node_id,edge_index,edge_weight,cluster_has_been_experienced)\n",
    "        mean_to_exp = mean_shortest_distance_to_cluster_djikstra(node_id,edge_index,edge_weight,cluster_has_been_experienced)\n",
    "\n",
    "        min_to_not_exp = shortest_path_to_cluster_djikstra(node_id,edge_index,edge_weight,~cluster_has_been_experienced)\n",
    "        mean_to_not_exp = mean_shortest_distance_to_cluster_djikstra(node_id,edge_index,edge_weight,~cluster_has_been_experienced)\n",
    "\n",
    "        node_data[\"min_to_exp\"].append(min_to_exp)\n",
    "        node_data[\"mean_to_exp\"].append(mean_to_exp)\n",
    "        node_data[\"min_to_not_exp\"].append(min_to_not_exp)\n",
    "        node_data[\"mean_to_not_exp\"].append(mean_to_not_exp)\n",
    "        node_data[\"experienced\"].append(cluster_has_been_experienced[node_id])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_semantic_to_liking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
